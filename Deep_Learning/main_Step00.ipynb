{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7220b52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init] root: experiments/Step_00\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 0. 공용 설정\n",
    "# =========================\n",
    "import os, json, time, random, hashlib, pickle, subprocess, gc\n",
    "import numpy as np\n",
    "\n",
    "EXPERIMENT_ROOT = \"experiments/Step_00\"\n",
    "DATASET_DIR = \"dataset/preprocessed\"\n",
    "os.makedirs(EXPERIMENT_ROOT, exist_ok=True)\n",
    "\n",
    "NAS_LOG_DIR = os.path.join(EXPERIMENT_ROOT, \"nas_runs\")\n",
    "os.makedirs(NAS_LOG_DIR, exist_ok=True)\n",
    "NAS_LOG_CSV = os.path.join(NAS_LOG_DIR, \"results.csv\")\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "N_CLASSES = 15\n",
    "\n",
    "print(\"[Init] root:\", EXPERIMENT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88ae5640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] splits.pkl 생성 완료 (train/val/label_map)\n",
      "[Split] Train=4860 | Val=540 | classes=15\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 1. 데이터 split 준비 (label_map 백워드 호환)\n",
    "# =========================\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "label_csv_path = os.path.join(DATASET_DIR, \"labels.csv\")\n",
    "split_file_path = os.path.join(EXPERIMENT_ROOT, \"splits.pkl\")\n",
    "\n",
    "df = pd.read_csv(label_csv_path)\n",
    "df['base_id'] = df['file'].apply(lambda x: x.rsplit('_', 1)[0])\n",
    "base_df = df.drop_duplicates('base_id').copy()\n",
    "\n",
    "# 안전한 할당 (SettingWithCopyWarning 회피)\n",
    "base_df.loc[:, 'subject'] = base_df['base_id'].apply(lambda x: x.split('_')[-1])\n",
    "base_df.loc[:, 'label_subject'] = base_df['label'].astype(str) + \"_\" + base_df['subject']\n",
    "\n",
    "label_subject_map = dict(zip(base_df['base_id'], base_df['label_subject']))\n",
    "label_map = dict(zip(base_df['base_id'], base_df['label']))\n",
    "\n",
    "if not os.path.exists(split_file_path):\n",
    "    base_ids = base_df['base_id'].tolist()\n",
    "    stratify_ls = [label_subject_map[bid] for bid in base_ids]\n",
    "    train_base, val_base = train_test_split(base_ids, test_size=0.1,\n",
    "                                            stratify=stratify_ls, random_state=18)\n",
    "    with open(split_file_path, 'wb') as f:\n",
    "        pickle.dump({'train': train_base, 'val': val_base, 'label_map': label_map}, f)\n",
    "    print(\"[Info] splits.pkl 생성 완료 (train/val/label_map)\")\n",
    "else:\n",
    "    with open(split_file_path, 'rb') as f:\n",
    "        split = pickle.load(f)\n",
    "    train_base = split.get('train')\n",
    "    val_base   = split.get('val')\n",
    "    if 'label_map' in split and isinstance(split['label_map'], dict):\n",
    "        label_map = split['label_map']\n",
    "    else:\n",
    "        # 예전 파일과의 호환: 새로 계산한 label_map 사용\n",
    "        label_map = dict(zip(base_df['base_id'], base_df['label']))\n",
    "        # 필요하면 파일 갱신\n",
    "        with open(split_file_path, 'wb') as f:\n",
    "            pickle.dump({'train': train_base, 'val': val_base, 'label_map': label_map}, f)\n",
    "        print(\"[Warn] 기존 splits.pkl에 label_map이 없어 갱신했습니다.\")\n",
    "\n",
    "print(f\"[Split] Train={len(train_base)} | Val={len(val_base)} | classes={len(set(label_map.values()))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51c49a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Cell 2. 탐색공간/유전 연산/제약\n",
    "# =========================\n",
    "SPACE_OUT = {\n",
    "    1: [16, 24, 32],\n",
    "    2: [40, 48, 56],\n",
    "    3: [64, 72, 80],\n",
    "    4: [88, 96, 104],\n",
    "}\n",
    "SPACE_REPEATS = [2, 2, 2, 2, 4, 4, 4, 6, 6]\n",
    "SPACE_STRIDE  = [1, 1, 1, 2, 2]\n",
    "SPACE_T = [2, 2, 2, 2, 4, 4, 4, 6, 6]\n",
    "SPACE_BLOCK   = ['mbconv', 'fused']\n",
    "SPACE_SE      = [True, False]\n",
    "CONV1x1_OUT   = [112, 120, 128]\n",
    "\n",
    "def sample_stage(si):\n",
    "    return {\n",
    "        \"block_type\": random.choice(SPACE_BLOCK),\n",
    "        \"out_channels\": random.choice(SPACE_OUT[si]),\n",
    "        \"stride\": random.choice(SPACE_STRIDE),\n",
    "        \"expand_ratio\": random.choice(SPACE_T),\n",
    "        \"use_se\": random.choice(SPACE_SE),\n",
    "        \"repeats\": random.choice(SPACE_REPEATS),\n",
    "    }\n",
    "\n",
    "def sample_stream():\n",
    "    return {\n",
    "        \"stage1\": sample_stage(1),\n",
    "        \"stage2\": sample_stage(2),\n",
    "        \"stage3\": sample_stage(3),\n",
    "        \"stage4\": sample_stage(4),\n",
    "        \"conv1x1_out\": random.choice(CONV1x1_OUT),\n",
    "    }\n",
    "\n",
    "def sample_config():\n",
    "    stream = sample_stream()\n",
    "    return {\"rtm\": stream, \"dtm\": json.loads(json.dumps(stream))}\n",
    "\n",
    "def enforce_stride_per_stream(cfg, min_s2=1):\n",
    "    \"\"\"각 스트림 최소 한 stage는 stride=2가 되도록 보정\"\"\"\n",
    "    for stream in [\"rtm\", \"dtm\"]:\n",
    "        if not any(cfg[stream][f\"stage{i}\"][\"stride\"] == 2 for i in range(1,5)):\n",
    "            pick = random.choice([1,2,3,4])\n",
    "            cfg[stream][f\"stage{pick}\"][\"stride\"] = 2\n",
    "    return cfg\n",
    "\n",
    "def cfg_hash(cfg):\n",
    "    s = json.dumps(cfg, sort_keys=True)\n",
    "    return hashlib.sha1(s.encode('utf-8')).hexdigest()\n",
    "\n",
    "def crossover(cfgA, cfgB):\n",
    "    # 부모 둘에서 child stream 생성\n",
    "    child_stream = {}\n",
    "    child_stream[\"conv1x1_out\"] = random.choice(\n",
    "        [cfgA[\"rtm\"][\"conv1x1_out\"], cfgB[\"rtm\"][\"conv1x1_out\"]]\n",
    "    )\n",
    "    for si in range(1, 5):\n",
    "        pick_parent = random.choice([cfgA, cfgB])\n",
    "        child_stream[f\"stage{si}\"] = dict(pick_parent[\"rtm\"][f\"stage{si}\"])\n",
    "    # 두 스트림 동일하게 복사\n",
    "    return {\"rtm\": child_stream, \"dtm\": json.loads(json.dumps(child_stream))}\n",
    "\n",
    "\n",
    "def mutate(cfg, prob=0.3):\n",
    "    def mut_stage(st, si):\n",
    "        if random.random() < prob:\n",
    "            st[\"block_type\"] = random.choice(SPACE_BLOCK)\n",
    "        if random.random() < prob:\n",
    "            st[\"out_channels\"] = random.choice(SPACE_OUT[si])\n",
    "        if random.random() < prob:\n",
    "            st[\"stride\"] = random.choice(SPACE_STRIDE)\n",
    "        if random.random() < prob:\n",
    "            st[\"expand_ratio\"] = random.choice(SPACE_T)\n",
    "        if random.random() < prob:\n",
    "            st[\"use_se\"] = random.choice(SPACE_SE)\n",
    "        if random.random() < prob:\n",
    "            st[\"repeats\"] = random.choice(SPACE_REPEATS)\n",
    "        return st\n",
    "\n",
    "    stream = json.loads(json.dumps(cfg[\"rtm\"]))  # deepcopy\n",
    "    for si in range(1, 5):\n",
    "        stream[f\"stage{si}\"] = mut_stage(stream[f\"stage{si}\"], si)\n",
    "    if random.random() < prob:\n",
    "        stream[\"conv1x1_out\"] = random.choice(CONV1x1_OUT)\n",
    "\n",
    "    return {\"rtm\": stream, \"dtm\": json.loads(json.dumps(stream))}\n",
    "\n",
    "\n",
    "def sample_config_with_constraint():\n",
    "    return enforce_stride_per_stream(sample_config())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a618599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# (REPLACE) Cell 3. subprocess 실행 & 유틸\n",
    "# =========================\n",
    "\n",
    "import shutil\n",
    "\n",
    "def prune_non_elites(gen_idx: int, records: list, elite_k: int = 4):\n",
    "    \"\"\"\n",
    "    현재 세대 gen_idx에서 평가된 run 디렉터리들 중,\n",
    "    Top-k를 제외하고 g{gen_idx:02d}_* 폴더를 삭제한다.\n",
    "    (이전 세대 carry-over는 지우지 않음)\n",
    "    \"\"\"\n",
    "    keep_hashes = {r[\"hash\"] for r in records[:elite_k]}\n",
    "    prefix = f\"g{gen_idx:02d}_\"\n",
    "    removed = []\n",
    "\n",
    "    for r in records:\n",
    "        run_dir = r[\"run_dir\"]\n",
    "        base = os.path.basename(run_dir)\n",
    "\n",
    "        # 안전장치: 현재 세대의 폴더만 (gXX_ 로 시작하는 것만) 건드림\n",
    "        if not base.startswith(prefix):\n",
    "            continue\n",
    "\n",
    "        # Top-k는 보존\n",
    "        if r[\"hash\"] in keep_hashes:\n",
    "            continue\n",
    "\n",
    "        # NAS_LOG_DIR 바깥은 절대 건드리지 않기\n",
    "        try:\n",
    "            if os.path.isdir(run_dir) and os.path.commonpath([NAS_LOG_DIR, run_dir]) == NAS_LOG_DIR:\n",
    "                shutil.rmtree(run_dir, ignore_errors=True)\n",
    "                removed.append(base)\n",
    "        except Exception as e:\n",
    "            print(f\"[GC] skip {base}: {e}\")\n",
    "\n",
    "    print(f\"[GC] Gen {gen_idx}: removed {len(removed)} run dirs (non-top{elite_k})\")\n",
    "    if removed:\n",
    "        # 너무 많으면 앞 일부만 출력\n",
    "        preview = \", \".join(removed[:8]) + (\" ...\" if len(removed) > 8 else \"\")\n",
    "        print(f\"     {preview}\")\n",
    "\n",
    "\n",
    "\n",
    "def run_cfg_in_subprocess(cfg, run_dir, train_base, val_base, label_map):\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    # 이전 결과 파일 제거\n",
    "    result_path = os.path.join(run_dir, \"result.json\")\n",
    "    if os.path.exists(result_path):\n",
    "        try: os.remove(result_path)\n",
    "        except Exception: pass\n",
    "\n",
    "    # pickle 파일 쓰기\n",
    "    with open(os.path.join(run_dir,\"train.pkl\"),\"wb\") as f: pickle.dump(train_base,f)\n",
    "    with open(os.path.join(run_dir,\"val.pkl\"),\"wb\") as f:   pickle.dump(val_base,f)\n",
    "    with open(os.path.join(run_dir,\"label.pkl\"),\"wb\") as f: pickle.dump(label_map,f)\n",
    "\n",
    "    cmd = [\n",
    "        \"python\",\"train\",\"train_one_cfg.py\",\n",
    "        \"--cfg_json\", json.dumps(cfg),\n",
    "        \"--train_ids\", os.path.join(run_dir,\"train.pkl\"),\n",
    "        \"--val_ids\", os.path.join(run_dir,\"val.pkl\"),\n",
    "        \"--label_map\", os.path.join(run_dir,\"label.pkl\"),\n",
    "        \"--out_dir\", run_dir\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n[Run-START] {os.path.basename(run_dir)}\")\n",
    "    print(json.dumps(cfg, sort_keys=True))\n",
    "\n",
    "    # 실행 (stderr도 캡쳐해 보여줌)\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "    if result.stderr:\n",
    "        # BestSaver 로그/경고/에러가 stderr로 찍힙니다\n",
    "        print(\"[Subprocess STDERR]\\n\" + result.stderr)\n",
    "\n",
    "    # 결과 파일 읽기\n",
    "    if not os.path.exists(result_path):\n",
    "        print(\"[Subprocess Error] result.json이 생성되지 않았습니다.\")\n",
    "        return None\n",
    "\n",
    "    with open(result_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        payload = json.load(f)\n",
    "\n",
    "    if payload.get(\"status\") != \"ok\":\n",
    "        print(\"[Subprocess Error] status!=ok :\", payload)\n",
    "        return None\n",
    "\n",
    "    out = {\n",
    "        \"val_acc\": payload[\"val_acc\"],\n",
    "        \"val_loss\": payload[\"val_loss\"],\n",
    "        \"params\": payload[\"params\"],\n",
    "        \"train_sec\": payload[\"train_sec\"],\n",
    "    }\n",
    "\n",
    "    print(f\"[Run-DONE ] {os.path.basename(run_dir)} | time={out['train_sec']:.1f}s | acc={out['val_acc']:.4f} | loss={out['val_loss']:.4f} | params={out['params']:,}\")\n",
    "    print(\"-\"*80)\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def compute_fitness(val_acc, params, train_sec, alpha_p=1e-3, beta_t=1e-4):\n",
    "    params_m = params / 1e6\n",
    "    return float(val_acc - alpha_p * params_m - beta_t * train_sec)\n",
    "\n",
    "def append_log(row: dict, csv_path=NAS_LOG_CSV):\n",
    "    df = pd.DataFrame([row])\n",
    "    if os.path.exists(csv_path):\n",
    "        df0 = pd.read_csv(csv_path)\n",
    "        df = pd.concat([df0, df], ignore_index=True)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "def print_leaderboard(records, gen_idx, topk=12):\n",
    "    df = pd.DataFrame([{\n",
    "        \"rank\": i+1,\n",
    "        \"hash8\": r[\"hash\"][:8],\n",
    "        \"fitness\": r[\"fitness\"],\n",
    "        \"acc\": r[\"val_acc\"],\n",
    "        \"loss\": r[\"val_loss\"],\n",
    "        \"params\": r[\"params\"],\n",
    "        \"sec\": r[\"train_sec\"],\n",
    "    } for i, r in enumerate(records[:topk])])\n",
    "    print(f\"\\n[Gen {gen_idx}] Leaderboard (Top {min(topk, len(records))})\")\n",
    "    print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d9793a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Generation 0 START (pop=12, init random) =========\n",
      "\n",
      "[Run-START] g00_4874c2e7\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 6, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 6, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 00:20:10.493211: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 00:20:10.659375: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 00:20:11.354123: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 00:20:12.445857: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:20:12.531691: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:20:12.531882: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:20:12.532199: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:20:17.513632: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:20:17.513841: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:20:17.514017: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:20:17.646967: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:20:17.647091: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:20:17.647106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 00:20:17.647188: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:20:17.647231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 00:20:49.055806: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 331 of 1024\n",
      "2025-09-23 00:20:55.145738: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] Shuffle buffer filled.\n",
      "2025-09-23 00:20:55.255999: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 00:20:55.912676: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 00:20:56.408081: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f931c00fc80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 00:20:56.408107: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 00:20:56.429664: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 00:20:56.570101: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.7157 -> experiments/Step_00/nas_runs/g00_4874c2e7/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.3241 loss=3.1255 -> experiments/Step_00/nas_runs/g00_4874c2e7/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.7352 loss=0.7151 -> experiments/Step_00/nas_runs/g00_4874c2e7/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.8204 loss=0.6791 -> experiments/Step_00/nas_runs/g00_4874c2e7/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9000 loss=0.3441 -> experiments/Step_00/nas_runs/g00_4874c2e7/best_model.keras\n",
      "\n",
      "[Run-DONE ] g00_4874c2e7 | time=240.6s | acc=0.9000 | loss=0.3441 | params=2,378,615\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g00_158e0f93\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 00:24:48.569036: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 00:24:48.591002: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 00:24:49.026824: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 00:24:49.782640: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:24:49.796312: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:24:49.796529: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:24:49.796947: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:24:55.766798: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:24:55.767345: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:24:55.768610: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:24:55.855251: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:24:55.855417: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:24:55.855432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 00:24:55.855522: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:24:55.855555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 00:25:18.378551: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 00:25:18.942823: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 00:25:19.439996: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f542a4b9220 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 00:25:19.440025: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 00:25:19.443120: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 00:25:19.539609: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=4.0239 -> experiments/Step_00/nas_runs/g00_158e0f93/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.5426 loss=1.2849 -> experiments/Step_00/nas_runs/g00_158e0f93/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8093 loss=0.5597 -> experiments/Step_00/nas_runs/g00_158e0f93/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.8278 loss=0.5256 -> experiments/Step_00/nas_runs/g00_158e0f93/best_model.keras\n",
      "\n",
      "[Run-DONE ] g00_158e0f93 | time=281.3s | acc=0.8278 | loss=0.5256 | params=2,040,119\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g00_58028ca3\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 48, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 6, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 48, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 6, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 00:30:06.799460: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 00:30:06.820929: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 00:30:07.256964: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 00:30:07.964282: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:30:07.978479: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:30:07.978656: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:30:07.979051: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:30:13.874411: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:30:13.874621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:30:13.874751: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:30:13.967890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:30:13.968060: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:30:13.968078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 00:30:13.968214: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:30:13.968255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 00:30:28.379009: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 00:30:29.334182: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 00:30:30.108370: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7c74001d40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 00:30:30.108417: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 00:30:30.112036: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 00:30:30.177941: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.9922 -> experiments/Step_00/nas_runs/g00_58028ca3/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.3148 loss=2.5181 -> experiments/Step_00/nas_runs/g00_58028ca3/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.6056 loss=1.4339 -> experiments/Step_00/nas_runs/g00_58028ca3/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.8093 loss=0.4977 -> experiments/Step_00/nas_runs/g00_58028ca3/best_model.keras\n",
      "\n",
      "[Run-DONE ] g00_58028ca3 | time=339.7s | acc=0.8093 | loss=0.4977 | params=1,710,655\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g00_97dd7dd9\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 4, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 4, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 00:36:12.126591: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 00:36:12.146553: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 00:36:12.582412: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 00:36:13.261003: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:36:13.274624: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:36:13.274804: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:36:13.275186: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:36:19.073996: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:36:19.074255: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:36:19.074430: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:36:19.152926: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:36:19.153120: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:36:19.153142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 00:36:19.153317: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:36:19.153364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 00:36:35.206541: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 00:36:35.897080: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 00:36:36.454097: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc2b4004520 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 00:36:36.454138: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 00:36:36.457654: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 00:36:36.524597: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.3923 -> experiments/Step_00/nas_runs/g00_97dd7dd9/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.5500 loss=1.6889 -> experiments/Step_00/nas_runs/g00_97dd7dd9/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.7407 loss=0.7842 -> experiments/Step_00/nas_runs/g00_97dd7dd9/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.8241 loss=0.5135 -> experiments/Step_00/nas_runs/g00_97dd7dd9/best_model.keras\n",
      "\n",
      "[Run-DONE ] g00_97dd7dd9 | time=258.8s | acc=0.8241 | loss=0.5135 | params=2,263,743\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g00_e0ee914e\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 72, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 72, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 00:41:01.263391: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 00:41:01.285647: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 00:41:01.717773: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 00:41:02.463533: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:41:02.476181: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:41:02.476485: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:41:02.476928: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:41:08.443889: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:41:08.444020: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:41:08.444114: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:41:08.528018: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:41:08.528182: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:41:08.528200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 00:41:08.528321: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:41:08.528361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 00:41:21.175159: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 00:41:21.910553: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 00:41:22.429835: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb6febe4840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 00:41:22.429866: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 00:41:22.432556: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 00:41:22.558221: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.3684 -> experiments/Step_00/nas_runs/g00_e0ee914e/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.3630 loss=2.5764 -> experiments/Step_00/nas_runs/g00_e0ee914e/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.7037 loss=1.1878 -> experiments/Step_00/nas_runs/g00_e0ee914e/best_model.keras\n",
      "\n",
      "[Run-DONE ] g00_e0ee914e | time=233.2s | acc=0.7037 | loss=1.1878 | params=4,452,463\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g00_2df70610\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 24, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 24, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 00:46:45.478252: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 00:46:45.499575: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 00:46:45.942083: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 00:46:47.035769: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:46:47.048796: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:46:47.049025: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:46:47.049437: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:46:54.878979: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:46:54.879170: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:46:54.879318: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:46:54.968443: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:46:54.968628: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:46:54.968643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 00:46:54.968790: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:46:54.968822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 00:47:13.675266: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 00:47:14.474665: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 00:47:15.114367: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd86c007290 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 00:47:15.114396: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 00:47:15.117951: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 00:47:15.183453: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.3508 -> experiments/Step_00/nas_runs/g00_2df70610/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4815 loss=2.2237 -> experiments/Step_00/nas_runs/g00_2df70610/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.5111 loss=1.8941 -> experiments/Step_00/nas_runs/g00_2df70610/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.5852 loss=1.5052 -> experiments/Step_00/nas_runs/g00_2df70610/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.7148 loss=1.0670 -> experiments/Step_00/nas_runs/g00_2df70610/best_model.keras\n",
      "\n",
      "[Run-DONE ] g00_2df70610 | time=296.6s | acc=0.7148 | loss=1.0670 | params=3,887,039\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g00_de747bc2\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 00:52:53.698590: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 00:52:53.719693: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 00:52:54.172579: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 00:52:55.034344: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:52:55.049464: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:52:55.053361: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:52:55.054161: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:53:17.270461: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:53:17.270680: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:53:17.270823: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:53:17.355026: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:53:17.355240: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:53:17.355256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 00:53:17.355411: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:53:17.355457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 00:53:37.694547: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 00:53:38.342665: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 00:53:38.753976: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5654d5f65470 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 00:53:38.754001: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 00:53:38.757196: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 00:53:38.823232: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.4471 -> experiments/Step_00/nas_runs/g00_de747bc2/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.5037 loss=1.4420 -> experiments/Step_00/nas_runs/g00_de747bc2/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8981 loss=0.3149 -> experiments/Step_00/nas_runs/g00_de747bc2/best_model.keras\n",
      "\n",
      "[Run-DONE ] g00_de747bc2 | time=187.5s | acc=0.8981 | loss=0.3149 | params=3,119,127\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g00_0107a693\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 24, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 6, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 24, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 6, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 00:56:47.501852: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 00:56:47.522465: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 00:56:47.942497: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 00:56:48.726176: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:56:48.736543: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:56:48.736709: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:56:48.737083: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:56:54.872697: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:56:54.872928: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:56:54.873445: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:56:54.961152: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:56:54.961352: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:56:54.961374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 00:56:54.961551: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 00:56:54.961594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 00:57:15.083454: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 00:57:15.896221: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 00:57:16.431767: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe960003cc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 00:57:16.431799: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 00:57:16.435288: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 00:57:16.500873: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.6645 -> experiments/Step_00/nas_runs/g00_0107a693/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4944 loss=2.0459 -> experiments/Step_00/nas_runs/g00_0107a693/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.5759 loss=1.8926 -> experiments/Step_00/nas_runs/g00_0107a693/best_model.keras\n",
      "\n",
      "[Run-DONE ] g00_0107a693 | time=348.1s | acc=0.5759 | loss=1.8926 | params=4,687,167\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g00_0f9f17d5\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 6, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 6, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 01:03:27.407155: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 01:03:27.428576: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 01:03:28.063378: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 01:03:29.572733: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:03:29.583588: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:03:29.583809: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:03:29.584224: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:03:38.901644: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:03:38.901888: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:03:38.901994: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:03:38.982024: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:03:38.982228: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:03:38.982248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 01:03:38.982430: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:03:38.982469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 01:04:00.087915: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 01:04:00.793703: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 01:04:01.333264: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa528003270 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 01:04:01.333298: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 01:04:01.336843: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 01:04:01.402440: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.9785 -> experiments/Step_00/nas_runs/g00_0f9f17d5/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4444 loss=1.7151 -> experiments/Step_00/nas_runs/g00_0f9f17d5/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.5074 loss=2.3949 -> experiments/Step_00/nas_runs/g00_0f9f17d5/best_model.keras\n",
      "\n",
      "[Run-DONE ] g00_0f9f17d5 | time=359.0s | acc=0.5074 | loss=2.3949 | params=3,132,607\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g00_fe8d833c\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 01:10:14.261139: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 01:10:14.283336: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 01:10:14.803859: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 01:10:15.551203: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:10:15.561802: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:10:15.562111: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:10:15.562580: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:10:21.718314: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:10:21.718494: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:10:21.718672: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:10:21.804246: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:10:21.804380: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:10:21.804395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 01:10:21.804481: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:10:21.804516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 01:10:45.962507: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 01:10:46.413088: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 01:10:46.701780: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8a208d09c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 01:10:46.701809: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 01:10:46.704785: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 01:10:46.766438: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.2963 -> experiments/Step_00/nas_runs/g00_fe8d833c/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.5519 loss=1.2620 -> experiments/Step_00/nas_runs/g00_fe8d833c/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8204 loss=0.6048 -> experiments/Step_00/nas_runs/g00_fe8d833c/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9185 loss=0.1924 -> experiments/Step_00/nas_runs/g00_fe8d833c/best_model.keras\n",
      "\n",
      "[Run-DONE ] g00_fe8d833c | time=191.6s | acc=0.9185 | loss=0.1924 | params=1,663,935\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g00_cf2799be\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 01:13:58.904058: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 01:13:58.926636: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 01:13:59.401328: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 01:14:00.147960: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:14:00.158440: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:14:00.158604: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:14:00.159329: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:14:06.297146: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:14:06.297359: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:14:06.297499: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:14:06.372513: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:14:06.372716: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:14:06.372738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 01:14:06.372894: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:14:06.372936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 01:14:25.504064: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 01:14:26.134114: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 01:14:26.555494: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2e60006350 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 01:14:26.555521: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 01:14:26.559111: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 01:14:26.624405: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.7585 -> experiments/Step_00/nas_runs/g00_cf2799be/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4944 loss=1.8793 -> experiments/Step_00/nas_runs/g00_cf2799be/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.5407 loss=2.5322 -> experiments/Step_00/nas_runs/g00_cf2799be/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.5500 loss=1.6946 -> experiments/Step_00/nas_runs/g00_cf2799be/best_model.keras\n",
      "\n",
      "[Run-DONE ] g00_cf2799be | time=301.3s | acc=0.5500 | loss=1.6946 | params=937,375\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g00_3584e74c\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 80, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 6, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 80, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 6, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 01:19:23.293081: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 01:19:23.317068: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 01:19:23.750372: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 01:19:24.454643: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:19:24.492076: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:19:24.492630: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:19:24.493788: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:19:30.389510: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:19:30.389696: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:19:30.389822: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:19:30.469605: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:19:30.469824: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:19:30.469847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 01:19:30.469981: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:19:30.470020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 01:19:50.551212: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 01:19:51.406161: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 01:19:52.059675: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55aaf33ef640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 01:19:52.059712: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 01:19:52.063966: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 01:19:52.128934: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.8135 -> experiments/Step_00/nas_runs/g00_3584e74c/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.3222 loss=2.4645 -> experiments/Step_00/nas_runs/g00_3584e74c/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.8019 loss=0.6587 -> experiments/Step_00/nas_runs/g00_3584e74c/best_model.keras\n",
      "\n",
      "[Run-DONE ] g00_3584e74c | time=399.1s | acc=0.8019 | loss=0.6587 | params=1,166,879\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Gen 0] Leaderboard (Top 12)\n",
      " rank    hash8  fitness      acc     loss  params        sec\n",
      "    1 fe8d833c 0.897694 0.918519 0.192434 1663935 191.609801\n",
      "    2 de747bc2 0.876275 0.898148 0.314928 3119127 187.537631\n",
      "    3 4874c2e7 0.873561 0.900000 0.344132 2378615 240.602271\n",
      "    4 158e0f93 0.797608 0.827778 0.525603 2040119 281.301811\n",
      "    5 97dd7dd9 0.795926 0.824074 0.513503 2263743 258.845902\n",
      "    6 58028ca3 0.773580 0.809259 0.497726 1710655 339.682004\n",
      "    7 3584e74c 0.760770 0.801852 0.658710 1166879 399.148870\n",
      "    8 2df70610 0.681273 0.714815 1.067035 3887039 296.550395\n",
      "    9 e0ee914e 0.675927 0.703704 1.187780 4452463 233.245264\n",
      "   10 0107a693 0.536424 0.575926 1.892639 4687167 348.148617\n",
      "   11 cf2799be 0.518932 0.550000 1.694631  937375 301.306413\n",
      "   12 0f9f17d5 0.468379 0.507407 2.394855 3132607 358.959785\n",
      "[GC] Gen 0: removed 8 run dirs (non-top4)\n",
      "     g00_97dd7dd9, g00_58028ca3, g00_3584e74c, g00_2df70610, g00_e0ee914e, g00_0107a693, g00_cf2799be, g00_0f9f17d5\n",
      "\n",
      "========= Generation 1 START (pop=12) =========\n",
      "\n",
      "[Run-START] g01_545e2f9c\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 01:26:30.505126: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 01:26:30.526170: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 01:26:30.974020: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 01:26:31.753060: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:26:31.764159: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:26:31.764303: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:26:31.764642: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:26:37.678236: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:26:37.678634: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:26:37.678877: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:26:37.773322: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:26:37.773489: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:26:37.773504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 01:26:37.773601: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:26:37.773640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 01:26:50.765576: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 01:26:51.288502: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 01:26:51.661916: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa1280068c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 01:26:51.661952: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 01:26:51.665155: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 01:26:51.730554: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.6065 -> experiments/Step_00/nas_runs/g01_545e2f9c/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.2796 loss=3.3094 -> experiments/Step_00/nas_runs/g01_545e2f9c/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.3981 loss=5.2449 -> experiments/Step_00/nas_runs/g01_545e2f9c/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.7296 loss=0.8679 -> experiments/Step_00/nas_runs/g01_545e2f9c/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.8315 loss=0.5434 -> experiments/Step_00/nas_runs/g01_545e2f9c/best_model.keras\n",
      "\n",
      "[Run-DONE ] g01_545e2f9c | time=139.7s | acc=0.8315 | loss=0.5434 | params=2,319,135\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g01_0d44d2b8\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 01:29:15.395932: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 01:29:15.416279: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 01:29:15.839089: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 01:29:16.556939: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:29:16.567674: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:29:16.567898: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:29:16.568333: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:29:22.535874: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:29:22.536153: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:29:22.536352: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:29:22.619598: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:29:22.619807: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:29:22.619825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 01:29:22.619984: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:29:22.620024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 01:29:39.739617: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 01:29:40.756997: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 01:29:41.545430: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb3dc00bc60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 01:29:41.545468: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 01:29:41.548650: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 01:29:41.613516: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=8.5975 -> experiments/Step_00/nas_runs/g01_0d44d2b8/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.1778 loss=5.3385 -> experiments/Step_00/nas_runs/g01_0d44d2b8/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.3833 loss=2.7866 -> experiments/Step_00/nas_runs/g01_0d44d2b8/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.7574 loss=0.6754 -> experiments/Step_00/nas_runs/g01_0d44d2b8/best_model.keras\n",
      "\n",
      "[Run-DONE ] g01_0d44d2b8 | time=425.2s | acc=0.7574 | loss=0.6754 | params=3,367,015\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g01_449f5166\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 01:36:54.205866: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 01:36:54.228120: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 01:36:54.667387: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 01:36:55.356731: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:36:55.367654: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:36:55.367940: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:36:55.368381: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:37:01.244787: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:37:01.245036: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:37:01.245188: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:37:01.473564: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:37:01.473736: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:37:01.473756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 01:37:01.473856: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:37:01.473887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 01:37:19.674501: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 01:37:20.321750: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 01:37:20.684592: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f67917dfd10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 01:37:20.684619: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 01:37:20.687964: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 01:37:20.753177: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.1648 loss=3.7102 -> experiments/Step_00/nas_runs/g01_449f5166/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.7778 loss=0.6814 -> experiments/Step_00/nas_runs/g01_449f5166/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9093 loss=0.2682 -> experiments/Step_00/nas_runs/g01_449f5166/best_model.keras\n",
      "\n",
      "[Run-DONE ] g01_449f5166 | time=151.6s | acc=0.9093 | loss=0.2682 | params=6,671,863\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g01_4eb9f618\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 01:40:10.268775: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 01:40:10.289750: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 01:40:10.719057: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 01:40:11.456879: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:40:11.467830: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:40:11.467980: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:40:11.468329: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:40:17.155057: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:40:17.155227: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:40:17.155345: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:40:17.234227: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:40:17.234398: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:40:17.234414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 01:40:17.234507: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:40:17.234542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 01:40:38.074713: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 01:40:38.601234: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 01:40:38.942108: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdd456d04b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 01:40:38.942138: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 01:40:38.944723: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 01:40:39.003803: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.6040 -> experiments/Step_00/nas_runs/g01_4eb9f618/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.6056 loss=1.3289 -> experiments/Step_00/nas_runs/g01_4eb9f618/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8630 loss=0.4460 -> experiments/Step_00/nas_runs/g01_4eb9f618/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9093 loss=0.2883 -> experiments/Step_00/nas_runs/g01_4eb9f618/best_model.keras\n",
      "\n",
      "[Run-DONE ] g01_4eb9f618 | time=175.8s | acc=0.9093 | loss=0.2883 | params=2,664,871\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g01_ccb11238\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 01:43:41.957447: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 01:43:41.980005: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 01:43:42.408843: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 01:43:43.190398: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:43:43.201166: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:43:43.201468: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:43:43.201931: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:43:48.940884: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:43:48.941128: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:43:48.941309: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:43:49.024823: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:43:49.025016: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:43:49.025043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 01:43:49.025263: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:43:49.025303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 01:44:08.210102: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 01:44:08.964905: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 01:44:09.468184: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff6b100f7e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 01:44:09.468212: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 01:44:09.470703: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 01:44:09.534661: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=4.1337 -> experiments/Step_00/nas_runs/g01_ccb11238/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.2167 loss=3.7748 -> experiments/Step_00/nas_runs/g01_ccb11238/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.7019 loss=1.3006 -> experiments/Step_00/nas_runs/g01_ccb11238/best_model.keras\n",
      "\n",
      "[Run-DONE ] g01_ccb11238 | time=414.2s | acc=0.7019 | loss=1.3006 | params=1,282,007\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g01_135ecade\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 6, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 6, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 01:51:04.671562: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 01:51:04.693399: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 01:51:05.133103: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 01:51:05.815534: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:51:05.827021: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:51:05.827298: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:51:05.827719: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:51:12.649904: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:51:12.650117: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:51:12.650276: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:51:12.738976: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:51:12.739208: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:51:12.739229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 01:51:12.739408: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:51:12.739456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 01:51:36.076240: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 01:51:36.725333: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 01:51:37.181817: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f5dcc00ecc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 01:51:37.181847: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 01:51:37.185337: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 01:51:37.251304: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.9025 -> experiments/Step_00/nas_runs/g01_135ecade/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4111 loss=1.9150 -> experiments/Step_00/nas_runs/g01_135ecade/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.5704 loss=1.8220 -> experiments/Step_00/nas_runs/g01_135ecade/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.6704 loss=1.2609 -> experiments/Step_00/nas_runs/g01_135ecade/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.8630 loss=0.4205 -> experiments/Step_00/nas_runs/g01_135ecade/best_model.keras\n",
      "\n",
      "[Run-DONE ] g01_135ecade | time=227.9s | acc=0.8630 | loss=0.4205 | params=3,864,663\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g01_6524a0f5\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 01:55:46.791488: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 01:55:46.812628: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 01:55:47.242113: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 01:55:47.955628: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:55:47.966948: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:55:47.967177: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:55:47.967577: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:55:53.804962: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:55:53.805126: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:55:53.805260: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:55:53.889606: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:55:53.889783: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:55:53.889801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 01:55:53.889897: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:55:53.889928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 01:56:11.129736: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 01:56:11.707237: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 01:56:12.136737: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bee937aad0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 01:56:12.136764: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 01:56:12.139890: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 01:56:12.204356: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.6913 -> experiments/Step_00/nas_runs/g01_6524a0f5/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.1444 loss=8.3478 -> experiments/Step_00/nas_runs/g01_6524a0f5/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.6481 loss=1.1582 -> experiments/Step_00/nas_runs/g01_6524a0f5/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.8278 loss=0.5224 -> experiments/Step_00/nas_runs/g01_6524a0f5/best_model.keras\n",
      "\n",
      "[Run-DONE ] g01_6524a0f5 | time=223.5s | acc=0.8278 | loss=0.5224 | params=1,438,719\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g01_daacb494\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 01:59:54.878810: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 01:59:54.901393: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 01:59:55.324954: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 01:59:56.007560: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:59:56.019103: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:59:56.019318: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 01:59:56.019652: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:00:01.956538: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:00:01.956714: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:00:01.956810: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:00:02.053110: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:00:02.053244: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:00:02.053262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 02:00:02.053353: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:00:02.053386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 02:00:24.487758: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 02:00:25.036692: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 02:00:25.380335: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc65c004460 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 02:00:25.380365: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 02:00:25.383686: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 02:00:25.447515: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.4768 -> experiments/Step_00/nas_runs/g01_daacb494/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.2944 loss=3.4538 -> experiments/Step_00/nas_runs/g01_daacb494/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.4630 loss=2.0333 -> experiments/Step_00/nas_runs/g01_daacb494/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.6241 loss=1.2498 -> experiments/Step_00/nas_runs/g01_daacb494/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.7444 loss=0.8720 -> experiments/Step_00/nas_runs/g01_daacb494/best_model.keras\n",
      "\n",
      "[Run-DONE ] g01_daacb494 | time=274.8s | acc=0.7444 | loss=0.8720 | params=2,706,271\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Gen 1] Leaderboard (Top 12)\n",
      " rank    hash8  fitness      acc     loss  params        sec\n",
      "    1 fe8d833c 0.897694 0.918519 0.192434 1663935 191.609801\n",
      "    2 4eb9f618 0.889014 0.909259 0.288303 2664871 175.799131\n",
      "    3 449f5166 0.887429 0.909259 0.268159 6671863 151.585911\n",
      "    4 de747bc2 0.876275 0.898148 0.314928 3119127 187.537631\n",
      "    5 4874c2e7 0.873561 0.900000 0.344132 2378615 240.602271\n",
      "    6 135ecade 0.836313 0.862963 0.420482 3864663 227.852323\n",
      "    7 545e2f9c 0.815195 0.831481 0.543414 2319135 139.670462\n",
      "    8 6524a0f5 0.803991 0.827778 0.522437 1438719 223.476553\n",
      "    9 158e0f93 0.797608 0.827778 0.525603 2040119 281.301811\n",
      "   10 daacb494 0.714260 0.744444 0.871996 2706271 274.776603\n",
      "   11 0d44d2b8 0.711519 0.757407 0.675423 3367015 425.211568\n",
      "   12 ccb11238 0.659147 0.701852 1.300575 1282007 414.225000\n",
      "[GC] Gen 1: removed 6 run dirs (non-top4)\n",
      "     g01_135ecade, g01_545e2f9c, g01_6524a0f5, g01_daacb494, g01_0d44d2b8, g01_ccb11238\n",
      "\n",
      "========= Generation 2 START (pop=12) =========\n",
      "\n",
      "[Run-START] g02_6531be99\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 6, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 6, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 02:05:10.306322: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 02:05:10.327359: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 02:05:10.754367: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 02:05:11.564754: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:05:11.575504: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:05:11.575752: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:05:11.576163: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:05:17.369370: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:05:17.369546: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:05:17.369681: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:05:17.454107: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:05:17.454286: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:05:17.454306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 02:05:17.454437: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:05:17.454473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 02:05:31.864981: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 02:05:32.357254: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 02:05:32.763308: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4868001f10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 02:05:32.763337: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 02:05:32.766503: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 02:05:32.831768: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.6790 -> experiments/Step_00/nas_runs/g02_6531be99/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.6907 loss=0.9212 -> experiments/Step_00/nas_runs/g02_6531be99/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.7778 loss=0.8204 -> experiments/Step_00/nas_runs/g02_6531be99/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.8222 loss=0.8981 -> experiments/Step_00/nas_runs/g02_6531be99/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9556 loss=0.1209 -> experiments/Step_00/nas_runs/g02_6531be99/best_model.keras\n",
      "\n",
      "[Run-DONE ] g02_6531be99 | time=145.2s | acc=0.9556 | loss=0.1209 | params=1,895,663\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g02_a93de1bf\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 48, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 48, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 02:08:01.668780: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 02:08:01.690055: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 02:08:02.145026: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 02:08:02.826874: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:08:02.838365: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:08:02.838553: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:08:02.838914: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:08:08.898960: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:08:08.899113: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:08:08.899211: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:08:08.978572: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:08:08.978738: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:08:08.978758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 02:08:08.978853: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:08:08.978884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 02:08:26.335182: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 02:08:26.827554: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 02:08:27.139187: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd55c002b10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 02:08:27.139219: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 02:08:27.143159: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 02:08:27.208645: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.3084 -> experiments/Step_00/nas_runs/g02_a93de1bf/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.3815 loss=2.1861 -> experiments/Step_00/nas_runs/g02_a93de1bf/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8222 loss=0.5572 -> experiments/Step_00/nas_runs/g02_a93de1bf/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9333 loss=0.2377 -> experiments/Step_00/nas_runs/g02_a93de1bf/best_model.keras\n",
      "\n",
      "[Run-DONE ] g02_a93de1bf | time=168.4s | acc=0.9333 | loss=0.2377 | params=1,691,599\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g02_8762eff1\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 02:11:16.718788: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 02:11:16.742979: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 02:11:17.191749: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 02:11:17.918404: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:11:17.929423: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:11:17.929593: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:11:17.929990: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:11:23.794881: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:11:23.795045: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:11:23.795173: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:11:23.878390: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:11:23.878567: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:11:23.878586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 02:11:23.878672: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:11:23.878713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 02:11:44.237582: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 02:11:44.932062: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 02:11:45.466832: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f01000109a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 02:11:45.466870: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 02:11:45.470063: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 02:11:45.577178: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.4803 -> experiments/Step_00/nas_runs/g02_8762eff1/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.7185 loss=0.8585 -> experiments/Step_00/nas_runs/g02_8762eff1/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.7426 loss=1.4209 -> experiments/Step_00/nas_runs/g02_8762eff1/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.7704 loss=0.8446 -> experiments/Step_00/nas_runs/g02_8762eff1/best_model.keras\n",
      "\n",
      "[Run-DONE ] g02_8762eff1 | time=260.8s | acc=0.7704 | loss=0.8446 | params=4,317,295\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g02_c0796665\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 02:16:25.578993: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 02:16:25.606207: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 02:16:26.019359: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 02:16:26.695426: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:16:26.707895: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:16:26.708109: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:16:26.708543: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:16:32.806307: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:16:32.806484: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:16:32.806574: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:16:32.902192: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:16:32.902454: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:16:32.902478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 02:16:32.902609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:16:32.902651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 02:16:54.107054: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 02:16:54.660939: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 02:16:55.003455: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f1e6099270 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 02:16:55.003484: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 02:16:55.006360: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 02:16:55.071752: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=4.3954 -> experiments/Step_00/nas_runs/g02_c0796665/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4241 loss=2.3464 -> experiments/Step_00/nas_runs/g02_c0796665/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.7944 loss=0.5921 -> experiments/Step_00/nas_runs/g02_c0796665/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.8907 loss=0.3477 -> experiments/Step_00/nas_runs/g02_c0796665/best_model.keras\n",
      "\n",
      "[Run-DONE ] g02_c0796665 | time=180.5s | acc=0.8907 | loss=0.3477 | params=4,749,727\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g02_e50cac05\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 80, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 4, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 80, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 4, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 02:20:14.426326: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 02:20:14.449981: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 02:20:14.909481: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 02:20:15.668843: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:20:15.683780: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:20:15.684822: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:20:15.686614: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:20:21.617382: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:20:21.617518: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:20:21.617609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:20:21.705857: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:20:21.706034: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:20:21.706053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 02:20:21.706141: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:20:21.706173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 02:20:48.209048: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 02:20:49.383942: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 02:20:49.434560: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 604.05MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-09-23 02:20:49.434610: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 604.82MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-09-23 02:20:49.472037: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 604.05MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-09-23 02:20:49.472093: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 605.74MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-09-23 02:20:50.366879: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7faf3400af10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 02:20:50.366905: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 02:20:50.369663: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 02:20:50.436464: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2025-09-23 02:21:16.217501: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 42.88MiB (rounded to 44957696)requested by op sub_2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2025-09-23 02:21:16.217570: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2025-09-23 02:21:16.217575: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 735, Chunks in use: 717. 183.8KiB allocated for chunks. 179.2KiB in use in bin. 113.4KiB client-requested in use in bin.\n",
      "2025-09-23 02:21:16.217577: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 448, Chunks in use: 428. 271.2KiB allocated for chunks. 261.2KiB in use in bin. 225.0KiB client-requested in use in bin.\n",
      "2025-09-23 02:21:16.217579: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 322, Chunks in use: 321. 366.8KiB allocated for chunks. 365.8KiB in use in bin. 321.1KiB client-requested in use in bin.\n",
      "2025-09-23 02:21:16.217581: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 144, Chunks in use: 144. 331.8KiB allocated for chunks. 331.8KiB in use in bin. 309.0KiB client-requested in use in bin.\n",
      "2025-09-23 02:21:16.217583: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 116, Chunks in use: 116. 620.5KiB allocated for chunks. 620.5KiB in use in bin. 605.6KiB client-requested in use in bin.\n",
      "2025-09-23 02:21:16.217585: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 119, Chunks in use: 118. 1.09MiB allocated for chunks. 1.08MiB in use in bin. 1.03MiB client-requested in use in bin.\n",
      "2025-09-23 02:21:16.217587: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 93, Chunks in use: 91. 2.04MiB allocated for chunks. 2.00MiB in use in bin. 1.97MiB client-requested in use in bin.\n",
      "2025-09-23 02:21:16.217589: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 194, Chunks in use: 194. 8.77MiB allocated for chunks. 8.77MiB in use in bin. 8.64MiB client-requested in use in bin.\n",
      "2025-09-23 02:21:16.217590: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 74, Chunks in use: 74. 6.24MiB allocated for chunks. 6.24MiB in use in bin. 6.00MiB client-requested in use in bin.\n",
      "2025-09-23 02:21:16.217592: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 58, Chunks in use: 58. 11.34MiB allocated for chunks. 11.34MiB in use in bin. 10.88MiB client-requested in use in bin.\n",
      "2025-09-23 02:21:16.217594: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 2, Chunks in use: 2. 776.8KiB allocated for chunks. 776.8KiB in use in bin. 555.8KiB client-requested in use in bin.\n",
      "2025-09-23 02:21:16.217596: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 13, Chunks in use: 13. 8.42MiB allocated for chunks. 8.42MiB in use in bin. 8.15MiB client-requested in use in bin.\n",
      "2025-09-23 02:21:16.217598: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 18, Chunks in use: 18. 23.82MiB allocated for chunks. 23.82MiB in use in bin. 23.73MiB client-requested in use in bin.\n",
      "2025-09-23 02:21:16.217600: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-09-23 02:21:16.217602: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 19, Chunks in use: 19. 118.32MiB allocated for chunks. 118.32MiB in use in bin. 113.31MiB client-requested in use in bin.\n",
      "2025-09-23 02:21:16.217604: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 49, Chunks in use: 49. 605.95MiB allocated for chunks. 605.95MiB in use in bin. 600.25MiB client-requested in use in bin.\n",
      "2025-09-23 02:21:16.217606: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 107, Chunks in use: 107. 2.51GiB allocated for chunks. 2.51GiB in use in bin. 2.43GiB client-requested in use in bin.\n",
      "2025-09-23 02:21:16.217608: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 58, Chunks in use: 58. 2.65GiB allocated for chunks. 2.65GiB in use in bin. 2.49GiB client-requested in use in bin.\n",
      "2025-09-23 02:21:16.217610: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 110, Chunks in use: 110. 8.72GiB allocated for chunks. 8.72GiB in use in bin. 8.61GiB client-requested in use in bin.\n",
      "2025-09-23 02:21:16.217612: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 36, Chunks in use: 36. 6.00GiB allocated for chunks. 6.00GiB in use in bin. 5.55GiB client-requested in use in bin.\n",
      "2025-09-23 02:21:16.217614: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 1, Chunks in use: 1. 303.18MiB allocated for chunks. 303.18MiB in use in bin. 183.75MiB client-requested in use in bin.\n",
      "2025-09-23 02:21:16.217616: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 42.88MiB was 32.00MiB, Chunk State: \n",
      "2025-09-23 02:21:16.217617: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 2097152\n",
      "2025-09-23 02:21:16.217621: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317800000 of size 1280 next 1\n",
      "2025-09-23 02:21:16.217623: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317800500 of size 38912 next 2\n",
      "2025-09-23 02:21:16.217624: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317809d00 of size 256 next 3\n",
      "2025-09-23 02:21:16.217625: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317809e00 of size 256 next 4\n",
      "2025-09-23 02:21:16.217627: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317809f00 of size 256 next 5\n",
      "2025-09-23 02:21:16.217628: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780a000 of size 256 next 6\n",
      "2025-09-23 02:21:16.217629: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780a100 of size 256 next 7\n",
      "2025-09-23 02:21:16.217630: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780a200 of size 256 next 8\n",
      "2025-09-23 02:21:16.217631: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780a300 of size 256 next 9\n",
      "2025-09-23 02:21:16.217633: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780a400 of size 256 next 10\n",
      "2025-09-23 02:21:16.217634: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780a500 of size 256 next 11\n",
      "2025-09-23 02:21:16.217635: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780a600 of size 4352 next 12\n",
      "2025-09-23 02:21:16.217637: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780b700 of size 256 next 13\n",
      "2025-09-23 02:21:16.217638: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780b800 of size 256 next 14\n",
      "2025-09-23 02:21:16.217639: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780b900 of size 256 next 15\n",
      "2025-09-23 02:21:16.217640: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780ba00 of size 256 next 16\n",
      "2025-09-23 02:21:16.217641: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780bb00 of size 256 next 18\n",
      "2025-09-23 02:21:16.217643: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780bc00 of size 256 next 19\n",
      "2025-09-23 02:21:16.217644: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780bd00 of size 256 next 17\n",
      "2025-09-23 02:21:16.217645: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780be00 of size 256 next 20\n",
      "2025-09-23 02:21:16.217646: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780bf00 of size 256 next 2017\n",
      "2025-09-23 02:21:16.217647: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780c000 of size 256 next 24\n",
      "2025-09-23 02:21:16.217648: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780c100 of size 256 next 25\n",
      "2025-09-23 02:21:16.217650: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780c200 of size 256 next 26\n",
      "2025-09-23 02:21:16.217652: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780c300 of size 256 next 29\n",
      "2025-09-23 02:21:16.217653: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780c400 of size 256 next 27\n",
      "2025-09-23 02:21:16.217654: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780c500 of size 256 next 2032\n",
      "2025-09-23 02:21:16.217655: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780c600 of size 256 next 32\n",
      "2025-09-23 02:21:16.217656: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780c700 of size 256 next 33\n",
      "2025-09-23 02:21:16.217658: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780c800 of size 256 next 34\n",
      "2025-09-23 02:21:16.217659: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780c900 of size 256 next 37\n",
      "2025-09-23 02:21:16.217660: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780ca00 of size 256 next 35\n",
      "2025-09-23 02:21:16.217661: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780cb00 of size 256 next 21\n",
      "2025-09-23 02:21:16.217663: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780cc00 of size 1792 next 22\n",
      "2025-09-23 02:21:16.217664: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780d300 of size 256 next 36\n",
      "2025-09-23 02:21:16.217665: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780d400 of size 256 next 39\n",
      "2025-09-23 02:21:16.217666: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780d500 of size 256 next 40\n",
      "2025-09-23 02:21:16.217667: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780d600 of size 256 next 43\n",
      "2025-09-23 02:21:16.217669: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780d700 of size 256 next 41\n",
      "2025-09-23 02:21:16.217670: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780d800 of size 256 next 2287\n",
      "2025-09-23 02:21:16.217671: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780d900 of size 256 next 46\n",
      "2025-09-23 02:21:16.217672: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780da00 of size 256 next 47\n",
      "2025-09-23 02:21:16.217673: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780db00 of size 256 next 48\n",
      "2025-09-23 02:21:16.217674: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780dc00 of size 256 next 38\n",
      "2025-09-23 02:21:16.217676: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780dd00 of size 1536 next 31\n",
      "2025-09-23 02:21:16.217677: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780e300 of size 2048 next 30\n",
      "2025-09-23 02:21:16.217678: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780eb00 of size 256 next 50\n",
      "2025-09-23 02:21:16.217679: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780ec00 of size 256 next 2115\n",
      "2025-09-23 02:21:16.217681: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780ed00 of size 256 next 53\n",
      "2025-09-23 02:21:16.217682: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780ee00 of size 256 next 54\n",
      "2025-09-23 02:21:16.217683: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780ef00 of size 256 next 55\n",
      "2025-09-23 02:21:16.217684: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780f000 of size 256 next 57\n",
      "2025-09-23 02:21:16.217685: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780f100 of size 256 next 58\n",
      "2025-09-23 02:21:16.217686: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780f200 of size 256 next 56\n",
      "2025-09-23 02:21:16.217687: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780f300 of size 256 next 59\n",
      "2025-09-23 02:21:16.217689: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780f400 of size 256 next 61\n",
      "2025-09-23 02:21:16.217690: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780f500 of size 256 next 62\n",
      "2025-09-23 02:21:16.217691: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780f600 of size 256 next 1843\n",
      "2025-09-23 02:21:16.217692: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780f700 of size 256 next 66\n",
      "2025-09-23 02:21:16.217694: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780f800 of size 256 next 67\n",
      "2025-09-23 02:21:16.217695: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780f900 of size 256 next 68\n",
      "2025-09-23 02:21:16.217696: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780fa00 of size 256 next 2391\n",
      "2025-09-23 02:21:16.217697: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780fb00 of size 256 next 2635\n",
      "2025-09-23 02:21:16.217698: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780fc00 of size 256 next 2729\n",
      "2025-09-23 02:21:16.217699: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780fd00 of size 256 next 102\n",
      "2025-09-23 02:21:16.217701: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780fe00 of size 256 next 116\n",
      "2025-09-23 02:21:16.217702: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780ff00 of size 512 next 132\n",
      "2025-09-23 02:21:16.217703: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317810100 of size 512 next 130\n",
      "2025-09-23 02:21:16.217708: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317810300 of size 256 next 2216\n",
      "2025-09-23 02:21:16.217709: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317810400 of size 256 next 2365\n",
      "2025-09-23 02:21:16.217710: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317810500 of size 256 next 2767\n",
      "2025-09-23 02:21:16.217712: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317810600 of size 256 next 135\n",
      "2025-09-23 02:21:16.217713: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317810700 of size 256 next 136\n",
      "2025-09-23 02:21:16.217714: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317810800 of size 256 next 137\n",
      "2025-09-23 02:21:16.217715: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317810900 of size 512 next 45\n",
      "2025-09-23 02:21:16.217717: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317810b00 of size 4096 next 44\n",
      "2025-09-23 02:21:16.217718: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317811b00 of size 2304 next 60\n",
      "2025-09-23 02:21:16.217719: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317812400 of size 256 next 1736\n",
      "2025-09-23 02:21:16.217721: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317812500 of size 256 next 153\n",
      "2025-09-23 02:21:16.217722: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317812600 of size 256 next 154\n",
      "2025-09-23 02:21:16.217723: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317812700 of size 256 next 155\n",
      "2025-09-23 02:21:16.217724: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317812800 of size 1024 next 158\n",
      "2025-09-23 02:21:16.217726: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317812c00 of size 1024 next 156\n",
      "2025-09-23 02:21:16.217727: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317813000 of size 1536 next 140\n",
      "2025-09-23 02:21:16.217728: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317813600 of size 4608 next 139\n",
      "2025-09-23 02:21:16.217730: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317814800 of size 256 next 1880\n",
      "2025-09-23 02:21:16.217731: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317814900 of size 256 next 2255\n",
      "2025-09-23 02:21:16.217732: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317814a00 of size 256 next 2031\n",
      "2025-09-23 02:21:16.217733: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317814b00 of size 256 next 157\n",
      "2025-09-23 02:21:16.217735: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317814c00 of size 256 next 161\n",
      "2025-09-23 02:21:16.217738: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317814d00 of size 256 next 162\n",
      "2025-09-23 02:21:16.217739: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317814e00 of size 1024 next 163\n",
      "2025-09-23 02:21:16.217741: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317815200 of size 1024 next 164\n",
      "2025-09-23 02:21:16.217742: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317815600 of size 512 next 2627\n",
      "2025-09-23 02:21:16.217743: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317815800 of size 768 next 52\n",
      "2025-09-23 02:21:16.217745: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317815b00 of size 8192 next 51\n",
      "2025-09-23 02:21:16.217748: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317817b00 of size 256 next 73\n",
      "2025-09-23 02:21:16.217749: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317817c00 of size 256 next 72\n",
      "2025-09-23 02:21:16.217751: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317817d00 of size 512 next 77\n",
      "2025-09-23 02:21:16.217752: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317817f00 of size 256 next 78\n",
      "2025-09-23 02:21:16.217753: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317818000 of size 256 next 79\n",
      "2025-09-23 02:21:16.217755: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317818100 of size 256 next 2535\n",
      "2025-09-23 02:21:16.217756: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317818200 of size 256 next 83\n",
      "2025-09-23 02:21:16.217758: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317818300 of size 256 next 84\n",
      "2025-09-23 02:21:16.217774: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317818400 of size 256 next 75\n",
      "2025-09-23 02:21:16.217777: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317818500 of size 2304 next 76\n",
      "2025-09-23 02:21:16.217779: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317818e00 of size 512 next 87\n",
      "2025-09-23 02:21:16.217780: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317819000 of size 256 next 89\n",
      "2025-09-23 02:21:16.217782: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317819100 of size 256 next 88\n",
      "2025-09-23 02:21:16.217783: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317819200 of size 512 next 92\n",
      "2025-09-23 02:21:16.217784: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317819400 of size 256 next 93\n",
      "2025-09-23 02:21:16.217785: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317819500 of size 256 next 94\n",
      "2025-09-23 02:21:16.217786: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317819600 of size 512 next 98\n",
      "2025-09-23 02:21:16.217788: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317819800 of size 256 next 99\n",
      "2025-09-23 02:21:16.217789: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317819900 of size 256 next 100\n",
      "2025-09-23 02:21:16.217790: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317819a00 of size 256 next 64\n",
      "2025-09-23 02:21:16.217791: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317819b00 of size 8192 next 63\n",
      "2025-09-23 02:21:16.217792: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131781bb00 of size 8192 next 69\n",
      "2025-09-23 02:21:16.217794: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131781db00 of size 2304 next 91\n",
      "2025-09-23 02:21:16.217795: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131781e400 of size 256 next 104\n",
      "2025-09-23 02:21:16.217796: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131781e500 of size 256 next 103\n",
      "2025-09-23 02:21:16.217797: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131781e600 of size 512 next 107\n",
      "2025-09-23 02:21:16.217798: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131781e800 of size 256 next 108\n",
      "2025-09-23 02:21:16.217799: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131781e900 of size 256 next 109\n",
      "2025-09-23 02:21:16.217801: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131781ea00 of size 512 next 112\n",
      "2025-09-23 02:21:16.217802: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131781ec00 of size 256 next 113\n",
      "2025-09-23 02:21:16.217803: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131781ed00 of size 256 next 106\n",
      "2025-09-23 02:21:16.217804: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131781ee00 of size 3328 next 81\n",
      "2025-09-23 02:21:16.217806: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131781fb00 of size 8192 next 80\n",
      "2025-09-23 02:21:16.217807: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317821b00 of size 8192 next 85\n",
      "2025-09-23 02:21:16.217808: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317823b00 of size 256 next 118\n",
      "2025-09-23 02:21:16.217809: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317823c00 of size 256 next 117\n",
      "2025-09-23 02:21:16.217811: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317823d00 of size 256 next 2489\n",
      "2025-09-23 02:21:16.217812: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317823e00 of size 256 next 122\n",
      "2025-09-23 02:21:16.217813: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317823f00 of size 256 next 123\n",
      "2025-09-23 02:21:16.217814: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317824000 of size 256 next 124\n",
      "2025-09-23 02:21:16.217815: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317824100 of size 512 next 128\n",
      "2025-09-23 02:21:16.217817: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317824300 of size 256 next 129\n",
      "2025-09-23 02:21:16.217818: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317824400 of size 256 next 120\n",
      "2025-09-23 02:21:16.217819: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317824500 of size 2304 next 121\n",
      "2025-09-23 02:21:16.217820: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317824e00 of size 512 next 138\n",
      "2025-09-23 02:21:16.217822: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317825000 of size 256 next 2226\n",
      "2025-09-23 02:21:16.217823: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317825100 of size 256 next 219\n",
      "2025-09-23 02:21:16.217824: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317825200 of size 256 next 2416\n",
      "2025-09-23 02:21:16.217825: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317825300 of size 256 next 142\n",
      "2025-09-23 02:21:16.217826: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317825400 of size 256 next 145\n",
      "2025-09-23 02:21:16.217828: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317825500 of size 512 next 147\n",
      "2025-09-23 02:21:16.217829: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317825700 of size 256 next 143\n",
      "2025-09-23 02:21:16.217830: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317825800 of size 256 next 144\n",
      "2025-09-23 02:21:16.217831: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317825900 of size 256 next 149\n",
      "2025-09-23 02:21:16.217832: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317825a00 of size 256 next 96\n",
      "2025-09-23 02:21:16.217833: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317825b00 of size 8192 next 95\n",
      "2025-09-23 02:21:16.217835: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317827b00 of size 8192 next 101\n",
      "2025-09-23 02:21:16.217836: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317829b00 of size 8192 next 110\n",
      "2025-09-23 02:21:16.217837: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782bb00 of size 8192 next 114\n",
      "2025-09-23 02:21:16.217838: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782db00 of size 256 next 2566\n",
      "2025-09-23 02:21:16.217839: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782dc00 of size 256 next 2766\n",
      "2025-09-23 02:21:16.217841: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782dd00 of size 256 next 2396\n",
      "2025-09-23 02:21:16.217842: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782de00 of size 256 next 167\n",
      "2025-09-23 02:21:16.217843: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782df00 of size 256 next 170\n",
      "2025-09-23 02:21:16.217844: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782e000 of size 1024 next 172\n",
      "2025-09-23 02:21:16.217845: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782e400 of size 256 next 174\n",
      "2025-09-23 02:21:16.217847: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782e500 of size 256 next 168\n",
      "2025-09-23 02:21:16.217848: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782e600 of size 256 next 2724\n",
      "2025-09-23 02:21:16.217849: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782e700 of size 256 next 176\n",
      "2025-09-23 02:21:16.217850: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782e800 of size 1024 next 179\n",
      "2025-09-23 02:21:16.217851: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782ec00 of size 1024 next 177\n",
      "2025-09-23 02:21:16.217853: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782f000 of size 1024 next 2583\n",
      "2025-09-23 02:21:16.217854: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782f400 of size 256 next 2229\n",
      "2025-09-23 02:21:16.217855: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782f500 of size 256 next 2411\n",
      "2025-09-23 02:21:16.217856: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782f600 of size 512 next 2571\n",
      "2025-09-23 02:21:16.217857: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782f800 of size 256 next 2133\n",
      "2025-09-23 02:21:16.217859: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782f900 of size 256 next 2575\n",
      "2025-09-23 02:21:16.217860: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782fa00 of size 256 next 126\n",
      "2025-09-23 02:21:16.217861: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782fb00 of size 8192 next 125\n",
      "2025-09-23 02:21:16.217863: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317831b00 of size 1024 next 181\n",
      "2025-09-23 02:21:16.217864: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317831f00 of size 1024 next 182\n",
      "2025-09-23 02:21:16.217865: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317832300 of size 2048 next 186\n",
      "2025-09-23 02:21:16.217866: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317832b00 of size 256 next 189\n",
      "2025-09-23 02:21:16.217867: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317832c00 of size 1024 next 191\n",
      "2025-09-23 02:21:16.217869: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317833000 of size 256 next 193\n",
      "2025-09-23 02:21:16.217870: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317833100 of size 256 next 187\n",
      "2025-09-23 02:21:16.217871: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317833200 of size 512 next 195\n",
      "2025-09-23 02:21:16.217872: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317833400 of size 1792 next 184\n",
      "2025-09-23 02:21:16.217873: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317833b00 of size 8192 next 183\n",
      "2025-09-23 02:21:16.217875: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317835b00 of size 1024 next 209\n",
      "2025-09-23 02:21:16.217876: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317835f00 of size 256 next 206\n",
      "2025-09-23 02:21:16.217877: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317836000 of size 1024 next 215\n",
      "2025-09-23 02:21:16.217878: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317836400 of size 1024 next 213\n",
      "2025-09-23 02:21:16.217879: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317836800 of size 2048 next 217\n",
      "2025-09-23 02:21:16.217881: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317837000 of size 1024 next 218\n",
      "2025-09-23 02:21:16.217882: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317837400 of size 1792 next 203\n",
      "2025-09-23 02:21:16.217883: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317837b00 of size 8192 next 134\n",
      "2025-09-23 02:21:16.217884: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317839b00 of size 16384 next 133\n",
      "2025-09-23 02:21:16.217885: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131783db00 of size 16384 next 146\n",
      "2025-09-23 02:21:16.217887: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317841b00 of size 16384 next 148\n",
      "2025-09-23 02:21:16.217888: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317845b00 of size 1024 next 198\n",
      "2025-09-23 02:21:16.217889: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317845f00 of size 512 next 2689\n",
      "2025-09-23 02:21:16.217890: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317846100 of size 512 next 2392\n",
      "2025-09-23 02:21:16.217891: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317846300 of size 512 next 1925\n",
      "2025-09-23 02:21:16.217893: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317846500 of size 512 next 197\n",
      "2025-09-23 02:21:16.217894: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317846700 of size 1024 next 200\n",
      "2025-09-23 02:21:16.217895: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317846b00 of size 1024 next 201\n",
      "2025-09-23 02:21:16.217896: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317846f00 of size 256 next 2328\n",
      "2025-09-23 02:21:16.217897: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317847000 of size 256 next 2662\n",
      "2025-09-23 02:21:16.217899: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317847100 of size 256 next 1999\n",
      "2025-09-23 02:21:16.217900: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317847200 of size 256 next 2049\n",
      "2025-09-23 02:21:16.217901: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317847300 of size 1024 next 204\n",
      "2025-09-23 02:21:16.217902: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317847700 of size 256 next 207\n",
      "2025-09-23 02:21:16.217904: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317847800 of size 256 next 211\n",
      "2025-09-23 02:21:16.217905: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317847900 of size 256 next 205\n",
      "2025-09-23 02:21:16.217906: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317847a00 of size 256 next 166\n",
      "2025-09-23 02:21:16.217907: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317847b00 of size 8192 next 165\n",
      "2025-09-23 02:21:16.217908: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317849b00 of size 512 next 2087\n",
      "2025-09-23 02:21:16.217910: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317849d00 of size 512 next 236\n",
      "2025-09-23 02:21:16.217911: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317849f00 of size 1536 next 258\n",
      "2025-09-23 02:21:16.217912: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784a500 of size 3072 next 256\n",
      "2025-09-23 02:21:16.217913: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784b100 of size 256 next 261\n",
      "2025-09-23 02:21:16.217914: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784b200 of size 256 next 262\n",
      "2025-09-23 02:21:16.217916: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784b300 of size 512 next 265\n",
      "2025-09-23 02:21:16.217917: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784b500 of size 1536 next 263\n",
      "2025-09-23 02:21:16.217918: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784bb00 of size 256 next 264\n",
      "2025-09-23 02:21:16.217919: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784bc00 of size 256 next 268\n",
      "2025-09-23 02:21:16.217920: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784bd00 of size 512 next 270\n",
      "2025-09-23 02:21:16.217922: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784bf00 of size 512 next 271\n",
      "2025-09-23 02:21:16.217923: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784c100 of size 512 next 2505\n",
      "2025-09-23 02:21:16.217924: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784c300 of size 512 next 274\n",
      "2025-09-23 02:21:16.217925: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784c500 of size 256 next 275\n",
      "2025-09-23 02:21:16.217926: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784c600 of size 256 next 276\n",
      "2025-09-23 02:21:16.217927: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784c700 of size 256 next 284\n",
      "2025-09-23 02:21:16.217929: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784c800 of size 256 next 285\n",
      "2025-09-23 02:21:16.217930: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784c900 of size 512 next 151\n",
      "2025-09-23 02:21:16.217931: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784cb00 of size 28672 next 150\n",
      "2025-09-23 02:21:16.217932: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317853b00 of size 1024 next 2509\n",
      "2025-09-23 02:21:16.217933: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317853f00 of size 512 next 323\n",
      "2025-09-23 02:21:16.217935: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317854100 of size 512 next 222\n",
      "2025-09-23 02:21:16.217936: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317854300 of size 256 next 223\n",
      "2025-09-23 02:21:16.217937: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317854400 of size 1024 next 224\n",
      "2025-09-23 02:21:16.217938: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317854800 of size 256 next 227\n",
      "2025-09-23 02:21:16.217941: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317854900 of size 256 next 229\n",
      "2025-09-23 02:21:16.217942: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317854a00 of size 512 next 232\n",
      "2025-09-23 02:21:16.217943: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317854c00 of size 1024 next 233\n",
      "2025-09-23 02:21:16.217945: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317855000 of size 1024 next 234\n",
      "2025-09-23 02:21:16.217946: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317855400 of size 256 next 1988\n",
      "2025-09-23 02:21:16.217947: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317855500 of size 256 next 1762\n",
      "2025-09-23 02:21:16.217948: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317855600 of size 1280 next 221\n",
      "2025-09-23 02:21:16.217950: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317855b00 of size 8192 next 220\n",
      "2025-09-23 02:21:16.217951: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317857b00 of size 25600 next 345\n",
      "2025-09-23 02:21:16.217953: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131785df00 of size 25600 next 347\n",
      "2025-09-23 02:21:16.217954: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317864300 of size 256 next 2545\n",
      "2025-09-23 02:21:16.217955: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317864400 of size 256 next 2089\n",
      "2025-09-23 02:21:16.217956: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317864500 of size 512 next 419\n",
      "2025-09-23 02:21:16.217958: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317864700 of size 256 next 421\n",
      "2025-09-23 02:21:16.217959: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317864800 of size 256 next 422\n",
      "2025-09-23 02:21:16.217960: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317864900 of size 256 next 420\n",
      "2025-09-23 02:21:16.217961: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317864a00 of size 256 next 423\n",
      "2025-09-23 02:21:16.217962: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317864b00 of size 256 next 432\n",
      "2025-09-23 02:21:16.217964: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317864c00 of size 256 next 433\n",
      "2025-09-23 02:21:16.217965: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317864d00 of size 256 next 2197\n",
      "2025-09-23 02:21:16.217966: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317864e00 of size 256 next 436\n",
      "2025-09-23 02:21:16.217968: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317864f00 of size 256 next 435\n",
      "2025-09-23 02:21:16.217969: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317865000 of size 2048 next 424\n",
      "2025-09-23 02:21:16.217970: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317865800 of size 1792 next 425\n",
      "2025-09-23 02:21:16.217971: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317865f00 of size 256 next 427\n",
      "2025-09-23 02:21:16.217973: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317866000 of size 256 next 426\n",
      "2025-09-23 02:21:16.217974: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317866100 of size 512 next 431\n",
      "2025-09-23 02:21:16.217975: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317866300 of size 256 next 438\n",
      "2025-09-23 02:21:16.217976: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317866400 of size 512 next 441\n",
      "2025-09-23 02:21:16.217978: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317866600 of size 256 next 442\n",
      "2025-09-23 02:21:16.217979: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317866700 of size 256 next 429\n",
      "2025-09-23 02:21:16.217980: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317866800 of size 2048 next 430\n",
      "2025-09-23 02:21:16.217982: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317867000 of size 256 next 2564\n",
      "2025-09-23 02:21:16.217983: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317867100 of size 256 next 445\n",
      "2025-09-23 02:21:16.217984: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317867200 of size 256 next 448\n",
      "2025-09-23 02:21:16.217986: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317867300 of size 256 next 446\n",
      "2025-09-23 02:21:16.217987: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317867400 of size 256 next 1862\n",
      "2025-09-23 02:21:16.217988: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317867500 of size 256 next 449\n",
      "2025-09-23 02:21:16.217989: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317867600 of size 256 next 451\n",
      "2025-09-23 02:21:16.217990: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317867700 of size 256 next 452\n",
      "2025-09-23 02:21:16.217992: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317867800 of size 256 next 384\n",
      "2025-09-23 02:21:16.217993: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317867900 of size 6912 next 383\n",
      "2025-09-23 02:21:16.217994: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317869400 of size 512 next 1771\n",
      "2025-09-23 02:21:16.217996: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317869600 of size 512 next 393\n",
      "2025-09-23 02:21:16.217997: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317869800 of size 768 next 394\n",
      "2025-09-23 02:21:16.217998: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317869b00 of size 768 next 395\n",
      "2025-09-23 02:21:16.217999: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317869e00 of size 1536 next 398\n",
      "2025-09-23 02:21:16.218001: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786a400 of size 768 next 400\n",
      "2025-09-23 02:21:16.218002: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786a700 of size 768 next 399\n",
      "2025-09-23 02:21:16.218003: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786aa00 of size 256 next 2021\n",
      "2025-09-23 02:21:16.218004: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786ab00 of size 256 next 2283\n",
      "2025-09-23 02:21:16.218005: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786ac00 of size 512 next 579\n",
      "2025-09-23 02:21:16.218007: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 131786ae00 of size 512 next 403\n",
      "2025-09-23 02:21:16.218008: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786b000 of size 256 next 404\n",
      "2025-09-23 02:21:16.218009: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786b100 of size 768 next 405\n",
      "2025-09-23 02:21:16.218010: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786b400 of size 512 next 406\n",
      "2025-09-23 02:21:16.218012: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786b600 of size 512 next 409\n",
      "2025-09-23 02:21:16.218013: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786b800 of size 256 next 1785\n",
      "2025-09-23 02:21:16.218014: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786b900 of size 256 next 2170\n",
      "2025-09-23 02:21:16.218015: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 131786ba00 of size 512 next 413\n",
      "2025-09-23 02:21:16.218016: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786bc00 of size 256 next 414\n",
      "2025-09-23 02:21:16.218018: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786bd00 of size 256 next 415\n",
      "2025-09-23 02:21:16.218019: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786be00 of size 512 next 416\n",
      "2025-09-23 02:21:16.218021: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786c000 of size 768 next 160\n",
      "2025-09-23 02:21:16.218022: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786c300 of size 50176 next 159\n",
      "2025-09-23 02:21:16.218023: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317878700 of size 50176 next 171\n",
      "2025-09-23 02:21:16.218024: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317884b00 of size 50176 next 173\n",
      "2025-09-23 02:21:16.218026: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317890f00 of size 50176 next 175\n",
      "2025-09-23 02:21:16.218027: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131789d300 of size 50176 next 180\n",
      "2025-09-23 02:21:16.218028: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13178a9700 of size 50176 next 190\n",
      "2025-09-23 02:21:16.218030: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13178b5b00 of size 50176 next 192\n",
      "2025-09-23 02:21:16.218031: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13178c1f00 of size 50176 next 194\n",
      "2025-09-23 02:21:16.218032: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13178ce300 of size 50176 next 199\n",
      "2025-09-23 02:21:16.218034: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13178da700 of size 50176 next 208\n",
      "2025-09-23 02:21:16.218035: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13178e6b00 of size 50176 next 210\n",
      "2025-09-23 02:21:16.218036: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13178f2f00 of size 50176 next 212\n",
      "2025-09-23 02:21:16.218037: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13178ff300 of size 50176 next 216\n",
      "2025-09-23 02:21:16.218039: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790b700 of size 1024 next 238\n",
      "2025-09-23 02:21:16.218040: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790bb00 of size 1024 next 237\n",
      "2025-09-23 02:21:16.218041: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790bf00 of size 512 next 2334\n",
      "2025-09-23 02:21:16.218042: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790c100 of size 512 next 2548\n",
      "2025-09-23 02:21:16.218044: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790c300 of size 1024 next 242\n",
      "2025-09-23 02:21:16.218045: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790c700 of size 256 next 243\n",
      "2025-09-23 02:21:16.218046: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790c800 of size 1024 next 244\n",
      "2025-09-23 02:21:16.218047: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790cc00 of size 256 next 247\n",
      "2025-09-23 02:21:16.218048: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790cd00 of size 256 next 249\n",
      "2025-09-23 02:21:16.218050: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790ce00 of size 256 next 2470\n",
      "2025-09-23 02:21:16.218051: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790cf00 of size 256 next 252\n",
      "2025-09-23 02:21:16.218052: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790d000 of size 256 next 253\n",
      "2025-09-23 02:21:16.218054: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790d100 of size 256 next 254\n",
      "2025-09-23 02:21:16.218055: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790d200 of size 1536 next 240\n",
      "2025-09-23 02:21:16.218056: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790d800 of size 8192 next 241\n",
      "2025-09-23 02:21:16.218057: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790f800 of size 2048 next 277\n",
      "2025-09-23 02:21:16.218059: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317910000 of size 2048 next 278\n",
      "2025-09-23 02:21:16.218060: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317910800 of size 4096 next 283\n",
      "2025-09-23 02:21:16.218069: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317911800 of size 2048 next 290\n",
      "2025-09-23 02:21:16.218071: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317912000 of size 256 next 287\n",
      "2025-09-23 02:21:16.218073: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317912100 of size 256 next 286\n",
      "2025-09-23 02:21:16.218074: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317912200 of size 512 next 292\n",
      "2025-09-23 02:21:16.218076: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317912400 of size 512 next 293\n",
      "2025-09-23 02:21:16.218077: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317912600 of size 512 next 2651\n",
      "2025-09-23 02:21:16.218078: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317912800 of size 256 next 2661\n",
      "2025-09-23 02:21:16.218080: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317912900 of size 256 next 296\n",
      "2025-09-23 02:21:16.218081: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317912a00 of size 2048 next 297\n",
      "2025-09-23 02:21:16.218089: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317913200 of size 2048 next 298\n",
      "2025-09-23 02:21:16.218092: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317913a00 of size 4096 next 301\n",
      "2025-09-23 02:21:16.218094: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317914a00 of size 512 next 304\n",
      "2025-09-23 02:21:16.218095: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317914c00 of size 2048 next 306\n",
      "2025-09-23 02:21:16.218096: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317915400 of size 512 next 302\n",
      "2025-09-23 02:21:16.218097: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317915600 of size 512 next 303\n",
      "2025-09-23 02:21:16.218099: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317915800 of size 512 next 2495\n",
      "2025-09-23 02:21:16.218100: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317915a00 of size 256 next 2063\n",
      "2025-09-23 02:21:16.218101: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317915b00 of size 256 next 310\n",
      "2025-09-23 02:21:16.218102: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317915c00 of size 2048 next 311\n",
      "2025-09-23 02:21:16.218104: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317916400 of size 2048 next 312\n",
      "2025-09-23 02:21:16.218105: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317916c00 of size 3840 next 226\n",
      "2025-09-23 02:21:16.218106: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317917b00 of size 50176 next 225\n",
      "2025-09-23 02:21:16.218108: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317923f00 of size 50176 next 228\n",
      "2025-09-23 02:21:16.218109: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317930300 of size 50176 next 230\n",
      "2025-09-23 02:21:16.218110: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131793c700 of size 50176 next 235\n",
      "2025-09-23 02:21:16.218111: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317948b00 of size 512 next 2423\n",
      "2025-09-23 02:21:16.218113: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317948d00 of size 512 next 1986\n",
      "2025-09-23 02:21:16.218114: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317948f00 of size 512 next 2120\n",
      "2025-09-23 02:21:16.218115: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317949100 of size 512 next 315\n",
      "2025-09-23 02:21:16.218116: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317949300 of size 512 next 316\n",
      "2025-09-23 02:21:16.218117: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317949500 of size 2048 next 317\n",
      "2025-09-23 02:21:16.218119: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317949d00 of size 512 next 320\n",
      "2025-09-23 02:21:16.218120: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317949f00 of size 512 next 322\n",
      "2025-09-23 02:21:16.218121: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794a100 of size 512 next 1841\n",
      "2025-09-23 02:21:16.218123: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 131794a300 of size 256 next 2380\n",
      "2025-09-23 02:21:16.218124: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794a400 of size 256 next 324\n",
      "2025-09-23 02:21:16.218125: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794a500 of size 256 next 325\n",
      "2025-09-23 02:21:16.218127: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794a600 of size 256 next 326\n",
      "2025-09-23 02:21:16.218128: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794a700 of size 768 next 327\n",
      "2025-09-23 02:21:16.218129: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794aa00 of size 768 next 328\n",
      "2025-09-23 02:21:16.218130: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794ad00 of size 1536 next 331\n",
      "2025-09-23 02:21:16.218131: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794b300 of size 256 next 332\n",
      "2025-09-23 02:21:16.218133: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794b400 of size 256 next 333\n",
      "2025-09-23 02:21:16.218134: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794b500 of size 768 next 335\n",
      "2025-09-23 02:21:16.218135: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794b800 of size 768 next 336\n",
      "2025-09-23 02:21:16.218137: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794bb00 of size 1536 next 337\n",
      "2025-09-23 02:21:16.218138: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794c100 of size 256 next 340\n",
      "2025-09-23 02:21:16.218139: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794c200 of size 256 next 341\n",
      "2025-09-23 02:21:16.218140: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794c300 of size 256 next 344\n",
      "2025-09-23 02:21:16.218141: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794c400 of size 768 next 346\n",
      "2025-09-23 02:21:16.218143: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794c700 of size 256 next 342\n",
      "2025-09-23 02:21:16.218144: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794c800 of size 256 next 343\n",
      "2025-09-23 02:21:16.218145: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794c900 of size 512 next 350\n",
      "2025-09-23 02:21:16.218147: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794cb00 of size 512 next 348\n",
      "2025-09-23 02:21:16.218148: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794cd00 of size 512 next 1968\n",
      "2025-09-23 02:21:16.218149: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794cf00 of size 512 next 352\n",
      "2025-09-23 02:21:16.218151: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794d100 of size 256 next 353\n",
      "2025-09-23 02:21:16.218152: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794d200 of size 256 next 354\n",
      "2025-09-23 02:21:16.218153: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794d300 of size 768 next 357\n",
      "2025-09-23 02:21:16.218155: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794d600 of size 768 next 355\n",
      "2025-09-23 02:21:16.218156: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794d900 of size 1536 next 359\n",
      "2025-09-23 02:21:16.218157: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794df00 of size 256 next 360\n",
      "2025-09-23 02:21:16.218159: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794e000 of size 256 next 361\n",
      "2025-09-23 02:21:16.218160: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794e100 of size 1280 next 338\n",
      "2025-09-23 02:21:16.218161: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794e600 of size 5888 next 339\n",
      "2025-09-23 02:21:16.218163: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794fd00 of size 768 next 364\n",
      "2025-09-23 02:21:16.218164: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317950000 of size 1536 next 363\n",
      "2025-09-23 02:21:16.218165: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317950600 of size 256 next 365\n",
      "2025-09-23 02:21:16.218167: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317950700 of size 768 next 367\n",
      "2025-09-23 02:21:16.218168: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317950a00 of size 512 next 368\n",
      "2025-09-23 02:21:16.218169: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317950c00 of size 512 next 371\n",
      "2025-09-23 02:21:16.218170: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317950e00 of size 256 next 2660\n",
      "2025-09-23 02:21:16.218171: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317950f00 of size 256 next 2430\n",
      "2025-09-23 02:21:16.218173: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317951000 of size 512 next 375\n",
      "2025-09-23 02:21:16.218174: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317951200 of size 768 next 376\n",
      "2025-09-23 02:21:16.218175: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317951500 of size 768 next 377\n",
      "2025-09-23 02:21:16.218177: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317951800 of size 1536 next 379\n",
      "2025-09-23 02:21:16.218178: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317951e00 of size 768 next 382\n",
      "2025-09-23 02:21:16.218179: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317952100 of size 768 next 380\n",
      "2025-09-23 02:21:16.218181: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317952400 of size 512 next 1770\n",
      "2025-09-23 02:21:16.218182: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317952600 of size 512 next 2704\n",
      "2025-09-23 02:21:16.218183: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317952800 of size 512 next 385\n",
      "2025-09-23 02:21:16.218184: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317952a00 of size 256 next 386\n",
      "2025-09-23 02:21:16.218186: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317952b00 of size 768 next 387\n",
      "2025-09-23 02:21:16.218187: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317952e00 of size 512 next 389\n",
      "2025-09-23 02:21:16.218188: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317953000 of size 768 next 366\n",
      "2025-09-23 02:21:16.218190: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317953300 of size 7168 next 246\n",
      "2025-09-23 02:21:16.218191: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317954f00 of size 50176 next 245\n",
      "2025-09-23 02:21:16.218192: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317961300 of size 50176 next 248\n",
      "2025-09-23 02:21:16.218194: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131796d700 of size 50176 next 250\n",
      "2025-09-23 02:21:16.218195: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317979b00 of size 51200 next 330\n",
      "2025-09-23 02:21:16.218197: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317986300 of size 61696 next 269\n",
      "2025-09-23 02:21:16.218198: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317995400 of size 112896 next 267\n",
      "2025-09-23 02:21:16.218199: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13179b0d00 of size 112896 next 266\n",
      "2025-09-23 02:21:16.218201: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13179cc600 of size 61440 next 351\n",
      "2025-09-23 02:21:16.218202: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13179db600 of size 36864 next 370\n",
      "2025-09-23 02:21:16.218204: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13179e4600 of size 113152 next 18446744073709551615\n",
      "2025-09-23 02:21:16.218205: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 4194304\n",
      "2025-09-23 02:21:16.218207: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c00000 of size 107520 next 272\n",
      "2025-09-23 02:21:16.218208: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c1a400 of size 153600 next 308\n",
      "2025-09-23 02:21:16.218210: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c3fc00 of size 256 next 462\n",
      "2025-09-23 02:21:16.218218: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c3fd00 of size 256 next 461\n",
      "2025-09-23 02:21:16.218221: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c3fe00 of size 256 next 2758\n",
      "2025-09-23 02:21:16.218222: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c3ff00 of size 256 next 466\n",
      "2025-09-23 02:21:16.218224: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c40000 of size 256 next 467\n",
      "2025-09-23 02:21:16.218225: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c40100 of size 256 next 468\n",
      "2025-09-23 02:21:16.218226: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317c40200 of size 256 next 2230\n",
      "2025-09-23 02:21:16.218227: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c40300 of size 256 next 471\n",
      "2025-09-23 02:21:16.218229: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c40400 of size 256 next 472\n",
      "2025-09-23 02:21:16.218230: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c40500 of size 256 next 464\n",
      "2025-09-23 02:21:16.218239: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c40600 of size 2304 next 465\n",
      "2025-09-23 02:21:16.218242: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c40f00 of size 256 next 2338\n",
      "2025-09-23 02:21:16.218244: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c41000 of size 256 next 475\n",
      "2025-09-23 02:21:16.218245: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c41100 of size 256 next 477\n",
      "2025-09-23 02:21:16.218248: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c41200 of size 256 next 476\n",
      "2025-09-23 02:21:16.218250: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317c41300 of size 256 next 2096\n",
      "2025-09-23 02:21:16.218251: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c41400 of size 256 next 480\n",
      "2025-09-23 02:21:16.218253: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c41500 of size 256 next 481\n",
      "2025-09-23 02:21:16.218254: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c41600 of size 256 next 482\n",
      "2025-09-23 02:21:16.218255: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c41700 of size 256 next 2465\n",
      "2025-09-23 02:21:16.218257: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317c41800 of size 256 next 485\n",
      "2025-09-23 02:21:16.218258: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c41900 of size 256 next 486\n",
      "2025-09-23 02:21:16.218266: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c41a00 of size 256 next 487\n",
      "2025-09-23 02:21:16.218269: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c41b00 of size 256 next 453\n",
      "2025-09-23 02:21:16.218270: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c41c00 of size 8192 next 454\n",
      "2025-09-23 02:21:16.218272: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c43c00 of size 8192 next 458\n",
      "2025-09-23 02:21:16.218273: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c45c00 of size 256 next 527\n",
      "2025-09-23 02:21:16.218274: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c45d00 of size 256 next 523\n",
      "2025-09-23 02:21:16.218275: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c45e00 of size 256 next 2339\n",
      "2025-09-23 02:21:16.218277: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c45f00 of size 256 next 530\n",
      "2025-09-23 02:21:16.218278: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c46000 of size 1024 next 533\n",
      "2025-09-23 02:21:16.218279: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c46400 of size 1024 next 531\n",
      "2025-09-23 02:21:16.218281: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c46800 of size 1536 next 521\n",
      "2025-09-23 02:21:16.218282: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c46e00 of size 7680 next 407\n",
      "2025-09-23 02:21:16.218283: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c48c00 of size 36864 next 392\n",
      "2025-09-23 02:21:16.218285: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c51c00 of size 73728 next 391\n",
      "2025-09-23 02:21:16.218286: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c63c00 of size 73728 next 396\n",
      "2025-09-23 02:21:16.218287: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c75c00 of size 43008 next 418\n",
      "2025-09-23 02:21:16.218289: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c80400 of size 8192 next 488\n",
      "2025-09-23 02:21:16.218290: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c82400 of size 8192 next 497\n",
      "2025-09-23 02:21:16.218291: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c84400 of size 8192 next 501\n",
      "2025-09-23 02:21:16.218293: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c86400 of size 256 next 294\n",
      "2025-09-23 02:21:16.218294: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c86500 of size 256 next 2518\n",
      "2025-09-23 02:21:16.218295: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317c86600 of size 512 next 532\n",
      "2025-09-23 02:21:16.218297: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c86800 of size 1024 next 538\n",
      "2025-09-23 02:21:16.218298: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c86c00 of size 1024 next 536\n",
      "2025-09-23 02:21:16.218299: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c87000 of size 1024 next 2394\n",
      "2025-09-23 02:21:16.218301: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c87400 of size 1024 next 539\n",
      "2025-09-23 02:21:16.218302: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c87800 of size 256 next 543\n",
      "2025-09-23 02:21:16.218303: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c87900 of size 1024 next 545\n",
      "2025-09-23 02:21:16.218304: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c87d00 of size 256 next 547\n",
      "2025-09-23 02:21:16.218306: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c87e00 of size 256 next 541\n",
      "2025-09-23 02:21:16.218307: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317c87f00 of size 256 next 2557\n",
      "2025-09-23 02:21:16.218308: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c88000 of size 256 next 549\n",
      "2025-09-23 02:21:16.218309: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c88100 of size 256 next 563\n",
      "2025-09-23 02:21:16.218311: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c88200 of size 256 next 566\n",
      "2025-09-23 02:21:16.218312: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c88300 of size 256 next 512\n",
      "2025-09-23 02:21:16.218313: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c88400 of size 10240 next 289\n",
      "2025-09-23 02:21:16.218315: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c8ac00 of size 230400 next 288\n",
      "2025-09-23 02:21:16.218316: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317cc3000 of size 230400 next 291\n",
      "2025-09-23 02:21:16.218317: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317cfb400 of size 73728 next 358\n",
      "2025-09-23 02:21:16.218319: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0d400 of size 6912 next 402\n",
      "2025-09-23 02:21:16.218320: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0ef00 of size 256 next 455\n",
      "2025-09-23 02:21:16.218321: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0f000 of size 256 next 456\n",
      "2025-09-23 02:21:16.218323: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0f100 of size 256 next 457\n",
      "2025-09-23 02:21:16.218324: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0f200 of size 1024 next 502\n",
      "2025-09-23 02:21:16.218325: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0f600 of size 256 next 503\n",
      "2025-09-23 02:21:16.218326: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0f700 of size 256 next 506\n",
      "2025-09-23 02:21:16.218328: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0f800 of size 256 next 504\n",
      "2025-09-23 02:21:16.218329: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0f900 of size 256 next 2295\n",
      "2025-09-23 02:21:16.218330: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0fa00 of size 256 next 507\n",
      "2025-09-23 02:21:16.218331: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0fb00 of size 256 next 509\n",
      "2025-09-23 02:21:16.218333: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0fc00 of size 256 next 510\n",
      "2025-09-23 02:21:16.218334: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0fd00 of size 256 next 2104\n",
      "2025-09-23 02:21:16.218335: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317d0fe00 of size 256 next 513\n",
      "2025-09-23 02:21:16.218337: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0ff00 of size 512 next 450\n",
      "2025-09-23 02:21:16.218338: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d10100 of size 3584 next 440\n",
      "2025-09-23 02:21:16.218339: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d10f00 of size 4096 next 439\n",
      "2025-09-23 02:21:16.218341: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d11f00 of size 2304 next 479\n",
      "2025-09-23 02:21:16.218342: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d12800 of size 256 next 491\n",
      "2025-09-23 02:21:16.218343: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d12900 of size 256 next 490\n",
      "2025-09-23 02:21:16.218344: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d12a00 of size 256 next 2602\n",
      "2025-09-23 02:21:16.218346: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d12b00 of size 256 next 494\n",
      "2025-09-23 02:21:16.218347: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d12c00 of size 256 next 495\n",
      "2025-09-23 02:21:16.218348: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d12d00 of size 256 next 496\n",
      "2025-09-23 02:21:16.218350: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317d12e00 of size 256 next 2341\n",
      "2025-09-23 02:21:16.218351: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d12f00 of size 256 next 499\n",
      "2025-09-23 02:21:16.218352: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d13000 of size 256 next 500\n",
      "2025-09-23 02:21:16.218354: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d13100 of size 256 next 493\n",
      "2025-09-23 02:21:16.218355: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d13200 of size 3328 next 444\n",
      "2025-09-23 02:21:16.218357: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d13f00 of size 9472 next 369\n",
      "2025-09-23 02:21:16.218358: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d16400 of size 43008 next 295\n",
      "2025-09-23 02:21:16.218359: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d20c00 of size 172032 next 260\n",
      "2025-09-23 02:21:16.218368: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d4ac00 of size 677376 next 259\n",
      "2025-09-23 02:21:16.218371: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317df0200 of size 677376 next 629\n",
      "2025-09-23 02:21:16.218372: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317e95800 of size 28672 next 1043\n",
      "2025-09-23 02:21:16.218373: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317e9c800 of size 28672 next 1044\n",
      "2025-09-23 02:21:16.218375: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ea3800 of size 28672 next 1045\n",
      "2025-09-23 02:21:16.218376: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317eaa800 of size 28672 next 1046\n",
      "2025-09-23 02:21:16.218377: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317eb1800 of size 50176 next 1055\n",
      "2025-09-23 02:21:16.218378: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ebdc00 of size 50176 next 1056\n",
      "2025-09-23 02:21:16.218379: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317eca000 of size 50176 next 1057\n",
      "2025-09-23 02:21:16.218381: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ed6400 of size 50176 next 1058\n",
      "2025-09-23 02:21:16.218382: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ee2800 of size 8192 next 1067\n",
      "2025-09-23 02:21:16.218383: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ee4800 of size 8192 next 1068\n",
      "2025-09-23 02:21:16.218384: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ee6800 of size 8192 next 1069\n",
      "2025-09-23 02:21:16.218386: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ee8800 of size 1024 next 1070\n",
      "2025-09-23 02:21:16.218387: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ee8c00 of size 1024 next 1071\n",
      "2025-09-23 02:21:16.218388: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ee9000 of size 1024 next 1072\n",
      "2025-09-23 02:21:16.218389: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ee9400 of size 1024 next 1073\n",
      "2025-09-23 02:21:16.218390: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ee9800 of size 1024 next 1074\n",
      "2025-09-23 02:21:16.218391: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ee9c00 of size 1024 next 1075\n",
      "2025-09-23 02:21:16.218393: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317eea000 of size 1024 next 1076\n",
      "2025-09-23 02:21:16.218394: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317eea400 of size 1024 next 1077\n",
      "2025-09-23 02:21:16.218395: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317eea800 of size 50176 next 1078\n",
      "2025-09-23 02:21:16.218396: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ef6c00 of size 50176 next 1079\n",
      "2025-09-23 02:21:16.218398: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f03000 of size 256 next 1080\n",
      "2025-09-23 02:21:16.218399: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f03100 of size 256 next 1081\n",
      "2025-09-23 02:21:16.218400: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f03200 of size 50176 next 1082\n",
      "2025-09-23 02:21:16.218401: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f0f600 of size 50176 next 1083\n",
      "2025-09-23 02:21:16.218402: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f1ba00 of size 256 next 1084\n",
      "2025-09-23 02:21:16.218404: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f1bb00 of size 256 next 1085\n",
      "2025-09-23 02:21:16.218405: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f1bc00 of size 50176 next 1086\n",
      "2025-09-23 02:21:16.218406: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f28000 of size 50176 next 1087\n",
      "2025-09-23 02:21:16.218407: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f34400 of size 1024 next 1088\n",
      "2025-09-23 02:21:16.218408: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f34800 of size 1024 next 1089\n",
      "2025-09-23 02:21:16.218410: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f34c00 of size 50176 next 1090\n",
      "2025-09-23 02:21:16.218412: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f41000 of size 50176 next 1091\n",
      "2025-09-23 02:21:16.218413: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f4d400 of size 1024 next 1092\n",
      "2025-09-23 02:21:16.218414: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f4d800 of size 1024 next 1093\n",
      "2025-09-23 02:21:16.218415: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f4dc00 of size 50176 next 1094\n",
      "2025-09-23 02:21:16.218416: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f5a000 of size 50176 next 1095\n",
      "2025-09-23 02:21:16.218417: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f66400 of size 50176 next 1096\n",
      "2025-09-23 02:21:16.218419: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f72800 of size 50176 next 1097\n",
      "2025-09-23 02:21:16.218420: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f7ec00 of size 256 next 1098\n",
      "2025-09-23 02:21:16.218421: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f7ed00 of size 256 next 1099\n",
      "2025-09-23 02:21:16.218422: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f7ee00 of size 256 next 1100\n",
      "2025-09-23 02:21:16.218423: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f7ef00 of size 256 next 1101\n",
      "2025-09-23 02:21:16.218425: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f7f000 of size 256 next 1102\n",
      "2025-09-23 02:21:16.218426: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f7f100 of size 256 next 1103\n",
      "2025-09-23 02:21:16.218427: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f7f200 of size 256 next 1104\n",
      "2025-09-23 02:21:16.218428: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f7f300 of size 256 next 1105\n",
      "2025-09-23 02:21:16.218429: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f7f400 of size 50176 next 1106\n",
      "2025-09-23 02:21:16.218431: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f8b800 of size 50176 next 1107\n",
      "2025-09-23 02:21:16.218432: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f97c00 of size 50176 next 1108\n",
      "2025-09-23 02:21:16.218433: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fa4000 of size 50176 next 1109\n",
      "2025-09-23 02:21:16.218434: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fb0400 of size 1024 next 1110\n",
      "2025-09-23 02:21:16.218435: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fb0800 of size 1024 next 1111\n",
      "2025-09-23 02:21:16.218437: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fb0c00 of size 1024 next 1112\n",
      "2025-09-23 02:21:16.218438: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fb1000 of size 1024 next 1113\n",
      "2025-09-23 02:21:16.218439: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fb1400 of size 1024 next 1114\n",
      "2025-09-23 02:21:16.218440: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fb1800 of size 1024 next 1115\n",
      "2025-09-23 02:21:16.218441: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fb1c00 of size 1024 next 1116\n",
      "2025-09-23 02:21:16.218442: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fb2000 of size 1024 next 1117\n",
      "2025-09-23 02:21:16.218444: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fb2400 of size 8192 next 1118\n",
      "2025-09-23 02:21:16.218445: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fb4400 of size 8192 next 1119\n",
      "2025-09-23 02:21:16.218446: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fb6400 of size 8192 next 1120\n",
      "2025-09-23 02:21:16.218447: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fb8400 of size 8192 next 1121\n",
      "2025-09-23 02:21:16.218449: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fba400 of size 1024 next 1122\n",
      "2025-09-23 02:21:16.218450: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fba800 of size 1024 next 1123\n",
      "2025-09-23 02:21:16.218451: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fbac00 of size 1024 next 1124\n",
      "2025-09-23 02:21:16.218452: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fbb000 of size 1024 next 1125\n",
      "2025-09-23 02:21:16.218454: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fbb400 of size 1024 next 1126\n",
      "2025-09-23 02:21:16.218455: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fbb800 of size 1024 next 1127\n",
      "2025-09-23 02:21:16.218456: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fbbc00 of size 1024 next 1128\n",
      "2025-09-23 02:21:16.218457: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fbc000 of size 1024 next 1129\n",
      "2025-09-23 02:21:16.218458: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fbc400 of size 50176 next 1130\n",
      "2025-09-23 02:21:16.218459: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fc8800 of size 50176 next 1131\n",
      "2025-09-23 02:21:16.218461: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fd4c00 of size 256 next 1132\n",
      "2025-09-23 02:21:16.218462: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fd4d00 of size 256 next 1133\n",
      "2025-09-23 02:21:16.218463: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fd4e00 of size 50176 next 1134\n",
      "2025-09-23 02:21:16.218464: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fe1200 of size 50176 next 1135\n",
      "2025-09-23 02:21:16.218465: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fed600 of size 256 next 1136\n",
      "2025-09-23 02:21:16.218467: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fed700 of size 256 next 1137\n",
      "2025-09-23 02:21:16.218468: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fed800 of size 75776 next 18446744073709551615\n",
      "2025-09-23 02:21:16.218469: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 8388608\n",
      "2025-09-23 02:21:16.218471: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318000000 of size 230400 next 305\n",
      "2025-09-23 02:21:16.218472: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318038400 of size 230400 next 307\n",
      "2025-09-23 02:21:16.218473: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318070800 of size 230400 next 319\n",
      "2025-09-23 02:21:16.218475: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13180a8c00 of size 230400 next 318\n",
      "2025-09-23 02:21:16.218476: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13180e1000 of size 230400 next 321\n",
      "2025-09-23 02:21:16.218477: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318119400 of size 36864 next 388\n",
      "2025-09-23 02:21:16.218478: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318122400 of size 8192 next 469\n",
      "2025-09-23 02:21:16.218479: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318124400 of size 8192 next 473\n",
      "2025-09-23 02:21:16.218481: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318126400 of size 512 next 515\n",
      "2025-09-23 02:21:16.218482: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1318126600 of size 256 next 1751\n",
      "2025-09-23 02:21:16.218483: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318126700 of size 256 next 2730\n",
      "2025-09-23 02:21:16.218484: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318126800 of size 256 next 2199\n",
      "2025-09-23 02:21:16.218486: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318126900 of size 256 next 517\n",
      "2025-09-23 02:21:16.218487: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318126a00 of size 512 next 518\n",
      "2025-09-23 02:21:16.218488: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318126c00 of size 512 next 519\n",
      "2025-09-23 02:21:16.218489: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318126e00 of size 256 next 2407\n",
      "2025-09-23 02:21:16.218491: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1318126f00 of size 512 next 273\n",
      "2025-09-23 02:21:16.218492: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318127100 of size 256 next 522\n",
      "2025-09-23 02:21:16.218493: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318127200 of size 256 next 525\n",
      "2025-09-23 02:21:16.218495: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318127300 of size 768 next 508\n",
      "2025-09-23 02:21:16.218498: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318127600 of size 3584 next 484\n",
      "2025-09-23 02:21:16.218499: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318128400 of size 12288 next 373\n",
      "2025-09-23 02:21:16.218501: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131812b400 of size 73728 next 372\n",
      "2025-09-23 02:21:16.218502: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131813d400 of size 36864 next 408\n",
      "2025-09-23 02:21:16.218503: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318146400 of size 16384 next 528\n",
      "2025-09-23 02:21:16.218505: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814a400 of size 1024 next 552\n",
      "2025-09-23 02:21:16.218506: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814a800 of size 1024 next 550\n",
      "2025-09-23 02:21:16.218507: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814ac00 of size 6144 next 588\n",
      "2025-09-23 02:21:16.218509: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814c400 of size 1024 next 593\n",
      "2025-09-23 02:21:16.218510: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814c800 of size 1024 next 591\n",
      "2025-09-23 02:21:16.218518: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814cc00 of size 1024 next 1868\n",
      "2025-09-23 02:21:16.218521: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814d000 of size 1024 next 596\n",
      "2025-09-23 02:21:16.218523: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814d400 of size 256 next 597\n",
      "2025-09-23 02:21:16.218524: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814d500 of size 1024 next 598\n",
      "2025-09-23 02:21:16.218526: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814d900 of size 256 next 601\n",
      "2025-09-23 02:21:16.218527: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814da00 of size 256 next 603\n",
      "2025-09-23 02:21:16.218528: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814db00 of size 256 next 362\n",
      "2025-09-23 02:21:16.218529: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814dc00 of size 256 next 606\n",
      "2025-09-23 02:21:16.218531: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814dd00 of size 1792 next 540\n",
      "2025-09-23 02:21:16.218532: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814e400 of size 13312 next 281\n",
      "2025-09-23 02:21:16.218534: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318151800 of size 1382400 next 279\n",
      "2025-09-23 02:21:16.218535: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13182a3000 of size 1382400 next 299\n",
      "2025-09-23 02:21:16.218536: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13183f4800 of size 16384 next 516\n",
      "2025-09-23 02:21:16.218538: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13183f8800 of size 16384 next 526\n",
      "2025-09-23 02:21:16.218540: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13183fc800 of size 1024 next 555\n",
      "2025-09-23 02:21:16.218542: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13183fcc00 of size 1024 next 556\n",
      "2025-09-23 02:21:16.218543: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13183fd000 of size 256 next 2459\n",
      "2025-09-23 02:21:16.218545: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13183fd100 of size 256 next 2713\n",
      "2025-09-23 02:21:16.218546: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13183fd200 of size 1536 next 560\n",
      "2025-09-23 02:21:16.218547: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13183fd800 of size 1024 next 562\n",
      "2025-09-23 02:21:16.218549: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 13183fdc00 of size 512 next 568\n",
      "2025-09-23 02:21:16.218550: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13183fde00 of size 1024 next 571\n",
      "2025-09-23 02:21:16.218551: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13183fe200 of size 1536 next 557\n",
      "2025-09-23 02:21:16.218552: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13183fe800 of size 8192 next 558\n",
      "2025-09-23 02:21:16.218554: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318400800 of size 1024 next 574\n",
      "2025-09-23 02:21:16.218555: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318400c00 of size 1024 next 573\n",
      "2025-09-23 02:21:16.218556: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318401000 of size 1024 next 1943\n",
      "2025-09-23 02:21:16.218557: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1318401400 of size 512 next 2393\n",
      "2025-09-23 02:21:16.218559: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318401600 of size 256 next 2516\n",
      "2025-09-23 02:21:16.218560: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318401700 of size 256 next 577\n",
      "2025-09-23 02:21:16.218561: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318401800 of size 256 next 580\n",
      "2025-09-23 02:21:16.218562: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318401900 of size 1024 next 582\n",
      "2025-09-23 02:21:16.218564: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318401d00 of size 256 next 584\n",
      "2025-09-23 02:21:16.218565: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318401e00 of size 256 next 578\n",
      "2025-09-23 02:21:16.218566: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1318401f00 of size 512 next 586\n",
      "2025-09-23 02:21:16.218568: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318402100 of size 1024 next 589\n",
      "2025-09-23 02:21:16.218569: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318402500 of size 1024 next 576\n",
      "2025-09-23 02:21:16.218570: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318402900 of size 16128 next 411\n",
      "2025-09-23 02:21:16.218572: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318406800 of size 73728 next 410\n",
      "2025-09-23 02:21:16.218573: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318418800 of size 28672 next 524\n",
      "2025-09-23 02:21:16.218575: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131841f800 of size 1024 next 607\n",
      "2025-09-23 02:21:16.218576: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131841fc00 of size 1024 next 1893\n",
      "2025-09-23 02:21:16.218577: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318420000 of size 1024 next 610\n",
      "2025-09-23 02:21:16.218579: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318420400 of size 1536 next 628\n",
      "2025-09-23 02:21:16.218580: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318420a00 of size 3072 next 627\n",
      "2025-09-23 02:21:16.218581: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318421600 of size 512 next 632\n",
      "2025-09-23 02:21:16.218582: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318421800 of size 1536 next 635\n",
      "2025-09-23 02:21:16.218584: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318421e00 of size 512 next 637\n",
      "2025-09-23 02:21:16.218585: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318422000 of size 512 next 630\n",
      "2025-09-23 02:21:16.218586: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318422200 of size 256 next 1900\n",
      "2025-09-23 02:21:16.218587: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318422300 of size 256 next 2254\n",
      "2025-09-23 02:21:16.218589: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318422400 of size 256 next 2183\n",
      "2025-09-23 02:21:16.218590: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318422500 of size 256 next 639\n",
      "2025-09-23 02:21:16.218591: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318422600 of size 2048 next 640\n",
      "2025-09-23 02:21:16.218593: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318422e00 of size 2560 next 595\n",
      "2025-09-23 02:21:16.218594: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318423800 of size 8192 next 594\n",
      "2025-09-23 02:21:16.218595: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318425800 of size 75776 next 535\n",
      "2025-09-23 02:21:16.218597: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318438000 of size 50176 next 534\n",
      "2025-09-23 02:21:16.218598: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318444400 of size 50176 next 544\n",
      "2025-09-23 02:21:16.218599: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318450800 of size 50176 next 546\n",
      "2025-09-23 02:21:16.218601: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131845cc00 of size 50176 next 548\n",
      "2025-09-23 02:21:16.218602: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318469000 of size 50176 next 553\n",
      "2025-09-23 02:21:16.218603: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318475400 of size 50176 next 564\n",
      "2025-09-23 02:21:16.218605: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318481800 of size 50176 next 565\n",
      "2025-09-23 02:21:16.218606: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131848dc00 of size 50176 next 567\n",
      "2025-09-23 02:21:16.218607: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131849a000 of size 50176 next 572\n",
      "2025-09-23 02:21:16.218608: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184a6400 of size 50176 next 581\n",
      "2025-09-23 02:21:16.218610: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184b2800 of size 50176 next 583\n",
      "2025-09-23 02:21:16.218611: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184bec00 of size 50176 next 585\n",
      "2025-09-23 02:21:16.218612: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184cb000 of size 50176 next 590\n",
      "2025-09-23 02:21:16.218613: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d7400 of size 1024 next 612\n",
      "2025-09-23 02:21:16.218614: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d7800 of size 1024 next 611\n",
      "2025-09-23 02:21:16.218616: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d7c00 of size 1024 next 2383\n",
      "2025-09-23 02:21:16.218617: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d8000 of size 256 next 2681\n",
      "2025-09-23 02:21:16.218618: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d8100 of size 256 next 2168\n",
      "2025-09-23 02:21:16.218619: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d8200 of size 256 next 2702\n",
      "2025-09-23 02:21:16.218621: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d8300 of size 256 next 616\n",
      "2025-09-23 02:21:16.218622: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d8400 of size 256 next 617\n",
      "2025-09-23 02:21:16.218623: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d8500 of size 1024 next 618\n",
      "2025-09-23 02:21:16.218624: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d8900 of size 256 next 621\n",
      "2025-09-23 02:21:16.218626: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d8a00 of size 256 next 623\n",
      "2025-09-23 02:21:16.218627: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d8b00 of size 256 next 2277\n",
      "2025-09-23 02:21:16.218628: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d8c00 of size 256 next 625\n",
      "2025-09-23 02:21:16.218630: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d8d00 of size 2048 next 614\n",
      "2025-09-23 02:21:16.218631: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d9500 of size 8192 next 615\n",
      "2025-09-23 02:21:16.218632: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184db500 of size 4096 next 645\n",
      "2025-09-23 02:21:16.218634: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184dc500 of size 512 next 648\n",
      "2025-09-23 02:21:16.218635: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184dc700 of size 2048 next 649\n",
      "2025-09-23 02:21:16.218636: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184dcf00 of size 512 next 646\n",
      "2025-09-23 02:21:16.218638: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184dd100 of size 512 next 647\n",
      "2025-09-23 02:21:16.218639: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184dd300 of size 256 next 2417\n",
      "2025-09-23 02:21:16.218640: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184dd400 of size 256 next 2006\n",
      "2025-09-23 02:21:16.218642: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184dd500 of size 256 next 2152\n",
      "2025-09-23 02:21:16.218643: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184dd600 of size 256 next 655\n",
      "2025-09-23 02:21:16.218644: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184dd700 of size 2048 next 656\n",
      "2025-09-23 02:21:16.218646: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184ddf00 of size 2048 next 657\n",
      "2025-09-23 02:21:16.218647: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184de700 of size 4096 next 661\n",
      "2025-09-23 02:21:16.218648: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184df700 of size 512 next 664\n",
      "2025-09-23 02:21:16.218650: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184df900 of size 2048 next 667\n",
      "2025-09-23 02:21:16.218651: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184e0100 of size 512 next 662\n",
      "2025-09-23 02:21:16.218652: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184e0300 of size 512 next 663\n",
      "2025-09-23 02:21:16.218654: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184e0500 of size 256 next 1810\n",
      "2025-09-23 02:21:16.218655: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184e0600 of size 256 next 2113\n",
      "2025-09-23 02:21:16.218656: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184e0700 of size 256 next 2728\n",
      "2025-09-23 02:21:16.218657: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184e0800 of size 256 next 670\n",
      "2025-09-23 02:21:16.218659: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184e0900 of size 2048 next 671\n",
      "2025-09-23 02:21:16.218660: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184e1100 of size 2048 next 672\n",
      "2025-09-23 02:21:16.218661: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184e1900 of size 4096 next 675\n",
      "2025-09-23 02:21:16.218663: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184e2900 of size 512 next 676\n",
      "2025-09-23 02:21:16.218664: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184e2b00 of size 3328 next 600\n",
      "2025-09-23 02:21:16.218665: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184e3800 of size 50176 next 599\n",
      "2025-09-23 02:21:16.218666: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184efc00 of size 50176 next 602\n",
      "2025-09-23 02:21:16.218667: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184fc000 of size 50176 next 604\n",
      "2025-09-23 02:21:16.218669: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318508400 of size 50176 next 609\n",
      "2025-09-23 02:21:16.218670: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318514800 of size 512 next 677\n",
      "2025-09-23 02:21:16.218671: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318514a00 of size 512 next 678\n",
      "2025-09-23 02:21:16.218673: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318514c00 of size 512 next 2284\n",
      "2025-09-23 02:21:16.218674: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1318514e00 of size 256 next 2188\n",
      "2025-09-23 02:21:16.218675: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318514f00 of size 256 next 682\n",
      "2025-09-23 02:21:16.218677: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318515000 of size 768 next 683\n",
      "2025-09-23 02:21:16.218678: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318515300 of size 768 next 684\n",
      "2025-09-23 02:21:16.218679: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318515600 of size 1024 next 1773\n",
      "2025-09-23 02:21:16.218681: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1318515a00 of size 512 next 688\n",
      "2025-09-23 02:21:16.218682: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318515c00 of size 768 next 690\n",
      "2025-09-23 02:21:16.218683: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318515f00 of size 768 next 691\n",
      "2025-09-23 02:21:16.218685: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1318516200 of size 512 next 1774\n",
      "2025-09-23 02:21:16.218686: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318516400 of size 256 next 1916\n",
      "2025-09-23 02:21:16.218695: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318516500 of size 256 next 2055\n",
      "2025-09-23 02:21:16.218697: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1318516600 of size 512 next 692\n",
      "2025-09-23 02:21:16.218699: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318516800 of size 256 next 695\n",
      "2025-09-23 02:21:16.218700: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318516900 of size 768 next 696\n",
      "2025-09-23 02:21:16.218701: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318516c00 of size 512 next 701\n",
      "2025-09-23 02:21:16.218702: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318516e00 of size 512 next 697\n",
      "2025-09-23 02:21:16.218704: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318517000 of size 256 next 1967\n",
      "2025-09-23 02:21:16.218705: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318517100 of size 256 next 2773\n",
      "2025-09-23 02:21:16.218706: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1318517200 of size 512 next 703\n",
      "2025-09-23 02:21:16.218707: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318517400 of size 768 next 706\n",
      "2025-09-23 02:21:16.218708: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318517700 of size 768 next 704\n",
      "2025-09-23 02:21:16.218710: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318517a00 of size 1280 next 1796\n",
      "2025-09-23 02:21:16.218711: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318517f00 of size 256 next 708\n",
      "2025-09-23 02:21:16.218712: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318518000 of size 768 next 711\n",
      "2025-09-23 02:21:16.218713: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318518300 of size 768 next 709\n",
      "2025-09-23 02:21:16.218715: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318518600 of size 512 next 587\n",
      "2025-09-23 02:21:16.218716: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318518800 of size 512 next 2005\n",
      "2025-09-23 02:21:16.218717: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318518a00 of size 768 next 693\n",
      "2025-09-23 02:21:16.218718: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318518d00 of size 5888 next 694\n",
      "2025-09-23 02:21:16.218719: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851a400 of size 256 next 1939\n",
      "2025-09-23 02:21:16.218721: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851a500 of size 256 next 2218\n",
      "2025-09-23 02:21:16.218722: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 131851a600 of size 512 next 760\n",
      "2025-09-23 02:21:16.218723: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851a800 of size 512 next 761\n",
      "2025-09-23 02:21:16.218724: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851aa00 of size 512 next 762\n",
      "2025-09-23 02:21:16.218725: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 131851ac00 of size 512 next 447\n",
      "2025-09-23 02:21:16.218726: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851ae00 of size 256 next 1949\n",
      "2025-09-23 02:21:16.218728: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851af00 of size 256 next 765\n",
      "2025-09-23 02:21:16.218729: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851b000 of size 256 next 766\n",
      "2025-09-23 02:21:16.218730: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851b100 of size 256 next 767\n",
      "2025-09-23 02:21:16.218731: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851b200 of size 256 next 770\n",
      "2025-09-23 02:21:16.218732: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851b300 of size 256 next 771\n",
      "2025-09-23 02:21:16.218733: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851b400 of size 256 next 772\n",
      "2025-09-23 02:21:16.218735: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851b500 of size 256 next 773\n",
      "2025-09-23 02:21:16.218736: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851b600 of size 256 next 774\n",
      "2025-09-23 02:21:16.218738: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851b700 of size 256 next 777\n",
      "2025-09-23 02:21:16.218739: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851b800 of size 256 next 775\n",
      "2025-09-23 02:21:16.218740: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851b900 of size 256 next 776\n",
      "2025-09-23 02:21:16.218741: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851ba00 of size 256 next 778\n",
      "2025-09-23 02:21:16.218742: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851bb00 of size 256 next 780\n",
      "2025-09-23 02:21:16.218743: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851bc00 of size 256 next 781\n",
      "2025-09-23 02:21:16.218745: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851bd00 of size 256 next 782\n",
      "2025-09-23 02:21:16.218746: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851be00 of size 256 next 750\n",
      "2025-09-23 02:21:16.218747: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851bf00 of size 6912 next 749\n",
      "2025-09-23 02:21:16.218748: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851da00 of size 256 next 786\n",
      "2025-09-23 02:21:16.218749: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851db00 of size 256 next 787\n",
      "2025-09-23 02:21:16.218751: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851dc00 of size 256 next 788\n",
      "2025-09-23 02:21:16.218752: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851dd00 of size 256 next 789\n",
      "2025-09-23 02:21:16.218753: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851de00 of size 256 next 790\n",
      "2025-09-23 02:21:16.218754: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851df00 of size 256 next 791\n",
      "2025-09-23 02:21:16.218755: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851e000 of size 256 next 792\n",
      "2025-09-23 02:21:16.218757: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851e100 of size 2048 next 793\n",
      "2025-09-23 02:21:16.218758: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851e900 of size 2048 next 794\n",
      "2025-09-23 02:21:16.218759: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851f100 of size 2048 next 795\n",
      "2025-09-23 02:21:16.218760: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851f900 of size 2048 next 796\n",
      "2025-09-23 02:21:16.218761: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318520100 of size 256 next 797\n",
      "2025-09-23 02:21:16.218763: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318520200 of size 256 next 798\n",
      "2025-09-23 02:21:16.218764: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318520300 of size 256 next 799\n",
      "2025-09-23 02:21:16.218765: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318520400 of size 256 next 800\n",
      "2025-09-23 02:21:16.218766: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318520500 of size 256 next 801\n",
      "2025-09-23 02:21:16.218767: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318520600 of size 256 next 802\n",
      "2025-09-23 02:21:16.218768: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318520700 of size 256 next 803\n",
      "2025-09-23 02:21:16.218770: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318520800 of size 256 next 804\n",
      "2025-09-23 02:21:16.218771: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318520900 of size 256 next 809\n",
      "2025-09-23 02:21:16.218772: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318520a00 of size 256 next 810\n",
      "2025-09-23 02:21:16.218773: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318520b00 of size 256 next 620\n",
      "2025-09-23 02:21:16.218774: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318520c00 of size 50176 next 619\n",
      "2025-09-23 02:21:16.218776: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131852d000 of size 50176 next 622\n",
      "2025-09-23 02:21:16.218777: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318539400 of size 52224 next 314\n",
      "2025-09-23 02:21:16.218779: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318546000 of size 1382400 next 313\n",
      "2025-09-23 02:21:16.218780: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318697800 of size 225792 next 634\n",
      "2025-09-23 02:21:16.218781: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13186cea00 of size 112896 next 633\n",
      "2025-09-23 02:21:16.218783: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13186ea300 of size 112896 next 636\n",
      "2025-09-23 02:21:16.218784: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318705c00 of size 107520 next 638\n",
      "2025-09-23 02:21:16.218785: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318720000 of size 256 next 712\n",
      "2025-09-23 02:21:16.218786: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318720100 of size 768 next 714\n",
      "2025-09-23 02:21:16.218787: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318720400 of size 512 next 715\n",
      "2025-09-23 02:21:16.218789: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318720600 of size 512 next 718\n",
      "2025-09-23 02:21:16.218790: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318720800 of size 512 next 2560\n",
      "2025-09-23 02:21:16.218791: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318720a00 of size 512 next 722\n",
      "2025-09-23 02:21:16.218792: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318720c00 of size 768 next 723\n",
      "2025-09-23 02:21:16.218793: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318720f00 of size 768 next 724\n",
      "2025-09-23 02:21:16.218795: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318721200 of size 256 next 2477\n",
      "2025-09-23 02:21:16.218796: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318721300 of size 256 next 2349\n",
      "2025-09-23 02:21:16.218797: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318721400 of size 256 next 2314\n",
      "2025-09-23 02:21:16.218798: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318721500 of size 256 next 1892\n",
      "2025-09-23 02:21:16.218799: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318721600 of size 256 next 2173\n",
      "2025-09-23 02:21:16.218800: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318721700 of size 256 next 727\n",
      "2025-09-23 02:21:16.218802: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318721800 of size 768 next 743\n",
      "2025-09-23 02:21:16.218803: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318721b00 of size 768 next 2616\n",
      "2025-09-23 02:21:16.218804: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318721e00 of size 768 next 746\n",
      "2025-09-23 02:21:16.218805: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318722100 of size 768 next 747\n",
      "2025-09-23 02:21:16.218806: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318722400 of size 768 next 748\n",
      "2025-09-23 02:21:16.218808: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318722700 of size 256 next 2613\n",
      "2025-09-23 02:21:16.218809: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318722800 of size 256 next 1831\n",
      "2025-09-23 02:21:16.218810: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318722900 of size 256 next 1906\n",
      "2025-09-23 02:21:16.218811: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318722a00 of size 256 next 1935\n",
      "2025-09-23 02:21:16.218812: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318722b00 of size 256 next 2530\n",
      "2025-09-23 02:21:16.218814: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318722c00 of size 256 next 752\n",
      "2025-09-23 02:21:16.218815: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318722d00 of size 256 next 753\n",
      "2025-09-23 02:21:16.218816: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318722e00 of size 768 next 754\n",
      "2025-09-23 02:21:16.218817: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318723100 of size 512 next 756\n",
      "2025-09-23 02:21:16.218818: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318723300 of size 768 next 713\n",
      "2025-09-23 02:21:16.218820: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318723600 of size 11776 next 698\n",
      "2025-09-23 02:21:16.218821: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318726400 of size 25600 next 686\n",
      "2025-09-23 02:21:16.218822: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131872c800 of size 51200 next 685\n",
      "2025-09-23 02:21:16.218824: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318739000 of size 25600 next 699\n",
      "2025-09-23 02:21:16.218825: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131873f400 of size 768 next 729\n",
      "2025-09-23 02:21:16.218826: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131873f700 of size 768 next 728\n",
      "2025-09-23 02:21:16.218827: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131873fa00 of size 256 next 1942\n",
      "2025-09-23 02:21:16.218828: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131873fb00 of size 256 next 2142\n",
      "2025-09-23 02:21:16.218830: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131873fc00 of size 256 next 2374\n",
      "2025-09-23 02:21:16.218831: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131873fd00 of size 256 next 511\n",
      "2025-09-23 02:21:16.218832: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131873fe00 of size 256 next 1857\n",
      "2025-09-23 02:21:16.218833: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 131873ff00 of size 256 next 733\n",
      "2025-09-23 02:21:16.218834: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318740000 of size 256 next 734\n",
      "2025-09-23 02:21:16.218836: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318740100 of size 768 next 735\n",
      "2025-09-23 02:21:16.218837: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318740400 of size 512 next 737\n",
      "2025-09-23 02:21:16.218838: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318740600 of size 512 next 738\n",
      "2025-09-23 02:21:16.218839: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318740800 of size 256 next 2238\n",
      "2025-09-23 02:21:16.218840: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318740900 of size 256 next 2065\n",
      "2025-09-23 02:21:16.218841: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318740a00 of size 256 next 1933\n",
      "2025-09-23 02:21:16.218843: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318740b00 of size 256 next 742\n",
      "2025-09-23 02:21:16.218844: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318740c00 of size 1024 next 731\n",
      "2025-09-23 02:21:16.218845: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318741000 of size 6912 next 732\n",
      "2025-09-23 02:21:16.218846: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318742b00 of size 1792 next 783\n",
      "2025-09-23 02:21:16.218848: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318743200 of size 1792 next 784\n",
      "2025-09-23 02:21:16.218849: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318743900 of size 1792 next 785\n",
      "2025-09-23 02:21:16.218850: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318744000 of size 2304 next 779\n",
      "2025-09-23 02:21:16.218851: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318744900 of size 3840 next 653\n",
      "2025-09-23 02:21:16.218853: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318745800 of size 153600 next 652\n",
      "2025-09-23 02:21:16.218854: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131876b000 of size 36864 next 717\n",
      "2025-09-23 02:21:16.218857: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318774000 of size 256 next 842\n",
      "2025-09-23 02:21:16.218858: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318774100 of size 256 next 843\n",
      "2025-09-23 02:21:16.218860: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318774200 of size 256 next 844\n",
      "2025-09-23 02:21:16.218861: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318774300 of size 256 next 845\n",
      "2025-09-23 02:21:16.218862: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318774400 of size 256 next 846\n",
      "2025-09-23 02:21:16.218863: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318774500 of size 256 next 847\n",
      "2025-09-23 02:21:16.218865: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318774600 of size 256 next 848\n",
      "2025-09-23 02:21:16.218866: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318774700 of size 256 next 849\n",
      "2025-09-23 02:21:16.218867: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318774800 of size 8192 next 850\n",
      "2025-09-23 02:21:16.218868: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318776800 of size 8192 next 851\n",
      "2025-09-23 02:21:16.218870: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318778800 of size 8192 next 852\n",
      "2025-09-23 02:21:16.218871: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877a800 of size 8192 next 853\n",
      "2025-09-23 02:21:16.218872: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877c800 of size 256 next 854\n",
      "2025-09-23 02:21:16.218874: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877c900 of size 256 next 855\n",
      "2025-09-23 02:21:16.218875: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877ca00 of size 256 next 856\n",
      "2025-09-23 02:21:16.218876: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877cb00 of size 256 next 857\n",
      "2025-09-23 02:21:16.218877: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877cc00 of size 256 next 858\n",
      "2025-09-23 02:21:16.218879: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877cd00 of size 256 next 859\n",
      "2025-09-23 02:21:16.218880: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877ce00 of size 256 next 860\n",
      "2025-09-23 02:21:16.218881: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877cf00 of size 256 next 861\n",
      "2025-09-23 02:21:16.218883: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877d000 of size 256 next 866\n",
      "2025-09-23 02:21:16.218884: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877d100 of size 256 next 867\n",
      "2025-09-23 02:21:16.218885: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877d200 of size 256 next 868\n",
      "2025-09-23 02:21:16.218886: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877d300 of size 256 next 869\n",
      "2025-09-23 02:21:16.218888: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877d400 of size 256 next 870\n",
      "2025-09-23 02:21:16.218889: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877d500 of size 256 next 871\n",
      "2025-09-23 02:21:16.218890: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877d600 of size 256 next 872\n",
      "2025-09-23 02:21:16.218892: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877d700 of size 256 next 873\n",
      "2025-09-23 02:21:16.218893: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877d800 of size 4096 next 764\n",
      "2025-09-23 02:21:16.218894: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877e800 of size 73728 next 650\n",
      "2025-09-23 02:21:16.218896: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318790800 of size 456704 next 18446744073709551615\n",
      "2025-09-23 02:21:16.218897: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 16777216\n",
      "2025-09-23 02:21:16.218899: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318800000 of size 230400 next 651\n",
      "2025-09-23 02:21:16.218900: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318838400 of size 230400 next 679\n",
      "2025-09-23 02:21:16.218902: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318870800 of size 230400 next 666\n",
      "2025-09-23 02:21:16.218903: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13188a8c00 of size 230400 next 665\n",
      "2025-09-23 02:21:16.218904: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13188e1000 of size 230400 next 668\n",
      "2025-09-23 02:21:16.218906: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318919400 of size 61440 next 702\n",
      "2025-09-23 02:21:16.218907: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318928400 of size 73728 next 707\n",
      "2025-09-23 02:21:16.218908: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893a400 of size 1280 next 805\n",
      "2025-09-23 02:21:16.218909: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893a900 of size 1280 next 806\n",
      "2025-09-23 02:21:16.218911: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893ae00 of size 1280 next 807\n",
      "2025-09-23 02:21:16.218912: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893b300 of size 1280 next 808\n",
      "2025-09-23 02:21:16.218913: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893b800 of size 256 next 811\n",
      "2025-09-23 02:21:16.218914: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893b900 of size 256 next 812\n",
      "2025-09-23 02:21:16.218915: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893ba00 of size 256 next 813\n",
      "2025-09-23 02:21:16.218917: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893bb00 of size 256 next 814\n",
      "2025-09-23 02:21:16.218918: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893bc00 of size 256 next 815\n",
      "2025-09-23 02:21:16.218919: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893bd00 of size 4096 next 816\n",
      "2025-09-23 02:21:16.218921: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893cd00 of size 4096 next 817\n",
      "2025-09-23 02:21:16.218922: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893dd00 of size 4096 next 818\n",
      "2025-09-23 02:21:16.218923: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893ed00 of size 4096 next 819\n",
      "2025-09-23 02:21:16.218924: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893fd00 of size 256 next 820\n",
      "2025-09-23 02:21:16.218926: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893fe00 of size 256 next 821\n",
      "2025-09-23 02:21:16.218927: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893ff00 of size 256 next 822\n",
      "2025-09-23 02:21:16.218928: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318940000 of size 256 next 823\n",
      "2025-09-23 02:21:16.218929: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318940100 of size 256 next 824\n",
      "2025-09-23 02:21:16.218931: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318940200 of size 256 next 825\n",
      "2025-09-23 02:21:16.218932: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318940300 of size 256 next 826\n",
      "2025-09-23 02:21:16.218933: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318940400 of size 256 next 827\n",
      "2025-09-23 02:21:16.218935: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318940500 of size 12032 next 716\n",
      "2025-09-23 02:21:16.218936: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318943400 of size 58368 next 644\n",
      "2025-09-23 02:21:16.218937: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318951800 of size 1382400 next 642\n",
      "2025-09-23 02:21:16.218939: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aa3000 of size 230400 next 680\n",
      "2025-09-23 02:21:16.218940: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318adb400 of size 36864 next 736\n",
      "2025-09-23 02:21:16.218941: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ae4400 of size 8192 next 828\n",
      "2025-09-23 02:21:16.218942: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ae6400 of size 8192 next 829\n",
      "2025-09-23 02:21:16.218944: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ae8400 of size 8192 next 830\n",
      "2025-09-23 02:21:16.218945: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aea400 of size 256 next 831\n",
      "2025-09-23 02:21:16.218946: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aea500 of size 256 next 832\n",
      "2025-09-23 02:21:16.218948: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aea600 of size 256 next 833\n",
      "2025-09-23 02:21:16.218949: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aea700 of size 256 next 834\n",
      "2025-09-23 02:21:16.218950: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aea800 of size 256 next 835\n",
      "2025-09-23 02:21:16.218952: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aea900 of size 256 next 836\n",
      "2025-09-23 02:21:16.218953: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aeaa00 of size 256 next 837\n",
      "2025-09-23 02:21:16.218954: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aeab00 of size 256 next 838\n",
      "2025-09-23 02:21:16.218955: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aeac00 of size 2304 next 839\n",
      "2025-09-23 02:21:16.218956: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aeb500 of size 2304 next 840\n",
      "2025-09-23 02:21:16.218958: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aebe00 of size 2304 next 841\n",
      "2025-09-23 02:21:16.218959: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aec700 of size 3328 next 720\n",
      "2025-09-23 02:21:16.218960: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aed400 of size 73728 next 719\n",
      "2025-09-23 02:21:16.218961: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aff400 of size 73728 next 725\n",
      "2025-09-23 02:21:16.218963: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b11400 of size 36864 next 755\n",
      "2025-09-23 02:21:16.218964: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b1a400 of size 36864 next 740\n",
      "2025-09-23 02:21:16.218965: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b23400 of size 73728 next 739\n",
      "2025-09-23 02:21:16.218966: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b35400 of size 73728 next 745\n",
      "2025-09-23 02:21:16.218968: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b47400 of size 8192 next 885\n",
      "2025-09-23 02:21:16.218969: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b49400 of size 8192 next 886\n",
      "2025-09-23 02:21:16.218970: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b4b400 of size 8192 next 887\n",
      "2025-09-23 02:21:16.218971: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b4d400 of size 256 next 888\n",
      "2025-09-23 02:21:16.218972: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b4d500 of size 256 next 889\n",
      "2025-09-23 02:21:16.218974: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b4d600 of size 256 next 890\n",
      "2025-09-23 02:21:16.218975: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b4d700 of size 256 next 891\n",
      "2025-09-23 02:21:16.218976: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b4d800 of size 256 next 892\n",
      "2025-09-23 02:21:16.218977: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b4d900 of size 256 next 893\n",
      "2025-09-23 02:21:16.218979: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b4da00 of size 256 next 894\n",
      "2025-09-23 02:21:16.218980: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b4db00 of size 256 next 895\n",
      "2025-09-23 02:21:16.218981: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b4dc00 of size 8192 next 896\n",
      "2025-09-23 02:21:16.218983: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b4fc00 of size 8192 next 897\n",
      "2025-09-23 02:21:16.218984: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b51c00 of size 8192 next 898\n",
      "2025-09-23 02:21:16.218985: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b53c00 of size 8192 next 899\n",
      "2025-09-23 02:21:16.218987: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b55c00 of size 256 next 900\n",
      "2025-09-23 02:21:16.218988: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b55d00 of size 256 next 901\n",
      "2025-09-23 02:21:16.218989: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b55e00 of size 256 next 902\n",
      "2025-09-23 02:21:16.218990: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b55f00 of size 256 next 903\n",
      "2025-09-23 02:21:16.218992: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b56000 of size 256 next 904\n",
      "2025-09-23 02:21:16.218993: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b56100 of size 256 next 905\n",
      "2025-09-23 02:21:16.218994: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b56200 of size 256 next 906\n",
      "2025-09-23 02:21:16.218995: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b56300 of size 256 next 907\n",
      "2025-09-23 02:21:16.218997: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b56400 of size 2304 next 908\n",
      "2025-09-23 02:21:16.218998: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b56d00 of size 2304 next 909\n",
      "2025-09-23 02:21:16.218999: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b57600 of size 2304 next 910\n",
      "2025-09-23 02:21:16.219000: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b57f00 of size 2304 next 911\n",
      "2025-09-23 02:21:16.219001: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b58800 of size 256 next 912\n",
      "2025-09-23 02:21:16.219003: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b58900 of size 256 next 913\n",
      "2025-09-23 02:21:16.219004: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b58a00 of size 256 next 914\n",
      "2025-09-23 02:21:16.219005: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b58b00 of size 256 next 915\n",
      "2025-09-23 02:21:16.219006: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b58c00 of size 256 next 916\n",
      "2025-09-23 02:21:16.219008: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b58d00 of size 256 next 917\n",
      "2025-09-23 02:21:16.219009: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b58e00 of size 256 next 918\n",
      "2025-09-23 02:21:16.219010: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b58f00 of size 256 next 919\n",
      "2025-09-23 02:21:16.219011: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b59000 of size 256 next 924\n",
      "2025-09-23 02:21:16.219013: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b59100 of size 256 next 925\n",
      "2025-09-23 02:21:16.219014: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b59200 of size 256 next 926\n",
      "2025-09-23 02:21:16.219015: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b59300 of size 256 next 759\n",
      "2025-09-23 02:21:16.219016: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b59400 of size 73728 next 758\n",
      "2025-09-23 02:21:16.219017: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b6b400 of size 8192 next 862\n",
      "2025-09-23 02:21:16.219019: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b6d400 of size 8192 next 863\n",
      "2025-09-23 02:21:16.219020: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b6f400 of size 8192 next 864\n",
      "2025-09-23 02:21:16.219021: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b71400 of size 8192 next 865\n",
      "2025-09-23 02:21:16.219022: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b73400 of size 2304 next 874\n",
      "2025-09-23 02:21:16.219024: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b73d00 of size 2304 next 875\n",
      "2025-09-23 02:21:16.219025: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b74600 of size 2304 next 876\n",
      "2025-09-23 02:21:16.219026: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b74f00 of size 256 next 877\n",
      "2025-09-23 02:21:16.219027: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b75000 of size 256 next 878\n",
      "2025-09-23 02:21:16.219028: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b75100 of size 256 next 879\n",
      "2025-09-23 02:21:16.219030: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b75200 of size 256 next 880\n",
      "2025-09-23 02:21:16.219031: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b75300 of size 256 next 881\n",
      "2025-09-23 02:21:16.219032: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b75400 of size 256 next 882\n",
      "2025-09-23 02:21:16.219034: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b75500 of size 256 next 883\n",
      "2025-09-23 02:21:16.219035: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b75600 of size 256 next 884\n",
      "2025-09-23 02:21:16.219036: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b75700 of size 15616 next 769\n",
      "2025-09-23 02:21:16.219037: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b79400 of size 57344 next 768\n",
      "2025-09-23 02:21:16.219039: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b87400 of size 8192 next 920\n",
      "2025-09-23 02:21:16.219040: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b89400 of size 8192 next 921\n",
      "2025-09-23 02:21:16.219041: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b8b400 of size 8192 next 922\n",
      "2025-09-23 02:21:16.219042: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b8d400 of size 8192 next 923\n",
      "2025-09-23 02:21:16.219044: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b8f400 of size 256 next 927\n",
      "2025-09-23 02:21:16.219045: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b8f500 of size 256 next 928\n",
      "2025-09-23 02:21:16.219046: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b8f600 of size 256 next 929\n",
      "2025-09-23 02:21:16.219048: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b8f700 of size 256 next 930\n",
      "2025-09-23 02:21:16.219049: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b8f800 of size 8192 next 931\n",
      "2025-09-23 02:21:16.219050: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b91800 of size 8192 next 932\n",
      "2025-09-23 02:21:16.219051: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b93800 of size 8192 next 933\n",
      "2025-09-23 02:21:16.219052: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b95800 of size 8192 next 934\n",
      "2025-09-23 02:21:16.219054: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b97800 of size 256 next 935\n",
      "2025-09-23 02:21:16.219055: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b97900 of size 256 next 936\n",
      "2025-09-23 02:21:16.219056: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b97a00 of size 256 next 937\n",
      "2025-09-23 02:21:16.219057: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b97b00 of size 256 next 938\n",
      "2025-09-23 02:21:16.219058: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b97c00 of size 256 next 939\n",
      "2025-09-23 02:21:16.219060: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b97d00 of size 256 next 940\n",
      "2025-09-23 02:21:16.219061: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b97e00 of size 256 next 941\n",
      "2025-09-23 02:21:16.219062: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b97f00 of size 256 next 942\n",
      "2025-09-23 02:21:16.219063: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b98000 of size 2304 next 943\n",
      "2025-09-23 02:21:16.219065: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b98900 of size 2304 next 944\n",
      "2025-09-23 02:21:16.219066: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b99200 of size 2304 next 945\n",
      "2025-09-23 02:21:16.219067: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b99b00 of size 2304 next 946\n",
      "2025-09-23 02:21:16.219068: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b9a400 of size 256 next 947\n",
      "2025-09-23 02:21:16.219069: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b9a500 of size 256 next 948\n",
      "2025-09-23 02:21:16.219071: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b9a600 of size 256 next 949\n",
      "2025-09-23 02:21:16.219072: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b9a700 of size 256 next 950\n",
      "2025-09-23 02:21:16.219073: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b9a800 of size 256 next 951\n",
      "2025-09-23 02:21:16.219074: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b9a900 of size 256 next 952\n",
      "2025-09-23 02:21:16.219076: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b9aa00 of size 256 next 953\n",
      "2025-09-23 02:21:16.219077: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b9ab00 of size 256 next 954\n",
      "2025-09-23 02:21:16.219078: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b9ac00 of size 8192 next 955\n",
      "2025-09-23 02:21:16.219079: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b9cc00 of size 8192 next 956\n",
      "2025-09-23 02:21:16.219080: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b9ec00 of size 8192 next 957\n",
      "2025-09-23 02:21:16.219082: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba0c00 of size 8192 next 958\n",
      "2025-09-23 02:21:16.219083: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba2c00 of size 256 next 959\n",
      "2025-09-23 02:21:16.219084: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba2d00 of size 256 next 960\n",
      "2025-09-23 02:21:16.219085: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba2e00 of size 256 next 961\n",
      "2025-09-23 02:21:16.219086: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba2f00 of size 256 next 962\n",
      "2025-09-23 02:21:16.219088: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba3000 of size 256 next 963\n",
      "2025-09-23 02:21:16.219089: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba3100 of size 256 next 964\n",
      "2025-09-23 02:21:16.219090: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba3200 of size 256 next 965\n",
      "2025-09-23 02:21:16.219091: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba3300 of size 256 next 966\n",
      "2025-09-23 02:21:16.219093: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba3400 of size 8192 next 967\n",
      "2025-09-23 02:21:16.219094: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba5400 of size 8192 next 968\n",
      "2025-09-23 02:21:16.219095: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba7400 of size 8192 next 969\n",
      "2025-09-23 02:21:16.219096: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba9400 of size 8192 next 970\n",
      "2025-09-23 02:21:16.219097: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bab400 of size 256 next 971\n",
      "2025-09-23 02:21:16.219099: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bab500 of size 256 next 972\n",
      "2025-09-23 02:21:16.219100: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bab600 of size 256 next 973\n",
      "2025-09-23 02:21:16.219101: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bab700 of size 256 next 974\n",
      "2025-09-23 02:21:16.219102: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bab800 of size 256 next 975\n",
      "2025-09-23 02:21:16.219103: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bab900 of size 256 next 976\n",
      "2025-09-23 02:21:16.219105: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318baba00 of size 256 next 977\n",
      "2025-09-23 02:21:16.219106: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318babb00 of size 256 next 978\n",
      "2025-09-23 02:21:16.219107: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318babc00 of size 2304 next 979\n",
      "2025-09-23 02:21:16.219109: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bac500 of size 2304 next 980\n",
      "2025-09-23 02:21:16.219110: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bace00 of size 2304 next 981\n",
      "2025-09-23 02:21:16.219111: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bad700 of size 2304 next 982\n",
      "2025-09-23 02:21:16.219112: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bae000 of size 256 next 983\n",
      "2025-09-23 02:21:16.219113: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bae100 of size 256 next 984\n",
      "2025-09-23 02:21:16.219115: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bae200 of size 256 next 985\n",
      "2025-09-23 02:21:16.219116: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bae300 of size 256 next 986\n",
      "2025-09-23 02:21:16.219117: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bae400 of size 256 next 987\n",
      "2025-09-23 02:21:16.219118: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bae500 of size 256 next 988\n",
      "2025-09-23 02:21:16.219119: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bae600 of size 256 next 989\n",
      "2025-09-23 02:21:16.219121: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bae700 of size 256 next 990\n",
      "2025-09-23 02:21:16.219122: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bae800 of size 8192 next 991\n",
      "2025-09-23 02:21:16.219123: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bb0800 of size 8192 next 992\n",
      "2025-09-23 02:21:16.219124: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bb2800 of size 8192 next 993\n",
      "2025-09-23 02:21:16.219126: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bb4800 of size 8192 next 994\n",
      "2025-09-23 02:21:16.219127: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bb6800 of size 256 next 995\n",
      "2025-09-23 02:21:16.219128: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bb6900 of size 256 next 996\n",
      "2025-09-23 02:21:16.219129: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bb6a00 of size 256 next 997\n",
      "2025-09-23 02:21:16.219131: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bb6b00 of size 256 next 998\n",
      "2025-09-23 02:21:16.219132: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bb6c00 of size 256 next 999\n",
      "2025-09-23 02:21:16.219133: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bb6d00 of size 256 next 1000\n",
      "2025-09-23 02:21:16.219135: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bb6e00 of size 256 next 1001\n",
      "2025-09-23 02:21:16.219136: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bb6f00 of size 256 next 1002\n",
      "2025-09-23 02:21:16.219137: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bb7000 of size 16384 next 1003\n",
      "2025-09-23 02:21:16.219139: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bbb000 of size 16384 next 1004\n",
      "2025-09-23 02:21:16.219140: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bbf000 of size 16384 next 1005\n",
      "2025-09-23 02:21:16.219141: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bc3000 of size 16384 next 1006\n",
      "2025-09-23 02:21:16.219142: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bc7000 of size 512 next 1007\n",
      "2025-09-23 02:21:16.219144: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bc7200 of size 512 next 1008\n",
      "2025-09-23 02:21:16.219145: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bc7400 of size 512 next 1009\n",
      "2025-09-23 02:21:16.219146: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bc7600 of size 512 next 1010\n",
      "2025-09-23 02:21:16.219147: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bc7800 of size 512 next 1011\n",
      "2025-09-23 02:21:16.219149: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bc7a00 of size 512 next 1012\n",
      "2025-09-23 02:21:16.219150: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bc7c00 of size 512 next 1013\n",
      "2025-09-23 02:21:16.219151: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bc7e00 of size 512 next 1014\n",
      "2025-09-23 02:21:16.219153: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bc8000 of size 4608 next 1015\n",
      "2025-09-23 02:21:16.219154: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bc9200 of size 4608 next 1016\n",
      "2025-09-23 02:21:16.219155: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bca400 of size 4608 next 1017\n",
      "2025-09-23 02:21:16.219157: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bcb600 of size 4608 next 1018\n",
      "2025-09-23 02:21:16.219158: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bcc800 of size 512 next 1019\n",
      "2025-09-23 02:21:16.219159: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bcca00 of size 512 next 1020\n",
      "2025-09-23 02:21:16.219160: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bccc00 of size 512 next 1021\n",
      "2025-09-23 02:21:16.219162: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bcce00 of size 512 next 1022\n",
      "2025-09-23 02:21:16.219163: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bcd000 of size 512 next 1023\n",
      "2025-09-23 02:21:16.219164: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bcd200 of size 512 next 1024\n",
      "2025-09-23 02:21:16.219165: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bcd400 of size 512 next 1025\n",
      "2025-09-23 02:21:16.219167: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bcd600 of size 512 next 1026\n",
      "2025-09-23 02:21:16.219168: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bcd800 of size 16384 next 1027\n",
      "2025-09-23 02:21:16.219169: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bd1800 of size 16384 next 1028\n",
      "2025-09-23 02:21:16.219170: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bd5800 of size 256 next 1029\n",
      "2025-09-23 02:21:16.219172: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bd5900 of size 256 next 1030\n",
      "2025-09-23 02:21:16.219173: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bd5a00 of size 16384 next 1031\n",
      "2025-09-23 02:21:16.219174: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bd9a00 of size 16384 next 1032\n",
      "2025-09-23 02:21:16.219175: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bdda00 of size 256 next 1033\n",
      "2025-09-23 02:21:16.219176: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bddb00 of size 256 next 1034\n",
      "2025-09-23 02:21:16.219178: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bddc00 of size 16384 next 1035\n",
      "2025-09-23 02:21:16.219179: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318be1c00 of size 16384 next 1036\n",
      "2025-09-23 02:21:16.219180: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318be5c00 of size 512 next 1037\n",
      "2025-09-23 02:21:16.219182: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318be5e00 of size 512 next 1038\n",
      "2025-09-23 02:21:16.219183: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318be6000 of size 16384 next 1039\n",
      "2025-09-23 02:21:16.219184: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bea000 of size 16384 next 1040\n",
      "2025-09-23 02:21:16.219186: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bee000 of size 512 next 1041\n",
      "2025-09-23 02:21:16.219187: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bee200 of size 512 next 1042\n",
      "2025-09-23 02:21:16.219188: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bee400 of size 256 next 1047\n",
      "2025-09-23 02:21:16.219189: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bee500 of size 256 next 1048\n",
      "2025-09-23 02:21:16.219191: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bee600 of size 256 next 1049\n",
      "2025-09-23 02:21:16.219192: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bee700 of size 256 next 1050\n",
      "2025-09-23 02:21:16.219193: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bee800 of size 256 next 1051\n",
      "2025-09-23 02:21:16.219195: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bee900 of size 256 next 1052\n",
      "2025-09-23 02:21:16.219196: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318beea00 of size 256 next 1053\n",
      "2025-09-23 02:21:16.219197: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318beeb00 of size 256 next 1054\n",
      "2025-09-23 02:21:16.219199: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318beec00 of size 1024 next 1059\n",
      "2025-09-23 02:21:16.219200: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bef000 of size 1024 next 1060\n",
      "2025-09-23 02:21:16.219201: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bef400 of size 1024 next 1061\n",
      "2025-09-23 02:21:16.219203: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bef800 of size 1024 next 1062\n",
      "2025-09-23 02:21:16.219204: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318befc00 of size 1024 next 1063\n",
      "2025-09-23 02:21:16.219205: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bf0000 of size 1024 next 1064\n",
      "2025-09-23 02:21:16.219206: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bf0400 of size 1024 next 1065\n",
      "2025-09-23 02:21:16.219207: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bf0800 of size 1024 next 1066\n",
      "2025-09-23 02:21:16.219209: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bf0c00 of size 15360 next 659\n",
      "2025-09-23 02:21:16.219210: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bf4800 of size 1382400 next 658\n",
      "2025-09-23 02:21:16.219211: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318d46000 of size 1382400 next 673\n",
      "2025-09-23 02:21:16.219212: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318e97800 of size 50176 next 1138\n",
      "2025-09-23 02:21:16.219214: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ea3c00 of size 1024 next 1139\n",
      "2025-09-23 02:21:16.219215: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ea4000 of size 1024 next 1140\n",
      "2025-09-23 02:21:16.219216: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ea4400 of size 50176 next 1141\n",
      "2025-09-23 02:21:16.219217: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318eb0800 of size 50176 next 1142\n",
      "2025-09-23 02:21:16.219219: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ebcc00 of size 1024 next 1143\n",
      "2025-09-23 02:21:16.219220: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ebd000 of size 1024 next 1144\n",
      "2025-09-23 02:21:16.219221: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ebd400 of size 50176 next 1145\n",
      "2025-09-23 02:21:16.219222: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ec9800 of size 50176 next 1146\n",
      "2025-09-23 02:21:16.219223: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ed5c00 of size 50176 next 1147\n",
      "2025-09-23 02:21:16.219225: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ee2000 of size 50176 next 1148\n",
      "2025-09-23 02:21:16.219226: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318eee400 of size 256 next 1149\n",
      "2025-09-23 02:21:16.219227: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318eee500 of size 256 next 1150\n",
      "2025-09-23 02:21:16.219228: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318eee600 of size 256 next 1151\n",
      "2025-09-23 02:21:16.219230: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318eee700 of size 256 next 1152\n",
      "2025-09-23 02:21:16.219231: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318eee800 of size 256 next 1153\n",
      "2025-09-23 02:21:16.219232: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318eee900 of size 256 next 1154\n",
      "2025-09-23 02:21:16.219233: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318eeea00 of size 256 next 1155\n",
      "2025-09-23 02:21:16.219234: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318eeeb00 of size 256 next 1156\n",
      "2025-09-23 02:21:16.219236: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318eeec00 of size 50176 next 1157\n",
      "2025-09-23 02:21:16.219237: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318efb000 of size 50176 next 1158\n",
      "2025-09-23 02:21:16.219238: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f07400 of size 50176 next 1159\n",
      "2025-09-23 02:21:16.219239: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f13800 of size 50176 next 1160\n",
      "2025-09-23 02:21:16.219241: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f1fc00 of size 1024 next 1161\n",
      "2025-09-23 02:21:16.219242: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f20000 of size 1024 next 1162\n",
      "2025-09-23 02:21:16.219243: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f20400 of size 1024 next 1163\n",
      "2025-09-23 02:21:16.219244: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f20800 of size 1024 next 1164\n",
      "2025-09-23 02:21:16.219246: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f20c00 of size 1024 next 1165\n",
      "2025-09-23 02:21:16.219247: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f21000 of size 1024 next 1166\n",
      "2025-09-23 02:21:16.219248: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f21400 of size 1024 next 1167\n",
      "2025-09-23 02:21:16.219249: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f21800 of size 1024 next 1168\n",
      "2025-09-23 02:21:16.219250: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f21c00 of size 8192 next 1169\n",
      "2025-09-23 02:21:16.219252: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f23c00 of size 8192 next 1170\n",
      "2025-09-23 02:21:16.219253: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f25c00 of size 8192 next 1171\n",
      "2025-09-23 02:21:16.219254: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f27c00 of size 8192 next 1172\n",
      "2025-09-23 02:21:16.219255: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f29c00 of size 1024 next 1173\n",
      "2025-09-23 02:21:16.219256: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f2a000 of size 1024 next 1174\n",
      "2025-09-23 02:21:16.219258: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f2a400 of size 1024 next 1175\n",
      "2025-09-23 02:21:16.219259: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f2a800 of size 1024 next 1176\n",
      "2025-09-23 02:21:16.219260: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f2ac00 of size 1024 next 1177\n",
      "2025-09-23 02:21:16.219261: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f2b000 of size 1024 next 1178\n",
      "2025-09-23 02:21:16.219262: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f2b400 of size 1024 next 1179\n",
      "2025-09-23 02:21:16.219264: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f2b800 of size 1024 next 1180\n",
      "2025-09-23 02:21:16.219265: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f2bc00 of size 50176 next 1181\n",
      "2025-09-23 02:21:16.219266: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f38000 of size 50176 next 1182\n",
      "2025-09-23 02:21:16.219267: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f44400 of size 256 next 1183\n",
      "2025-09-23 02:21:16.219269: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f44500 of size 256 next 1184\n",
      "2025-09-23 02:21:16.219270: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f44600 of size 50176 next 1185\n",
      "2025-09-23 02:21:16.219271: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f50a00 of size 50176 next 1186\n",
      "2025-09-23 02:21:16.219272: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f5ce00 of size 256 next 1187\n",
      "2025-09-23 02:21:16.219274: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f5cf00 of size 256 next 1188\n",
      "2025-09-23 02:21:16.219275: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f5d000 of size 50176 next 1189\n",
      "2025-09-23 02:21:16.219277: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f69400 of size 50176 next 1190\n",
      "2025-09-23 02:21:16.219278: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f75800 of size 1024 next 1191\n",
      "2025-09-23 02:21:16.219279: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f75c00 of size 1024 next 1192\n",
      "2025-09-23 02:21:16.219281: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f76000 of size 50176 next 1193\n",
      "2025-09-23 02:21:16.219282: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f82400 of size 50176 next 1194\n",
      "2025-09-23 02:21:16.219283: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f8e800 of size 1024 next 1195\n",
      "2025-09-23 02:21:16.219284: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f8ec00 of size 1024 next 1196\n",
      "2025-09-23 02:21:16.219286: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f8f000 of size 50176 next 1197\n",
      "2025-09-23 02:21:16.219287: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f9b400 of size 50176 next 1198\n",
      "2025-09-23 02:21:16.219288: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fa7800 of size 50176 next 1199\n",
      "2025-09-23 02:21:16.219289: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fb3c00 of size 50176 next 1200\n",
      "2025-09-23 02:21:16.219291: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fc0000 of size 256 next 1201\n",
      "2025-09-23 02:21:16.219292: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fc0100 of size 256 next 1202\n",
      "2025-09-23 02:21:16.219293: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fc0200 of size 256 next 1203\n",
      "2025-09-23 02:21:16.219294: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fc0300 of size 256 next 1204\n",
      "2025-09-23 02:21:16.219296: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fc0400 of size 256 next 1205\n",
      "2025-09-23 02:21:16.219297: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fc0500 of size 256 next 1206\n",
      "2025-09-23 02:21:16.219298: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fc0600 of size 256 next 1207\n",
      "2025-09-23 02:21:16.219299: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fc0700 of size 256 next 1208\n",
      "2025-09-23 02:21:16.219301: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fc0800 of size 50176 next 1209\n",
      "2025-09-23 02:21:16.219302: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fccc00 of size 50176 next 1210\n",
      "2025-09-23 02:21:16.219303: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fd9000 of size 50176 next 1211\n",
      "2025-09-23 02:21:16.219304: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fe5400 of size 50176 next 1212\n",
      "2025-09-23 02:21:16.219305: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ff1800 of size 1024 next 1213\n",
      "2025-09-23 02:21:16.219307: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ff1c00 of size 1024 next 1214\n",
      "2025-09-23 02:21:16.219308: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ff2000 of size 1024 next 1215\n",
      "2025-09-23 02:21:16.219309: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ff2400 of size 1024 next 1216\n",
      "2025-09-23 02:21:16.219310: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ff2800 of size 1024 next 1217\n",
      "2025-09-23 02:21:16.219312: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ff2c00 of size 1024 next 1218\n",
      "2025-09-23 02:21:16.219313: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ff3000 of size 1024 next 1219\n",
      "2025-09-23 02:21:16.219314: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ff3400 of size 1024 next 1220\n",
      "2025-09-23 02:21:16.219315: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ff3800 of size 8192 next 1221\n",
      "2025-09-23 02:21:16.219316: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ff5800 of size 8192 next 1222\n",
      "2025-09-23 02:21:16.219318: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ff7800 of size 8192 next 1223\n",
      "2025-09-23 02:21:16.219319: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ff9800 of size 8192 next 1224\n",
      "2025-09-23 02:21:16.219320: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ffb800 of size 1024 next 1225\n",
      "2025-09-23 02:21:16.219321: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ffbc00 of size 1024 next 1226\n",
      "2025-09-23 02:21:16.219322: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ffc000 of size 1024 next 1227\n",
      "2025-09-23 02:21:16.219324: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ffc400 of size 1024 next 1228\n",
      "2025-09-23 02:21:16.219325: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ffc800 of size 1024 next 1229\n",
      "2025-09-23 02:21:16.219326: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ffcc00 of size 1024 next 1230\n",
      "2025-09-23 02:21:16.219327: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ffd000 of size 1024 next 1231\n",
      "2025-09-23 02:21:16.219329: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ffd400 of size 1024 next 1232\n",
      "2025-09-23 02:21:16.219330: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ffd800 of size 50176 next 1233\n",
      "2025-09-23 02:21:16.219331: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319009c00 of size 50176 next 1234\n",
      "2025-09-23 02:21:16.219332: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319016000 of size 256 next 1235\n",
      "2025-09-23 02:21:16.219334: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319016100 of size 256 next 1236\n",
      "2025-09-23 02:21:16.219335: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319016200 of size 50176 next 1237\n",
      "2025-09-23 02:21:16.219336: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319022600 of size 50176 next 1238\n",
      "2025-09-23 02:21:16.219338: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131902ea00 of size 256 next 1239\n",
      "2025-09-23 02:21:16.219339: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131902eb00 of size 256 next 1240\n",
      "2025-09-23 02:21:16.219340: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131902ec00 of size 50176 next 1241\n",
      "2025-09-23 02:21:16.219341: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131903b000 of size 50176 next 1242\n",
      "2025-09-23 02:21:16.219343: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319047400 of size 1024 next 1243\n",
      "2025-09-23 02:21:16.219344: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319047800 of size 1024 next 1244\n",
      "2025-09-23 02:21:16.219345: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319047c00 of size 50176 next 1245\n",
      "2025-09-23 02:21:16.219346: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319054000 of size 50176 next 1246\n",
      "2025-09-23 02:21:16.219348: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319060400 of size 1024 next 1247\n",
      "2025-09-23 02:21:16.219349: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319060800 of size 1024 next 1248\n",
      "2025-09-23 02:21:16.219350: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319060c00 of size 50176 next 1249\n",
      "2025-09-23 02:21:16.219351: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131906d000 of size 50176 next 1250\n",
      "2025-09-23 02:21:16.219352: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319079400 of size 50176 next 1251\n",
      "2025-09-23 02:21:16.219354: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319085800 of size 50176 next 1252\n",
      "2025-09-23 02:21:16.219355: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319091c00 of size 256 next 1253\n",
      "2025-09-23 02:21:16.219356: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319091d00 of size 256 next 1254\n",
      "2025-09-23 02:21:16.219357: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319091e00 of size 256 next 1255\n",
      "2025-09-23 02:21:16.219359: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319091f00 of size 256 next 1256\n",
      "2025-09-23 02:21:16.219360: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319092000 of size 256 next 1257\n",
      "2025-09-23 02:21:16.219361: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319092100 of size 256 next 1258\n",
      "2025-09-23 02:21:16.219362: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319092200 of size 256 next 1259\n",
      "2025-09-23 02:21:16.219363: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319092300 of size 256 next 1260\n",
      "2025-09-23 02:21:16.219365: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319092400 of size 50176 next 1261\n",
      "2025-09-23 02:21:16.219366: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131909e800 of size 50176 next 1262\n",
      "2025-09-23 02:21:16.219367: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190aac00 of size 50176 next 1263\n",
      "2025-09-23 02:21:16.219368: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190b7000 of size 50176 next 1264\n",
      "2025-09-23 02:21:16.219370: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190c3400 of size 1024 next 1265\n",
      "2025-09-23 02:21:16.219371: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190c3800 of size 1024 next 1266\n",
      "2025-09-23 02:21:16.219372: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190c3c00 of size 1024 next 1267\n",
      "2025-09-23 02:21:16.219373: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190c4000 of size 1024 next 1268\n",
      "2025-09-23 02:21:16.219374: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190c4400 of size 1024 next 1269\n",
      "2025-09-23 02:21:16.219376: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190c4800 of size 1024 next 1270\n",
      "2025-09-23 02:21:16.219377: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190c4c00 of size 1024 next 1271\n",
      "2025-09-23 02:21:16.219378: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190c5000 of size 1024 next 1272\n",
      "2025-09-23 02:21:16.219379: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190c5400 of size 8192 next 1273\n",
      "2025-09-23 02:21:16.219381: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190c7400 of size 8192 next 1274\n",
      "2025-09-23 02:21:16.219382: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190c9400 of size 8192 next 1275\n",
      "2025-09-23 02:21:16.219383: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190cb400 of size 8192 next 1276\n",
      "2025-09-23 02:21:16.219384: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190cd400 of size 1024 next 1277\n",
      "2025-09-23 02:21:16.219385: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190cd800 of size 1024 next 1278\n",
      "2025-09-23 02:21:16.219387: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190cdc00 of size 1024 next 1279\n",
      "2025-09-23 02:21:16.219388: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190ce000 of size 1024 next 1280\n",
      "2025-09-23 02:21:16.219389: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190ce400 of size 1024 next 1281\n",
      "2025-09-23 02:21:16.219398: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190ce800 of size 1024 next 1282\n",
      "2025-09-23 02:21:16.219401: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190cec00 of size 1024 next 1283\n",
      "2025-09-23 02:21:16.219402: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190cf000 of size 1024 next 1284\n",
      "2025-09-23 02:21:16.219403: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190cf400 of size 50176 next 1285\n",
      "2025-09-23 02:21:16.219405: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190db800 of size 50176 next 1286\n",
      "2025-09-23 02:21:16.219406: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190e7c00 of size 256 next 1287\n",
      "2025-09-23 02:21:16.219408: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190e7d00 of size 256 next 1288\n",
      "2025-09-23 02:21:16.219409: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190e7e00 of size 50176 next 1289\n",
      "2025-09-23 02:21:16.219410: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190f4200 of size 50176 next 1290\n",
      "2025-09-23 02:21:16.219412: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319100600 of size 256 next 1291\n",
      "2025-09-23 02:21:16.219413: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319100700 of size 256 next 1292\n",
      "2025-09-23 02:21:16.219414: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319100800 of size 50176 next 1293\n",
      "2025-09-23 02:21:16.219415: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131910cc00 of size 50176 next 1294\n",
      "2025-09-23 02:21:16.219417: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319119000 of size 1024 next 1295\n",
      "2025-09-23 02:21:16.219418: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319119400 of size 1024 next 1296\n",
      "2025-09-23 02:21:16.219419: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319119800 of size 50176 next 1297\n",
      "2025-09-23 02:21:16.219420: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319125c00 of size 50176 next 1298\n",
      "2025-09-23 02:21:16.219421: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319132000 of size 1024 next 1299\n",
      "2025-09-23 02:21:16.219423: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319132400 of size 1024 next 1300\n",
      "2025-09-23 02:21:16.219424: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319132800 of size 50176 next 1301\n",
      "2025-09-23 02:21:16.219425: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131913ec00 of size 50176 next 1302\n",
      "2025-09-23 02:21:16.219426: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131914b000 of size 50176 next 1303\n",
      "2025-09-23 02:21:16.219428: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319157400 of size 50176 next 1304\n",
      "2025-09-23 02:21:16.219429: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319163800 of size 256 next 1305\n",
      "2025-09-23 02:21:16.219430: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319163900 of size 256 next 1306\n",
      "2025-09-23 02:21:16.219431: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319163a00 of size 256 next 1307\n",
      "2025-09-23 02:21:16.219432: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319163b00 of size 256 next 1308\n",
      "2025-09-23 02:21:16.219434: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319163c00 of size 256 next 1309\n",
      "2025-09-23 02:21:16.219435: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319163d00 of size 256 next 1310\n",
      "2025-09-23 02:21:16.219436: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319163e00 of size 256 next 1311\n",
      "2025-09-23 02:21:16.219437: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319163f00 of size 256 next 1312\n",
      "2025-09-23 02:21:16.219439: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319164000 of size 677376 next 1313\n",
      "2025-09-23 02:21:16.219440: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319209600 of size 677376 next 1314\n",
      "2025-09-23 02:21:16.219441: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13192aec00 of size 677376 next 1315\n",
      "2025-09-23 02:21:16.219443: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319354200 of size 677376 next 1316\n",
      "2025-09-23 02:21:16.219444: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13193f9800 of size 1536 next 1317\n",
      "2025-09-23 02:21:16.219445: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13193f9e00 of size 1536 next 1318\n",
      "2025-09-23 02:21:16.219447: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13193fa400 of size 1536 next 1319\n",
      "2025-09-23 02:21:16.219448: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13193faa00 of size 1536 next 1320\n",
      "2025-09-23 02:21:16.219449: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13193fb000 of size 1536 next 1321\n",
      "2025-09-23 02:21:16.219450: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13193fb600 of size 1536 next 1322\n",
      "2025-09-23 02:21:16.219451: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13193fbc00 of size 1536 next 1323\n",
      "2025-09-23 02:21:16.219453: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13193fc200 of size 1536 next 1324\n",
      "2025-09-23 02:21:16.219454: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13193fc800 of size 112896 next 1325\n",
      "2025-09-23 02:21:16.219455: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319418100 of size 112896 next 1326\n",
      "2025-09-23 02:21:16.219456: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319433a00 of size 512 next 1327\n",
      "2025-09-23 02:21:16.219458: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319433c00 of size 512 next 1328\n",
      "2025-09-23 02:21:16.219459: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319433e00 of size 112896 next 1329\n",
      "2025-09-23 02:21:16.219460: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131944f700 of size 112896 next 1330\n",
      "2025-09-23 02:21:16.219461: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131946b000 of size 512 next 1331\n",
      "2025-09-23 02:21:16.219463: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131946b200 of size 512 next 1332\n",
      "2025-09-23 02:21:16.219464: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131946b400 of size 112896 next 1333\n",
      "2025-09-23 02:21:16.219465: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319486d00 of size 112896 next 1334\n",
      "2025-09-23 02:21:16.219466: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13194a2600 of size 1536 next 1335\n",
      "2025-09-23 02:21:16.219468: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13194a2c00 of size 1536 next 1336\n",
      "2025-09-23 02:21:16.219469: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13194a3200 of size 112896 next 1337\n",
      "2025-09-23 02:21:16.219470: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13194beb00 of size 112896 next 1338\n",
      "2025-09-23 02:21:16.219471: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13194da400 of size 1536 next 1339\n",
      "2025-09-23 02:21:16.219473: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13194daa00 of size 1536 next 1340\n",
      "2025-09-23 02:21:16.219474: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13194db000 of size 107520 next 1341\n",
      "2025-09-23 02:21:16.219475: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13194f5400 of size 107520 next 1342\n",
      "2025-09-23 02:21:16.219476: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131950f800 of size 107520 next 1343\n",
      "2025-09-23 02:21:16.219477: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319529c00 of size 107520 next 1344\n",
      "2025-09-23 02:21:16.219479: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319544000 of size 512 next 1345\n",
      "2025-09-23 02:21:16.219480: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319544200 of size 512 next 1346\n",
      "2025-09-23 02:21:16.219481: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319544400 of size 512 next 1347\n",
      "2025-09-23 02:21:16.219482: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319544600 of size 512 next 1348\n",
      "2025-09-23 02:21:16.219484: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319544800 of size 512 next 1349\n",
      "2025-09-23 02:21:16.219485: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319544a00 of size 512 next 1350\n",
      "2025-09-23 02:21:16.219486: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319544c00 of size 512 next 1351\n",
      "2025-09-23 02:21:16.219487: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319544e00 of size 512 next 1352\n",
      "2025-09-23 02:21:16.219489: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319545000 of size 1382400 next 1353\n",
      "2025-09-23 02:21:16.219491: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319696800 of size 1480704 next 18446744073709551615\n",
      "2025-09-23 02:21:16.219492: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 33554432\n",
      "2025-09-23 02:21:16.219494: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319800000 of size 1382400 next 1355\n",
      "2025-09-23 02:21:16.219495: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319951800 of size 1382400 next 1356\n",
      "2025-09-23 02:21:16.219497: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319aa3000 of size 2048 next 1357\n",
      "2025-09-23 02:21:16.219498: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319aa3800 of size 2048 next 1358\n",
      "2025-09-23 02:21:16.219499: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319aa4000 of size 2048 next 1359\n",
      "2025-09-23 02:21:16.219500: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319aa4800 of size 2048 next 1360\n",
      "2025-09-23 02:21:16.219501: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319aa5000 of size 2048 next 1361\n",
      "2025-09-23 02:21:16.219503: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319aa5800 of size 2048 next 1362\n",
      "2025-09-23 02:21:16.219504: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319aa6000 of size 2048 next 1363\n",
      "2025-09-23 02:21:16.219505: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319aa6800 of size 2048 next 1364\n",
      "2025-09-23 02:21:16.219506: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319aa7000 of size 230400 next 1365\n",
      "2025-09-23 02:21:16.219508: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319adf400 of size 230400 next 1366\n",
      "2025-09-23 02:21:16.219509: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319b17800 of size 512 next 1367\n",
      "2025-09-23 02:21:16.219510: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319b17a00 of size 512 next 1368\n",
      "2025-09-23 02:21:16.219511: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319b17c00 of size 230400 next 1369\n",
      "2025-09-23 02:21:16.219512: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319b50000 of size 230400 next 1370\n",
      "2025-09-23 02:21:16.219514: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319b88400 of size 512 next 1371\n",
      "2025-09-23 02:21:16.219515: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319b88600 of size 512 next 1372\n",
      "2025-09-23 02:21:16.219516: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319b88800 of size 230400 next 1373\n",
      "2025-09-23 02:21:16.219517: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319bc0c00 of size 230400 next 1374\n",
      "2025-09-23 02:21:16.219519: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319bf9000 of size 2048 next 1375\n",
      "2025-09-23 02:21:16.219520: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319bf9800 of size 2048 next 1376\n",
      "2025-09-23 02:21:16.219521: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319bfa000 of size 230400 next 1377\n",
      "2025-09-23 02:21:16.219523: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319c32400 of size 230400 next 1378\n",
      "2025-09-23 02:21:16.219524: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319c6a800 of size 2048 next 1379\n",
      "2025-09-23 02:21:16.219525: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319c6b000 of size 2048 next 1380\n",
      "2025-09-23 02:21:16.219526: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319c6b800 of size 153600 next 1381\n",
      "2025-09-23 02:21:16.219528: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319c91000 of size 153600 next 1382\n",
      "2025-09-23 02:21:16.219529: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319cb6800 of size 153600 next 1383\n",
      "2025-09-23 02:21:16.219530: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319cdc000 of size 153600 next 1384\n",
      "2025-09-23 02:21:16.219531: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319d01800 of size 512 next 1385\n",
      "2025-09-23 02:21:16.219533: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319d01a00 of size 512 next 1386\n",
      "2025-09-23 02:21:16.219534: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319d01c00 of size 512 next 1387\n",
      "2025-09-23 02:21:16.219535: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319d01e00 of size 512 next 1388\n",
      "2025-09-23 02:21:16.219536: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319d02000 of size 512 next 1389\n",
      "2025-09-23 02:21:16.219537: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319d02200 of size 512 next 1390\n",
      "2025-09-23 02:21:16.219539: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319d02400 of size 512 next 1391\n",
      "2025-09-23 02:21:16.219540: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319d02600 of size 512 next 1392\n",
      "2025-09-23 02:21:16.219541: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319d02800 of size 1382400 next 1393\n",
      "2025-09-23 02:21:16.219542: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319e54000 of size 1382400 next 1394\n",
      "2025-09-23 02:21:16.219544: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319fa5800 of size 1382400 next 1395\n",
      "2025-09-23 02:21:16.219545: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a0f7000 of size 1382400 next 1396\n",
      "2025-09-23 02:21:16.219546: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a248800 of size 2048 next 1397\n",
      "2025-09-23 02:21:16.219548: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a249000 of size 2048 next 1398\n",
      "2025-09-23 02:21:16.219549: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a249800 of size 2048 next 1399\n",
      "2025-09-23 02:21:16.219550: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a24a000 of size 2048 next 1400\n",
      "2025-09-23 02:21:16.219551: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a24a800 of size 2048 next 1401\n",
      "2025-09-23 02:21:16.219553: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a24b000 of size 2048 next 1402\n",
      "2025-09-23 02:21:16.219554: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a24b800 of size 2048 next 1403\n",
      "2025-09-23 02:21:16.219555: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a24c000 of size 2048 next 1404\n",
      "2025-09-23 02:21:16.219556: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a24c800 of size 230400 next 1405\n",
      "2025-09-23 02:21:16.219557: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a284c00 of size 230400 next 1406\n",
      "2025-09-23 02:21:16.219559: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a2bd000 of size 512 next 1407\n",
      "2025-09-23 02:21:16.219560: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a2bd200 of size 512 next 1408\n",
      "2025-09-23 02:21:16.219561: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a2bd400 of size 230400 next 1409\n",
      "2025-09-23 02:21:16.219562: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a2f5800 of size 230400 next 1410\n",
      "2025-09-23 02:21:16.219563: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a32dc00 of size 512 next 1411\n",
      "2025-09-23 02:21:16.219565: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a32de00 of size 512 next 1412\n",
      "2025-09-23 02:21:16.219566: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a32e000 of size 230400 next 1413\n",
      "2025-09-23 02:21:16.219567: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a366400 of size 230400 next 1414\n",
      "2025-09-23 02:21:16.219568: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a39e800 of size 2048 next 1415\n",
      "2025-09-23 02:21:16.219570: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a39f000 of size 2048 next 1416\n",
      "2025-09-23 02:21:16.219571: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a39f800 of size 230400 next 1417\n",
      "2025-09-23 02:21:16.219572: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a3d7c00 of size 230400 next 1418\n",
      "2025-09-23 02:21:16.219573: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a410000 of size 2048 next 1419\n",
      "2025-09-23 02:21:16.219575: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a410800 of size 2048 next 1420\n",
      "2025-09-23 02:21:16.219576: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a411000 of size 153600 next 1421\n",
      "2025-09-23 02:21:16.219577: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a436800 of size 153600 next 1422\n",
      "2025-09-23 02:21:16.219578: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a45c000 of size 153600 next 1423\n",
      "2025-09-23 02:21:16.219579: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a481800 of size 153600 next 1424\n",
      "2025-09-23 02:21:16.219581: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a4a7000 of size 512 next 1425\n",
      "2025-09-23 02:21:16.219582: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a4a7200 of size 512 next 1426\n",
      "2025-09-23 02:21:16.219583: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a4a7400 of size 512 next 1427\n",
      "2025-09-23 02:21:16.219584: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a4a7600 of size 512 next 1428\n",
      "2025-09-23 02:21:16.219586: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a4a7800 of size 512 next 1429\n",
      "2025-09-23 02:21:16.219587: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a4a7a00 of size 512 next 1430\n",
      "2025-09-23 02:21:16.219588: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a4a7c00 of size 512 next 1431\n",
      "2025-09-23 02:21:16.219589: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a4a7e00 of size 512 next 1432\n",
      "2025-09-23 02:21:16.219591: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a4a8000 of size 1382400 next 1433\n",
      "2025-09-23 02:21:16.219592: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a5f9800 of size 1382400 next 1434\n",
      "2025-09-23 02:21:16.219593: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a74b000 of size 1382400 next 1435\n",
      "2025-09-23 02:21:16.219594: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a89c800 of size 1382400 next 1436\n",
      "2025-09-23 02:21:16.219596: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a9ee000 of size 2048 next 1437\n",
      "2025-09-23 02:21:16.219597: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a9ee800 of size 2048 next 1438\n",
      "2025-09-23 02:21:16.219598: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a9ef000 of size 2048 next 1439\n",
      "2025-09-23 02:21:16.219600: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a9ef800 of size 2048 next 1440\n",
      "2025-09-23 02:21:16.219601: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a9f0000 of size 2048 next 1441\n",
      "2025-09-23 02:21:16.219602: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a9f0800 of size 2048 next 1442\n",
      "2025-09-23 02:21:16.219603: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a9f1000 of size 2048 next 1443\n",
      "2025-09-23 02:21:16.219605: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a9f1800 of size 2048 next 1444\n",
      "2025-09-23 02:21:16.219606: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a9f2000 of size 230400 next 1445\n",
      "2025-09-23 02:21:16.219607: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aa2a400 of size 230400 next 1446\n",
      "2025-09-23 02:21:16.219608: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aa62800 of size 512 next 1447\n",
      "2025-09-23 02:21:16.219610: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aa62a00 of size 512 next 1448\n",
      "2025-09-23 02:21:16.219611: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aa62c00 of size 230400 next 1449\n",
      "2025-09-23 02:21:16.219612: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aa9b000 of size 230400 next 1450\n",
      "2025-09-23 02:21:16.219613: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aad3400 of size 512 next 1451\n",
      "2025-09-23 02:21:16.219615: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aad3600 of size 512 next 1452\n",
      "2025-09-23 02:21:16.219616: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aad3800 of size 230400 next 1453\n",
      "2025-09-23 02:21:16.219617: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ab0bc00 of size 230400 next 1454\n",
      "2025-09-23 02:21:16.219618: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ab44000 of size 2048 next 1455\n",
      "2025-09-23 02:21:16.219619: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ab44800 of size 2048 next 1456\n",
      "2025-09-23 02:21:16.219621: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ab45000 of size 230400 next 1457\n",
      "2025-09-23 02:21:16.219622: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ab7d400 of size 230400 next 1458\n",
      "2025-09-23 02:21:16.219623: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131abb5800 of size 2048 next 1459\n",
      "2025-09-23 02:21:16.219624: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131abb6000 of size 2048 next 1460\n",
      "2025-09-23 02:21:16.219626: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131abb6800 of size 153600 next 1461\n",
      "2025-09-23 02:21:16.219627: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131abdc000 of size 153600 next 1462\n",
      "2025-09-23 02:21:16.219628: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac01800 of size 153600 next 1463\n",
      "2025-09-23 02:21:16.219629: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac27000 of size 153600 next 1464\n",
      "2025-09-23 02:21:16.219631: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac4c800 of size 512 next 1465\n",
      "2025-09-23 02:21:16.219632: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac4ca00 of size 512 next 1466\n",
      "2025-09-23 02:21:16.219633: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac4cc00 of size 512 next 1467\n",
      "2025-09-23 02:21:16.219634: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac4ce00 of size 512 next 1468\n",
      "2025-09-23 02:21:16.219635: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac4d000 of size 512 next 1469\n",
      "2025-09-23 02:21:16.219637: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac4d200 of size 512 next 1470\n",
      "2025-09-23 02:21:16.219638: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac4d400 of size 512 next 1471\n",
      "2025-09-23 02:21:16.219639: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac4d600 of size 512 next 1472\n",
      "2025-09-23 02:21:16.219640: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac4d800 of size 51200 next 1473\n",
      "2025-09-23 02:21:16.219642: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac5a000 of size 51200 next 1474\n",
      "2025-09-23 02:21:16.219643: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac66800 of size 51200 next 1475\n",
      "2025-09-23 02:21:16.219644: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac73000 of size 51200 next 1476\n",
      "2025-09-23 02:21:16.219645: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac7f800 of size 768 next 1477\n",
      "2025-09-23 02:21:16.219647: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac7fb00 of size 768 next 1478\n",
      "2025-09-23 02:21:16.219648: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac7fe00 of size 768 next 1479\n",
      "2025-09-23 02:21:16.219649: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac80100 of size 768 next 1480\n",
      "2025-09-23 02:21:16.219650: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac80400 of size 768 next 1481\n",
      "2025-09-23 02:21:16.219652: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac80700 of size 768 next 1482\n",
      "2025-09-23 02:21:16.219653: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac80a00 of size 768 next 1483\n",
      "2025-09-23 02:21:16.219654: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac80d00 of size 768 next 1484\n",
      "2025-09-23 02:21:16.219655: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac81000 of size 5888 next 1485\n",
      "2025-09-23 02:21:16.219657: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac82700 of size 5888 next 1486\n",
      "2025-09-23 02:21:16.219658: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac83e00 of size 5888 next 1487\n",
      "2025-09-23 02:21:16.219659: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac85500 of size 5888 next 1488\n",
      "2025-09-23 02:21:16.219660: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac86c00 of size 768 next 1489\n",
      "2025-09-23 02:21:16.219661: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac86f00 of size 768 next 1490\n",
      "2025-09-23 02:21:16.219663: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac87200 of size 768 next 1491\n",
      "2025-09-23 02:21:16.219664: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac87500 of size 768 next 1492\n",
      "2025-09-23 02:21:16.219665: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac87800 of size 768 next 1493\n",
      "2025-09-23 02:21:16.219666: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac87b00 of size 768 next 1494\n",
      "2025-09-23 02:21:16.219668: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac87e00 of size 768 next 1495\n",
      "2025-09-23 02:21:16.219669: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac88100 of size 768 next 1496\n",
      "2025-09-23 02:21:16.219670: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac88400 of size 25600 next 1497\n",
      "2025-09-23 02:21:16.219671: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac8e800 of size 25600 next 1498\n",
      "2025-09-23 02:21:16.219672: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac94c00 of size 256 next 1499\n",
      "2025-09-23 02:21:16.219674: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac94d00 of size 256 next 1500\n",
      "2025-09-23 02:21:16.219675: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac94e00 of size 25600 next 1501\n",
      "2025-09-23 02:21:16.219676: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac9b200 of size 25600 next 1502\n",
      "2025-09-23 02:21:16.219677: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aca1600 of size 256 next 1503\n",
      "2025-09-23 02:21:16.219679: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aca1700 of size 256 next 1504\n",
      "2025-09-23 02:21:16.219680: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aca1800 of size 25600 next 1505\n",
      "2025-09-23 02:21:16.219681: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aca7c00 of size 25600 next 1506\n",
      "2025-09-23 02:21:16.219682: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acae000 of size 768 next 1507\n",
      "2025-09-23 02:21:16.219683: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acae300 of size 768 next 1508\n",
      "2025-09-23 02:21:16.219685: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acae600 of size 25600 next 1509\n",
      "2025-09-23 02:21:16.219686: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acb4a00 of size 25600 next 1510\n",
      "2025-09-23 02:21:16.219687: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acbae00 of size 768 next 1511\n",
      "2025-09-23 02:21:16.219688: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acbb100 of size 768 next 1512\n",
      "2025-09-23 02:21:16.219690: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acbb400 of size 61440 next 1513\n",
      "2025-09-23 02:21:16.219691: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acca400 of size 61440 next 1514\n",
      "2025-09-23 02:21:16.219692: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acd9400 of size 61440 next 1515\n",
      "2025-09-23 02:21:16.219693: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ace8400 of size 61440 next 1516\n",
      "2025-09-23 02:21:16.219695: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acf7400 of size 512 next 1517\n",
      "2025-09-23 02:21:16.219696: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acf7600 of size 512 next 1518\n",
      "2025-09-23 02:21:16.219697: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acf7800 of size 512 next 1519\n",
      "2025-09-23 02:21:16.219698: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acf7a00 of size 512 next 1520\n",
      "2025-09-23 02:21:16.219700: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acf7c00 of size 512 next 1521\n",
      "2025-09-23 02:21:16.219701: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acf7e00 of size 512 next 1522\n",
      "2025-09-23 02:21:16.219702: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acf8000 of size 512 next 1523\n",
      "2025-09-23 02:21:16.219703: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acf8200 of size 512 next 1524\n",
      "2025-09-23 02:21:16.219704: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acf8400 of size 73728 next 1525\n",
      "2025-09-23 02:21:16.219706: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad0a400 of size 73728 next 1526\n",
      "2025-09-23 02:21:16.219707: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad1c400 of size 73728 next 1527\n",
      "2025-09-23 02:21:16.219708: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad2e400 of size 73728 next 1528\n",
      "2025-09-23 02:21:16.219709: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad40400 of size 768 next 1529\n",
      "2025-09-23 02:21:16.219711: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad40700 of size 768 next 1530\n",
      "2025-09-23 02:21:16.219712: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad40a00 of size 768 next 1531\n",
      "2025-09-23 02:21:16.219713: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad40d00 of size 768 next 1532\n",
      "2025-09-23 02:21:16.219714: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad41000 of size 768 next 1533\n",
      "2025-09-23 02:21:16.219715: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad41300 of size 768 next 1534\n",
      "2025-09-23 02:21:16.219717: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad41600 of size 768 next 1535\n",
      "2025-09-23 02:21:16.219718: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad41900 of size 768 next 1536\n",
      "2025-09-23 02:21:16.219719: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad41c00 of size 6912 next 1537\n",
      "2025-09-23 02:21:16.219720: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad43700 of size 6912 next 1538\n",
      "2025-09-23 02:21:16.219722: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad45200 of size 6912 next 1539\n",
      "2025-09-23 02:21:16.219723: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad46d00 of size 6912 next 1540\n",
      "2025-09-23 02:21:16.219724: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad48800 of size 768 next 1541\n",
      "2025-09-23 02:21:16.219725: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad48b00 of size 768 next 1542\n",
      "2025-09-23 02:21:16.219727: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad48e00 of size 768 next 1543\n",
      "2025-09-23 02:21:16.219728: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad49100 of size 768 next 1544\n",
      "2025-09-23 02:21:16.219729: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad49400 of size 768 next 1545\n",
      "2025-09-23 02:21:16.219730: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad49700 of size 768 next 1546\n",
      "2025-09-23 02:21:16.219732: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad49a00 of size 768 next 1547\n",
      "2025-09-23 02:21:16.219733: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad49d00 of size 768 next 1548\n",
      "2025-09-23 02:21:16.219734: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad4a000 of size 36864 next 1549\n",
      "2025-09-23 02:21:16.219735: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad53000 of size 36864 next 1550\n",
      "2025-09-23 02:21:16.219736: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad5c000 of size 256 next 1551\n",
      "2025-09-23 02:21:16.219738: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad5c100 of size 256 next 1552\n",
      "2025-09-23 02:21:16.219739: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad5c200 of size 36864 next 1553\n",
      "2025-09-23 02:21:16.219740: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad65200 of size 36864 next 1554\n",
      "2025-09-23 02:21:16.219741: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad6e200 of size 256 next 1555\n",
      "2025-09-23 02:21:16.219743: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad6e300 of size 256 next 1556\n",
      "2025-09-23 02:21:16.219744: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad6e400 of size 36864 next 1557\n",
      "2025-09-23 02:21:16.219745: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad77400 of size 36864 next 1558\n",
      "2025-09-23 02:21:16.219746: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad80400 of size 768 next 1559\n",
      "2025-09-23 02:21:16.219747: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad80700 of size 768 next 1560\n",
      "2025-09-23 02:21:16.219749: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad80a00 of size 36864 next 1561\n",
      "2025-09-23 02:21:16.219750: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad89a00 of size 36864 next 1562\n",
      "2025-09-23 02:21:16.219751: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad92a00 of size 768 next 1563\n",
      "2025-09-23 02:21:16.219752: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad92d00 of size 768 next 1564\n",
      "2025-09-23 02:21:16.219754: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad93000 of size 73728 next 1565\n",
      "2025-09-23 02:21:16.219755: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ada5000 of size 73728 next 1566\n",
      "2025-09-23 02:21:16.219756: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131adb7000 of size 73728 next 1567\n",
      "2025-09-23 02:21:16.219757: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131adc9000 of size 73728 next 1568\n",
      "2025-09-23 02:21:16.219758: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131addb000 of size 512 next 1569\n",
      "2025-09-23 02:21:16.219760: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131addb200 of size 512 next 1570\n",
      "2025-09-23 02:21:16.219761: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131addb400 of size 512 next 1571\n",
      "2025-09-23 02:21:16.219779: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131addb600 of size 512 next 1572\n",
      "2025-09-23 02:21:16.219782: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131addb800 of size 512 next 1573\n",
      "2025-09-23 02:21:16.219784: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131addba00 of size 512 next 1574\n",
      "2025-09-23 02:21:16.219785: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131addbc00 of size 512 next 1575\n",
      "2025-09-23 02:21:16.219787: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131addbe00 of size 512 next 1576\n",
      "2025-09-23 02:21:16.219788: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131addc000 of size 73728 next 1577\n",
      "2025-09-23 02:21:16.219789: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131adee000 of size 73728 next 1578\n",
      "2025-09-23 02:21:16.219790: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae00000 of size 73728 next 1579\n",
      "2025-09-23 02:21:16.219792: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae12000 of size 73728 next 1580\n",
      "2025-09-23 02:21:16.219793: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae24000 of size 768 next 1581\n",
      "2025-09-23 02:21:16.219794: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae24300 of size 768 next 1582\n",
      "2025-09-23 02:21:16.219795: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae24600 of size 768 next 1583\n",
      "2025-09-23 02:21:16.219796: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae24900 of size 768 next 1584\n",
      "2025-09-23 02:21:16.219800: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae24c00 of size 768 next 1585\n",
      "2025-09-23 02:21:16.219801: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae24f00 of size 768 next 1586\n",
      "2025-09-23 02:21:16.219802: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae25200 of size 768 next 1587\n",
      "2025-09-23 02:21:16.219803: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae25500 of size 768 next 1588\n",
      "2025-09-23 02:21:16.219805: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae25800 of size 6912 next 1589\n",
      "2025-09-23 02:21:16.219806: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae27300 of size 6912 next 1590\n",
      "2025-09-23 02:21:16.219807: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae28e00 of size 6912 next 1591\n",
      "2025-09-23 02:21:16.219808: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae2a900 of size 6912 next 1592\n",
      "2025-09-23 02:21:16.219809: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae2c400 of size 768 next 1593\n",
      "2025-09-23 02:21:16.219811: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae2c700 of size 768 next 1594\n",
      "2025-09-23 02:21:16.219812: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae2ca00 of size 768 next 1595\n",
      "2025-09-23 02:21:16.219813: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae2cd00 of size 768 next 1596\n",
      "2025-09-23 02:21:16.219814: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae2d000 of size 768 next 1597\n",
      "2025-09-23 02:21:16.219815: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae2d300 of size 768 next 1598\n",
      "2025-09-23 02:21:16.219816: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae2d600 of size 768 next 1599\n",
      "2025-09-23 02:21:16.219818: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae2d900 of size 768 next 1600\n",
      "2025-09-23 02:21:16.219819: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae2dc00 of size 36864 next 1601\n",
      "2025-09-23 02:21:16.219820: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae36c00 of size 36864 next 1602\n",
      "2025-09-23 02:21:16.219821: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae3fc00 of size 256 next 1603\n",
      "2025-09-23 02:21:16.219823: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae3fd00 of size 256 next 1604\n",
      "2025-09-23 02:21:16.219824: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae3fe00 of size 36864 next 1605\n",
      "2025-09-23 02:21:16.219826: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae48e00 of size 36864 next 1606\n",
      "2025-09-23 02:21:16.219827: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae51e00 of size 256 next 1607\n",
      "2025-09-23 02:21:16.219828: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae51f00 of size 256 next 1608\n",
      "2025-09-23 02:21:16.219829: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae52000 of size 36864 next 1609\n",
      "2025-09-23 02:21:16.219830: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae5b000 of size 36864 next 1610\n",
      "2025-09-23 02:21:16.219832: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae64000 of size 768 next 1611\n",
      "2025-09-23 02:21:16.219833: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae64300 of size 768 next 1612\n",
      "2025-09-23 02:21:16.219834: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae64600 of size 36864 next 1613\n",
      "2025-09-23 02:21:16.219835: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae6d600 of size 36864 next 1614\n",
      "2025-09-23 02:21:16.219836: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae76600 of size 768 next 1615\n",
      "2025-09-23 02:21:16.219837: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae76900 of size 768 next 1616\n",
      "2025-09-23 02:21:16.219839: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae76c00 of size 73728 next 1617\n",
      "2025-09-23 02:21:16.219840: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae88c00 of size 73728 next 1618\n",
      "2025-09-23 02:21:16.219841: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae9ac00 of size 73728 next 1619\n",
      "2025-09-23 02:21:16.219842: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aeacc00 of size 73728 next 1620\n",
      "2025-09-23 02:21:16.219843: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aebec00 of size 512 next 1621\n",
      "2025-09-23 02:21:16.219845: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aebee00 of size 512 next 1622\n",
      "2025-09-23 02:21:16.219846: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aebf000 of size 512 next 1623\n",
      "2025-09-23 02:21:16.219847: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aebf200 of size 512 next 1624\n",
      "2025-09-23 02:21:16.219848: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aebf400 of size 512 next 1625\n",
      "2025-09-23 02:21:16.219849: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aebf600 of size 512 next 1626\n",
      "2025-09-23 02:21:16.219851: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aebf800 of size 512 next 1627\n",
      "2025-09-23 02:21:16.219852: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aebfa00 of size 512 next 1628\n",
      "2025-09-23 02:21:16.219853: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aebfc00 of size 73728 next 1629\n",
      "2025-09-23 02:21:16.219854: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aed1c00 of size 73728 next 1630\n",
      "2025-09-23 02:21:16.219855: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aee3c00 of size 73728 next 1631\n",
      "2025-09-23 02:21:16.219857: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aef5c00 of size 73728 next 1632\n",
      "2025-09-23 02:21:16.219858: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af07c00 of size 768 next 1633\n",
      "2025-09-23 02:21:16.219859: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af07f00 of size 768 next 1634\n",
      "2025-09-23 02:21:16.219860: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af08200 of size 768 next 1635\n",
      "2025-09-23 02:21:16.219861: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af08500 of size 768 next 1636\n",
      "2025-09-23 02:21:16.219862: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af08800 of size 768 next 1637\n",
      "2025-09-23 02:21:16.219864: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af08b00 of size 768 next 1638\n",
      "2025-09-23 02:21:16.219865: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af08e00 of size 768 next 1639\n",
      "2025-09-23 02:21:16.219867: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af09100 of size 768 next 1640\n",
      "2025-09-23 02:21:16.219868: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af09400 of size 6912 next 1641\n",
      "2025-09-23 02:21:16.219869: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af0af00 of size 6912 next 1642\n",
      "2025-09-23 02:21:16.219870: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af0ca00 of size 6912 next 1643\n",
      "2025-09-23 02:21:16.219871: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af0e500 of size 6912 next 1644\n",
      "2025-09-23 02:21:16.219873: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af10000 of size 768 next 1645\n",
      "2025-09-23 02:21:16.219874: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af10300 of size 768 next 1646\n",
      "2025-09-23 02:21:16.219875: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af10600 of size 768 next 1647\n",
      "2025-09-23 02:21:16.219876: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af10900 of size 768 next 1648\n",
      "2025-09-23 02:21:16.219877: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af10c00 of size 768 next 1649\n",
      "2025-09-23 02:21:16.219878: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af10f00 of size 768 next 1650\n",
      "2025-09-23 02:21:16.219880: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af11200 of size 768 next 1651\n",
      "2025-09-23 02:21:16.219884: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af11500 of size 768 next 1652\n",
      "2025-09-23 02:21:16.219885: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af11800 of size 36864 next 1653\n",
      "2025-09-23 02:21:16.219886: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af1a800 of size 36864 next 1654\n",
      "2025-09-23 02:21:16.219888: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af23800 of size 256 next 1655\n",
      "2025-09-23 02:21:16.219889: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af23900 of size 256 next 1656\n",
      "2025-09-23 02:21:16.219890: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af23a00 of size 36864 next 1657\n",
      "2025-09-23 02:21:16.219891: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af2ca00 of size 36864 next 1658\n",
      "2025-09-23 02:21:16.219892: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af35a00 of size 256 next 1659\n",
      "2025-09-23 02:21:16.219894: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af35b00 of size 256 next 1660\n",
      "2025-09-23 02:21:16.219895: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af35c00 of size 36864 next 1661\n",
      "2025-09-23 02:21:16.219896: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af3ec00 of size 36864 next 1662\n",
      "2025-09-23 02:21:16.219897: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af47c00 of size 768 next 1663\n",
      "2025-09-23 02:21:16.219899: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af47f00 of size 768 next 1664\n",
      "2025-09-23 02:21:16.219900: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af48200 of size 36864 next 1665\n",
      "2025-09-23 02:21:16.219901: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af51200 of size 36864 next 1666\n",
      "2025-09-23 02:21:16.219902: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af5a200 of size 768 next 1667\n",
      "2025-09-23 02:21:16.219904: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af5a500 of size 768 next 1668\n",
      "2025-09-23 02:21:16.219905: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af5a800 of size 73728 next 1669\n",
      "2025-09-23 02:21:16.219906: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af6c800 of size 73728 next 1670\n",
      "2025-09-23 02:21:16.219907: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af7e800 of size 73728 next 1671\n",
      "2025-09-23 02:21:16.219908: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af90800 of size 73728 next 1672\n",
      "2025-09-23 02:21:16.219910: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afa2800 of size 512 next 1673\n",
      "2025-09-23 02:21:16.219911: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afa2a00 of size 512 next 1674\n",
      "2025-09-23 02:21:16.219912: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afa2c00 of size 512 next 1675\n",
      "2025-09-23 02:21:16.219913: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afa2e00 of size 512 next 1676\n",
      "2025-09-23 02:21:16.219915: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afa3000 of size 512 next 1677\n",
      "2025-09-23 02:21:16.219916: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afa3200 of size 512 next 1678\n",
      "2025-09-23 02:21:16.219917: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afa3400 of size 512 next 1679\n",
      "2025-09-23 02:21:16.219919: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afa3600 of size 512 next 1680\n",
      "2025-09-23 02:21:16.219920: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afa3800 of size 43008 next 1681\n",
      "2025-09-23 02:21:16.219921: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afae000 of size 43008 next 1682\n",
      "2025-09-23 02:21:16.219922: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afb8800 of size 43008 next 1683\n",
      "2025-09-23 02:21:16.219924: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afc3000 of size 43008 next 1684\n",
      "2025-09-23 02:21:16.219925: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afcd800 of size 512 next 1685\n",
      "2025-09-23 02:21:16.219926: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afcda00 of size 512 next 1686\n",
      "2025-09-23 02:21:16.219928: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afcdc00 of size 512 next 1687\n",
      "2025-09-23 02:21:16.219929: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afcde00 of size 512 next 1688\n",
      "2025-09-23 02:21:16.219930: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afce000 of size 512 next 1689\n",
      "2025-09-23 02:21:16.219932: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afce200 of size 512 next 1690\n",
      "2025-09-23 02:21:16.219933: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afce400 of size 512 next 1691\n",
      "2025-09-23 02:21:16.219935: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afce600 of size 512 next 1692\n",
      "2025-09-23 02:21:16.219936: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afce800 of size 57344 next 1693\n",
      "2025-09-23 02:21:16.219938: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afdc800 of size 57344 next 1694\n",
      "2025-09-23 02:21:16.219939: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afea800 of size 256 next 1695\n",
      "2025-09-23 02:21:16.219941: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afea900 of size 256 next 1696\n",
      "2025-09-23 02:21:16.219942: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afeaa00 of size 256 next 1697\n",
      "2025-09-23 02:21:16.219943: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afeab00 of size 256 next 1698\n",
      "2025-09-23 02:21:16.219946: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afeac00 of size 256 next 1699\n",
      "2025-09-23 02:21:16.219947: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afead00 of size 256 next 1700\n",
      "2025-09-23 02:21:16.219949: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afeae00 of size 3840 next 1701\n",
      "2025-09-23 02:21:16.219950: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afebd00 of size 3840 next 1702\n",
      "2025-09-23 02:21:16.219951: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afecc00 of size 256 next 1703\n",
      "2025-09-23 02:21:16.219952: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afecd00 of size 256 next 1704\n",
      "2025-09-23 02:21:16.219953: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afece00 of size 256 next 1705\n",
      "2025-09-23 02:21:16.219955: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afecf00 of size 256 next 1706\n",
      "2025-09-23 02:21:16.219956: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afed000 of size 256 next 1707\n",
      "2025-09-23 02:21:16.219957: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afed100 of size 256 next 1708\n",
      "2025-09-23 02:21:16.219958: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afed200 of size 256 next 1709\n",
      "2025-09-23 02:21:16.219960: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afed300 of size 256 next 1710\n",
      "2025-09-23 02:21:16.219961: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afed400 of size 256 next 1711\n",
      "2025-09-23 02:21:16.219962: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afed500 of size 256 next 1712\n",
      "2025-09-23 02:21:16.219963: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afed600 of size 256 next 1713\n",
      "2025-09-23 02:21:16.219965: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afed700 of size 256 next 1714\n",
      "2025-09-23 02:21:16.219966: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afed800 of size 256 next 1715\n",
      "2025-09-23 02:21:16.219967: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afed900 of size 256 next 1716\n",
      "2025-09-23 02:21:16.219968: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afeda00 of size 256 next 1717\n",
      "2025-09-23 02:21:16.219970: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afedb00 of size 256 next 1718\n",
      "2025-09-23 02:21:16.219971: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afedc00 of size 256 next 1719\n",
      "2025-09-23 02:21:16.219972: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afedd00 of size 256 next 1720\n",
      "2025-09-23 02:21:16.219973: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afede00 of size 256 next 1721\n",
      "2025-09-23 02:21:16.219975: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afedf00 of size 256 next 1722\n",
      "2025-09-23 02:21:16.219976: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afee000 of size 256 next 1723\n",
      "2025-09-23 02:21:16.219977: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afee100 of size 256 next 1724\n",
      "2025-09-23 02:21:16.219978: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afee200 of size 256 next 1725\n",
      "2025-09-23 02:21:16.219980: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afee300 of size 256 next 1726\n",
      "2025-09-23 02:21:16.219981: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afee400 of size 256 next 1727\n",
      "2025-09-23 02:21:16.219982: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afee500 of size 256 next 1728\n",
      "2025-09-23 02:21:16.219983: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afee600 of size 256 next 1729\n",
      "2025-09-23 02:21:16.219985: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afee700 of size 256 next 1730\n",
      "2025-09-23 02:21:16.219986: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afee800 of size 256 next 1731\n",
      "2025-09-23 02:21:16.219987: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afee900 of size 256 next 1732\n",
      "2025-09-23 02:21:16.219988: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afeea00 of size 256 next 2009\n",
      "2025-09-23 02:21:16.219990: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afeeb00 of size 512 next 2008\n",
      "2025-09-23 02:21:16.219991: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afeed00 of size 256 next 1733\n",
      "2025-09-23 02:21:16.219992: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afeee00 of size 6741504 next 1974\n",
      "2025-09-23 02:21:16.219993: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b65cc00 of size 1024 next 2347\n",
      "2025-09-23 02:21:16.219995: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b65d000 of size 4096 next 1912\n",
      "2025-09-23 02:21:16.219996: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b65e000 of size 2048 next 654\n",
      "2025-09-23 02:21:16.219998: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b65e800 of size 36096 next 2232\n",
      "2025-09-23 02:21:16.219999: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b667500 of size 1024 next 1918\n",
      "2025-09-23 02:21:16.220000: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b667900 of size 1024 next 1776\n",
      "2025-09-23 02:21:16.220001: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b667d00 of size 1024 next 2467\n",
      "2025-09-23 02:21:16.220003: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b668100 of size 1024 next 1946\n",
      "2025-09-23 02:21:16.220004: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b668500 of size 1024 next 2291\n",
      "2025-09-23 02:21:16.220005: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b668900 of size 1024 next 741\n",
      "2025-09-23 02:21:16.220006: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b668d00 of size 1024 next 2282\n",
      "2025-09-23 02:21:16.220008: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b669100 of size 2048 next 1966\n",
      "2025-09-23 02:21:16.220009: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b669900 of size 49408 next 378\n",
      "2025-09-23 02:21:16.220010: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b675a00 of size 2048 next 2645\n",
      "2025-09-23 02:21:16.220012: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b676200 of size 1024 next 2415\n",
      "2025-09-23 02:21:16.220013: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b676600 of size 4096 next 2108\n",
      "2025-09-23 02:21:16.220014: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b677600 of size 1024 next 2189\n",
      "2025-09-23 02:21:16.220015: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b677a00 of size 36864 next 2242\n",
      "2025-09-23 02:21:16.220017: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b680a00 of size 2048 next 401\n",
      "2025-09-23 02:21:16.220018: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b681200 of size 46080 next 2081\n",
      "2025-09-23 02:21:16.220020: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b68c600 of size 1024 next 2040\n",
      "2025-09-23 02:21:16.220021: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b68ca00 of size 1024 next 2240\n",
      "2025-09-23 02:21:16.220023: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b68ce00 of size 55808 next 2437\n",
      "2025-09-23 02:21:16.220024: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b69a800 of size 512 next 2179\n",
      "2025-09-23 02:21:16.220025: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b69aa00 of size 256 next 2144\n",
      "2025-09-23 02:21:16.220027: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b69ab00 of size 256 next 1792\n",
      "2025-09-23 02:21:16.220028: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b69ac00 of size 256 next 2354\n",
      "2025-09-23 02:21:16.220029: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b69ad00 of size 256 next 2301\n",
      "2025-09-23 02:21:16.220031: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b69ae00 of size 76800 next 2097\n",
      "2025-09-23 02:21:16.220032: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ada00 of size 185600 next 2593\n",
      "2025-09-23 02:21:16.220034: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6daf00 of size 1536 next 2432\n",
      "2025-09-23 02:21:16.220035: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6db500 of size 768 next 2491\n",
      "2025-09-23 02:21:16.220036: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6db800 of size 256 next 1807\n",
      "2025-09-23 02:21:16.220038: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6db900 of size 256 next 2275\n",
      "2025-09-23 02:21:16.220039: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6dba00 of size 2560 next 2085\n",
      "2025-09-23 02:21:16.220040: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6dc400 of size 512 next 2726\n",
      "2025-09-23 02:21:16.220042: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6dc600 of size 27648 next 1887\n",
      "2025-09-23 02:21:16.220043: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6e3200 of size 1536 next 505\n",
      "2025-09-23 02:21:16.220045: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 131b6e3800 of size 256 next 2584\n",
      "2025-09-23 02:21:16.220046: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6e3900 of size 4352 next 520\n",
      "2025-09-23 02:21:16.220047: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6e4a00 of size 32256 next 1866\n",
      "2025-09-23 02:21:16.220049: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ec800 of size 768 next 2431\n",
      "2025-09-23 02:21:16.220050: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ecb00 of size 256 next 1851\n",
      "2025-09-23 02:21:16.220051: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ecc00 of size 256 next 2628\n",
      "2025-09-23 02:21:16.220053: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ecd00 of size 256 next 2360\n",
      "2025-09-23 02:21:16.220054: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ece00 of size 256 next 1876\n",
      "2025-09-23 02:21:16.220056: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ecf00 of size 256 next 1970\n",
      "2025-09-23 02:21:16.220057: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ed000 of size 256 next 2378\n",
      "2025-09-23 02:21:16.220058: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ed100 of size 256 next 2177\n",
      "2025-09-23 02:21:16.220060: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ed200 of size 256 next 2687\n",
      "2025-09-23 02:21:16.220061: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ed300 of size 256 next 1763\n",
      "2025-09-23 02:21:16.220063: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ed400 of size 256 next 2693\n",
      "2025-09-23 02:21:16.220064: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ed500 of size 256 next 559\n",
      "2025-09-23 02:21:16.220065: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ed600 of size 256 next 2186\n",
      "2025-09-23 02:21:16.220067: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ed700 of size 1024 next 2145\n",
      "2025-09-23 02:21:16.220068: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6edb00 of size 14336 next 2686\n",
      "2025-09-23 02:21:16.220070: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6f1300 of size 8192 next 2759\n",
      "2025-09-23 02:21:16.220071: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6f3300 of size 8704 next 2312\n",
      "2025-09-23 02:21:16.220072: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6f5500 of size 1024 next 1748\n",
      "2025-09-23 02:21:16.220073: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6f5900 of size 256 next 2070\n",
      "2025-09-23 02:21:16.220075: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6f5a00 of size 256 next 700\n",
      "2025-09-23 02:21:16.220076: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6f5b00 of size 256 next 2129\n",
      "2025-09-23 02:21:16.220077: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6f5c00 of size 256 next 131\n",
      "2025-09-23 02:21:16.220078: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 131b6f5d00 of size 256 next 2322\n",
      "2025-09-23 02:21:16.220080: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6f5e00 of size 512 next 1814\n",
      "2025-09-23 02:21:16.220081: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6f6000 of size 18432 next 2051\n",
      "2025-09-23 02:21:16.220082: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6fa800 of size 18432 next 2460\n",
      "2025-09-23 02:21:16.220083: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ff000 of size 256 next 2735\n",
      "2025-09-23 02:21:16.220085: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ff100 of size 256 next 1975\n",
      "2025-09-23 02:21:16.220086: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ff200 of size 149248 next 2258\n",
      "2025-09-23 02:21:16.220087: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b723900 of size 1024 next 1756\n",
      "2025-09-23 02:21:16.220088: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b723d00 of size 256 next 1969\n",
      "2025-09-23 02:21:16.220090: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b723e00 of size 256 next 2048\n",
      "2025-09-23 02:21:16.220091: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b723f00 of size 256 next 2207\n",
      "2025-09-23 02:21:16.220092: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b724000 of size 256 next 2025\n",
      "2025-09-23 02:21:16.220093: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b724100 of size 256 next 2259\n",
      "2025-09-23 02:21:16.220095: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b724200 of size 256 next 613\n",
      "2025-09-23 02:21:16.220096: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b724300 of size 256 next 2010\n",
      "2025-09-23 02:21:16.220097: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b724400 of size 256 next 1881\n",
      "2025-09-23 02:21:16.220098: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b724500 of size 85760 next 2406\n",
      "2025-09-23 02:21:16.220100: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 131b739400 of size 512 next 2440\n",
      "2025-09-23 02:21:16.220101: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b739600 of size 4096 next 1865\n",
      "2025-09-23 02:21:16.220102: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b73a600 of size 2048 next 2429\n",
      "2025-09-23 02:21:16.220104: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b73ae00 of size 97792 next 2136\n",
      "2025-09-23 02:21:16.220105: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b752c00 of size 512 next 608\n",
      "2025-09-23 02:21:16.220106: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b752e00 of size 338688 next 2485\n",
      "2025-09-23 02:21:16.220108: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b7a5900 of size 115200 next 2335\n",
      "2025-09-23 02:21:16.220109: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b7c1b00 of size 36864 next 2418\n",
      "2025-09-23 02:21:16.220110: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b7cab00 of size 12800 next 1827\n",
      "2025-09-23 02:21:16.220111: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b7cdd00 of size 36864 next 1886\n",
      "2025-09-23 02:21:16.220113: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b7d6d00 of size 168704 next 18446744073709551615\n",
      "2025-09-23 02:21:16.220114: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 67108864\n",
      "2025-09-23 02:21:16.220116: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b800000 of size 7175424 next 2531\n",
      "2025-09-23 02:21:16.220117: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bed7d00 of size 1024 next 1780\n",
      "2025-09-23 02:21:16.220119: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bed8100 of size 69888 next 2464\n",
      "2025-09-23 02:21:16.220120: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bee9200 of size 1024 next 1738\n",
      "2025-09-23 02:21:16.220121: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bee9600 of size 1024 next 2263\n",
      "2025-09-23 02:21:16.220122: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bee9a00 of size 1024 next 2521\n",
      "2025-09-23 02:21:16.220124: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bee9e00 of size 256 next 2178\n",
      "2025-09-23 02:21:16.220125: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bee9f00 of size 256 next 2124\n",
      "2025-09-23 02:21:16.220126: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131beea000 of size 256 next 2361\n",
      "2025-09-23 02:21:16.220127: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131beea100 of size 256 next 2044\n",
      "2025-09-23 02:21:16.220129: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131beea200 of size 131072 next 2678\n",
      "2025-09-23 02:21:16.220130: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf0a200 of size 256 next 2524\n",
      "2025-09-23 02:21:16.220131: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf0a300 of size 256 next 2018\n",
      "2025-09-23 02:21:16.220133: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf0a400 of size 1024 next 1920\n",
      "2025-09-23 02:21:16.220134: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf0a800 of size 102400 next 2363\n",
      "2025-09-23 02:21:16.220135: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf23800 of size 256 next 2359\n",
      "2025-09-23 02:21:16.220136: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf23900 of size 256 next 1794\n",
      "2025-09-23 02:21:16.220138: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf23a00 of size 76800 next 2772\n",
      "2025-09-23 02:21:16.220139: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf36600 of size 181248 next 2649\n",
      "2025-09-23 02:21:16.220140: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf62a00 of size 768 next 2542\n",
      "2025-09-23 02:21:16.220142: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf62d00 of size 256 next 2302\n",
      "2025-09-23 02:21:16.220143: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf62e00 of size 256 next 1940\n",
      "2025-09-23 02:21:16.220145: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf62f00 of size 32512 next 2715\n",
      "2025-09-23 02:21:16.220146: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf6ae00 of size 768 next 605\n",
      "2025-09-23 02:21:16.220147: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf6b100 of size 35840 next 2202\n",
      "2025-09-23 02:21:16.220149: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf73d00 of size 1024 next 2196\n",
      "2025-09-23 02:21:16.220150: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf74100 of size 40960 next 2103\n",
      "2025-09-23 02:21:16.220151: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf7e100 of size 256 next 2317\n",
      "2025-09-23 02:21:16.220153: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf7e200 of size 256 next 2519\n",
      "2025-09-23 02:21:16.220154: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf7e300 of size 6422528 next 1754\n",
      "2025-09-23 02:21:16.220155: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131c59e300 of size 6422528 next 2002\n",
      "2025-09-23 02:21:16.220156: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131cbbe300 of size 6422528 next 2350\n",
      "2025-09-23 02:21:16.220158: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131d1de300 of size 7393536 next 2000\n",
      "2025-09-23 02:21:16.220159: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131d8eb400 of size 256 next 2001\n",
      "2025-09-23 02:21:16.220161: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131d8eb500 of size 4608 next 2095\n",
      "2025-09-23 02:21:16.220162: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131d8ec700 of size 256 next 42\n",
      "2025-09-23 02:21:16.220163: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131d8ec800 of size 6144 next 2132\n",
      "2025-09-23 02:21:16.220165: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131d8ee000 of size 256 next 2139\n",
      "2025-09-23 02:21:16.220166: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131d8ee100 of size 3840 next 1890\n",
      "2025-09-23 02:21:16.220167: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131d8ef000 of size 1024 next 2658\n",
      "2025-09-23 02:21:16.220169: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131d8ef400 of size 615424 next 2699\n",
      "2025-09-23 02:21:16.220170: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131d985800 of size 512 next 2685\n",
      "2025-09-23 02:21:16.220172: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131d985a00 of size 768 next 2569\n",
      "2025-09-23 02:21:16.220173: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131d985d00 of size 6422528 next 1898\n",
      "2025-09-23 02:21:16.220175: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131dfa5d00 of size 25535232 next 18446744073709551615\n",
      "2025-09-23 02:21:16.220176: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 134217728\n",
      "2025-09-23 02:21:16.220178: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 131f800000 of size 256 next 2022\n",
      "2025-09-23 02:21:16.220179: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131f800100 of size 512 next 2024\n",
      "2025-09-23 02:21:16.220180: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131f800300 of size 256 next 2004\n",
      "2025-09-23 02:21:16.220182: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131f800400 of size 12845056 next 2257\n",
      "2025-09-23 02:21:16.220183: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1320440400 of size 12845056 next 2436\n",
      "2025-09-23 02:21:16.220184: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1321080400 of size 12845056 next 1878\n",
      "2025-09-23 02:21:16.220185: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1321cc0400 of size 12845056 next 2568\n",
      "2025-09-23 02:21:16.220187: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1322900400 of size 12845056 next 2554\n",
      "2025-09-23 02:21:16.220188: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1323540400 of size 12845056 next 2278\n",
      "2025-09-23 02:21:16.220189: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1324180400 of size 6422528 next 2306\n",
      "2025-09-23 02:21:16.220191: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13247a0400 of size 19267584 next 2725\n",
      "2025-09-23 02:21:16.220192: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1325a00400 of size 6422528 next 2723\n",
      "2025-09-23 02:21:16.220194: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1326020400 of size 25033728 next 18446744073709551615\n",
      "2025-09-23 02:21:16.220195: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 268435456\n",
      "2025-09-23 02:21:16.220196: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1329200000 of size 25690112 next 2561\n",
      "2025-09-23 02:21:16.220198: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 132aa80000 of size 25690112 next 2107\n",
      "2025-09-23 02:21:16.220199: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 132c300000 of size 25690112 next 2761\n",
      "2025-09-23 02:21:16.220200: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 132db80000 of size 12845056 next 2079\n",
      "2025-09-23 02:21:16.220202: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 132e7c0000 of size 12845056 next 2102\n",
      "2025-09-23 02:21:16.220203: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 132f400000 of size 6422528 next 1741\n",
      "2025-09-23 02:21:16.220204: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 132fa20000 of size 19267584 next 2382\n",
      "2025-09-23 02:21:16.220206: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1330c80000 of size 6422528 next 2441\n",
      "2025-09-23 02:21:16.220207: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13312a0000 of size 25690112 next 2274\n",
      "2025-09-23 02:21:16.220209: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1332b20000 of size 25690112 next 2700\n",
      "2025-09-23 02:21:16.220210: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13343a0000 of size 25690112 next 2670\n",
      "2025-09-23 02:21:16.220211: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1335c20000 of size 25690112 next 2580\n",
      "2025-09-23 02:21:16.220213: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13374a0000 of size 30801920 next 18446744073709551615\n",
      "2025-09-23 02:21:16.220214: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 536870912\n",
      "2025-09-23 02:21:16.220216: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1339200000 of size 25690112 next 1938\n",
      "2025-09-23 02:21:16.220217: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 133aa80000 of size 25690112 next 2222\n",
      "2025-09-23 02:21:16.220218: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 133c300000 of size 25690112 next 1993\n",
      "2025-09-23 02:21:16.220219: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 133db80000 of size 25690112 next 2261\n",
      "2025-09-23 02:21:16.220221: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 133f400000 of size 25690112 next 1951\n",
      "2025-09-23 02:21:16.220222: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1340c80000 of size 25690112 next 2148\n",
      "2025-09-23 02:21:16.220223: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1342500000 of size 25690112 next 1818\n",
      "2025-09-23 02:21:16.220225: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1343d80000 of size 25690112 next 1950\n",
      "2025-09-23 02:21:16.220226: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1345600000 of size 25690112 next 542\n",
      "2025-09-23 02:21:16.220227: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1346e80000 of size 25690112 next 2233\n",
      "2025-09-23 02:21:16.220228: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1348700000 of size 12845056 next 2204\n",
      "2025-09-23 02:21:16.220230: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1349340000 of size 12845056 next 2625\n",
      "2025-09-23 02:21:16.220231: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1349f80000 of size 12845056 next 1955\n",
      "2025-09-23 02:21:16.220232: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 134abc0000 of size 6422528 next 2484\n",
      "2025-09-23 02:21:16.220234: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 134b1e0000 of size 19267584 next 1808\n",
      "2025-09-23 02:21:16.220235: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 134c440000 of size 6422528 next 2497\n",
      "2025-09-23 02:21:16.220236: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 134ca60000 of size 25690112 next 2224\n",
      "2025-09-23 02:21:16.220237: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 134e2e0000 of size 25690112 next 2117\n",
      "2025-09-23 02:21:16.220239: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 134fb60000 of size 25690112 next 2716\n",
      "2025-09-23 02:21:16.220240: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13513e0000 of size 25690112 next 2181\n",
      "2025-09-23 02:21:16.220241: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1352c60000 of size 25690112 next 2750\n",
      "2025-09-23 02:21:16.220243: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13544e0000 of size 25690112 next 2617\n",
      "2025-09-23 02:21:16.220244: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1355d60000 of size 25690112 next 2596\n",
      "2025-09-23 02:21:16.220246: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13575e0000 of size 29491200 next 18446744073709551615\n",
      "2025-09-23 02:21:16.220249: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 1073741824\n",
      "2025-09-23 02:21:16.220251: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1359200000 of size 89915392 next 2546\n",
      "2025-09-23 02:21:16.220252: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 135e7c0000 of size 89915392 next 2458\n",
      "2025-09-23 02:21:16.220253: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1363d80000 of size 89915392 next 2527\n",
      "2025-09-23 02:21:16.220254: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1369340000 of size 89915392 next 1832\n",
      "2025-09-23 02:21:16.220256: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 136e900000 of size 89915392 next 2614\n",
      "2025-09-23 02:21:16.220257: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1373ec0000 of size 89915392 next 726\n",
      "2025-09-23 02:21:16.220258: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1379480000 of size 89915392 next 2221\n",
      "2025-09-23 02:21:16.220259: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 137ea40000 of size 89915392 next 2666\n",
      "2025-09-23 02:21:16.220261: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1384000000 of size 89915392 next 2463\n",
      "2025-09-23 02:21:16.220262: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13895c0000 of size 89915392 next 2020\n",
      "2025-09-23 02:21:16.220263: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 138eb80000 of size 174587904 next 18446744073709551615\n",
      "2025-09-23 02:21:16.220265: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 2147483648\n",
      "2025-09-23 02:21:16.220266: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1399200000 of size 192675840 next 1994\n",
      "2025-09-23 02:21:16.220267: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13a49c0000 of size 16056320 next 2690\n",
      "2025-09-23 02:21:16.220269: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13a5910000 of size 64225280 next 1813\n",
      "2025-09-23 02:21:16.220270: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13a9650000 of size 64225280 next 1864\n",
      "2025-09-23 02:21:16.220271: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13ad390000 of size 768 next 2623\n",
      "2025-09-23 02:21:16.220273: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13ad390300 of size 768 next 2368\n",
      "2025-09-23 02:21:16.220274: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13ad390600 of size 768 next 2342\n",
      "2025-09-23 02:21:16.220275: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13ad390900 of size 768 next 309\n",
      "2025-09-23 02:21:16.220277: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13ad390c00 of size 64225280 next 2435\n",
      "2025-09-23 02:21:16.220278: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13b10d0c00 of size 768 next 2094\n",
      "2025-09-23 02:21:16.220280: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13b10d0f00 of size 768 next 2203\n",
      "2025-09-23 02:21:16.220281: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13b10d1200 of size 768 next 2604\n",
      "2025-09-23 02:21:16.220283: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13b10d1500 of size 768 next 2620\n",
      "2025-09-23 02:21:16.220284: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13b10d1800 of size 64225280 next 2654\n",
      "2025-09-23 02:21:16.220285: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13b4e11800 of size 64225280 next 2711\n",
      "2025-09-23 02:21:16.220287: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13b8b51800 of size 64225280 next 1797\n",
      "2025-09-23 02:21:16.220288: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13bc891800 of size 64225280 next 2086\n",
      "2025-09-23 02:21:16.220290: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13c05d1800 of size 64225280 next 2507\n",
      "2025-09-23 02:21:16.220291: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13c4311800 of size 64225280 next 2426\n",
      "2025-09-23 02:21:16.220292: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13c8051800 of size 768 next 2769\n",
      "2025-09-23 02:21:16.220294: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13c8051b00 of size 768 next 2559\n",
      "2025-09-23 02:21:16.220295: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13c8051e00 of size 768 next 2062\n",
      "2025-09-23 02:21:16.220297: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13c8052100 of size 768 next 2270\n",
      "2025-09-23 02:21:16.220298: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13c8052400 of size 64225280 next 2141\n",
      "2025-09-23 02:21:16.220300: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13cbd92400 of size 64225280 next 2534\n",
      "2025-09-23 02:21:16.220301: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13cfad2400 of size 5120 next 1899\n",
      "2025-09-23 02:21:16.220302: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13cfad3800 of size 5120 next 2305\n",
      "2025-09-23 02:21:16.220304: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13cfad4c00 of size 1280 next 2775\n",
      "2025-09-23 02:21:16.220305: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13cfad5100 of size 1280 next 2413\n",
      "2025-09-23 02:21:16.220306: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13cfad5600 of size 5120 next 1971\n",
      "2025-09-23 02:21:16.220308: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13cfad6a00 of size 5120 next 2655\n",
      "2025-09-23 02:21:16.220309: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13cfad7e00 of size 64225280 next 2180\n",
      "2025-09-23 02:21:16.220311: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13d3817e00 of size 64225280 next 2443\n",
      "2025-09-23 02:21:16.220312: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13d7557e00 of size 38535168 next 478\n",
      "2025-09-23 02:21:16.220314: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13d9a17e00 of size 38535168 next 1812\n",
      "2025-09-23 02:21:16.220315: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13dbed7e00 of size 38535168 next 2746\n",
      "2025-09-23 02:21:16.220316: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13de397e00 of size 38535168 next 2762\n",
      "2025-09-23 02:21:16.220317: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e0857e00 of size 512 next 1791\n",
      "2025-09-23 02:21:16.220319: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e0858000 of size 512 next 2311\n",
      "2025-09-23 02:21:16.220320: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e0858200 of size 512 next 757\n",
      "2025-09-23 02:21:16.220321: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e0858400 of size 19267584 next 1821\n",
      "2025-09-23 02:21:16.220322: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1ab8400 of size 768 next 1976\n",
      "2025-09-23 02:21:16.220324: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1ab8700 of size 768 next 2193\n",
      "2025-09-23 02:21:16.220325: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1ab8a00 of size 768 next 119\n",
      "2025-09-23 02:21:16.220326: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1ab8d00 of size 768 next 2452\n",
      "2025-09-23 02:21:16.220327: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1ab9000 of size 768 next 2455\n",
      "2025-09-23 02:21:16.220329: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1ab9300 of size 768 next 2271\n",
      "2025-09-23 02:21:16.220330: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1ab9600 of size 768 next 641\n",
      "2025-09-23 02:21:16.220331: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1ab9900 of size 768 next 1804\n",
      "2025-09-23 02:21:16.220333: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1ab9c00 of size 768 next 2376\n",
      "2025-09-23 02:21:16.220334: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1ab9f00 of size 768 next 1873\n",
      "2025-09-23 02:21:16.220336: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1aba200 of size 768 next 2626\n",
      "2025-09-23 02:21:16.220337: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1aba500 of size 6144 next 1883\n",
      "2025-09-23 02:21:16.220338: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1abbd00 of size 6144 next 1985\n",
      "2025-09-23 02:21:16.220339: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1abd500 of size 1536 next 2457\n",
      "2025-09-23 02:21:16.220341: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1abdb00 of size 1536 next 2066\n",
      "2025-09-23 02:21:16.220342: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1abe100 of size 6144 next 2112\n",
      "2025-09-23 02:21:16.220343: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1abf900 of size 6144 next 2098\n",
      "2025-09-23 02:21:16.220344: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1ac1100 of size 57766656 next 2269\n",
      "2025-09-23 02:21:16.220346: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e51d8400 of size 19267584 next 2256\n",
      "2025-09-23 02:21:16.220347: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e6438400 of size 77070336 next 2722\n",
      "2025-09-23 02:21:16.220348: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13eadb8400 of size 77070336 next 2741\n",
      "2025-09-23 02:21:16.220350: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13ef738400 of size 77070336 next 428\n",
      "2025-09-23 02:21:16.220351: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13f40b8400 of size 77070336 next 1863\n",
      "2025-09-23 02:21:16.220352: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13f8a38400 of size 77070336 next 2755\n",
      "2025-09-23 02:21:16.220353: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13fd3b8400 of size 77070336 next 2636\n",
      "2025-09-23 02:21:16.220354: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1401d38400 of size 77070336 next 2745\n",
      "2025-09-23 02:21:16.220356: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14066b8400 of size 77070336 next 2220\n",
      "2025-09-23 02:21:16.220357: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 140b038400 of size 77070336 next 2592\n",
      "2025-09-23 02:21:16.220358: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 140f9b8400 of size 77070336 next 2023\n",
      "2025-09-23 02:21:16.220360: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1414338400 of size 82607104 next 18446744073709551615\n",
      "2025-09-23 02:21:16.220361: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 4294967296\n",
      "2025-09-23 02:21:16.220363: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1419200000 of size 25690112 next 231\n",
      "2025-09-23 02:21:16.220364: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 141aa80000 of size 25690112 next 2768\n",
      "2025-09-23 02:21:16.220366: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 141c300000 of size 25690112 next 2012\n",
      "2025-09-23 02:21:16.220367: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 141db80000 of size 25690112 next 2039\n",
      "2025-09-23 02:21:16.220368: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 141f400000 of size 25690112 next 1745\n",
      "2025-09-23 02:21:16.220370: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1420c80000 of size 25690112 next 1923\n",
      "2025-09-23 02:21:16.220371: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1422500000 of size 25690112 next 498\n",
      "2025-09-23 02:21:16.220373: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1423d80000 of size 12845056 next 2395\n",
      "2025-09-23 02:21:16.220374: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14249c0000 of size 12845056 next 2346\n",
      "2025-09-23 02:21:16.220375: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1425600000 of size 12845056 next 2126\n",
      "2025-09-23 02:21:16.220377: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1426240000 of size 6422528 next 105\n",
      "2025-09-23 02:21:16.220378: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1426860000 of size 19267584 next 554\n",
      "2025-09-23 02:21:16.220380: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1427ac0000 of size 6422528 next 1744\n",
      "2025-09-23 02:21:16.220381: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14280e0000 of size 25690112 next 710\n",
      "2025-09-23 02:21:16.220383: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1429960000 of size 28901888 next 2694\n",
      "2025-09-23 02:21:16.220384: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 142b4f0200 of size 4096 next 349\n",
      "2025-09-23 02:21:16.220385: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 142b4f1200 of size 4096 next 2213\n",
      "2025-09-23 02:21:16.220386: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 142b4f2200 of size 4096 next 2122\n",
      "2025-09-23 02:21:16.220388: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 142b4f3200 of size 32112640 next 1859\n",
      "2025-09-23 02:21:16.220389: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 142d393200 of size 32112640 next 2279\n",
      "2025-09-23 02:21:16.220391: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 142f233200 of size 32112640 next 2574\n",
      "2025-09-23 02:21:16.220392: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14310d3200 of size 512 next 1783\n",
      "2025-09-23 02:21:16.220394: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14310d3400 of size 16056320 next 2244\n",
      "2025-09-23 02:21:16.220395: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1432023400 of size 2048 next 626\n",
      "2025-09-23 02:21:16.220396: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1432023c00 of size 2048 next 2386\n",
      "2025-09-23 02:21:16.220398: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1432024400 of size 2048 next 2260\n",
      "2025-09-23 02:21:16.220399: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1432024c00 of size 2048 next 2355\n",
      "2025-09-23 02:21:16.220400: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1432025400 of size 2048 next 2191\n",
      "2025-09-23 02:21:16.220402: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1432025c00 of size 2048 next 2506\n",
      "2025-09-23 02:21:16.220403: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1432026400 of size 2048 next 1735\n",
      "2025-09-23 02:21:16.220404: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1432026c00 of size 2048 next 551\n",
      "2025-09-23 02:21:16.220405: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1432027400 of size 15360 next 2538\n",
      "2025-09-23 02:21:16.220407: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 143202b000 of size 15360 next 2740\n",
      "2025-09-23 02:21:16.220408: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 143202ec00 of size 3840 next 2490\n",
      "2025-09-23 02:21:16.220409: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 143202fb00 of size 3840 next 2147\n",
      "2025-09-23 02:21:16.220410: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1432030a00 of size 15360 next 1907\n",
      "2025-09-23 02:21:16.220412: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1432034600 of size 15360 next 2424\n",
      "2025-09-23 02:21:16.220413: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1432038200 of size 48083456 next 561\n",
      "2025-09-23 02:21:16.220414: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1434e13400 of size 16056320 next 2703\n",
      "2025-09-23 02:21:16.220416: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1435d63400 of size 192675840 next 2227\n",
      "2025-09-23 02:21:16.220417: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1441523400 of size 192675840 next 2206\n",
      "2025-09-23 02:21:16.220418: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 144cce3400 of size 192675840 next 2249\n",
      "2025-09-23 02:21:16.220419: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14584a3400 of size 192675840 next 2453\n",
      "2025-09-23 02:21:16.220421: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1463c63400 of size 192675840 next 2736\n",
      "2025-09-23 02:21:16.220422: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146f423400 of size 192675840 next 2078\n",
      "2025-09-23 02:21:16.220423: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 147abe3400 of size 192675840 next 2037\n",
      "2025-09-23 02:21:16.220424: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14863a3400 of size 32112640 next 2428\n",
      "2025-09-23 02:21:16.220426: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1488243400 of size 32112640 next 2734\n",
      "2025-09-23 02:21:16.220427: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148a0e3400 of size 32112640 next 1905\n",
      "2025-09-23 02:21:16.220428: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148bf83400 of size 512 next 2047\n",
      "2025-09-23 02:21:16.220429: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148bf83600 of size 16056320 next 2370\n",
      "2025-09-23 02:21:16.220431: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148ced3600 of size 2048 next 1820\n",
      "2025-09-23 02:21:16.220432: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148ced3e00 of size 2048 next 2034\n",
      "2025-09-23 02:21:16.220433: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148ced4600 of size 2048 next 2118\n",
      "2025-09-23 02:21:16.220435: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148ced4e00 of size 2048 next 2513\n",
      "2025-09-23 02:21:16.220436: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148ced5600 of size 2048 next 2237\n",
      "2025-09-23 02:21:16.220437: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148ced5e00 of size 2048 next 1854\n",
      "2025-09-23 02:21:16.220438: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148ced6600 of size 2048 next 1945\n",
      "2025-09-23 02:21:16.220440: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148ced6e00 of size 2048 next 2576\n",
      "2025-09-23 02:21:16.220441: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148ced7600 of size 15360 next 2622\n",
      "2025-09-23 02:21:16.220442: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148cedb200 of size 15360 next 569\n",
      "2025-09-23 02:21:16.220444: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148cedee00 of size 3840 next 185\n",
      "2025-09-23 02:21:16.220445: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148cedfd00 of size 3840 next 2343\n",
      "2025-09-23 02:21:16.220446: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148cee0c00 of size 3840 next 2528\n",
      "2025-09-23 02:21:16.220448: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148cee1b00 of size 15360 next 1871\n",
      "2025-09-23 02:21:16.220449: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148cee5700 of size 15360 next 1752\n",
      "2025-09-23 02:21:16.220451: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148cee9300 of size 32112640 next 2029\n",
      "2025-09-23 02:21:16.220452: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148ed89300 of size 48070912 next 2508\n",
      "2025-09-23 02:21:16.220454: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1491b61400 of size 4096 next 2533\n",
      "2025-09-23 02:21:16.220455: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1491b62400 of size 4096 next 1998\n",
      "2025-09-23 02:21:16.220457: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1491b63400 of size 192675840 next 2500\n",
      "2025-09-23 02:21:16.220458: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 149d323400 of size 16056320 next 2479\n",
      "2025-09-23 02:21:16.220459: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 149e273400 of size 192675840 next 2121\n",
      "2025-09-23 02:21:16.220460: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14a9a33400 of size 192675840 next 2647\n",
      "2025-09-23 02:21:16.220462: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14b51f3400 of size 192675840 next 1852\n",
      "2025-09-23 02:21:16.220463: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14c09b3400 of size 192675840 next 90\n",
      "2025-09-23 02:21:16.220465: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14cc173400 of size 192675840 next 2352\n",
      "2025-09-23 02:21:16.220466: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d7933400 of size 192675840 next 2231\n",
      "2025-09-23 02:21:16.220468: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14e30f3400 of size 192675840 next 2621\n",
      "2025-09-23 02:21:16.220469: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14ee8b3400 of size 32112640 next 2389\n",
      "2025-09-23 02:21:16.220471: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f0753400 of size 32112640 next 1919\n",
      "2025-09-23 02:21:16.220472: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f25f3400 of size 512 next 2074\n",
      "2025-09-23 02:21:16.220473: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f25f3600 of size 16056320 next 2243\n",
      "2025-09-23 02:21:16.220475: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f3543600 of size 80269312 next 2585\n",
      "2025-09-23 02:21:16.220476: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d0600 of size 768 next 2149\n",
      "2025-09-23 02:21:16.220477: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d0900 of size 256 next 705\n",
      "2025-09-23 02:21:16.220479: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d0a00 of size 256 next 417\n",
      "2025-09-23 02:21:16.220480: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d0b00 of size 256 next 2691\n",
      "2025-09-23 02:21:16.220482: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d0c00 of size 256 next 2563\n",
      "2025-09-23 02:21:16.220483: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d0d00 of size 256 next 2639\n",
      "2025-09-23 02:21:16.220484: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d0e00 of size 256 next 2294\n",
      "2025-09-23 02:21:16.220486: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d0f00 of size 768 next 2630\n",
      "2025-09-23 02:21:16.220487: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d1200 of size 768 next 2475\n",
      "2025-09-23 02:21:16.220488: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d1500 of size 256 next 2210\n",
      "2025-09-23 02:21:16.220490: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d1600 of size 256 next 2720\n",
      "2025-09-23 02:21:16.220491: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d1700 of size 256 next 2043\n",
      "2025-09-23 02:21:16.220493: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d1800 of size 256 next 1941\n",
      "2025-09-23 02:21:16.220494: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d1900 of size 256 next 1753\n",
      "2025-09-23 02:21:16.220496: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d1a00 of size 256 next 492\n",
      "2025-09-23 02:21:16.220497: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d1b00 of size 1536 next 2272\n",
      "2025-09-23 02:21:16.220498: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d2100 of size 25690112 next 1761\n",
      "2025-09-23 02:21:16.220500: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f9a52100 of size 25690112 next 2073\n",
      "2025-09-23 02:21:16.220501: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14fb2d2100 of size 25690112 next 2007\n",
      "2025-09-23 02:21:16.220502: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14fcb52100 of size 25690112 next 2650\n",
      "2025-09-23 02:21:16.220504: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14fe3d2100 of size 12845056 next 2721\n",
      "2025-09-23 02:21:16.220505: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14ff012100 of size 12845056 next 2367\n",
      "2025-09-23 02:21:16.220507: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14ffc52100 of size 12845056 next 1929\n",
      "2025-09-23 02:21:16.220508: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1500892100 of size 6422528 next 2659\n",
      "2025-09-23 02:21:16.220510: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1500eb2100 of size 19267584 next 2631\n",
      "2025-09-23 02:21:16.220511: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1502112100 of size 6422528 next 1992\n",
      "2025-09-23 02:21:16.220512: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1502732100 of size 25690112 next 2400\n",
      "2025-09-23 02:21:16.220514: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1503fb2100 of size 25690112 next 2164\n",
      "2025-09-23 02:21:16.220515: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1505832100 of size 25690112 next 111\n",
      "2025-09-23 02:21:16.220516: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15070b2100 of size 25690112 next 2556\n",
      "2025-09-23 02:21:16.220518: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1508932100 of size 25690112 next 2515\n",
      "2025-09-23 02:21:16.220519: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 150a1b2100 of size 25690112 next 1740\n",
      "2025-09-23 02:21:16.220521: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 150ba32100 of size 25690112 next 2372\n",
      "2025-09-23 02:21:16.220522: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 150d2b2100 of size 25690112 next 2562\n",
      "2025-09-23 02:21:16.220524: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 150eb32100 of size 25690112 next 483\n",
      "2025-09-23 02:21:16.220525: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15103b2100 of size 25690112 next 2640\n",
      "2025-09-23 02:21:16.220526: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1511c32100 of size 25690112 next 2419\n",
      "2025-09-23 02:21:16.220528: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15134b2100 of size 25690112 next 2075\n",
      "2025-09-23 02:21:16.220529: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1514d32100 of size 12845056 next 2045\n",
      "2025-09-23 02:21:16.220530: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1515972100 of size 12845056 next 592\n",
      "2025-09-23 02:21:16.220531: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15165b2100 of size 12845056 next 2577\n",
      "2025-09-23 02:21:16.220533: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15171f2100 of size 6422528 next 2320\n",
      "2025-09-23 02:21:16.220534: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1517812100 of size 4096 next 2041\n",
      "2025-09-23 02:21:16.220535: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1517813100 of size 4096 next 2399\n",
      "2025-09-23 02:21:16.220536: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1517814100 of size 4096 next 2707\n",
      "2025-09-23 02:21:16.220538: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1517815100 of size 27176704 next 18446744073709551615\n",
      "2025-09-23 02:21:16.220539: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 8589934592\n",
      "2025-09-23 02:21:16.220540: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1519200000 of size 89915392 next 2059\n",
      "2025-09-23 02:21:16.220542: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 151e7c0000 of size 89915392 next 1801\n",
      "2025-09-23 02:21:16.220543: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1523d80000 of size 89915392 next 2153\n",
      "2025-09-23 02:21:16.220544: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1529340000 of size 89915392 next 2469\n",
      "2025-09-23 02:21:16.220545: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 152e900000 of size 22478848 next 1789\n",
      "2025-09-23 02:21:16.220547: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 152fe70000 of size 22478848 next 2488\n",
      "2025-09-23 02:21:16.220548: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15313e0000 of size 22478848 next 2403\n",
      "2025-09-23 02:21:16.220549: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1532950000 of size 256 next 2309\n",
      "2025-09-23 02:21:16.220551: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1532950100 of size 256 next 2401\n",
      "2025-09-23 02:21:16.220552: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1532950200 of size 11239424 next 1917\n",
      "2025-09-23 02:21:16.220553: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1533408200 of size 1024 next 2526\n",
      "2025-09-23 02:21:16.220555: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1533408600 of size 1024 next 2195\n",
      "2025-09-23 02:21:16.220556: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1533408a00 of size 1024 next 2019\n",
      "2025-09-23 02:21:16.220557: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1533408e00 of size 1024 next 300\n",
      "2025-09-23 02:21:16.220559: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1533409200 of size 1024 next 2099\n",
      "2025-09-23 02:21:16.220560: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1533409600 of size 1024 next 2480\n",
      "2025-09-23 02:21:16.220562: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1533409a00 of size 1024 next 570\n",
      "2025-09-23 02:21:16.220563: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1533409e00 of size 1024 next 1734\n",
      "2025-09-23 02:21:16.220565: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 153340a200 of size 1024 next 2169\n",
      "2025-09-23 02:21:16.220566: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 153340a600 of size 1024 next 1891\n",
      "2025-09-23 02:21:16.220567: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 153340aa00 of size 1024 next 2612\n",
      "2025-09-23 02:21:16.220569: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 153340ae00 of size 1024 next 1914\n",
      "2025-09-23 02:21:16.220570: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 153340b200 of size 1024 next 2013\n",
      "2025-09-23 02:21:16.220571: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 153340b600 of size 7168 next 1922\n",
      "2025-09-23 02:21:16.220573: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 153340d200 of size 7168 next 2615\n",
      "2025-09-23 02:21:16.220574: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 153340ee00 of size 1792 next 2262\n",
      "2025-09-23 02:21:16.220576: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 153340f500 of size 1792 next 2234\n",
      "2025-09-23 02:21:16.220577: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 153340fc00 of size 1792 next 1869\n",
      "2025-09-23 02:21:16.220578: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1533410300 of size 7168 next 152\n",
      "2025-09-23 02:21:16.220580: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1533411f00 of size 7168 next 1896\n",
      "2025-09-23 02:21:16.220581: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1533413b00 of size 33670912 next 1779\n",
      "2025-09-23 02:21:16.220582: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1535430200 of size 11239424 next 2388\n",
      "2025-09-23 02:21:16.220584: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1535ee8200 of size 89915392 next 2633\n",
      "2025-09-23 02:21:16.220585: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 153b4a8200 of size 89915392 next 1909\n",
      "2025-09-23 02:21:16.220587: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1540a68200 of size 89915392 next 2127\n",
      "2025-09-23 02:21:16.220588: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1546028200 of size 89915392 next 2131\n",
      "2025-09-23 02:21:16.220589: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 154b5e8200 of size 89915392 next 2733\n",
      "2025-09-23 02:21:16.220591: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1550ba8200 of size 89915392 next 2481\n",
      "2025-09-23 02:21:16.220592: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1556168200 of size 104366592 next 2607\n",
      "2025-09-23 02:21:16.220594: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 155c4f0400 of size 4096 next 2014\n",
      "2025-09-23 02:21:16.220595: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 155c4f1400 of size 4096 next 2362\n",
      "2025-09-23 02:21:16.220596: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 155c4f2400 of size 4096 next 2156\n",
      "2025-09-23 02:21:16.220598: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 155c4f3400 of size 192675840 next 2198\n",
      "2025-09-23 02:21:16.220599: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1567cb3400 of size 192675840 next 2541\n",
      "2025-09-23 02:21:16.220600: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1573473400 of size 192675840 next 2265\n",
      "2025-09-23 02:21:16.220601: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 157ec33400 of size 192675840 next 2068\n",
      "2025-09-23 02:21:16.220603: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 158a3f3400 of size 192675840 next 2555\n",
      "2025-09-23 02:21:16.220604: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1595bb3400 of size 192675840 next 2738\n",
      "2025-09-23 02:21:16.220605: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15a1373400 of size 317907968 next 463\n",
      "2025-09-23 02:21:16.220606: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b42a1800 of size 22478848 next 1972\n",
      "2025-09-23 02:21:16.220608: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b5811800 of size 22478848 next 2250\n",
      "2025-09-23 02:21:16.220609: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b6d81800 of size 22478848 next 1902\n",
      "2025-09-23 02:21:16.220610: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b82f1800 of size 11239424 next 178\n",
      "2025-09-23 02:21:16.220611: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8da9800 of size 1024 next 1991\n",
      "2025-09-23 02:21:16.220613: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8da9c00 of size 1024 next 669\n",
      "2025-09-23 02:21:16.220614: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8daa000 of size 1024 next 2398\n",
      "2025-09-23 02:21:16.220615: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8daa400 of size 1024 next 2319\n",
      "2025-09-23 02:21:16.220616: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8daa800 of size 1024 next 1798\n",
      "2025-09-23 02:21:16.220618: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8daac00 of size 1024 next 1995\n",
      "2025-09-23 02:21:16.220619: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8dab000 of size 1024 next 1781\n",
      "2025-09-23 02:21:16.220620: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8dab400 of size 7168 next 2327\n",
      "2025-09-23 02:21:16.220622: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8dad000 of size 7168 next 2276\n",
      "2025-09-23 02:21:16.220623: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8daec00 of size 1792 next 1816\n",
      "2025-09-23 02:21:16.220625: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8daf300 of size 1792 next 2109\n",
      "2025-09-23 02:21:16.220626: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8dafa00 of size 1792 next 2462\n",
      "2025-09-23 02:21:16.220628: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8db0100 of size 7168 next 2537\n",
      "2025-09-23 02:21:16.220629: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8db1d00 of size 7168 next 2719\n",
      "2025-09-23 02:21:16.220630: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8db3900 of size 33677056 next 1805\n",
      "2025-09-23 02:21:16.220632: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15badd1800 of size 11239424 next 2461\n",
      "2025-09-23 02:21:16.220633: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15bb889800 of size 89915392 next 2540\n",
      "2025-09-23 02:21:16.220634: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15c0e49800 of size 89915392 next 2739\n",
      "2025-09-23 02:21:16.220636: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15c6409800 of size 89915392 next 2732\n",
      "2025-09-23 02:21:16.220637: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15cb9c9800 of size 89915392 next 2247\n",
      "2025-09-23 02:21:16.220639: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15d0f89800 of size 89915392 next 2632\n",
      "2025-09-23 02:21:16.220640: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15d6549800 of size 89915392 next 1979\n",
      "2025-09-23 02:21:16.220641: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15dbb09800 of size 89915392 next 2296\n",
      "2025-09-23 02:21:16.220643: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15e10c9800 of size 89915392 next 2532\n",
      "2025-09-23 02:21:16.220644: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15e6689800 of size 89915392 next 2125\n",
      "2025-09-23 02:21:16.220645: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15ebc49800 of size 165374976 next 2763\n",
      "2025-09-23 02:21:16.220647: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15f5a00400 of size 768 next 65\n",
      "2025-09-23 02:21:16.220648: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15f5a00700 of size 2560 next 1901\n",
      "2025-09-23 02:21:16.220650: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15f5a01100 of size 77070336 next 2408\n",
      "2025-09-23 02:21:16.220651: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15fa381100 of size 77070336 next 1838\n",
      "2025-09-23 02:21:16.220652: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15fed01100 of size 77070336 next 2344\n",
      "2025-09-23 02:21:16.220654: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1603681100 of size 38535168 next 1983\n",
      "2025-09-23 02:21:16.220655: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1605b41100 of size 38535168 next 2478\n",
      "2025-09-23 02:21:16.220657: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1608001100 of size 512 next 2190\n",
      "2025-09-23 02:21:16.220658: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1608001300 of size 38535168 next 687\n",
      "2025-09-23 02:21:16.220659: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160a4c1300 of size 512 next 2448\n",
      "2025-09-23 02:21:16.220661: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160a4c1500 of size 512 next 1800\n",
      "2025-09-23 02:21:16.220662: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160a4c1700 of size 512 next 2456\n",
      "2025-09-23 02:21:16.220664: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160a4c1900 of size 512 next 2657\n",
      "2025-09-23 02:21:16.220665: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160a4c1b00 of size 19267584 next 2751\n",
      "2025-09-23 02:21:16.220666: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b721b00 of size 768 next 71\n",
      "2025-09-23 02:21:16.220668: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b721e00 of size 768 next 681\n",
      "2025-09-23 02:21:16.220669: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b722100 of size 768 next 2318\n",
      "2025-09-23 02:21:16.220670: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b722400 of size 768 next 2579\n",
      "2025-09-23 02:21:16.220672: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b722700 of size 768 next 1749\n",
      "2025-09-23 02:21:16.220673: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b722a00 of size 768 next 2105\n",
      "2025-09-23 02:21:16.220675: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b722d00 of size 768 next 2669\n",
      "2025-09-23 02:21:16.220676: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b723000 of size 768 next 2641\n",
      "2025-09-23 02:21:16.220677: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b723300 of size 768 next 2539\n",
      "2025-09-23 02:21:16.220679: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b723600 of size 768 next 2330\n",
      "2025-09-23 02:21:16.220680: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b723900 of size 768 next 70\n",
      "2025-09-23 02:21:16.220681: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b723c00 of size 6144 next 2667\n",
      "2025-09-23 02:21:16.220682: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b725400 of size 6144 next 2742\n",
      "2025-09-23 02:21:16.220684: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b726c00 of size 1536 next 2756\n",
      "2025-09-23 02:21:16.220685: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b727200 of size 1536 next 1737\n",
      "2025-09-23 02:21:16.220686: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b727800 of size 1536 next 1772\n",
      "2025-09-23 02:21:16.220687: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b727e00 of size 6144 next 1739\n",
      "2025-09-23 02:21:16.220689: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b729600 of size 6144 next 529\n",
      "2025-09-23 02:21:16.220690: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b72ae00 of size 57765120 next 460\n",
      "2025-09-23 02:21:16.220691: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160ee41b00 of size 19267584 next 2498\n",
      "2025-09-23 02:21:16.220693: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16100a1b00 of size 77070336 next 1750\n",
      "2025-09-23 02:21:16.220694: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1614a21b00 of size 77070336 next 2629\n",
      "2025-09-23 02:21:16.220695: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16193a1b00 of size 77070336 next 2326\n",
      "2025-09-23 02:21:16.220697: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 161dd21b00 of size 77070336 next 2774\n",
      "2025-09-23 02:21:16.220698: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16226a1b00 of size 77070336 next 2553\n",
      "2025-09-23 02:21:16.220699: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1627021b00 of size 77070336 next 1747\n",
      "2025-09-23 02:21:16.220700: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 162b9a1b00 of size 77070336 next 1809\n",
      "2025-09-23 02:21:16.220702: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1630321b00 of size 77070336 next 2550\n",
      "2025-09-23 02:21:16.220703: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1634ca1b00 of size 77070336 next 1823\n",
      "2025-09-23 02:21:16.220704: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1639621b00 of size 77070336 next 1928\n",
      "2025-09-23 02:21:16.220706: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 163dfa1b00 of size 77070336 next 2061\n",
      "2025-09-23 02:21:16.220707: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1642921b00 of size 77070336 next 2747\n",
      "2025-09-23 02:21:16.220708: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16472a1b00 of size 77070336 next 2307\n",
      "2025-09-23 02:21:16.220710: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 164bc21b00 of size 77070336 next 202\n",
      "2025-09-23 02:21:16.220711: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16505a1b00 of size 38535168 next 2603\n",
      "2025-09-23 02:21:16.220713: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1652a61b00 of size 38535168 next 2176\n",
      "2025-09-23 02:21:16.220714: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1654f21b00 of size 38535168 next 2143\n",
      "2025-09-23 02:21:16.220715: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16573e1b00 of size 512 next 2046\n",
      "2025-09-23 02:21:16.220717: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16573e1d00 of size 19267584 next 2718\n",
      "2025-09-23 02:21:16.220718: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658641d00 of size 768 next 2192\n",
      "2025-09-23 02:21:16.220720: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658642000 of size 768 next 2289\n",
      "2025-09-23 02:21:16.220721: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658642300 of size 768 next 1913\n",
      "2025-09-23 02:21:16.220722: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658642600 of size 768 next 23\n",
      "2025-09-23 02:21:16.220724: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658642900 of size 768 next 2366\n",
      "2025-09-23 02:21:16.220725: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658642c00 of size 768 next 2496\n",
      "2025-09-23 02:21:16.220726: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658642f00 of size 768 next 2551\n",
      "2025-09-23 02:21:16.220728: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658643200 of size 768 next 2511\n",
      "2025-09-23 02:21:16.220729: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658643500 of size 768 next 2208\n",
      "2025-09-23 02:21:16.220731: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658643800 of size 768 next 2727\n",
      "2025-09-23 02:21:16.220732: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658643b00 of size 768 next 2410\n",
      "2025-09-23 02:21:16.220733: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658643e00 of size 6144 next 2235\n",
      "2025-09-23 02:21:16.220735: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658645600 of size 6144 next 1802\n",
      "2025-09-23 02:21:16.220736: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658646e00 of size 1536 next 2770\n",
      "2025-09-23 02:21:16.220737: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658647400 of size 1536 next 2084\n",
      "2025-09-23 02:21:16.220738: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658647a00 of size 1536 next 2433\n",
      "2025-09-23 02:21:16.220740: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658648000 of size 6144 next 2076\n",
      "2025-09-23 02:21:16.220741: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658649800 of size 6144 next 2058\n",
      "2025-09-23 02:21:16.220742: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 165864b000 of size 57765120 next 2228\n",
      "2025-09-23 02:21:16.220743: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 165bd61d00 of size 19267584 next 2217\n",
      "2025-09-23 02:21:16.220745: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 165cfc1d00 of size 77070336 next 434\n",
      "2025-09-23 02:21:16.220746: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1661941d00 of size 77070336 next 1981\n",
      "2025-09-23 02:21:16.220747: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16662c1d00 of size 77070336 next 2760\n",
      "2025-09-23 02:21:16.220748: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 166ac41d00 of size 77070336 next 2494\n",
      "2025-09-23 02:21:16.220750: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 166f5c1d00 of size 77070336 next 1963\n",
      "2025-09-23 02:21:16.220751: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1673f41d00 of size 77070336 next 470\n",
      "2025-09-23 02:21:16.220753: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16788c1d00 of size 77070336 next 2252\n",
      "2025-09-23 02:21:16.220754: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 167d241d00 of size 77070336 next 459\n",
      "2025-09-23 02:21:16.220756: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1681bc1d00 of size 77070336 next 443\n",
      "2025-09-23 02:21:16.220757: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1686541d00 of size 77070336 next 1888\n",
      "2025-09-23 02:21:16.220758: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 168aec1d00 of size 77070336 next 2601\n",
      "2025-09-23 02:21:16.220759: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 168f841d00 of size 77070336 next 1978\n",
      "2025-09-23 02:21:16.220761: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16941c1d00 of size 77070336 next 2698\n",
      "2025-09-23 02:21:16.220762: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1698b41d00 of size 77070336 next 1835\n",
      "2025-09-23 02:21:16.220764: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 169d4c1d00 of size 38535168 next 624\n",
      "2025-09-23 02:21:16.220765: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 169f981d00 of size 38535168 next 2071\n",
      "2025-09-23 02:21:16.220767: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16a1e41d00 of size 38535168 next 2323\n",
      "2025-09-23 02:21:16.220768: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16a4301d00 of size 512 next 2248\n",
      "2025-09-23 02:21:16.220769: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16a4301f00 of size 512 next 2138\n",
      "2025-09-23 02:21:16.220771: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16a4302100 of size 512 next 86\n",
      "2025-09-23 02:21:16.220772: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16a4302300 of size 19267584 next 2676\n",
      "2025-09-23 02:21:16.220773: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16a5562300 of size 57802752 next 2525\n",
      "2025-09-23 02:21:16.220775: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16a8c82300 of size 19267584 next 1897\n",
      "2025-09-23 02:21:16.220776: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16a9ee2300 of size 44957696 next 390\n",
      "2025-09-23 02:21:16.220777: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16ac9c2300 of size 44957696 next 1885\n",
      "2025-09-23 02:21:16.220779: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16af4a2300 of size 44957696 next 660\n",
      "2025-09-23 02:21:16.220780: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16b1f82300 of size 512 next 2159\n",
      "2025-09-23 02:21:16.220781: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16b1f82500 of size 512 next 1828\n",
      "2025-09-23 02:21:16.220782: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16b1f82700 of size 512 next 2451\n",
      "2025-09-23 02:21:16.220784: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16b1f82900 of size 512 next 1962\n",
      "2025-09-23 02:21:16.220785: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 16b1f82b00 of size 18176 next 2522\n",
      "2025-09-23 02:21:16.220786: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16b1f87200 of size 256 next 2474\n",
      "2025-09-23 02:21:16.220787: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 16b1f87300 of size 9728 next 2035\n",
      "2025-09-23 02:21:16.220789: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16b1f89900 of size 3840 next 2776\n",
      "2025-09-23 02:21:16.220790: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16b1f8a800 of size 57344 next 1927\n",
      "2025-09-23 02:21:16.220791: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16b1f98800 of size 44957696 next 2597\n",
      "2025-09-23 02:21:16.220792: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16b4a78800 of size 44957696 next 2610\n",
      "2025-09-23 02:21:16.220794: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16b7558800 of size 44957696 next 2434\n",
      "2025-09-23 02:21:16.220795: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16ba038800 of size 85008384 next 2356\n",
      "2025-09-23 02:21:16.220797: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16bf14a800 of size 1024 next 2483\n",
      "2025-09-23 02:21:16.220798: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16bf14ac00 of size 1024 next 1829\n",
      "2025-09-23 02:21:16.220799: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16bf14b000 of size 1024 next 2072\n",
      "2025-09-23 02:21:16.220801: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16bf14b400 of size 1024 next 2466\n",
      "2025-09-23 02:21:16.220802: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16bf14b800 of size 1024 next 2215\n",
      "2025-09-23 02:21:16.220803: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16bf14bc00 of size 1024 next 2146\n",
      "2025-09-23 02:21:16.220805: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16bf14c000 of size 134873088 next 2157\n",
      "2025-09-23 02:21:16.220806: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16c71ec000 of size 134873088 next 2570\n",
      "2025-09-23 02:21:16.220808: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16cf28c000 of size 134873088 next 2214\n",
      "2025-09-23 02:21:16.220809: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16d732c000 of size 134873088 next 196\n",
      "2025-09-23 02:21:16.220810: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16df3cc000 of size 134873088 next 2504\n",
      "2025-09-23 02:21:16.220811: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16e746c000 of size 134873088 next 2371\n",
      "2025-09-23 02:21:16.220813: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16ef50c000 of size 134873088 next 1947\n",
      "2025-09-23 02:21:16.220814: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16f75ac000 of size 32112640 next 2590\n",
      "2025-09-23 02:21:16.220815: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16f944c000 of size 32112640 next 721\n",
      "2025-09-23 02:21:16.220816: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fb2ec000 of size 512 next 2285\n",
      "2025-09-23 02:21:16.220818: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fb2ec200 of size 32112640 next 2304\n",
      "2025-09-23 02:21:16.220819: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fd18c200 of size 512 next 763\n",
      "2025-09-23 02:21:16.220820: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fd18c400 of size 512 next 2420\n",
      "2025-09-23 02:21:16.220822: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fd18c600 of size 512 next 2357\n",
      "2025-09-23 02:21:16.220823: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fd18c800 of size 512 next 1799\n",
      "2025-09-23 02:21:16.220825: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fd18ca00 of size 16056320 next 1952\n",
      "2025-09-23 02:21:16.220826: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0dca00 of size 2048 next 2137\n",
      "2025-09-23 02:21:16.220827: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0dd200 of size 2048 next 2310\n",
      "2025-09-23 02:21:16.220829: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0dda00 of size 2048 next 2572\n",
      "2025-09-23 02:21:16.220830: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0de200 of size 2048 next 2246\n",
      "2025-09-23 02:21:16.220831: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0dea00 of size 2048 next 2674\n",
      "2025-09-23 02:21:16.220833: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0df200 of size 2048 next 2638\n",
      "2025-09-23 02:21:16.220834: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0dfa00 of size 2048 next 2026\n",
      "2025-09-23 02:21:16.220836: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0e0200 of size 2048 next 1850\n",
      "2025-09-23 02:21:16.220837: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0e0a00 of size 15360 next 1766\n",
      "2025-09-23 02:21:16.220839: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0e4600 of size 15360 next 1822\n",
      "2025-09-23 02:21:16.220840: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0e8200 of size 3840 next 2594\n",
      "2025-09-23 02:21:16.220841: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0e9100 of size 3840 next 1840\n",
      "2025-09-23 02:21:16.220843: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0ea000 of size 15360 next 2753\n",
      "2025-09-23 02:21:16.220844: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0edc00 of size 15360 next 2293\n",
      "2025-09-23 02:21:16.220846: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0f1800 of size 48083456 next 2445\n",
      "2025-09-23 02:21:16.220847: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1700ecca00 of size 16056320 next 1790\n",
      "2025-09-23 02:21:16.220848: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1701e1ca00 of size 261710336 next 1765\n",
      "2025-09-23 02:21:16.220849: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17117b2c00 of size 1024 next 1826\n",
      "2025-09-23 02:21:16.220851: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17117b3000 of size 1024 next 1853\n",
      "2025-09-23 02:21:16.220852: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17117b3400 of size 1024 next 2501\n",
      "2025-09-23 02:21:16.220853: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17117b3800 of size 3072 next 2502\n",
      "2025-09-23 02:21:16.220854: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17117b4400 of size 12845056 next 2493\n",
      "2025-09-23 02:21:16.220856: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17123f4400 of size 12845056 next 1837\n",
      "2025-09-23 02:21:16.220857: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1713034400 of size 12845056 next 2608\n",
      "2025-09-23 02:21:16.220858: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1713c74400 of size 12845056 next 631\n",
      "2025-09-23 02:21:16.220859: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17148b4400 of size 12845056 next 1911\n",
      "2025-09-23 02:21:16.220861: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17154f4400 of size 12845056 next 2765\n",
      "2025-09-23 02:21:16.220862: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1716134400 of size 12845056 next 2663\n",
      "2025-09-23 02:21:16.220863: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1716d74400 of size 12845056 next 2743\n",
      "2025-09-23 02:21:16.220865: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17179b4400 of size 25476096 next 18446744073709551615\n",
      "2025-09-23 02:21:16.220866: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 5322571776\n",
      "2025-09-23 02:21:16.220867: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1719200000 of size 6422528 next 2492\n",
      "2025-09-23 02:21:16.220869: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1719820000 of size 51380224 next 2348\n",
      "2025-09-23 02:21:16.220870: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 171c920000 of size 51380224 next 1895\n",
      "2025-09-23 02:21:16.220872: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 171fa20000 of size 51380224 next 2101\n",
      "2025-09-23 02:21:16.220873: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1722b20000 of size 51380224 next 2171\n",
      "2025-09-23 02:21:16.220874: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1725c20000 of size 51380224 next 2165\n",
      "2025-09-23 02:21:16.220875: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1728d20000 of size 51380224 next 1845\n",
      "2025-09-23 02:21:16.220877: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 172be20000 of size 51380224 next 1977\n",
      "2025-09-23 02:21:16.220878: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 172ef20000 of size 51380224 next 214\n",
      "2025-09-23 02:21:16.220880: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1732020000 of size 51380224 next 1961\n",
      "2025-09-23 02:21:16.220881: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1735120000 of size 96338432 next 2427\n",
      "2025-09-23 02:21:16.220882: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173ad00200 of size 1024 next 1847\n",
      "2025-09-23 02:21:16.220884: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173ad00600 of size 691200 next 2706\n",
      "2025-09-23 02:21:16.220885: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173ada9200 of size 691200 next 2589\n",
      "2025-09-23 02:21:16.220886: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173ae51e00 of size 691200 next 2709\n",
      "2025-09-23 02:21:16.220888: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173aefaa00 of size 691200 next 2588\n",
      "2025-09-23 02:21:16.220889: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173afa3600 of size 76800 next 141\n",
      "2025-09-23 02:21:16.220890: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173afb6200 of size 691200 next 489\n",
      "2025-09-23 02:21:16.220891: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b05ee00 of size 115200 next 2581\n",
      "2025-09-23 02:21:16.220893: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b07b000 of size 115200 next 2273\n",
      "2025-09-23 02:21:16.220894: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b097200 of size 36864 next 2668\n",
      "2025-09-23 02:21:16.220895: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b0a0200 of size 115200 next 1959\n",
      "2025-09-23 02:21:16.220896: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b0bc400 of size 76800 next 2446\n",
      "2025-09-23 02:21:16.220898: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b0cf000 of size 12800 next 2267\n",
      "2025-09-23 02:21:16.220899: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b0d2200 of size 18432 next 1839\n",
      "2025-09-23 02:21:16.220900: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b0d6a00 of size 36864 next 1806\n",
      "2025-09-23 02:21:16.220902: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b0dfa00 of size 18432 next 1743\n",
      "2025-09-23 02:21:16.220903: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b0e4200 of size 36864 next 49\n",
      "2025-09-23 02:21:16.220905: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b0ed200 of size 115200 next 2624\n",
      "2025-09-23 02:21:16.220906: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b109400 of size 691200 next 2549\n",
      "2025-09-23 02:21:16.220908: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b1b2000 of size 36864 next 2648\n",
      "2025-09-23 02:21:16.220909: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b1bb000 of size 18432 next 2150\n",
      "2025-09-23 02:21:16.220910: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b1bf800 of size 115200 next 1904\n",
      "2025-09-23 02:21:16.220912: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b1dba00 of size 115200 next 2529\n",
      "2025-09-23 02:21:16.220913: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b1f7c00 of size 76800 next 2069\n",
      "2025-09-23 02:21:16.220914: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b20a800 of size 36864 next 2701\n",
      "2025-09-23 02:21:16.220916: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b213800 of size 18432 next 2397\n",
      "2025-09-23 02:21:16.220917: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b218000 of size 76800 next 2288\n",
      "2025-09-23 02:21:16.220919: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b22ac00 of size 30720 next 1746\n",
      "2025-09-23 02:21:16.220920: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b232400 of size 56576 next 2111\n",
      "2025-09-23 02:21:16.220922: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b240100 of size 36864 next 689\n",
      "2025-09-23 02:21:16.220923: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b249100 of size 25600 next 2605\n",
      "2025-09-23 02:21:16.220924: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b24f500 of size 12800 next 1957\n",
      "2025-09-23 02:21:16.220926: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b252700 of size 18432 next 1811\n",
      "2025-09-23 02:21:16.220927: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b256f00 of size 30720 next 2618\n",
      "2025-09-23 02:21:16.220928: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b25e700 of size 8192 next 2425\n",
      "2025-09-23 02:21:16.220930: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b260700 of size 18432 next 2050\n",
      "2025-09-23 02:21:16.220931: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 173b264f00 of size 28672 next 1958\n",
      "2025-09-23 02:21:16.220933: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b26bf00 of size 18432 next 412\n",
      "2025-09-23 02:21:16.220934: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b270700 of size 25088 next 2209\n",
      "2025-09-23 02:21:16.220935: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b276900 of size 21504 next 1990\n",
      "2025-09-23 02:21:16.220937: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b27bd00 of size 12800 next 2444\n",
      "2025-09-23 02:21:16.220938: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b27ef00 of size 36864 next 1989\n",
      "2025-09-23 02:21:16.220939: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b287f00 of size 18432 next 2345\n",
      "2025-09-23 02:21:16.220941: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b28c700 of size 18432 next 1982\n",
      "2025-09-23 02:21:16.220942: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b290f00 of size 21504 next 1964\n",
      "2025-09-23 02:21:16.220943: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b296300 of size 25088 next 2472\n",
      "2025-09-23 02:21:16.220945: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b29c500 of size 25088 next 2402\n",
      "2025-09-23 02:21:16.220946: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2a2700 of size 36864 next 2212\n",
      "2025-09-23 02:21:16.220948: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2ab700 of size 25088 next 2239\n",
      "2025-09-23 02:21:16.220949: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2b1900 of size 25088 next 2033\n",
      "2025-09-23 02:21:16.220950: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2b7b00 of size 25088 next 2409\n",
      "2025-09-23 02:21:16.220952: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2bdd00 of size 4096 next 1833\n",
      "2025-09-23 02:21:16.220953: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2bed00 of size 4096 next 2016\n",
      "2025-09-23 02:21:16.220954: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2bfd00 of size 25088 next 1764\n",
      "2025-09-23 02:21:16.220956: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2c5f00 of size 4096 next 2174\n",
      "2025-09-23 02:21:16.220957: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2c6f00 of size 25088 next 2375\n",
      "2025-09-23 02:21:16.220959: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2cd100 of size 4096 next 2280\n",
      "2025-09-23 02:21:16.220960: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2ce100 of size 4096 next 2543\n",
      "2025-09-23 02:21:16.220961: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2cf100 of size 4096 next 2442\n",
      "2025-09-23 02:21:16.220962: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2d0100 of size 4096 next 2404\n",
      "2025-09-23 02:21:16.220964: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2d1100 of size 8192 next 2194\n",
      "2025-09-23 02:21:16.220965: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2d3100 of size 4096 next 2315\n",
      "2025-09-23 02:21:16.220966: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2d4100 of size 25088 next 2656\n",
      "2025-09-23 02:21:16.220967: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2da300 of size 25088 next 2712\n",
      "2025-09-23 02:21:16.220969: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2e0500 of size 25088 next 1778\n",
      "2025-09-23 02:21:16.220970: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2e6700 of size 25088 next 2211\n",
      "2025-09-23 02:21:16.220971: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2ec900 of size 25088 next 282\n",
      "2025-09-23 02:21:16.220972: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2f2b00 of size 4096 next 1861\n",
      "2025-09-23 02:21:16.220974: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2f3b00 of size 4096 next 1824\n",
      "2025-09-23 02:21:16.220975: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2f4b00 of size 4096 next 1872\n",
      "2025-09-23 02:21:16.220976: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2f5b00 of size 8192 next 2119\n",
      "2025-09-23 02:21:16.220978: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2f7b00 of size 25088 next 1867\n",
      "2025-09-23 02:21:16.220979: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2fdd00 of size 25088 next 2080\n",
      "2025-09-23 02:21:16.220980: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b303f00 of size 4096 next 1848\n",
      "2025-09-23 02:21:16.220982: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b304f00 of size 4096 next 2161\n",
      "2025-09-23 02:21:16.220983: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b305f00 of size 25088 next 1980\n",
      "2025-09-23 02:21:16.220985: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b30c100 of size 25088 next 2090\n",
      "2025-09-23 02:21:16.220986: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b312300 of size 25088 next 537\n",
      "2025-09-23 02:21:16.220988: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b318500 of size 8192 next 74\n",
      "2025-09-23 02:21:16.220989: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b31a500 of size 25088 next 1931\n",
      "2025-09-23 02:21:16.220990: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b320700 of size 25088 next 1932\n",
      "2025-09-23 02:21:16.220992: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b326900 of size 25088 next 1997\n",
      "2025-09-23 02:21:16.220993: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b32cb00 of size 25088 next 2643\n",
      "2025-09-23 02:21:16.220994: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b332d00 of size 25088 next 334\n",
      "2025-09-23 02:21:16.220996: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b338f00 of size 25088 next 2162\n",
      "2025-09-23 02:21:16.220997: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b33f100 of size 4096 next 2449\n",
      "2025-09-23 02:21:16.220998: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b340100 of size 4096 next 2385\n",
      "2025-09-23 02:21:16.221000: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b341100 of size 25088 next 2316\n",
      "2025-09-23 02:21:16.221001: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b347300 of size 25088 next 2038\n",
      "2025-09-23 02:21:16.221002: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b34d500 of size 25088 next 2503\n",
      "2025-09-23 02:21:16.221003: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b353700 of size 25088 next 2308\n",
      "2025-09-23 02:21:16.221005: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b359900 of size 18432 next 2011\n",
      "2025-09-23 02:21:16.221006: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b35e100 of size 25088 next 2027\n",
      "2025-09-23 02:21:16.221007: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b364300 of size 4096 next 2598\n",
      "2025-09-23 02:21:16.221008: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b365300 of size 25088 next 2130\n",
      "2025-09-23 02:21:16.221010: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b36b500 of size 4096 next 2268\n",
      "2025-09-23 02:21:16.221011: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b36c500 of size 25088 next 2454\n",
      "2025-09-23 02:21:16.221012: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b372700 of size 25088 next 2358\n",
      "2025-09-23 02:21:16.221014: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b378900 of size 4096 next 1930\n",
      "2025-09-23 02:21:16.221015: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b379900 of size 25088 next 1759\n",
      "2025-09-23 02:21:16.221016: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b37fb00 of size 25088 next 2552\n",
      "2025-09-23 02:21:16.221018: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b385d00 of size 4096 next 1984\n",
      "2025-09-23 02:21:16.221019: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b386d00 of size 4096 next 2056\n",
      "2025-09-23 02:21:16.221021: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b387d00 of size 25088 next 2644\n",
      "2025-09-23 02:21:16.221022: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b38df00 of size 12397312 next 1836\n",
      "2025-09-23 02:21:16.221024: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf60a00 of size 768 next 2679\n",
      "2025-09-23 02:21:16.221025: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf60d00 of size 256 next 1777\n",
      "2025-09-23 02:21:16.221026: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf60e00 of size 256 next 2064\n",
      "2025-09-23 02:21:16.221028: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf60f00 of size 256 next 2652\n",
      "2025-09-23 02:21:16.221029: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf61000 of size 256 next 239\n",
      "2025-09-23 02:21:16.221030: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf61100 of size 256 next 2151\n",
      "2025-09-23 02:21:16.221032: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf61200 of size 256 next 674\n",
      "2025-09-23 02:21:16.221033: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf61300 of size 768 next 2390\n",
      "2025-09-23 02:21:16.221035: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf61600 of size 768 next 2578\n",
      "2025-09-23 02:21:16.221036: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf61900 of size 256 next 2471\n",
      "2025-09-23 02:21:16.221037: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf61a00 of size 256 next 2336\n",
      "2025-09-23 02:21:16.221038: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf61b00 of size 256 next 1860\n",
      "2025-09-23 02:21:16.221040: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf61c00 of size 256 next 1936\n",
      "2025-09-23 02:21:16.221041: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf61d00 of size 256 next 1944\n",
      "2025-09-23 02:21:16.221042: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf61e00 of size 256 next 1877\n",
      "2025-09-23 02:21:16.221043: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf61f00 of size 1536 next 2321\n",
      "2025-09-23 02:21:16.221045: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf62500 of size 89915392 next 2671\n",
      "2025-09-23 02:21:16.221046: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1741522500 of size 89915392 next 2377\n",
      "2025-09-23 02:21:16.221047: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1746ae2500 of size 89915392 next 1757\n",
      "2025-09-23 02:21:16.221048: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 174c0a2500 of size 89915392 next 2381\n",
      "2025-09-23 02:21:16.221050: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1751662500 of size 89915392 next 2053\n",
      "2025-09-23 02:21:16.221051: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1756c22500 of size 89915392 next 2696\n",
      "2025-09-23 02:21:16.221052: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 175c1e2500 of size 89915392 next 188\n",
      "2025-09-23 02:21:16.221054: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17617a2500 of size 89915392 next 2468\n",
      "2025-09-23 02:21:16.221055: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1766d62500 of size 89915392 next 2340\n",
      "2025-09-23 02:21:16.221057: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 176c322500 of size 22478848 next 127\n",
      "2025-09-23 02:21:16.221058: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 176d892500 of size 22478848 next 2134\n",
      "2025-09-23 02:21:16.221059: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 176ee02500 of size 22478848 next 2717\n",
      "2025-09-23 02:21:16.221061: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770372500 of size 11239424 next 2642\n",
      "2025-09-23 02:21:16.221062: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2a500 of size 1024 next 381\n",
      "2025-09-23 02:21:16.221063: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2a900 of size 1024 next 2264\n",
      "2025-09-23 02:21:16.221065: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2ad00 of size 1024 next 2333\n",
      "2025-09-23 02:21:16.221066: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2b100 of size 1024 next 1786\n",
      "2025-09-23 02:21:16.221067: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2b500 of size 1024 next 2646\n",
      "2025-09-23 02:21:16.221069: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2b900 of size 1024 next 82\n",
      "2025-09-23 02:21:16.221070: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2bd00 of size 1024 next 2373\n",
      "2025-09-23 02:21:16.221071: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2c100 of size 1024 next 1817\n",
      "2025-09-23 02:21:16.221073: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2c500 of size 1024 next 2205\n",
      "2025-09-23 02:21:16.221074: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2c900 of size 1024 next 2653\n",
      "2025-09-23 02:21:16.221075: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2cd00 of size 1024 next 2565\n",
      "2025-09-23 02:21:16.221076: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2d100 of size 1024 next 2266\n",
      "2025-09-23 02:21:16.221078: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2d500 of size 1024 next 2100\n",
      "2025-09-23 02:21:16.221079: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2d900 of size 1024 next 255\n",
      "2025-09-23 02:21:16.221080: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2dd00 of size 7168 next 2054\n",
      "2025-09-23 02:21:16.221081: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2f900 of size 7168 next 329\n",
      "2025-09-23 02:21:16.221083: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e31500 of size 1792 next 2379\n",
      "2025-09-23 02:21:16.221084: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e31c00 of size 1792 next 2042\n",
      "2025-09-23 02:21:16.221085: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e32300 of size 1792 next 2705\n",
      "2025-09-23 02:21:16.221086: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e32a00 of size 7168 next 2158\n",
      "2025-09-23 02:21:16.221088: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e34600 of size 7168 next 2325\n",
      "2025-09-23 02:21:16.221089: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e36200 of size 33669888 next 1755\n",
      "2025-09-23 02:21:16.221091: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1772e52500 of size 11239424 next 2093\n",
      "2025-09-23 02:21:16.221092: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 177390a500 of size 89915392 next 2184\n",
      "2025-09-23 02:21:16.221093: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1778eca500 of size 89915392 next 2688\n",
      "2025-09-23 02:21:16.221095: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 177e48a500 of size 178218752 next 2172\n",
      "2025-09-23 02:21:16.221096: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e80c00 of size 768 next 2060\n",
      "2025-09-23 02:21:16.221098: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e80f00 of size 256 next 2619\n",
      "2025-09-23 02:21:16.221099: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e81000 of size 256 next 2510\n",
      "2025-09-23 02:21:16.221100: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e81100 of size 256 next 1742\n",
      "2025-09-23 02:21:16.221102: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e81200 of size 256 next 2771\n",
      "2025-09-23 02:21:16.221103: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e81300 of size 256 next 437\n",
      "2025-09-23 02:21:16.221104: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e81400 of size 256 next 251\n",
      "2025-09-23 02:21:16.221106: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e81500 of size 768 next 2083\n",
      "2025-09-23 02:21:16.221107: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e81800 of size 768 next 1849\n",
      "2025-09-23 02:21:16.221108: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e81b00 of size 256 next 2299\n",
      "2025-09-23 02:21:16.221110: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e81c00 of size 256 next 2329\n",
      "2025-09-23 02:21:16.221111: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e81d00 of size 256 next 2405\n",
      "2025-09-23 02:21:16.221112: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e81e00 of size 256 next 1996\n",
      "2025-09-23 02:21:16.221113: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e81f00 of size 512 next 744\n",
      "2025-09-23 02:21:16.221115: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e82100 of size 1536 next 1819\n",
      "2025-09-23 02:21:16.221116: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e82700 of size 89915392 next 2106\n",
      "2025-09-23 02:21:16.221117: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 178e442700 of size 89915392 next 1855\n",
      "2025-09-23 02:21:16.221118: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1793a02700 of size 89915392 next 1844\n",
      "2025-09-23 02:21:16.221120: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1798fc2700 of size 89915392 next 2135\n",
      "2025-09-23 02:21:16.221121: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 179e582700 of size 89915392 next 1937\n",
      "2025-09-23 02:21:16.221122: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17a3b42700 of size 89915392 next 2313\n",
      "2025-09-23 02:21:16.221123: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17a9102700 of size 89915392 next 1825\n",
      "2025-09-23 02:21:16.221125: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17ae6c2700 of size 89915392 next 1910\n",
      "2025-09-23 02:21:16.221126: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17b3c82700 of size 89915392 next 2200\n",
      "2025-09-23 02:21:16.221127: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17b9242700 of size 89915392 next 2290\n",
      "2025-09-23 02:21:16.221128: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17be802700 of size 89915392 next 1956\n",
      "2025-09-23 02:21:16.221130: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c3dc2700 of size 22478848 next 1788\n",
      "2025-09-23 02:21:16.221131: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c5332700 of size 22478848 next 2223\n",
      "2025-09-23 02:21:16.221133: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c68a2700 of size 22478848 next 1965\n",
      "2025-09-23 02:21:16.221134: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c7e12700 of size 256 next 2384\n",
      "2025-09-23 02:21:16.221135: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c7e12800 of size 256 next 2052\n",
      "2025-09-23 02:21:16.221137: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c7e12900 of size 11239424 next 1787\n",
      "2025-09-23 02:21:16.221138: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88ca900 of size 1536 next 1874\n",
      "2025-09-23 02:21:16.221139: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88caf00 of size 1536 next 1875\n",
      "2025-09-23 02:21:16.221141: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88cb500 of size 1536 next 2682\n",
      "2025-09-23 02:21:16.221142: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88cbb00 of size 1536 next 2123\n",
      "2025-09-23 02:21:16.221143: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88cc100 of size 1536 next 2128\n",
      "2025-09-23 02:21:16.221145: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88cc700 of size 1536 next 356\n",
      "2025-09-23 02:21:16.221146: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88ccd00 of size 1536 next 1954\n",
      "2025-09-23 02:21:16.221147: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88cd300 of size 1536 next 397\n",
      "2025-09-23 02:21:16.221148: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88cd900 of size 10752 next 1815\n",
      "2025-09-23 02:21:16.221150: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88d0300 of size 10752 next 2595\n",
      "2025-09-23 02:21:16.221151: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88d2d00 of size 2816 next 2187\n",
      "2025-09-23 02:21:16.221152: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88d3800 of size 2816 next 1924\n",
      "2025-09-23 02:21:16.221153: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88d4300 of size 2816 next 2606\n",
      "2025-09-23 02:21:16.221155: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88d4e00 of size 10752 next 2155\n",
      "2025-09-23 02:21:16.221156: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88d7800 of size 10752 next 1948\n",
      "2025-09-23 02:21:16.221157: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88da200 of size 33654528 next 2599\n",
      "2025-09-23 02:21:16.221158: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17ca8f2900 of size 11239424 next 2067\n",
      "2025-09-23 02:21:16.221160: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17cb3aa900 of size 178218752 next 2664\n",
      "2025-09-23 02:21:16.221161: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17d5da1000 of size 768 next 1921\n",
      "2025-09-23 02:21:16.221162: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17d5da1300 of size 512 next 2675\n",
      "2025-09-23 02:21:16.221163: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17d5da1500 of size 512 next 2116\n",
      "2025-09-23 02:21:16.221165: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17d5da1700 of size 512 next 2297\n",
      "2025-09-23 02:21:16.221166: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17d5da1900 of size 768 next 2300\n",
      "2025-09-23 02:21:16.221167: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17d5da1c00 of size 768 next 2708\n",
      "2025-09-23 02:21:16.221168: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17d5da1f00 of size 512 next 2332\n",
      "2025-09-23 02:21:16.221170: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17d5da2100 of size 512 next 1846\n",
      "2025-09-23 02:21:16.221171: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17d5da2300 of size 512 next 2175\n",
      "2025-09-23 02:21:16.221173: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17d5da2500 of size 1536 next 2028\n",
      "2025-09-23 02:21:16.221174: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17d5da2b00 of size 89915392 next 2298\n",
      "2025-09-23 02:21:16.221176: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17db362b00 of size 89915392 next 514\n",
      "2025-09-23 02:21:16.221177: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17e0922b00 of size 89915392 next 2163\n",
      "2025-09-23 02:21:16.221178: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17e5ee2b00 of size 89915392 next 2160\n",
      "2025-09-23 02:21:16.221180: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17eb4a2b00 of size 89915392 next 2731\n",
      "2025-09-23 02:21:16.221181: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17f0a62b00 of size 89915392 next 2637\n",
      "2025-09-23 02:21:16.221183: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17f6022b00 of size 89915392 next 2536\n",
      "2025-09-23 02:21:16.221184: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17fb5e2b00 of size 22478848 next 2611\n",
      "2025-09-23 02:21:16.221185: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17fcb52b00 of size 22478848 next 97\n",
      "2025-09-23 02:21:16.221186: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17fe0c2b00 of size 22478848 next 2634\n",
      "2025-09-23 02:21:16.221188: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17ff632b00 of size 11239424 next 2088\n",
      "2025-09-23 02:21:16.221189: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000eab00 of size 1024 next 2476\n",
      "2025-09-23 02:21:16.221190: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000eaf00 of size 1024 next 1973\n",
      "2025-09-23 02:21:16.221191: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000eb300 of size 1024 next 2757\n",
      "2025-09-23 02:21:16.221192: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000eb700 of size 1024 next 2754\n",
      "2025-09-23 02:21:16.221194: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000ebb00 of size 1024 next 2324\n",
      "2025-09-23 02:21:16.221195: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000ebf00 of size 1024 next 1926\n",
      "2025-09-23 02:21:16.221196: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000ec300 of size 1024 next 1894\n",
      "2025-09-23 02:21:16.221198: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000ec700 of size 1024 next 2438\n",
      "2025-09-23 02:21:16.221199: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000ecb00 of size 1024 next 1884\n",
      "2025-09-23 02:21:16.221201: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000ecf00 of size 1024 next 2414\n",
      "2025-09-23 02:21:16.221202: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000ed300 of size 1024 next 2499\n",
      "2025-09-23 02:21:16.221203: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000ed700 of size 7168 next 2110\n",
      "2025-09-23 02:21:16.221204: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000ef300 of size 7168 next 2558\n",
      "2025-09-23 02:21:16.221206: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000f0f00 of size 1792 next 1953\n",
      "2025-09-23 02:21:16.221207: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000f1600 of size 1792 next 2487\n",
      "2025-09-23 02:21:16.221208: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000f1d00 of size 7168 next 2154\n",
      "2025-09-23 02:21:16.221209: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000f3900 of size 7168 next 2714\n",
      "2025-09-23 02:21:16.221211: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000f5500 of size 33674752 next 1842\n",
      "2025-09-23 02:21:16.221212: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1802112b00 of size 11239424 next 2665\n",
      "2025-09-23 02:21:16.221213: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1802bcab00 of size 89915392 next 2091\n",
      "2025-09-23 02:21:16.221214: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 180818ab00 of size 89915392 next 2512\n",
      "2025-09-23 02:21:16.221216: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 180d74ab00 of size 89915392 next 2683\n",
      "2025-09-23 02:21:16.221217: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1812d0ab00 of size 89915392 next 2748\n",
      "2025-09-23 02:21:16.221218: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18182cab00 of size 158951168 next 2609\n",
      "2025-09-23 02:21:16.221220: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1821a61200 of size 512 next 2281\n",
      "2025-09-23 02:21:16.221221: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1821a61400 of size 512 next 1870\n",
      "2025-09-23 02:21:16.221222: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1821a61600 of size 25690112 next 1858\n",
      "2025-09-23 02:21:16.221224: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18232e1600 of size 25690112 next 2353\n",
      "2025-09-23 02:21:16.221225: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1824b61600 of size 25690112 next 2544\n",
      "2025-09-23 02:21:16.221226: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18263e1600 of size 25690112 next 1882\n",
      "2025-09-23 02:21:16.221228: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1827c61600 of size 25690112 next 2752\n",
      "2025-09-23 02:21:16.221229: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18294e1600 of size 25690112 next 2517\n",
      "2025-09-23 02:21:16.221230: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 182ad61600 of size 25690112 next 1830\n",
      "2025-09-23 02:21:16.221231: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 182c5e1600 of size 25690112 next 2695\n",
      "2025-09-23 02:21:16.221233: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 182de61600 of size 25691136 next 1775\n",
      "2025-09-23 02:21:16.221234: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 182f6e1a00 of size 1024 next 1793\n",
      "2025-09-23 02:21:16.221235: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 182f6e1e00 of size 51380224 next 2245\n",
      "2025-09-23 02:21:16.221237: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18327e1e00 of size 51380224 next 2412\n",
      "2025-09-23 02:21:16.221238: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18358e1e00 of size 51380224 next 2591\n",
      "2025-09-23 02:21:16.221239: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18389e1e00 of size 51380224 next 2586\n",
      "2025-09-23 02:21:16.221241: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 183bae1e00 of size 22478848 next 2166\n",
      "2025-09-23 02:21:16.221242: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 183d051e00 of size 22478848 next 2514\n",
      "2025-09-23 02:21:16.221243: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 183e5c1e00 of size 22478848 next 2236\n",
      "2025-09-23 02:21:16.221244: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 183fb31e00 of size 11239424 next 169\n",
      "2025-09-23 02:21:16.221246: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18405e9e00 of size 7168 next 2387\n",
      "2025-09-23 02:21:16.221247: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18405eba00 of size 7168 next 374\n",
      "2025-09-23 02:21:16.221248: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18405ed600 of size 1792 next 2082\n",
      "2025-09-23 02:21:16.221249: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18405edd00 of size 1792 next 575\n",
      "2025-09-23 02:21:16.221251: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18405ee400 of size 1792 next 2673\n",
      "2025-09-23 02:21:16.221252: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18405eeb00 of size 1792 next 2547\n",
      "2025-09-23 02:21:16.221253: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18405ef200 of size 7168 next 2337\n",
      "2025-09-23 02:21:16.221254: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18405f0e00 of size 7168 next 2182\n",
      "2025-09-23 02:21:16.221256: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18405f2a00 of size 33682432 next 2587\n",
      "2025-09-23 02:21:16.221257: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1842611e00 of size 11239424 next 2567\n",
      "2025-09-23 02:21:16.221259: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18430c9e00 of size 89915392 next 2582\n",
      "2025-09-23 02:21:16.221260: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1848689e00 of size 89915392 next 2225\n",
      "2025-09-23 02:21:16.221261: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 184dc49e00 of size 144400896 next 18446744073709551615\n",
      "2025-09-23 02:21:16.221263: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2025-09-23 02:21:16.221265: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 717 Chunks of size 256 totalling 179.2KiB\n",
      "2025-09-23 02:21:16.221267: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 239 Chunks of size 512 totalling 119.5KiB\n",
      "2025-09-23 02:21:16.221268: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 189 Chunks of size 768 totalling 141.8KiB\n",
      "2025-09-23 02:21:16.221270: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 238 Chunks of size 1024 totalling 238.0KiB\n",
      "2025-09-23 02:21:16.221271: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 10 Chunks of size 1280 totalling 12.5KiB\n",
      "2025-09-23 02:21:16.221273: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 50 Chunks of size 1536 totalling 75.0KiB\n",
      "2025-09-23 02:21:16.221274: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 23 Chunks of size 1792 totalling 40.2KiB\n",
      "2025-09-23 02:21:16.221277: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 91 Chunks of size 2048 totalling 182.0KiB\n",
      "2025-09-23 02:21:16.221278: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 25 Chunks of size 2304 totalling 56.2KiB\n",
      "2025-09-23 02:21:16.221280: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 2560 totalling 7.5KiB\n",
      "2025-09-23 02:21:16.221281: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 2816 totalling 8.2KiB\n",
      "2025-09-23 02:21:16.221283: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 3072 totalling 9.0KiB\n",
      "2025-09-23 02:21:16.221284: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 3328 totalling 13.0KiB\n",
      "2025-09-23 02:21:16.221286: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 3584 totalling 7.0KiB\n",
      "2025-09-23 02:21:16.221287: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 13 Chunks of size 3840 totalling 48.8KiB\n",
      "2025-09-23 02:21:16.221289: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 46 Chunks of size 4096 totalling 184.0KiB\n",
      "2025-09-23 02:21:16.221290: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 4352 totalling 8.5KiB\n",
      "2025-09-23 02:21:16.221291: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 4608 totalling 27.0KiB\n",
      "2025-09-23 02:21:16.221293: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 5120 totalling 20.0KiB\n",
      "2025-09-23 02:21:16.221294: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 5888 totalling 34.5KiB\n",
      "2025-09-23 02:21:16.221296: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 14 Chunks of size 6144 totalling 84.0KiB\n",
      "2025-09-23 02:21:16.221297: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 16 Chunks of size 6912 totalling 108.0KiB\n",
      "2025-09-23 02:21:16.221299: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 21 Chunks of size 7168 totalling 147.0KiB\n",
      "2025-09-23 02:21:16.221302: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 7680 totalling 7.5KiB\n",
      "2025-09-23 02:21:16.221304: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 87 Chunks of size 8192 totalling 696.0KiB\n",
      "2025-09-23 02:21:16.221305: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 8704 totalling 8.5KiB\n",
      "2025-09-23 02:21:16.221307: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 9472 totalling 9.2KiB\n",
      "2025-09-23 02:21:16.221308: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 10240 totalling 10.0KiB\n",
      "2025-09-23 02:21:16.221309: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 10752 totalling 42.0KiB\n",
      "2025-09-23 02:21:16.221311: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 11776 totalling 11.5KiB\n",
      "2025-09-23 02:21:16.221312: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 12032 totalling 11.8KiB\n",
      "2025-09-23 02:21:16.221314: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 12288 totalling 12.0KiB\n",
      "2025-09-23 02:21:16.221315: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 12800 totalling 50.0KiB\n",
      "2025-09-23 02:21:16.221317: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 13312 totalling 13.0KiB\n",
      "2025-09-23 02:21:16.221318: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 14336 totalling 14.0KiB\n",
      "2025-09-23 02:21:16.221319: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 13 Chunks of size 15360 totalling 195.0KiB\n",
      "2025-09-23 02:21:16.221321: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 15616 totalling 15.2KiB\n",
      "2025-09-23 02:21:16.221323: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 16128 totalling 15.8KiB\n",
      "2025-09-23 02:21:16.221324: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 18 Chunks of size 16384 totalling 288.0KiB\n",
      "2025-09-23 02:21:16.221326: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 12 Chunks of size 18432 totalling 216.0KiB\n",
      "2025-09-23 02:21:16.221329: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 21504 totalling 42.0KiB\n",
      "2025-09-23 02:21:16.221331: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 35 Chunks of size 25088 totalling 857.5KiB\n",
      "2025-09-23 02:21:16.221332: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 13 Chunks of size 25600 totalling 325.0KiB\n",
      "2025-09-23 02:21:16.221334: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 27648 totalling 27.0KiB\n",
      "2025-09-23 02:21:16.221335: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 28672 totalling 168.0KiB\n",
      "2025-09-23 02:21:16.221336: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 30720 totalling 60.0KiB\n",
      "2025-09-23 02:21:16.221338: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 32256 totalling 31.5KiB\n",
      "2025-09-23 02:21:16.221339: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 32512 totalling 31.8KiB\n",
      "2025-09-23 02:21:16.221341: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 35840 totalling 35.0KiB\n",
      "2025-09-23 02:21:16.221342: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 36096 totalling 35.2KiB\n",
      "2025-09-23 02:21:16.221343: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 43 Chunks of size 36864 totalling 1.51MiB\n",
      "2025-09-23 02:21:16.221345: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 38912 totalling 38.0KiB\n",
      "2025-09-23 02:21:16.221346: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 40960 totalling 40.0KiB\n",
      "2025-09-23 02:21:16.221348: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 43008 totalling 252.0KiB\n",
      "2025-09-23 02:21:16.221349: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 46080 totalling 45.0KiB\n",
      "2025-09-23 02:21:16.221350: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 49408 totalling 48.2KiB\n",
      "2025-09-23 02:21:16.221352: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 118 Chunks of size 50176 totalling 5.65MiB\n",
      "2025-09-23 02:21:16.221354: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 51200 totalling 300.0KiB\n",
      "2025-09-23 02:21:16.221355: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 52224 totalling 51.0KiB\n",
      "2025-09-23 02:21:16.221357: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 55808 totalling 54.5KiB\n",
      "2025-09-23 02:21:16.221358: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 56576 totalling 55.2KiB\n",
      "2025-09-23 02:21:16.221359: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 57344 totalling 224.0KiB\n",
      "2025-09-23 02:21:16.221361: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 58368 totalling 57.0KiB\n",
      "2025-09-23 02:21:16.221362: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 61440 totalling 360.0KiB\n",
      "2025-09-23 02:21:16.221364: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 61696 totalling 60.2KiB\n",
      "2025-09-23 02:21:16.221366: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 69888 totalling 68.2KiB\n",
      "2025-09-23 02:21:16.221367: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 36 Chunks of size 73728 totalling 2.53MiB\n",
      "2025-09-23 02:21:16.221369: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 75776 totalling 148.0KiB\n",
      "2025-09-23 02:21:16.221370: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 76800 totalling 450.0KiB\n",
      "2025-09-23 02:21:16.221372: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 85760 totalling 83.8KiB\n",
      "2025-09-23 02:21:16.221373: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 97792 totalling 95.5KiB\n",
      "2025-09-23 02:21:16.221377: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 102400 totalling 100.0KiB\n",
      "2025-09-23 02:21:16.221378: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 107520 totalling 630.0KiB\n",
      "2025-09-23 02:21:16.221380: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 12 Chunks of size 112896 totalling 1.29MiB\n",
      "2025-09-23 02:21:16.221381: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 113152 totalling 110.5KiB\n",
      "2025-09-23 02:21:16.221383: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 7 Chunks of size 115200 totalling 787.5KiB\n",
      "2025-09-23 02:21:16.221384: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 131072 totalling 128.0KiB\n",
      "2025-09-23 02:21:16.221386: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 149248 totalling 145.8KiB\n",
      "2025-09-23 02:21:16.221387: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 14 Chunks of size 153600 totalling 2.05MiB\n",
      "2025-09-23 02:21:16.221389: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 168704 totalling 164.8KiB\n",
      "2025-09-23 02:21:16.221390: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 172032 totalling 168.0KiB\n",
      "2025-09-23 02:21:16.221391: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 181248 totalling 177.0KiB\n",
      "2025-09-23 02:21:16.221393: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 185600 totalling 181.2KiB\n",
      "2025-09-23 02:21:16.221394: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 225792 totalling 220.5KiB\n",
      "2025-09-23 02:21:16.221396: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 37 Chunks of size 230400 totalling 8.13MiB\n",
      "2025-09-23 02:21:16.221397: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 338688 totalling 330.8KiB\n",
      "2025-09-23 02:21:16.221399: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 456704 totalling 446.0KiB\n",
      "2025-09-23 02:21:16.221400: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 615424 totalling 601.0KiB\n",
      "2025-09-23 02:21:16.221401: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 677376 totalling 3.88MiB\n",
      "2025-09-23 02:21:16.221403: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 691200 totalling 3.96MiB\n",
      "2025-09-23 02:21:16.221405: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 17 Chunks of size 1382400 totalling 22.41MiB\n",
      "2025-09-23 02:21:16.221408: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1480704 totalling 1.41MiB\n",
      "2025-09-23 02:21:16.221410: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 16 Chunks of size 6422528 totalling 98.00MiB\n",
      "2025-09-23 02:21:16.221411: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 6741504 totalling 6.43MiB\n",
      "2025-09-23 02:21:16.221412: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 7175424 totalling 6.84MiB\n",
      "2025-09-23 02:21:16.221414: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 7393536 totalling 7.05MiB\n",
      "2025-09-23 02:21:16.221415: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 12 Chunks of size 11239424 totalling 128.62MiB\n",
      "2025-09-23 02:21:16.221417: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 12397312 totalling 11.82MiB\n",
      "2025-09-23 02:21:16.221418: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 28 Chunks of size 12845056 totalling 343.00MiB\n",
      "2025-09-23 02:21:16.221420: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 8 Chunks of size 16056320 totalling 122.50MiB\n",
      "2025-09-23 02:21:16.221421: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 13 Chunks of size 19267584 totalling 238.88MiB\n",
      "2025-09-23 02:21:16.221423: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 18 Chunks of size 22478848 totalling 385.88MiB\n",
      "2025-09-23 02:21:16.221424: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 25033728 totalling 23.87MiB\n",
      "2025-09-23 02:21:16.221425: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 25476096 totalling 24.30MiB\n",
      "2025-09-23 02:21:16.221427: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 25535232 totalling 24.35MiB\n",
      "2025-09-23 02:21:16.221430: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 56 Chunks of size 25690112 totalling 1.34GiB\n",
      "2025-09-23 02:21:16.221432: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 25691136 totalling 24.50MiB\n",
      "2025-09-23 02:21:16.221434: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 27176704 totalling 25.92MiB\n",
      "2025-09-23 02:21:16.221435: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 28901888 totalling 27.56MiB\n",
      "2025-09-23 02:21:16.221436: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 29491200 totalling 28.12MiB\n",
      "2025-09-23 02:21:16.221438: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 30801920 totalling 29.38MiB\n",
      "2025-09-23 02:21:16.221439: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 12 Chunks of size 32112640 totalling 367.50MiB\n",
      "2025-09-23 02:21:16.221441: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 33654528 totalling 32.09MiB\n",
      "2025-09-23 02:21:16.221442: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 33669888 totalling 32.11MiB\n",
      "2025-09-23 02:21:16.221444: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 33670912 totalling 32.11MiB\n",
      "2025-09-23 02:21:16.221445: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 33674752 totalling 32.11MiB\n",
      "2025-09-23 02:21:16.221447: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 33677056 totalling 32.12MiB\n",
      "2025-09-23 02:21:16.221448: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 33682432 totalling 32.12MiB\n",
      "2025-09-23 02:21:16.221449: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 13 Chunks of size 38535168 totalling 477.75MiB\n",
      "2025-09-23 02:21:16.221451: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 44957696 totalling 257.25MiB\n",
      "2025-09-23 02:21:16.221453: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 48070912 totalling 45.84MiB\n",
      "2025-09-23 02:21:16.221456: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 48083456 totalling 91.71MiB\n",
      "2025-09-23 02:21:16.221458: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 13 Chunks of size 51380224 totalling 637.00MiB\n",
      "2025-09-23 02:21:16.221459: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 57765120 totalling 110.18MiB\n",
      "2025-09-23 02:21:16.221461: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 57766656 totalling 55.09MiB\n",
      "2025-09-23 02:21:16.221462: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 57802752 totalling 55.12MiB\n",
      "2025-09-23 02:21:16.221463: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 13 Chunks of size 64225280 totalling 796.25MiB\n",
      "2025-09-23 02:21:16.221465: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 41 Chunks of size 77070336 totalling 2.94GiB\n",
      "2025-09-23 02:21:16.221466: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 80269312 totalling 76.55MiB\n",
      "2025-09-23 02:21:16.221468: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 82607104 totalling 78.78MiB\n",
      "2025-09-23 02:21:16.221469: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 85008384 totalling 81.07MiB\n",
      "2025-09-23 02:21:16.221470: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 64 Chunks of size 89915392 totalling 5.36GiB\n",
      "2025-09-23 02:21:16.221472: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 96338432 totalling 91.88MiB\n",
      "2025-09-23 02:21:16.221473: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 104366592 totalling 99.53MiB\n",
      "2025-09-23 02:21:16.221475: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 7 Chunks of size 134873088 totalling 900.38MiB\n",
      "2025-09-23 02:21:16.221477: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 144400896 totalling 137.71MiB\n",
      "2025-09-23 02:21:16.221478: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 158951168 totalling 151.59MiB\n",
      "2025-09-23 02:21:16.221480: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 165374976 totalling 157.71MiB\n",
      "2025-09-23 02:21:16.221481: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 174587904 totalling 166.50MiB\n",
      "2025-09-23 02:21:16.221482: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 178218752 totalling 339.92MiB\n",
      "2025-09-23 02:21:16.221484: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 22 Chunks of size 192675840 totalling 3.95GiB\n",
      "2025-09-23 02:21:16.221485: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 261710336 totalling 249.59MiB\n",
      "2025-09-23 02:21:16.221487: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 317907968 totalling 303.18MiB\n",
      "2025-09-23 02:21:16.221488: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 20.95GiB\n",
      "2025-09-23 02:21:16.221490: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 22500343808 memory_limit_: 22500343808 available bytes: 0 curr_region_allocation_bytes_: 34359738368\n",
      "2025-09-23 02:21:16.221494: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                     22500343808\n",
      "InUse:                     22500271360\n",
      "MaxInUse:                  22500271360\n",
      "NumAllocs:                       34883\n",
      "MaxAllocSize:               1259334912\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-09-23 02:21:16.221524: W tensorflow/tsl/framework/bfc_allocator.cc:497] ****************************************************************************************************\n",
      "2025-09-23 02:21:16.221553: W tensorflow/core/framework/op_kernel.cc:1816] RESOURCE_EXHAUSTED: failed to allocate memory\n",
      "2025-09-23 02:21:26.221872: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 42.88MiB (rounded to 44957696)requested by op sub_4\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2025-09-23 02:21:26.221949: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2025-09-23 02:21:26.221954: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 735, Chunks in use: 717. 183.8KiB allocated for chunks. 179.2KiB in use in bin. 113.4KiB client-requested in use in bin.\n",
      "2025-09-23 02:21:26.221956: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 448, Chunks in use: 428. 271.2KiB allocated for chunks. 261.2KiB in use in bin. 225.0KiB client-requested in use in bin.\n",
      "2025-09-23 02:21:26.221958: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 322, Chunks in use: 321. 366.8KiB allocated for chunks. 365.8KiB in use in bin. 321.1KiB client-requested in use in bin.\n",
      "2025-09-23 02:21:26.221960: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 144, Chunks in use: 144. 331.8KiB allocated for chunks. 331.8KiB in use in bin. 309.0KiB client-requested in use in bin.\n",
      "2025-09-23 02:21:26.221962: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 116, Chunks in use: 116. 620.5KiB allocated for chunks. 620.5KiB in use in bin. 605.6KiB client-requested in use in bin.\n",
      "2025-09-23 02:21:26.221964: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 119, Chunks in use: 118. 1.09MiB allocated for chunks. 1.08MiB in use in bin. 1.03MiB client-requested in use in bin.\n",
      "2025-09-23 02:21:26.221966: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 93, Chunks in use: 91. 2.04MiB allocated for chunks. 2.00MiB in use in bin. 1.97MiB client-requested in use in bin.\n",
      "2025-09-23 02:21:26.221968: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 194, Chunks in use: 194. 8.77MiB allocated for chunks. 8.77MiB in use in bin. 8.64MiB client-requested in use in bin.\n",
      "2025-09-23 02:21:26.221969: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 74, Chunks in use: 74. 6.24MiB allocated for chunks. 6.24MiB in use in bin. 6.00MiB client-requested in use in bin.\n",
      "2025-09-23 02:21:26.221971: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 58, Chunks in use: 58. 11.34MiB allocated for chunks. 11.34MiB in use in bin. 10.88MiB client-requested in use in bin.\n",
      "2025-09-23 02:21:26.221973: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 2, Chunks in use: 2. 776.8KiB allocated for chunks. 776.8KiB in use in bin. 555.8KiB client-requested in use in bin.\n",
      "2025-09-23 02:21:26.221975: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 13, Chunks in use: 13. 8.42MiB allocated for chunks. 8.42MiB in use in bin. 8.15MiB client-requested in use in bin.\n",
      "2025-09-23 02:21:26.221977: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 18, Chunks in use: 18. 23.82MiB allocated for chunks. 23.82MiB in use in bin. 23.73MiB client-requested in use in bin.\n",
      "2025-09-23 02:21:26.221979: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-09-23 02:21:26.221981: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 19, Chunks in use: 19. 118.32MiB allocated for chunks. 118.32MiB in use in bin. 113.31MiB client-requested in use in bin.\n",
      "2025-09-23 02:21:26.221983: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 49, Chunks in use: 49. 605.95MiB allocated for chunks. 605.95MiB in use in bin. 600.25MiB client-requested in use in bin.\n",
      "2025-09-23 02:21:26.221985: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 107, Chunks in use: 107. 2.51GiB allocated for chunks. 2.51GiB in use in bin. 2.43GiB client-requested in use in bin.\n",
      "2025-09-23 02:21:26.221987: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 58, Chunks in use: 58. 2.65GiB allocated for chunks. 2.65GiB in use in bin. 2.49GiB client-requested in use in bin.\n",
      "2025-09-23 02:21:26.221989: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 110, Chunks in use: 110. 8.72GiB allocated for chunks. 8.72GiB in use in bin. 8.61GiB client-requested in use in bin.\n",
      "2025-09-23 02:21:26.221991: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 36, Chunks in use: 36. 6.00GiB allocated for chunks. 6.00GiB in use in bin. 5.55GiB client-requested in use in bin.\n",
      "2025-09-23 02:21:26.221992: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 1, Chunks in use: 1. 303.18MiB allocated for chunks. 303.18MiB in use in bin. 183.75MiB client-requested in use in bin.\n",
      "2025-09-23 02:21:26.221994: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 42.88MiB was 32.00MiB, Chunk State: \n",
      "2025-09-23 02:21:26.221996: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 2097152\n",
      "2025-09-23 02:21:26.222000: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317800000 of size 1280 next 1\n",
      "2025-09-23 02:21:26.222001: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317800500 of size 38912 next 2\n",
      "2025-09-23 02:21:26.222004: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317809d00 of size 256 next 3\n",
      "2025-09-23 02:21:26.222005: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317809e00 of size 256 next 4\n",
      "2025-09-23 02:21:26.222006: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317809f00 of size 256 next 5\n",
      "2025-09-23 02:21:26.222007: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780a000 of size 256 next 6\n",
      "2025-09-23 02:21:26.222008: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780a100 of size 256 next 7\n",
      "2025-09-23 02:21:26.222010: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780a200 of size 256 next 8\n",
      "2025-09-23 02:21:26.222011: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780a300 of size 256 next 9\n",
      "2025-09-23 02:21:26.222012: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780a400 of size 256 next 10\n",
      "2025-09-23 02:21:26.222013: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780a500 of size 256 next 11\n",
      "2025-09-23 02:21:26.222015: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780a600 of size 4352 next 12\n",
      "2025-09-23 02:21:26.222016: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780b700 of size 256 next 13\n",
      "2025-09-23 02:21:26.222017: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780b800 of size 256 next 14\n",
      "2025-09-23 02:21:26.222019: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780b900 of size 256 next 15\n",
      "2025-09-23 02:21:26.222020: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780ba00 of size 256 next 16\n",
      "2025-09-23 02:21:26.222021: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780bb00 of size 256 next 18\n",
      "2025-09-23 02:21:26.222023: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780bc00 of size 256 next 19\n",
      "2025-09-23 02:21:26.222025: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780bd00 of size 256 next 17\n",
      "2025-09-23 02:21:26.222026: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780be00 of size 256 next 20\n",
      "2025-09-23 02:21:26.222027: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780bf00 of size 256 next 2017\n",
      "2025-09-23 02:21:26.222028: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780c000 of size 256 next 24\n",
      "2025-09-23 02:21:26.222030: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780c100 of size 256 next 25\n",
      "2025-09-23 02:21:26.222031: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780c200 of size 256 next 26\n",
      "2025-09-23 02:21:26.222032: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780c300 of size 256 next 29\n",
      "2025-09-23 02:21:26.222033: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780c400 of size 256 next 27\n",
      "2025-09-23 02:21:26.222035: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780c500 of size 256 next 2032\n",
      "2025-09-23 02:21:26.222036: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780c600 of size 256 next 32\n",
      "2025-09-23 02:21:26.222037: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780c700 of size 256 next 33\n",
      "2025-09-23 02:21:26.222039: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780c800 of size 256 next 34\n",
      "2025-09-23 02:21:26.222040: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780c900 of size 256 next 37\n",
      "2025-09-23 02:21:26.222041: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780ca00 of size 256 next 35\n",
      "2025-09-23 02:21:26.222043: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780cb00 of size 256 next 21\n",
      "2025-09-23 02:21:26.222044: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780cc00 of size 1792 next 22\n",
      "2025-09-23 02:21:26.222046: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780d300 of size 256 next 36\n",
      "2025-09-23 02:21:26.222047: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780d400 of size 256 next 39\n",
      "2025-09-23 02:21:26.222048: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780d500 of size 256 next 40\n",
      "2025-09-23 02:21:26.222050: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780d600 of size 256 next 43\n",
      "2025-09-23 02:21:26.222051: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780d700 of size 256 next 41\n",
      "2025-09-23 02:21:26.222052: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780d800 of size 256 next 2287\n",
      "2025-09-23 02:21:26.222053: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780d900 of size 256 next 46\n",
      "2025-09-23 02:21:26.222054: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780da00 of size 256 next 47\n",
      "2025-09-23 02:21:26.222056: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780db00 of size 256 next 48\n",
      "2025-09-23 02:21:26.222057: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780dc00 of size 256 next 38\n",
      "2025-09-23 02:21:26.222058: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780dd00 of size 1536 next 31\n",
      "2025-09-23 02:21:26.222059: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780e300 of size 2048 next 30\n",
      "2025-09-23 02:21:26.222061: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780eb00 of size 256 next 50\n",
      "2025-09-23 02:21:26.222062: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780ec00 of size 256 next 2115\n",
      "2025-09-23 02:21:26.222063: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780ed00 of size 256 next 53\n",
      "2025-09-23 02:21:26.222064: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780ee00 of size 256 next 54\n",
      "2025-09-23 02:21:26.222065: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780ef00 of size 256 next 55\n",
      "2025-09-23 02:21:26.222067: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780f000 of size 256 next 57\n",
      "2025-09-23 02:21:26.222068: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780f100 of size 256 next 58\n",
      "2025-09-23 02:21:26.222069: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780f200 of size 256 next 56\n",
      "2025-09-23 02:21:26.222070: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780f300 of size 256 next 59\n",
      "2025-09-23 02:21:26.222072: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780f400 of size 256 next 61\n",
      "2025-09-23 02:21:26.222073: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780f500 of size 256 next 62\n",
      "2025-09-23 02:21:26.222074: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780f600 of size 256 next 1843\n",
      "2025-09-23 02:21:26.222075: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780f700 of size 256 next 66\n",
      "2025-09-23 02:21:26.222077: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780f800 of size 256 next 67\n",
      "2025-09-23 02:21:26.222078: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780f900 of size 256 next 68\n",
      "2025-09-23 02:21:26.222079: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780fa00 of size 256 next 2391\n",
      "2025-09-23 02:21:26.222081: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780fb00 of size 256 next 2635\n",
      "2025-09-23 02:21:26.222082: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780fc00 of size 256 next 2729\n",
      "2025-09-23 02:21:26.222083: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780fd00 of size 256 next 102\n",
      "2025-09-23 02:21:26.222085: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780fe00 of size 256 next 116\n",
      "2025-09-23 02:21:26.222086: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131780ff00 of size 512 next 132\n",
      "2025-09-23 02:21:26.222089: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317810100 of size 512 next 130\n",
      "2025-09-23 02:21:26.222091: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317810300 of size 256 next 2216\n",
      "2025-09-23 02:21:26.222092: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317810400 of size 256 next 2365\n",
      "2025-09-23 02:21:26.222093: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317810500 of size 256 next 2767\n",
      "2025-09-23 02:21:26.222095: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317810600 of size 256 next 135\n",
      "2025-09-23 02:21:26.222096: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317810700 of size 256 next 136\n",
      "2025-09-23 02:21:26.222097: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317810800 of size 256 next 137\n",
      "2025-09-23 02:21:26.222099: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317810900 of size 512 next 45\n",
      "2025-09-23 02:21:26.222100: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317810b00 of size 4096 next 44\n",
      "2025-09-23 02:21:26.222101: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317811b00 of size 2304 next 60\n",
      "2025-09-23 02:21:26.222103: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317812400 of size 256 next 1736\n",
      "2025-09-23 02:21:26.222104: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317812500 of size 256 next 153\n",
      "2025-09-23 02:21:26.222105: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317812600 of size 256 next 154\n",
      "2025-09-23 02:21:26.222107: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317812700 of size 256 next 155\n",
      "2025-09-23 02:21:26.222108: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317812800 of size 1024 next 158\n",
      "2025-09-23 02:21:26.222118: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317812c00 of size 1024 next 156\n",
      "2025-09-23 02:21:26.222121: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317813000 of size 1536 next 140\n",
      "2025-09-23 02:21:26.222122: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317813600 of size 4608 next 139\n",
      "2025-09-23 02:21:26.222124: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317814800 of size 256 next 1880\n",
      "2025-09-23 02:21:26.222126: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317814900 of size 256 next 2255\n",
      "2025-09-23 02:21:26.222127: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317814a00 of size 256 next 2031\n",
      "2025-09-23 02:21:26.222128: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317814b00 of size 256 next 157\n",
      "2025-09-23 02:21:26.222130: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317814c00 of size 256 next 161\n",
      "2025-09-23 02:21:26.222131: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317814d00 of size 256 next 162\n",
      "2025-09-23 02:21:26.222132: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317814e00 of size 1024 next 163\n",
      "2025-09-23 02:21:26.222133: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317815200 of size 1024 next 164\n",
      "2025-09-23 02:21:26.222135: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317815600 of size 512 next 2627\n",
      "2025-09-23 02:21:26.222136: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317815800 of size 768 next 52\n",
      "2025-09-23 02:21:26.222137: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317815b00 of size 8192 next 51\n",
      "2025-09-23 02:21:26.222139: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317817b00 of size 256 next 73\n",
      "2025-09-23 02:21:26.222140: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317817c00 of size 256 next 72\n",
      "2025-09-23 02:21:26.222142: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317817d00 of size 512 next 77\n",
      "2025-09-23 02:21:26.222143: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317817f00 of size 256 next 78\n",
      "2025-09-23 02:21:26.222144: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317818000 of size 256 next 79\n",
      "2025-09-23 02:21:26.222145: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317818100 of size 256 next 2535\n",
      "2025-09-23 02:21:26.222147: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317818200 of size 256 next 83\n",
      "2025-09-23 02:21:26.222148: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317818300 of size 256 next 84\n",
      "2025-09-23 02:21:26.222149: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317818400 of size 256 next 75\n",
      "2025-09-23 02:21:26.222150: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317818500 of size 2304 next 76\n",
      "2025-09-23 02:21:26.222152: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317818e00 of size 512 next 87\n",
      "2025-09-23 02:21:26.222153: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317819000 of size 256 next 89\n",
      "2025-09-23 02:21:26.222155: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317819100 of size 256 next 88\n",
      "2025-09-23 02:21:26.222156: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317819200 of size 512 next 92\n",
      "2025-09-23 02:21:26.222157: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317819400 of size 256 next 93\n",
      "2025-09-23 02:21:26.222158: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317819500 of size 256 next 94\n",
      "2025-09-23 02:21:26.222160: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317819600 of size 512 next 98\n",
      "2025-09-23 02:21:26.222161: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317819800 of size 256 next 99\n",
      "2025-09-23 02:21:26.222162: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317819900 of size 256 next 100\n",
      "2025-09-23 02:21:26.222163: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317819a00 of size 256 next 64\n",
      "2025-09-23 02:21:26.222165: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317819b00 of size 8192 next 63\n",
      "2025-09-23 02:21:26.222166: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131781bb00 of size 8192 next 69\n",
      "2025-09-23 02:21:26.222167: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131781db00 of size 2304 next 91\n",
      "2025-09-23 02:21:26.222168: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131781e400 of size 256 next 104\n",
      "2025-09-23 02:21:26.222169: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131781e500 of size 256 next 103\n",
      "2025-09-23 02:21:26.222171: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131781e600 of size 512 next 107\n",
      "2025-09-23 02:21:26.222172: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131781e800 of size 256 next 108\n",
      "2025-09-23 02:21:26.222173: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131781e900 of size 256 next 109\n",
      "2025-09-23 02:21:26.222174: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131781ea00 of size 512 next 112\n",
      "2025-09-23 02:21:26.222176: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131781ec00 of size 256 next 113\n",
      "2025-09-23 02:21:26.222177: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131781ed00 of size 256 next 106\n",
      "2025-09-23 02:21:26.222178: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131781ee00 of size 3328 next 81\n",
      "2025-09-23 02:21:26.222180: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131781fb00 of size 8192 next 80\n",
      "2025-09-23 02:21:26.222181: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317821b00 of size 8192 next 85\n",
      "2025-09-23 02:21:26.222182: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317823b00 of size 256 next 118\n",
      "2025-09-23 02:21:26.222183: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317823c00 of size 256 next 117\n",
      "2025-09-23 02:21:26.222185: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317823d00 of size 256 next 2489\n",
      "2025-09-23 02:21:26.222186: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317823e00 of size 256 next 122\n",
      "2025-09-23 02:21:26.222187: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317823f00 of size 256 next 123\n",
      "2025-09-23 02:21:26.222188: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317824000 of size 256 next 124\n",
      "2025-09-23 02:21:26.222190: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317824100 of size 512 next 128\n",
      "2025-09-23 02:21:26.222191: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317824300 of size 256 next 129\n",
      "2025-09-23 02:21:26.222192: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317824400 of size 256 next 120\n",
      "2025-09-23 02:21:26.222194: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317824500 of size 2304 next 121\n",
      "2025-09-23 02:21:26.222195: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317824e00 of size 512 next 138\n",
      "2025-09-23 02:21:26.222204: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317825000 of size 256 next 2226\n",
      "2025-09-23 02:21:26.222207: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317825100 of size 256 next 219\n",
      "2025-09-23 02:21:26.222209: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317825200 of size 256 next 2416\n",
      "2025-09-23 02:21:26.222210: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317825300 of size 256 next 142\n",
      "2025-09-23 02:21:26.222211: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317825400 of size 256 next 145\n",
      "2025-09-23 02:21:26.222213: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317825500 of size 512 next 147\n",
      "2025-09-23 02:21:26.222214: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317825700 of size 256 next 143\n",
      "2025-09-23 02:21:26.222216: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317825800 of size 256 next 144\n",
      "2025-09-23 02:21:26.222217: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317825900 of size 256 next 149\n",
      "2025-09-23 02:21:26.222218: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317825a00 of size 256 next 96\n",
      "2025-09-23 02:21:26.222220: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317825b00 of size 8192 next 95\n",
      "2025-09-23 02:21:26.222221: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317827b00 of size 8192 next 101\n",
      "2025-09-23 02:21:26.222222: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317829b00 of size 8192 next 110\n",
      "2025-09-23 02:21:26.222224: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782bb00 of size 8192 next 114\n",
      "2025-09-23 02:21:26.222225: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782db00 of size 256 next 2566\n",
      "2025-09-23 02:21:26.222226: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782dc00 of size 256 next 2766\n",
      "2025-09-23 02:21:26.222227: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782dd00 of size 256 next 2396\n",
      "2025-09-23 02:21:26.222229: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782de00 of size 256 next 167\n",
      "2025-09-23 02:21:26.222230: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782df00 of size 256 next 170\n",
      "2025-09-23 02:21:26.222231: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782e000 of size 1024 next 172\n",
      "2025-09-23 02:21:26.222232: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782e400 of size 256 next 174\n",
      "2025-09-23 02:21:26.222234: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782e500 of size 256 next 168\n",
      "2025-09-23 02:21:26.222235: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782e600 of size 256 next 2724\n",
      "2025-09-23 02:21:26.222236: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782e700 of size 256 next 176\n",
      "2025-09-23 02:21:26.222238: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782e800 of size 1024 next 179\n",
      "2025-09-23 02:21:26.222239: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782ec00 of size 1024 next 177\n",
      "2025-09-23 02:21:26.222240: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782f000 of size 1024 next 2583\n",
      "2025-09-23 02:21:26.222241: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782f400 of size 256 next 2229\n",
      "2025-09-23 02:21:26.222243: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782f500 of size 256 next 2411\n",
      "2025-09-23 02:21:26.222244: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782f600 of size 512 next 2571\n",
      "2025-09-23 02:21:26.222245: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782f800 of size 256 next 2133\n",
      "2025-09-23 02:21:26.222246: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782f900 of size 256 next 2575\n",
      "2025-09-23 02:21:26.222248: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782fa00 of size 256 next 126\n",
      "2025-09-23 02:21:26.222249: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131782fb00 of size 8192 next 125\n",
      "2025-09-23 02:21:26.222250: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317831b00 of size 1024 next 181\n",
      "2025-09-23 02:21:26.222251: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317831f00 of size 1024 next 182\n",
      "2025-09-23 02:21:26.222253: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317832300 of size 2048 next 186\n",
      "2025-09-23 02:21:26.222254: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317832b00 of size 256 next 189\n",
      "2025-09-23 02:21:26.222255: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317832c00 of size 1024 next 191\n",
      "2025-09-23 02:21:26.222256: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317833000 of size 256 next 193\n",
      "2025-09-23 02:21:26.222257: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317833100 of size 256 next 187\n",
      "2025-09-23 02:21:26.222259: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317833200 of size 512 next 195\n",
      "2025-09-23 02:21:26.222260: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317833400 of size 1792 next 184\n",
      "2025-09-23 02:21:26.222262: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317833b00 of size 8192 next 183\n",
      "2025-09-23 02:21:26.222263: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317835b00 of size 1024 next 209\n",
      "2025-09-23 02:21:26.222264: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317835f00 of size 256 next 206\n",
      "2025-09-23 02:21:26.222265: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317836000 of size 1024 next 215\n",
      "2025-09-23 02:21:26.222267: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317836400 of size 1024 next 213\n",
      "2025-09-23 02:21:26.222268: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317836800 of size 2048 next 217\n",
      "2025-09-23 02:21:26.222269: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317837000 of size 1024 next 218\n",
      "2025-09-23 02:21:26.222270: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317837400 of size 1792 next 203\n",
      "2025-09-23 02:21:26.222272: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317837b00 of size 8192 next 134\n",
      "2025-09-23 02:21:26.222300: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317839b00 of size 16384 next 133\n",
      "2025-09-23 02:21:26.222322: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131783db00 of size 16384 next 146\n",
      "2025-09-23 02:21:26.222325: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317841b00 of size 16384 next 148\n",
      "2025-09-23 02:21:26.222326: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317845b00 of size 1024 next 198\n",
      "2025-09-23 02:21:26.222328: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317845f00 of size 512 next 2689\n",
      "2025-09-23 02:21:26.222329: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317846100 of size 512 next 2392\n",
      "2025-09-23 02:21:26.222330: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317846300 of size 512 next 1925\n",
      "2025-09-23 02:21:26.222332: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317846500 of size 512 next 197\n",
      "2025-09-23 02:21:26.222333: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317846700 of size 1024 next 200\n",
      "2025-09-23 02:21:26.222334: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317846b00 of size 1024 next 201\n",
      "2025-09-23 02:21:26.222335: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317846f00 of size 256 next 2328\n",
      "2025-09-23 02:21:26.222337: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317847000 of size 256 next 2662\n",
      "2025-09-23 02:21:26.222338: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317847100 of size 256 next 1999\n",
      "2025-09-23 02:21:26.222339: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317847200 of size 256 next 2049\n",
      "2025-09-23 02:21:26.222340: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317847300 of size 1024 next 204\n",
      "2025-09-23 02:21:26.222342: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317847700 of size 256 next 207\n",
      "2025-09-23 02:21:26.222343: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317847800 of size 256 next 211\n",
      "2025-09-23 02:21:26.222344: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317847900 of size 256 next 205\n",
      "2025-09-23 02:21:26.222345: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317847a00 of size 256 next 166\n",
      "2025-09-23 02:21:26.222347: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317847b00 of size 8192 next 165\n",
      "2025-09-23 02:21:26.222348: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317849b00 of size 512 next 2087\n",
      "2025-09-23 02:21:26.222349: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317849d00 of size 512 next 236\n",
      "2025-09-23 02:21:26.222350: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317849f00 of size 1536 next 258\n",
      "2025-09-23 02:21:26.222352: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784a500 of size 3072 next 256\n",
      "2025-09-23 02:21:26.222353: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784b100 of size 256 next 261\n",
      "2025-09-23 02:21:26.222355: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784b200 of size 256 next 262\n",
      "2025-09-23 02:21:26.222356: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784b300 of size 512 next 265\n",
      "2025-09-23 02:21:26.222357: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784b500 of size 1536 next 263\n",
      "2025-09-23 02:21:26.222358: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784bb00 of size 256 next 264\n",
      "2025-09-23 02:21:26.222360: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784bc00 of size 256 next 268\n",
      "2025-09-23 02:21:26.222361: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784bd00 of size 512 next 270\n",
      "2025-09-23 02:21:26.222362: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784bf00 of size 512 next 271\n",
      "2025-09-23 02:21:26.222363: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784c100 of size 512 next 2505\n",
      "2025-09-23 02:21:26.222365: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784c300 of size 512 next 274\n",
      "2025-09-23 02:21:26.222366: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784c500 of size 256 next 275\n",
      "2025-09-23 02:21:26.222367: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784c600 of size 256 next 276\n",
      "2025-09-23 02:21:26.222369: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784c700 of size 256 next 284\n",
      "2025-09-23 02:21:26.222370: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784c800 of size 256 next 285\n",
      "2025-09-23 02:21:26.222371: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784c900 of size 512 next 151\n",
      "2025-09-23 02:21:26.222372: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131784cb00 of size 28672 next 150\n",
      "2025-09-23 02:21:26.222374: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317853b00 of size 1024 next 2509\n",
      "2025-09-23 02:21:26.222375: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317853f00 of size 512 next 323\n",
      "2025-09-23 02:21:26.222376: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317854100 of size 512 next 222\n",
      "2025-09-23 02:21:26.222377: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317854300 of size 256 next 223\n",
      "2025-09-23 02:21:26.222379: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317854400 of size 1024 next 224\n",
      "2025-09-23 02:21:26.222380: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317854800 of size 256 next 227\n",
      "2025-09-23 02:21:26.222381: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317854900 of size 256 next 229\n",
      "2025-09-23 02:21:26.222382: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317854a00 of size 512 next 232\n",
      "2025-09-23 02:21:26.222384: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317854c00 of size 1024 next 233\n",
      "2025-09-23 02:21:26.222385: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317855000 of size 1024 next 234\n",
      "2025-09-23 02:21:26.222386: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317855400 of size 256 next 1988\n",
      "2025-09-23 02:21:26.222387: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317855500 of size 256 next 1762\n",
      "2025-09-23 02:21:26.222389: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317855600 of size 1280 next 221\n",
      "2025-09-23 02:21:26.222390: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317855b00 of size 8192 next 220\n",
      "2025-09-23 02:21:26.222391: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317857b00 of size 25600 next 345\n",
      "2025-09-23 02:21:26.222393: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131785df00 of size 25600 next 347\n",
      "2025-09-23 02:21:26.222394: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317864300 of size 256 next 2545\n",
      "2025-09-23 02:21:26.222395: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317864400 of size 256 next 2089\n",
      "2025-09-23 02:21:26.222396: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317864500 of size 512 next 419\n",
      "2025-09-23 02:21:26.222398: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317864700 of size 256 next 421\n",
      "2025-09-23 02:21:26.222401: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317864800 of size 256 next 422\n",
      "2025-09-23 02:21:26.222402: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317864900 of size 256 next 420\n",
      "2025-09-23 02:21:26.222403: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317864a00 of size 256 next 423\n",
      "2025-09-23 02:21:26.222404: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317864b00 of size 256 next 432\n",
      "2025-09-23 02:21:26.222406: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317864c00 of size 256 next 433\n",
      "2025-09-23 02:21:26.222407: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317864d00 of size 256 next 2197\n",
      "2025-09-23 02:21:26.222408: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317864e00 of size 256 next 436\n",
      "2025-09-23 02:21:26.222410: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317864f00 of size 256 next 435\n",
      "2025-09-23 02:21:26.222411: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317865000 of size 2048 next 424\n",
      "2025-09-23 02:21:26.222412: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317865800 of size 1792 next 425\n",
      "2025-09-23 02:21:26.222414: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317865f00 of size 256 next 427\n",
      "2025-09-23 02:21:26.222415: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317866000 of size 256 next 426\n",
      "2025-09-23 02:21:26.222417: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317866100 of size 512 next 431\n",
      "2025-09-23 02:21:26.222418: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317866300 of size 256 next 438\n",
      "2025-09-23 02:21:26.222421: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317866400 of size 512 next 441\n",
      "2025-09-23 02:21:26.222423: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317866600 of size 256 next 442\n",
      "2025-09-23 02:21:26.222424: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317866700 of size 256 next 429\n",
      "2025-09-23 02:21:26.222425: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317866800 of size 2048 next 430\n",
      "2025-09-23 02:21:26.222428: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317867000 of size 256 next 2564\n",
      "2025-09-23 02:21:26.222430: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317867100 of size 256 next 445\n",
      "2025-09-23 02:21:26.222431: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317867200 of size 256 next 448\n",
      "2025-09-23 02:21:26.222433: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317867300 of size 256 next 446\n",
      "2025-09-23 02:21:26.222434: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317867400 of size 256 next 1862\n",
      "2025-09-23 02:21:26.222435: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317867500 of size 256 next 449\n",
      "2025-09-23 02:21:26.222439: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317867600 of size 256 next 451\n",
      "2025-09-23 02:21:26.222441: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317867700 of size 256 next 452\n",
      "2025-09-23 02:21:26.222442: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317867800 of size 256 next 384\n",
      "2025-09-23 02:21:26.222443: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317867900 of size 6912 next 383\n",
      "2025-09-23 02:21:26.222445: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317869400 of size 512 next 1771\n",
      "2025-09-23 02:21:26.222446: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317869600 of size 512 next 393\n",
      "2025-09-23 02:21:26.222447: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317869800 of size 768 next 394\n",
      "2025-09-23 02:21:26.222449: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317869b00 of size 768 next 395\n",
      "2025-09-23 02:21:26.222450: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317869e00 of size 1536 next 398\n",
      "2025-09-23 02:21:26.222451: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786a400 of size 768 next 400\n",
      "2025-09-23 02:21:26.222452: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786a700 of size 768 next 399\n",
      "2025-09-23 02:21:26.222454: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786aa00 of size 256 next 2021\n",
      "2025-09-23 02:21:26.222455: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786ab00 of size 256 next 2283\n",
      "2025-09-23 02:21:26.222456: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786ac00 of size 512 next 579\n",
      "2025-09-23 02:21:26.222457: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 131786ae00 of size 512 next 403\n",
      "2025-09-23 02:21:26.222458: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786b000 of size 256 next 404\n",
      "2025-09-23 02:21:26.222460: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786b100 of size 768 next 405\n",
      "2025-09-23 02:21:26.222461: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786b400 of size 512 next 406\n",
      "2025-09-23 02:21:26.222462: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786b600 of size 512 next 409\n",
      "2025-09-23 02:21:26.222464: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786b800 of size 256 next 1785\n",
      "2025-09-23 02:21:26.222465: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786b900 of size 256 next 2170\n",
      "2025-09-23 02:21:26.222466: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 131786ba00 of size 512 next 413\n",
      "2025-09-23 02:21:26.222467: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786bc00 of size 256 next 414\n",
      "2025-09-23 02:21:26.222469: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786bd00 of size 256 next 415\n",
      "2025-09-23 02:21:26.222470: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786be00 of size 512 next 416\n",
      "2025-09-23 02:21:26.222473: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786c000 of size 768 next 160\n",
      "2025-09-23 02:21:26.222474: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131786c300 of size 50176 next 159\n",
      "2025-09-23 02:21:26.222476: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317878700 of size 50176 next 171\n",
      "2025-09-23 02:21:26.222477: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317884b00 of size 50176 next 173\n",
      "2025-09-23 02:21:26.222478: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317890f00 of size 50176 next 175\n",
      "2025-09-23 02:21:26.222479: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131789d300 of size 50176 next 180\n",
      "2025-09-23 02:21:26.222481: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13178a9700 of size 50176 next 190\n",
      "2025-09-23 02:21:26.222482: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13178b5b00 of size 50176 next 192\n",
      "2025-09-23 02:21:26.222483: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13178c1f00 of size 50176 next 194\n",
      "2025-09-23 02:21:26.222484: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13178ce300 of size 50176 next 199\n",
      "2025-09-23 02:21:26.222486: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13178da700 of size 50176 next 208\n",
      "2025-09-23 02:21:26.222495: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13178e6b00 of size 50176 next 210\n",
      "2025-09-23 02:21:26.222498: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13178f2f00 of size 50176 next 212\n",
      "2025-09-23 02:21:26.222500: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13178ff300 of size 50176 next 216\n",
      "2025-09-23 02:21:26.222502: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790b700 of size 1024 next 238\n",
      "2025-09-23 02:21:26.222504: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790bb00 of size 1024 next 237\n",
      "2025-09-23 02:21:26.222505: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790bf00 of size 512 next 2334\n",
      "2025-09-23 02:21:26.222507: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790c100 of size 512 next 2548\n",
      "2025-09-23 02:21:26.222508: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790c300 of size 1024 next 242\n",
      "2025-09-23 02:21:26.222509: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790c700 of size 256 next 243\n",
      "2025-09-23 02:21:26.222511: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790c800 of size 1024 next 244\n",
      "2025-09-23 02:21:26.222512: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790cc00 of size 256 next 247\n",
      "2025-09-23 02:21:26.222513: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790cd00 of size 256 next 249\n",
      "2025-09-23 02:21:26.222514: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790ce00 of size 256 next 2470\n",
      "2025-09-23 02:21:26.222516: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790cf00 of size 256 next 252\n",
      "2025-09-23 02:21:26.222517: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790d000 of size 256 next 253\n",
      "2025-09-23 02:21:26.222518: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790d100 of size 256 next 254\n",
      "2025-09-23 02:21:26.222520: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790d200 of size 1536 next 240\n",
      "2025-09-23 02:21:26.222521: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790d800 of size 8192 next 241\n",
      "2025-09-23 02:21:26.222522: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131790f800 of size 2048 next 277\n",
      "2025-09-23 02:21:26.222523: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317910000 of size 2048 next 278\n",
      "2025-09-23 02:21:26.222525: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317910800 of size 4096 next 283\n",
      "2025-09-23 02:21:26.222526: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317911800 of size 2048 next 290\n",
      "2025-09-23 02:21:26.222527: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317912000 of size 256 next 287\n",
      "2025-09-23 02:21:26.222528: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317912100 of size 256 next 286\n",
      "2025-09-23 02:21:26.222530: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317912200 of size 512 next 292\n",
      "2025-09-23 02:21:26.222531: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317912400 of size 512 next 293\n",
      "2025-09-23 02:21:26.222532: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317912600 of size 512 next 2651\n",
      "2025-09-23 02:21:26.222533: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317912800 of size 256 next 2661\n",
      "2025-09-23 02:21:26.222535: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317912900 of size 256 next 296\n",
      "2025-09-23 02:21:26.222538: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317912a00 of size 2048 next 297\n",
      "2025-09-23 02:21:26.222539: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317913200 of size 2048 next 298\n",
      "2025-09-23 02:21:26.222540: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317913a00 of size 4096 next 301\n",
      "2025-09-23 02:21:26.222542: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317914a00 of size 512 next 304\n",
      "2025-09-23 02:21:26.222543: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317914c00 of size 2048 next 306\n",
      "2025-09-23 02:21:26.222544: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317915400 of size 512 next 302\n",
      "2025-09-23 02:21:26.222545: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317915600 of size 512 next 303\n",
      "2025-09-23 02:21:26.222547: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317915800 of size 512 next 2495\n",
      "2025-09-23 02:21:26.222548: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317915a00 of size 256 next 2063\n",
      "2025-09-23 02:21:26.222549: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317915b00 of size 256 next 310\n",
      "2025-09-23 02:21:26.222550: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317915c00 of size 2048 next 311\n",
      "2025-09-23 02:21:26.222552: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317916400 of size 2048 next 312\n",
      "2025-09-23 02:21:26.222553: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317916c00 of size 3840 next 226\n",
      "2025-09-23 02:21:26.222554: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317917b00 of size 50176 next 225\n",
      "2025-09-23 02:21:26.222556: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317923f00 of size 50176 next 228\n",
      "2025-09-23 02:21:26.222557: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317930300 of size 50176 next 230\n",
      "2025-09-23 02:21:26.222558: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131793c700 of size 50176 next 235\n",
      "2025-09-23 02:21:26.222559: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317948b00 of size 512 next 2423\n",
      "2025-09-23 02:21:26.222561: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317948d00 of size 512 next 1986\n",
      "2025-09-23 02:21:26.222562: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317948f00 of size 512 next 2120\n",
      "2025-09-23 02:21:26.222563: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317949100 of size 512 next 315\n",
      "2025-09-23 02:21:26.222564: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317949300 of size 512 next 316\n",
      "2025-09-23 02:21:26.222565: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317949500 of size 2048 next 317\n",
      "2025-09-23 02:21:26.222567: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317949d00 of size 512 next 320\n",
      "2025-09-23 02:21:26.222568: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317949f00 of size 512 next 322\n",
      "2025-09-23 02:21:26.222569: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794a100 of size 512 next 1841\n",
      "2025-09-23 02:21:26.222571: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 131794a300 of size 256 next 2380\n",
      "2025-09-23 02:21:26.222572: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794a400 of size 256 next 324\n",
      "2025-09-23 02:21:26.222573: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794a500 of size 256 next 325\n",
      "2025-09-23 02:21:26.222574: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794a600 of size 256 next 326\n",
      "2025-09-23 02:21:26.222576: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794a700 of size 768 next 327\n",
      "2025-09-23 02:21:26.222577: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794aa00 of size 768 next 328\n",
      "2025-09-23 02:21:26.222578: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794ad00 of size 1536 next 331\n",
      "2025-09-23 02:21:26.222580: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794b300 of size 256 next 332\n",
      "2025-09-23 02:21:26.222581: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794b400 of size 256 next 333\n",
      "2025-09-23 02:21:26.222582: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794b500 of size 768 next 335\n",
      "2025-09-23 02:21:26.222583: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794b800 of size 768 next 336\n",
      "2025-09-23 02:21:26.222585: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794bb00 of size 1536 next 337\n",
      "2025-09-23 02:21:26.222586: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794c100 of size 256 next 340\n",
      "2025-09-23 02:21:26.222587: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794c200 of size 256 next 341\n",
      "2025-09-23 02:21:26.222588: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794c300 of size 256 next 344\n",
      "2025-09-23 02:21:26.222590: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794c400 of size 768 next 346\n",
      "2025-09-23 02:21:26.222591: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794c700 of size 256 next 342\n",
      "2025-09-23 02:21:26.222592: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794c800 of size 256 next 343\n",
      "2025-09-23 02:21:26.222593: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794c900 of size 512 next 350\n",
      "2025-09-23 02:21:26.222594: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794cb00 of size 512 next 348\n",
      "2025-09-23 02:21:26.222596: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794cd00 of size 512 next 1968\n",
      "2025-09-23 02:21:26.222597: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794cf00 of size 512 next 352\n",
      "2025-09-23 02:21:26.222598: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794d100 of size 256 next 353\n",
      "2025-09-23 02:21:26.222601: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794d200 of size 256 next 354\n",
      "2025-09-23 02:21:26.222603: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794d300 of size 768 next 357\n",
      "2025-09-23 02:21:26.222604: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794d600 of size 768 next 355\n",
      "2025-09-23 02:21:26.222605: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794d900 of size 1536 next 359\n",
      "2025-09-23 02:21:26.222606: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794df00 of size 256 next 360\n",
      "2025-09-23 02:21:26.222608: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794e000 of size 256 next 361\n",
      "2025-09-23 02:21:26.222609: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794e100 of size 1280 next 338\n",
      "2025-09-23 02:21:26.222610: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794e600 of size 5888 next 339\n",
      "2025-09-23 02:21:26.222613: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131794fd00 of size 768 next 364\n",
      "2025-09-23 02:21:26.222615: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317950000 of size 1536 next 363\n",
      "2025-09-23 02:21:26.222616: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317950600 of size 256 next 365\n",
      "2025-09-23 02:21:26.222618: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317950700 of size 768 next 367\n",
      "2025-09-23 02:21:26.222619: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317950a00 of size 512 next 368\n",
      "2025-09-23 02:21:26.222620: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317950c00 of size 512 next 371\n",
      "2025-09-23 02:21:26.222622: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317950e00 of size 256 next 2660\n",
      "2025-09-23 02:21:26.222623: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317950f00 of size 256 next 2430\n",
      "2025-09-23 02:21:26.222624: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317951000 of size 512 next 375\n",
      "2025-09-23 02:21:26.222625: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317951200 of size 768 next 376\n",
      "2025-09-23 02:21:26.222627: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317951500 of size 768 next 377\n",
      "2025-09-23 02:21:26.222628: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317951800 of size 1536 next 379\n",
      "2025-09-23 02:21:26.222629: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317951e00 of size 768 next 382\n",
      "2025-09-23 02:21:26.222630: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317952100 of size 768 next 380\n",
      "2025-09-23 02:21:26.222632: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317952400 of size 512 next 1770\n",
      "2025-09-23 02:21:26.222633: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317952600 of size 512 next 2704\n",
      "2025-09-23 02:21:26.222634: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317952800 of size 512 next 385\n",
      "2025-09-23 02:21:26.222635: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317952a00 of size 256 next 386\n",
      "2025-09-23 02:21:26.222636: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317952b00 of size 768 next 387\n",
      "2025-09-23 02:21:26.222638: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317952e00 of size 512 next 389\n",
      "2025-09-23 02:21:26.222639: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317953000 of size 768 next 366\n",
      "2025-09-23 02:21:26.222640: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317953300 of size 7168 next 246\n",
      "2025-09-23 02:21:26.222642: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317954f00 of size 50176 next 245\n",
      "2025-09-23 02:21:26.222643: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317961300 of size 50176 next 248\n",
      "2025-09-23 02:21:26.222644: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131796d700 of size 50176 next 250\n",
      "2025-09-23 02:21:26.222647: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317979b00 of size 51200 next 330\n",
      "2025-09-23 02:21:26.222649: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317986300 of size 61696 next 269\n",
      "2025-09-23 02:21:26.222650: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317995400 of size 112896 next 267\n",
      "2025-09-23 02:21:26.222652: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13179b0d00 of size 112896 next 266\n",
      "2025-09-23 02:21:26.222653: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13179cc600 of size 61440 next 351\n",
      "2025-09-23 02:21:26.222654: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13179db600 of size 36864 next 370\n",
      "2025-09-23 02:21:26.222656: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13179e4600 of size 113152 next 18446744073709551615\n",
      "2025-09-23 02:21:26.222658: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 4194304\n",
      "2025-09-23 02:21:26.222659: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c00000 of size 107520 next 272\n",
      "2025-09-23 02:21:26.222661: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c1a400 of size 153600 next 308\n",
      "2025-09-23 02:21:26.222662: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c3fc00 of size 256 next 462\n",
      "2025-09-23 02:21:26.222663: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c3fd00 of size 256 next 461\n",
      "2025-09-23 02:21:26.222665: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c3fe00 of size 256 next 2758\n",
      "2025-09-23 02:21:26.222666: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c3ff00 of size 256 next 466\n",
      "2025-09-23 02:21:26.222667: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c40000 of size 256 next 467\n",
      "2025-09-23 02:21:26.222669: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c40100 of size 256 next 468\n",
      "2025-09-23 02:21:26.222670: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317c40200 of size 256 next 2230\n",
      "2025-09-23 02:21:26.222671: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c40300 of size 256 next 471\n",
      "2025-09-23 02:21:26.222673: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c40400 of size 256 next 472\n",
      "2025-09-23 02:21:26.222674: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c40500 of size 256 next 464\n",
      "2025-09-23 02:21:26.222675: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c40600 of size 2304 next 465\n",
      "2025-09-23 02:21:26.222677: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c40f00 of size 256 next 2338\n",
      "2025-09-23 02:21:26.222678: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c41000 of size 256 next 475\n",
      "2025-09-23 02:21:26.222679: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c41100 of size 256 next 477\n",
      "2025-09-23 02:21:26.222681: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c41200 of size 256 next 476\n",
      "2025-09-23 02:21:26.222682: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317c41300 of size 256 next 2096\n",
      "2025-09-23 02:21:26.222683: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c41400 of size 256 next 480\n",
      "2025-09-23 02:21:26.222685: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c41500 of size 256 next 481\n",
      "2025-09-23 02:21:26.222686: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c41600 of size 256 next 482\n",
      "2025-09-23 02:21:26.222687: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c41700 of size 256 next 2465\n",
      "2025-09-23 02:21:26.222688: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317c41800 of size 256 next 485\n",
      "2025-09-23 02:21:26.222689: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c41900 of size 256 next 486\n",
      "2025-09-23 02:21:26.222691: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c41a00 of size 256 next 487\n",
      "2025-09-23 02:21:26.222692: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c41b00 of size 256 next 453\n",
      "2025-09-23 02:21:26.222693: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c41c00 of size 8192 next 454\n",
      "2025-09-23 02:21:26.222694: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c43c00 of size 8192 next 458\n",
      "2025-09-23 02:21:26.222696: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c45c00 of size 256 next 527\n",
      "2025-09-23 02:21:26.222697: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c45d00 of size 256 next 523\n",
      "2025-09-23 02:21:26.222698: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c45e00 of size 256 next 2339\n",
      "2025-09-23 02:21:26.222699: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c45f00 of size 256 next 530\n",
      "2025-09-23 02:21:26.222700: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c46000 of size 1024 next 533\n",
      "2025-09-23 02:21:26.222702: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c46400 of size 1024 next 531\n",
      "2025-09-23 02:21:26.222703: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c46800 of size 1536 next 521\n",
      "2025-09-23 02:21:26.222704: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c46e00 of size 7680 next 407\n",
      "2025-09-23 02:21:26.222713: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c48c00 of size 36864 next 392\n",
      "2025-09-23 02:21:26.222716: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c51c00 of size 73728 next 391\n",
      "2025-09-23 02:21:26.222717: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c63c00 of size 73728 next 396\n",
      "2025-09-23 02:21:26.222719: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c75c00 of size 43008 next 418\n",
      "2025-09-23 02:21:26.222721: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c80400 of size 8192 next 488\n",
      "2025-09-23 02:21:26.222722: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c82400 of size 8192 next 497\n",
      "2025-09-23 02:21:26.222723: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c84400 of size 8192 next 501\n",
      "2025-09-23 02:21:26.222725: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c86400 of size 256 next 294\n",
      "2025-09-23 02:21:26.222726: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c86500 of size 256 next 2518\n",
      "2025-09-23 02:21:26.222728: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317c86600 of size 512 next 532\n",
      "2025-09-23 02:21:26.222737: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c86800 of size 1024 next 538\n",
      "2025-09-23 02:21:26.222740: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c86c00 of size 1024 next 536\n",
      "2025-09-23 02:21:26.222743: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c87000 of size 1024 next 2394\n",
      "2025-09-23 02:21:26.222745: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c87400 of size 1024 next 539\n",
      "2025-09-23 02:21:26.222747: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c87800 of size 256 next 543\n",
      "2025-09-23 02:21:26.222748: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c87900 of size 1024 next 545\n",
      "2025-09-23 02:21:26.222751: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c87d00 of size 256 next 547\n",
      "2025-09-23 02:21:26.222753: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c87e00 of size 256 next 541\n",
      "2025-09-23 02:21:26.222754: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317c87f00 of size 256 next 2557\n",
      "2025-09-23 02:21:26.222755: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c88000 of size 256 next 549\n",
      "2025-09-23 02:21:26.222757: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c88100 of size 256 next 563\n",
      "2025-09-23 02:21:26.222758: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c88200 of size 256 next 566\n",
      "2025-09-23 02:21:26.222759: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c88300 of size 256 next 512\n",
      "2025-09-23 02:21:26.222761: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c88400 of size 10240 next 289\n",
      "2025-09-23 02:21:26.222762: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317c8ac00 of size 230400 next 288\n",
      "2025-09-23 02:21:26.222763: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317cc3000 of size 230400 next 291\n",
      "2025-09-23 02:21:26.222765: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317cfb400 of size 73728 next 358\n",
      "2025-09-23 02:21:26.222766: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0d400 of size 6912 next 402\n",
      "2025-09-23 02:21:26.222767: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0ef00 of size 256 next 455\n",
      "2025-09-23 02:21:26.222768: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0f000 of size 256 next 456\n",
      "2025-09-23 02:21:26.222770: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0f100 of size 256 next 457\n",
      "2025-09-23 02:21:26.222771: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0f200 of size 1024 next 502\n",
      "2025-09-23 02:21:26.222772: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0f600 of size 256 next 503\n",
      "2025-09-23 02:21:26.222773: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0f700 of size 256 next 506\n",
      "2025-09-23 02:21:26.222775: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0f800 of size 256 next 504\n",
      "2025-09-23 02:21:26.222776: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0f900 of size 256 next 2295\n",
      "2025-09-23 02:21:26.222777: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0fa00 of size 256 next 507\n",
      "2025-09-23 02:21:26.222778: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0fb00 of size 256 next 509\n",
      "2025-09-23 02:21:26.222780: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0fc00 of size 256 next 510\n",
      "2025-09-23 02:21:26.222781: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0fd00 of size 256 next 2104\n",
      "2025-09-23 02:21:26.222782: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317d0fe00 of size 256 next 513\n",
      "2025-09-23 02:21:26.222783: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d0ff00 of size 512 next 450\n",
      "2025-09-23 02:21:26.222784: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d10100 of size 3584 next 440\n",
      "2025-09-23 02:21:26.222786: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d10f00 of size 4096 next 439\n",
      "2025-09-23 02:21:26.222788: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d11f00 of size 2304 next 479\n",
      "2025-09-23 02:21:26.222789: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d12800 of size 256 next 491\n",
      "2025-09-23 02:21:26.222790: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d12900 of size 256 next 490\n",
      "2025-09-23 02:21:26.222792: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d12a00 of size 256 next 2602\n",
      "2025-09-23 02:21:26.222793: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d12b00 of size 256 next 494\n",
      "2025-09-23 02:21:26.222794: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d12c00 of size 256 next 495\n",
      "2025-09-23 02:21:26.222795: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d12d00 of size 256 next 496\n",
      "2025-09-23 02:21:26.222797: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1317d12e00 of size 256 next 2341\n",
      "2025-09-23 02:21:26.222798: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d12f00 of size 256 next 499\n",
      "2025-09-23 02:21:26.222799: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d13000 of size 256 next 500\n",
      "2025-09-23 02:21:26.222801: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d13100 of size 256 next 493\n",
      "2025-09-23 02:21:26.222802: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d13200 of size 3328 next 444\n",
      "2025-09-23 02:21:26.222803: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d13f00 of size 9472 next 369\n",
      "2025-09-23 02:21:26.222804: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d16400 of size 43008 next 295\n",
      "2025-09-23 02:21:26.222806: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d20c00 of size 172032 next 260\n",
      "2025-09-23 02:21:26.222807: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317d4ac00 of size 677376 next 259\n",
      "2025-09-23 02:21:26.222816: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317df0200 of size 677376 next 629\n",
      "2025-09-23 02:21:26.222819: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317e95800 of size 28672 next 1043\n",
      "2025-09-23 02:21:26.222820: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317e9c800 of size 28672 next 1044\n",
      "2025-09-23 02:21:26.222821: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ea3800 of size 28672 next 1045\n",
      "2025-09-23 02:21:26.222823: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317eaa800 of size 28672 next 1046\n",
      "2025-09-23 02:21:26.222824: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317eb1800 of size 50176 next 1055\n",
      "2025-09-23 02:21:26.222825: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ebdc00 of size 50176 next 1056\n",
      "2025-09-23 02:21:26.222826: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317eca000 of size 50176 next 1057\n",
      "2025-09-23 02:21:26.222827: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ed6400 of size 50176 next 1058\n",
      "2025-09-23 02:21:26.222829: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ee2800 of size 8192 next 1067\n",
      "2025-09-23 02:21:26.222830: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ee4800 of size 8192 next 1068\n",
      "2025-09-23 02:21:26.222831: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ee6800 of size 8192 next 1069\n",
      "2025-09-23 02:21:26.222832: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ee8800 of size 1024 next 1070\n",
      "2025-09-23 02:21:26.222834: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ee8c00 of size 1024 next 1071\n",
      "2025-09-23 02:21:26.222835: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ee9000 of size 1024 next 1072\n",
      "2025-09-23 02:21:26.222836: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ee9400 of size 1024 next 1073\n",
      "2025-09-23 02:21:26.222838: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ee9800 of size 1024 next 1074\n",
      "2025-09-23 02:21:26.222839: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ee9c00 of size 1024 next 1075\n",
      "2025-09-23 02:21:26.222840: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317eea000 of size 1024 next 1076\n",
      "2025-09-23 02:21:26.222842: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317eea400 of size 1024 next 1077\n",
      "2025-09-23 02:21:26.222843: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317eea800 of size 50176 next 1078\n",
      "2025-09-23 02:21:26.222844: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317ef6c00 of size 50176 next 1079\n",
      "2025-09-23 02:21:26.222846: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f03000 of size 256 next 1080\n",
      "2025-09-23 02:21:26.222847: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f03100 of size 256 next 1081\n",
      "2025-09-23 02:21:26.222848: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f03200 of size 50176 next 1082\n",
      "2025-09-23 02:21:26.222849: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f0f600 of size 50176 next 1083\n",
      "2025-09-23 02:21:26.222850: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f1ba00 of size 256 next 1084\n",
      "2025-09-23 02:21:26.222852: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f1bb00 of size 256 next 1085\n",
      "2025-09-23 02:21:26.222853: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f1bc00 of size 50176 next 1086\n",
      "2025-09-23 02:21:26.222854: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f28000 of size 50176 next 1087\n",
      "2025-09-23 02:21:26.222856: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f34400 of size 1024 next 1088\n",
      "2025-09-23 02:21:26.222857: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f34800 of size 1024 next 1089\n",
      "2025-09-23 02:21:26.222858: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f34c00 of size 50176 next 1090\n",
      "2025-09-23 02:21:26.222860: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f41000 of size 50176 next 1091\n",
      "2025-09-23 02:21:26.222861: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f4d400 of size 1024 next 1092\n",
      "2025-09-23 02:21:26.222862: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f4d800 of size 1024 next 1093\n",
      "2025-09-23 02:21:26.222863: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f4dc00 of size 50176 next 1094\n",
      "2025-09-23 02:21:26.222864: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f5a000 of size 50176 next 1095\n",
      "2025-09-23 02:21:26.222866: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f66400 of size 50176 next 1096\n",
      "2025-09-23 02:21:26.222867: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f72800 of size 50176 next 1097\n",
      "2025-09-23 02:21:26.222868: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f7ec00 of size 256 next 1098\n",
      "2025-09-23 02:21:26.222869: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f7ed00 of size 256 next 1099\n",
      "2025-09-23 02:21:26.222871: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f7ee00 of size 256 next 1100\n",
      "2025-09-23 02:21:26.222872: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f7ef00 of size 256 next 1101\n",
      "2025-09-23 02:21:26.222873: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f7f000 of size 256 next 1102\n",
      "2025-09-23 02:21:26.222874: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f7f100 of size 256 next 1103\n",
      "2025-09-23 02:21:26.222876: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f7f200 of size 256 next 1104\n",
      "2025-09-23 02:21:26.222877: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f7f300 of size 256 next 1105\n",
      "2025-09-23 02:21:26.222879: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f7f400 of size 50176 next 1106\n",
      "2025-09-23 02:21:26.222880: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f8b800 of size 50176 next 1107\n",
      "2025-09-23 02:21:26.222881: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317f97c00 of size 50176 next 1108\n",
      "2025-09-23 02:21:26.222882: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fa4000 of size 50176 next 1109\n",
      "2025-09-23 02:21:26.222883: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fb0400 of size 1024 next 1110\n",
      "2025-09-23 02:21:26.222885: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fb0800 of size 1024 next 1111\n",
      "2025-09-23 02:21:26.222886: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fb0c00 of size 1024 next 1112\n",
      "2025-09-23 02:21:26.222887: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fb1000 of size 1024 next 1113\n",
      "2025-09-23 02:21:26.222888: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fb1400 of size 1024 next 1114\n",
      "2025-09-23 02:21:26.222889: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fb1800 of size 1024 next 1115\n",
      "2025-09-23 02:21:26.222891: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fb1c00 of size 1024 next 1116\n",
      "2025-09-23 02:21:26.222892: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fb2000 of size 1024 next 1117\n",
      "2025-09-23 02:21:26.222893: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fb2400 of size 8192 next 1118\n",
      "2025-09-23 02:21:26.222894: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fb4400 of size 8192 next 1119\n",
      "2025-09-23 02:21:26.222896: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fb6400 of size 8192 next 1120\n",
      "2025-09-23 02:21:26.222897: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fb8400 of size 8192 next 1121\n",
      "2025-09-23 02:21:26.222898: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fba400 of size 1024 next 1122\n",
      "2025-09-23 02:21:26.222899: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fba800 of size 1024 next 1123\n",
      "2025-09-23 02:21:26.222900: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fbac00 of size 1024 next 1124\n",
      "2025-09-23 02:21:26.222902: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fbb000 of size 1024 next 1125\n",
      "2025-09-23 02:21:26.222903: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fbb400 of size 1024 next 1126\n",
      "2025-09-23 02:21:26.222904: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fbb800 of size 1024 next 1127\n",
      "2025-09-23 02:21:26.222906: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fbbc00 of size 1024 next 1128\n",
      "2025-09-23 02:21:26.222907: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fbc000 of size 1024 next 1129\n",
      "2025-09-23 02:21:26.222908: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fbc400 of size 50176 next 1130\n",
      "2025-09-23 02:21:26.222910: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fc8800 of size 50176 next 1131\n",
      "2025-09-23 02:21:26.222911: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fd4c00 of size 256 next 1132\n",
      "2025-09-23 02:21:26.222912: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fd4d00 of size 256 next 1133\n",
      "2025-09-23 02:21:26.222914: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fd4e00 of size 50176 next 1134\n",
      "2025-09-23 02:21:26.222915: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fe1200 of size 50176 next 1135\n",
      "2025-09-23 02:21:26.222916: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fed600 of size 256 next 1136\n",
      "2025-09-23 02:21:26.222917: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fed700 of size 256 next 1137\n",
      "2025-09-23 02:21:26.222919: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1317fed800 of size 75776 next 18446744073709551615\n",
      "2025-09-23 02:21:26.222921: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 8388608\n",
      "2025-09-23 02:21:26.222922: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318000000 of size 230400 next 305\n",
      "2025-09-23 02:21:26.222924: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318038400 of size 230400 next 307\n",
      "2025-09-23 02:21:26.222925: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318070800 of size 230400 next 319\n",
      "2025-09-23 02:21:26.222927: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13180a8c00 of size 230400 next 318\n",
      "2025-09-23 02:21:26.222928: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13180e1000 of size 230400 next 321\n",
      "2025-09-23 02:21:26.222929: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318119400 of size 36864 next 388\n",
      "2025-09-23 02:21:26.222931: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318122400 of size 8192 next 469\n",
      "2025-09-23 02:21:26.222932: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318124400 of size 8192 next 473\n",
      "2025-09-23 02:21:26.222933: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318126400 of size 512 next 515\n",
      "2025-09-23 02:21:26.222934: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1318126600 of size 256 next 1751\n",
      "2025-09-23 02:21:26.222936: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318126700 of size 256 next 2730\n",
      "2025-09-23 02:21:26.222937: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318126800 of size 256 next 2199\n",
      "2025-09-23 02:21:26.222938: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318126900 of size 256 next 517\n",
      "2025-09-23 02:21:26.222939: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318126a00 of size 512 next 518\n",
      "2025-09-23 02:21:26.222941: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318126c00 of size 512 next 519\n",
      "2025-09-23 02:21:26.222942: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318126e00 of size 256 next 2407\n",
      "2025-09-23 02:21:26.222943: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1318126f00 of size 512 next 273\n",
      "2025-09-23 02:21:26.222944: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318127100 of size 256 next 522\n",
      "2025-09-23 02:21:26.222945: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318127200 of size 256 next 525\n",
      "2025-09-23 02:21:26.222947: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318127300 of size 768 next 508\n",
      "2025-09-23 02:21:26.222948: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318127600 of size 3584 next 484\n",
      "2025-09-23 02:21:26.222949: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318128400 of size 12288 next 373\n",
      "2025-09-23 02:21:26.222951: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131812b400 of size 73728 next 372\n",
      "2025-09-23 02:21:26.222952: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131813d400 of size 36864 next 408\n",
      "2025-09-23 02:21:26.222953: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318146400 of size 16384 next 528\n",
      "2025-09-23 02:21:26.222954: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814a400 of size 1024 next 552\n",
      "2025-09-23 02:21:26.222956: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814a800 of size 1024 next 550\n",
      "2025-09-23 02:21:26.222957: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814ac00 of size 6144 next 588\n",
      "2025-09-23 02:21:26.222959: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814c400 of size 1024 next 593\n",
      "2025-09-23 02:21:26.222960: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814c800 of size 1024 next 591\n",
      "2025-09-23 02:21:26.222961: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814cc00 of size 1024 next 1868\n",
      "2025-09-23 02:21:26.222963: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814d000 of size 1024 next 596\n",
      "2025-09-23 02:21:26.222964: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814d400 of size 256 next 597\n",
      "2025-09-23 02:21:26.222965: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814d500 of size 1024 next 598\n",
      "2025-09-23 02:21:26.222966: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814d900 of size 256 next 601\n",
      "2025-09-23 02:21:26.222967: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814da00 of size 256 next 603\n",
      "2025-09-23 02:21:26.222969: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814db00 of size 256 next 362\n",
      "2025-09-23 02:21:26.222970: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814dc00 of size 256 next 606\n",
      "2025-09-23 02:21:26.222971: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814dd00 of size 1792 next 540\n",
      "2025-09-23 02:21:26.222973: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131814e400 of size 13312 next 281\n",
      "2025-09-23 02:21:26.222974: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318151800 of size 1382400 next 279\n",
      "2025-09-23 02:21:26.222976: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13182a3000 of size 1382400 next 299\n",
      "2025-09-23 02:21:26.222977: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13183f4800 of size 16384 next 516\n",
      "2025-09-23 02:21:26.222978: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13183f8800 of size 16384 next 526\n",
      "2025-09-23 02:21:26.222979: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13183fc800 of size 1024 next 555\n",
      "2025-09-23 02:21:26.222981: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13183fcc00 of size 1024 next 556\n",
      "2025-09-23 02:21:26.222982: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13183fd000 of size 256 next 2459\n",
      "2025-09-23 02:21:26.222983: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13183fd100 of size 256 next 2713\n",
      "2025-09-23 02:21:26.222984: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13183fd200 of size 1536 next 560\n",
      "2025-09-23 02:21:26.222985: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13183fd800 of size 1024 next 562\n",
      "2025-09-23 02:21:26.222987: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 13183fdc00 of size 512 next 568\n",
      "2025-09-23 02:21:26.222988: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13183fde00 of size 1024 next 571\n",
      "2025-09-23 02:21:26.222989: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13183fe200 of size 1536 next 557\n",
      "2025-09-23 02:21:26.222990: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13183fe800 of size 8192 next 558\n",
      "2025-09-23 02:21:26.222992: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318400800 of size 1024 next 574\n",
      "2025-09-23 02:21:26.222993: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318400c00 of size 1024 next 573\n",
      "2025-09-23 02:21:26.222994: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318401000 of size 1024 next 1943\n",
      "2025-09-23 02:21:26.222995: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1318401400 of size 512 next 2393\n",
      "2025-09-23 02:21:26.222996: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318401600 of size 256 next 2516\n",
      "2025-09-23 02:21:26.222998: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318401700 of size 256 next 577\n",
      "2025-09-23 02:21:26.222999: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318401800 of size 256 next 580\n",
      "2025-09-23 02:21:26.223000: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318401900 of size 1024 next 582\n",
      "2025-09-23 02:21:26.223001: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318401d00 of size 256 next 584\n",
      "2025-09-23 02:21:26.223003: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318401e00 of size 256 next 578\n",
      "2025-09-23 02:21:26.223004: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1318401f00 of size 512 next 586\n",
      "2025-09-23 02:21:26.223005: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318402100 of size 1024 next 589\n",
      "2025-09-23 02:21:26.223006: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318402500 of size 1024 next 576\n",
      "2025-09-23 02:21:26.223008: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318402900 of size 16128 next 411\n",
      "2025-09-23 02:21:26.223009: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318406800 of size 73728 next 410\n",
      "2025-09-23 02:21:26.223010: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318418800 of size 28672 next 524\n",
      "2025-09-23 02:21:26.223012: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131841f800 of size 1024 next 607\n",
      "2025-09-23 02:21:26.223013: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131841fc00 of size 1024 next 1893\n",
      "2025-09-23 02:21:26.223014: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318420000 of size 1024 next 610\n",
      "2025-09-23 02:21:26.223015: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318420400 of size 1536 next 628\n",
      "2025-09-23 02:21:26.223017: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318420a00 of size 3072 next 627\n",
      "2025-09-23 02:21:26.223018: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318421600 of size 512 next 632\n",
      "2025-09-23 02:21:26.223019: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318421800 of size 1536 next 635\n",
      "2025-09-23 02:21:26.223020: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318421e00 of size 512 next 637\n",
      "2025-09-23 02:21:26.223021: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318422000 of size 512 next 630\n",
      "2025-09-23 02:21:26.223023: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318422200 of size 256 next 1900\n",
      "2025-09-23 02:21:26.223024: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318422300 of size 256 next 2254\n",
      "2025-09-23 02:21:26.223025: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318422400 of size 256 next 2183\n",
      "2025-09-23 02:21:26.223026: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318422500 of size 256 next 639\n",
      "2025-09-23 02:21:26.223028: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318422600 of size 2048 next 640\n",
      "2025-09-23 02:21:26.223029: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318422e00 of size 2560 next 595\n",
      "2025-09-23 02:21:26.223030: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318423800 of size 8192 next 594\n",
      "2025-09-23 02:21:26.223031: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318425800 of size 75776 next 535\n",
      "2025-09-23 02:21:26.223034: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318438000 of size 50176 next 534\n",
      "2025-09-23 02:21:26.223036: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318444400 of size 50176 next 544\n",
      "2025-09-23 02:21:26.223037: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318450800 of size 50176 next 546\n",
      "2025-09-23 02:21:26.223038: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131845cc00 of size 50176 next 548\n",
      "2025-09-23 02:21:26.223040: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318469000 of size 50176 next 553\n",
      "2025-09-23 02:21:26.223041: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318475400 of size 50176 next 564\n",
      "2025-09-23 02:21:26.223042: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318481800 of size 50176 next 565\n",
      "2025-09-23 02:21:26.223043: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131848dc00 of size 50176 next 567\n",
      "2025-09-23 02:21:26.223044: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131849a000 of size 50176 next 572\n",
      "2025-09-23 02:21:26.223046: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184a6400 of size 50176 next 581\n",
      "2025-09-23 02:21:26.223047: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184b2800 of size 50176 next 583\n",
      "2025-09-23 02:21:26.223049: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184bec00 of size 50176 next 585\n",
      "2025-09-23 02:21:26.223050: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184cb000 of size 50176 next 590\n",
      "2025-09-23 02:21:26.223051: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d7400 of size 1024 next 612\n",
      "2025-09-23 02:21:26.223053: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d7800 of size 1024 next 611\n",
      "2025-09-23 02:21:26.223054: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d7c00 of size 1024 next 2383\n",
      "2025-09-23 02:21:26.223055: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d8000 of size 256 next 2681\n",
      "2025-09-23 02:21:26.223056: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d8100 of size 256 next 2168\n",
      "2025-09-23 02:21:26.223058: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d8200 of size 256 next 2702\n",
      "2025-09-23 02:21:26.223059: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d8300 of size 256 next 616\n",
      "2025-09-23 02:21:26.223060: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d8400 of size 256 next 617\n",
      "2025-09-23 02:21:26.223061: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d8500 of size 1024 next 618\n",
      "2025-09-23 02:21:26.223063: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d8900 of size 256 next 621\n",
      "2025-09-23 02:21:26.223064: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d8a00 of size 256 next 623\n",
      "2025-09-23 02:21:26.223065: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d8b00 of size 256 next 2277\n",
      "2025-09-23 02:21:26.223066: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d8c00 of size 256 next 625\n",
      "2025-09-23 02:21:26.223067: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d8d00 of size 2048 next 614\n",
      "2025-09-23 02:21:26.223069: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184d9500 of size 8192 next 615\n",
      "2025-09-23 02:21:26.223070: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184db500 of size 4096 next 645\n",
      "2025-09-23 02:21:26.223071: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184dc500 of size 512 next 648\n",
      "2025-09-23 02:21:26.223072: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184dc700 of size 2048 next 649\n",
      "2025-09-23 02:21:26.223074: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184dcf00 of size 512 next 646\n",
      "2025-09-23 02:21:26.223075: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184dd100 of size 512 next 647\n",
      "2025-09-23 02:21:26.223076: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184dd300 of size 256 next 2417\n",
      "2025-09-23 02:21:26.223078: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184dd400 of size 256 next 2006\n",
      "2025-09-23 02:21:26.223079: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184dd500 of size 256 next 2152\n",
      "2025-09-23 02:21:26.223080: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184dd600 of size 256 next 655\n",
      "2025-09-23 02:21:26.223081: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184dd700 of size 2048 next 656\n",
      "2025-09-23 02:21:26.223082: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184ddf00 of size 2048 next 657\n",
      "2025-09-23 02:21:26.223084: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184de700 of size 4096 next 661\n",
      "2025-09-23 02:21:26.223085: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184df700 of size 512 next 664\n",
      "2025-09-23 02:21:26.223086: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184df900 of size 2048 next 667\n",
      "2025-09-23 02:21:26.223087: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184e0100 of size 512 next 662\n",
      "2025-09-23 02:21:26.223089: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184e0300 of size 512 next 663\n",
      "2025-09-23 02:21:26.223090: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184e0500 of size 256 next 1810\n",
      "2025-09-23 02:21:26.223091: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184e0600 of size 256 next 2113\n",
      "2025-09-23 02:21:26.223092: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184e0700 of size 256 next 2728\n",
      "2025-09-23 02:21:26.223093: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184e0800 of size 256 next 670\n",
      "2025-09-23 02:21:26.223095: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184e0900 of size 2048 next 671\n",
      "2025-09-23 02:21:26.223096: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184e1100 of size 2048 next 672\n",
      "2025-09-23 02:21:26.223097: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184e1900 of size 4096 next 675\n",
      "2025-09-23 02:21:26.223098: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184e2900 of size 512 next 676\n",
      "2025-09-23 02:21:26.223100: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184e2b00 of size 3328 next 600\n",
      "2025-09-23 02:21:26.223101: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184e3800 of size 50176 next 599\n",
      "2025-09-23 02:21:26.223102: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184efc00 of size 50176 next 602\n",
      "2025-09-23 02:21:26.223103: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13184fc000 of size 50176 next 604\n",
      "2025-09-23 02:21:26.223104: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318508400 of size 50176 next 609\n",
      "2025-09-23 02:21:26.223106: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318514800 of size 512 next 677\n",
      "2025-09-23 02:21:26.223107: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318514a00 of size 512 next 678\n",
      "2025-09-23 02:21:26.223108: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318514c00 of size 512 next 2284\n",
      "2025-09-23 02:21:26.223110: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1318514e00 of size 256 next 2188\n",
      "2025-09-23 02:21:26.223111: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318514f00 of size 256 next 682\n",
      "2025-09-23 02:21:26.223112: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318515000 of size 768 next 683\n",
      "2025-09-23 02:21:26.223114: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318515300 of size 768 next 684\n",
      "2025-09-23 02:21:26.223115: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318515600 of size 1024 next 1773\n",
      "2025-09-23 02:21:26.223116: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1318515a00 of size 512 next 688\n",
      "2025-09-23 02:21:26.223117: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318515c00 of size 768 next 690\n",
      "2025-09-23 02:21:26.223118: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318515f00 of size 768 next 691\n",
      "2025-09-23 02:21:26.223120: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1318516200 of size 512 next 1774\n",
      "2025-09-23 02:21:26.223121: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318516400 of size 256 next 1916\n",
      "2025-09-23 02:21:26.223122: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318516500 of size 256 next 2055\n",
      "2025-09-23 02:21:26.223124: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1318516600 of size 512 next 692\n",
      "2025-09-23 02:21:26.223125: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318516800 of size 256 next 695\n",
      "2025-09-23 02:21:26.223126: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318516900 of size 768 next 696\n",
      "2025-09-23 02:21:26.223127: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318516c00 of size 512 next 701\n",
      "2025-09-23 02:21:26.223129: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318516e00 of size 512 next 697\n",
      "2025-09-23 02:21:26.223130: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318517000 of size 256 next 1967\n",
      "2025-09-23 02:21:26.223131: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318517100 of size 256 next 2773\n",
      "2025-09-23 02:21:26.223132: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1318517200 of size 512 next 703\n",
      "2025-09-23 02:21:26.223134: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318517400 of size 768 next 706\n",
      "2025-09-23 02:21:26.223135: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318517700 of size 768 next 704\n",
      "2025-09-23 02:21:26.223136: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318517a00 of size 1280 next 1796\n",
      "2025-09-23 02:21:26.223137: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318517f00 of size 256 next 708\n",
      "2025-09-23 02:21:26.223138: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318518000 of size 768 next 711\n",
      "2025-09-23 02:21:26.223140: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318518300 of size 768 next 709\n",
      "2025-09-23 02:21:26.223141: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318518600 of size 512 next 587\n",
      "2025-09-23 02:21:26.223142: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318518800 of size 512 next 2005\n",
      "2025-09-23 02:21:26.223144: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318518a00 of size 768 next 693\n",
      "2025-09-23 02:21:26.223145: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318518d00 of size 5888 next 694\n",
      "2025-09-23 02:21:26.223146: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851a400 of size 256 next 1939\n",
      "2025-09-23 02:21:26.223147: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851a500 of size 256 next 2218\n",
      "2025-09-23 02:21:26.223148: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 131851a600 of size 512 next 760\n",
      "2025-09-23 02:21:26.223150: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851a800 of size 512 next 761\n",
      "2025-09-23 02:21:26.223151: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851aa00 of size 512 next 762\n",
      "2025-09-23 02:21:26.223152: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 131851ac00 of size 512 next 447\n",
      "2025-09-23 02:21:26.223153: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851ae00 of size 256 next 1949\n",
      "2025-09-23 02:21:26.223154: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851af00 of size 256 next 765\n",
      "2025-09-23 02:21:26.223156: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851b000 of size 256 next 766\n",
      "2025-09-23 02:21:26.223157: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851b100 of size 256 next 767\n",
      "2025-09-23 02:21:26.223158: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851b200 of size 256 next 770\n",
      "2025-09-23 02:21:26.223159: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851b300 of size 256 next 771\n",
      "2025-09-23 02:21:26.223161: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851b400 of size 256 next 772\n",
      "2025-09-23 02:21:26.223162: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851b500 of size 256 next 773\n",
      "2025-09-23 02:21:26.223163: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851b600 of size 256 next 774\n",
      "2025-09-23 02:21:26.223164: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851b700 of size 256 next 777\n",
      "2025-09-23 02:21:26.223165: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851b800 of size 256 next 775\n",
      "2025-09-23 02:21:26.223167: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851b900 of size 256 next 776\n",
      "2025-09-23 02:21:26.223168: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851ba00 of size 256 next 778\n",
      "2025-09-23 02:21:26.223169: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851bb00 of size 256 next 780\n",
      "2025-09-23 02:21:26.223170: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851bc00 of size 256 next 781\n",
      "2025-09-23 02:21:26.223171: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851bd00 of size 256 next 782\n",
      "2025-09-23 02:21:26.223173: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851be00 of size 256 next 750\n",
      "2025-09-23 02:21:26.223174: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851bf00 of size 6912 next 749\n",
      "2025-09-23 02:21:26.223175: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851da00 of size 256 next 786\n",
      "2025-09-23 02:21:26.223176: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851db00 of size 256 next 787\n",
      "2025-09-23 02:21:26.223177: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851dc00 of size 256 next 788\n",
      "2025-09-23 02:21:26.223179: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851dd00 of size 256 next 789\n",
      "2025-09-23 02:21:26.223180: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851de00 of size 256 next 790\n",
      "2025-09-23 02:21:26.223181: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851df00 of size 256 next 791\n",
      "2025-09-23 02:21:26.223183: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851e000 of size 256 next 792\n",
      "2025-09-23 02:21:26.223184: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851e100 of size 2048 next 793\n",
      "2025-09-23 02:21:26.223185: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851e900 of size 2048 next 794\n",
      "2025-09-23 02:21:26.223186: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851f100 of size 2048 next 795\n",
      "2025-09-23 02:21:26.223188: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131851f900 of size 2048 next 796\n",
      "2025-09-23 02:21:26.223189: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318520100 of size 256 next 797\n",
      "2025-09-23 02:21:26.223190: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318520200 of size 256 next 798\n",
      "2025-09-23 02:21:26.223191: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318520300 of size 256 next 799\n",
      "2025-09-23 02:21:26.223193: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318520400 of size 256 next 800\n",
      "2025-09-23 02:21:26.223194: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318520500 of size 256 next 801\n",
      "2025-09-23 02:21:26.223195: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318520600 of size 256 next 802\n",
      "2025-09-23 02:21:26.223196: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318520700 of size 256 next 803\n",
      "2025-09-23 02:21:26.223197: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318520800 of size 256 next 804\n",
      "2025-09-23 02:21:26.223199: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318520900 of size 256 next 809\n",
      "2025-09-23 02:21:26.223200: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318520a00 of size 256 next 810\n",
      "2025-09-23 02:21:26.223201: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318520b00 of size 256 next 620\n",
      "2025-09-23 02:21:26.223202: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318520c00 of size 50176 next 619\n",
      "2025-09-23 02:21:26.223204: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131852d000 of size 50176 next 622\n",
      "2025-09-23 02:21:26.223205: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318539400 of size 52224 next 314\n",
      "2025-09-23 02:21:26.223207: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318546000 of size 1382400 next 313\n",
      "2025-09-23 02:21:26.223208: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318697800 of size 225792 next 634\n",
      "2025-09-23 02:21:26.223209: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13186cea00 of size 112896 next 633\n",
      "2025-09-23 02:21:26.223211: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13186ea300 of size 112896 next 636\n",
      "2025-09-23 02:21:26.223212: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318705c00 of size 107520 next 638\n",
      "2025-09-23 02:21:26.223213: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318720000 of size 256 next 712\n",
      "2025-09-23 02:21:26.223214: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318720100 of size 768 next 714\n",
      "2025-09-23 02:21:26.223216: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318720400 of size 512 next 715\n",
      "2025-09-23 02:21:26.223217: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318720600 of size 512 next 718\n",
      "2025-09-23 02:21:26.223218: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318720800 of size 512 next 2560\n",
      "2025-09-23 02:21:26.223219: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318720a00 of size 512 next 722\n",
      "2025-09-23 02:21:26.223221: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318720c00 of size 768 next 723\n",
      "2025-09-23 02:21:26.223222: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318720f00 of size 768 next 724\n",
      "2025-09-23 02:21:26.223223: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318721200 of size 256 next 2477\n",
      "2025-09-23 02:21:26.223224: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318721300 of size 256 next 2349\n",
      "2025-09-23 02:21:26.223226: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318721400 of size 256 next 2314\n",
      "2025-09-23 02:21:26.223227: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318721500 of size 256 next 1892\n",
      "2025-09-23 02:21:26.223228: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318721600 of size 256 next 2173\n",
      "2025-09-23 02:21:26.223229: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318721700 of size 256 next 727\n",
      "2025-09-23 02:21:26.223230: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318721800 of size 768 next 743\n",
      "2025-09-23 02:21:26.223232: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318721b00 of size 768 next 2616\n",
      "2025-09-23 02:21:26.223233: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318721e00 of size 768 next 746\n",
      "2025-09-23 02:21:26.223234: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318722100 of size 768 next 747\n",
      "2025-09-23 02:21:26.223236: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318722400 of size 768 next 748\n",
      "2025-09-23 02:21:26.223237: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318722700 of size 256 next 2613\n",
      "2025-09-23 02:21:26.223238: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318722800 of size 256 next 1831\n",
      "2025-09-23 02:21:26.223239: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318722900 of size 256 next 1906\n",
      "2025-09-23 02:21:26.223241: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318722a00 of size 256 next 1935\n",
      "2025-09-23 02:21:26.223242: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318722b00 of size 256 next 2530\n",
      "2025-09-23 02:21:26.223243: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318722c00 of size 256 next 752\n",
      "2025-09-23 02:21:26.223244: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318722d00 of size 256 next 753\n",
      "2025-09-23 02:21:26.223245: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318722e00 of size 768 next 754\n",
      "2025-09-23 02:21:26.223247: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318723100 of size 512 next 756\n",
      "2025-09-23 02:21:26.223248: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318723300 of size 768 next 713\n",
      "2025-09-23 02:21:26.223249: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318723600 of size 11776 next 698\n",
      "2025-09-23 02:21:26.223251: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318726400 of size 25600 next 686\n",
      "2025-09-23 02:21:26.223252: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131872c800 of size 51200 next 685\n",
      "2025-09-23 02:21:26.223254: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318739000 of size 25600 next 699\n",
      "2025-09-23 02:21:26.223255: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131873f400 of size 768 next 729\n",
      "2025-09-23 02:21:26.223256: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131873f700 of size 768 next 728\n",
      "2025-09-23 02:21:26.223257: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131873fa00 of size 256 next 1942\n",
      "2025-09-23 02:21:26.223259: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131873fb00 of size 256 next 2142\n",
      "2025-09-23 02:21:26.223260: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131873fc00 of size 256 next 2374\n",
      "2025-09-23 02:21:26.223261: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131873fd00 of size 256 next 511\n",
      "2025-09-23 02:21:26.223262: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131873fe00 of size 256 next 1857\n",
      "2025-09-23 02:21:26.223263: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 131873ff00 of size 256 next 733\n",
      "2025-09-23 02:21:26.223265: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318740000 of size 256 next 734\n",
      "2025-09-23 02:21:26.223266: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318740100 of size 768 next 735\n",
      "2025-09-23 02:21:26.223267: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318740400 of size 512 next 737\n",
      "2025-09-23 02:21:26.223268: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318740600 of size 512 next 738\n",
      "2025-09-23 02:21:26.223269: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318740800 of size 256 next 2238\n",
      "2025-09-23 02:21:26.223271: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318740900 of size 256 next 2065\n",
      "2025-09-23 02:21:26.223272: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318740a00 of size 256 next 1933\n",
      "2025-09-23 02:21:26.223273: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318740b00 of size 256 next 742\n",
      "2025-09-23 02:21:26.223274: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318740c00 of size 1024 next 731\n",
      "2025-09-23 02:21:26.223276: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318741000 of size 6912 next 732\n",
      "2025-09-23 02:21:26.223277: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318742b00 of size 1792 next 783\n",
      "2025-09-23 02:21:26.223278: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318743200 of size 1792 next 784\n",
      "2025-09-23 02:21:26.223279: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318743900 of size 1792 next 785\n",
      "2025-09-23 02:21:26.223281: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318744000 of size 2304 next 779\n",
      "2025-09-23 02:21:26.223282: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318744900 of size 3840 next 653\n",
      "2025-09-23 02:21:26.223283: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318745800 of size 153600 next 652\n",
      "2025-09-23 02:21:26.223284: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131876b000 of size 36864 next 717\n",
      "2025-09-23 02:21:26.223286: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318774000 of size 256 next 842\n",
      "2025-09-23 02:21:26.223287: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318774100 of size 256 next 843\n",
      "2025-09-23 02:21:26.223289: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318774200 of size 256 next 844\n",
      "2025-09-23 02:21:26.223290: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318774300 of size 256 next 845\n",
      "2025-09-23 02:21:26.223291: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318774400 of size 256 next 846\n",
      "2025-09-23 02:21:26.223292: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318774500 of size 256 next 847\n",
      "2025-09-23 02:21:26.223293: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318774600 of size 256 next 848\n",
      "2025-09-23 02:21:26.223295: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318774700 of size 256 next 849\n",
      "2025-09-23 02:21:26.223296: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318774800 of size 8192 next 850\n",
      "2025-09-23 02:21:26.223297: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318776800 of size 8192 next 851\n",
      "2025-09-23 02:21:26.223299: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318778800 of size 8192 next 852\n",
      "2025-09-23 02:21:26.223300: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877a800 of size 8192 next 853\n",
      "2025-09-23 02:21:26.223301: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877c800 of size 256 next 854\n",
      "2025-09-23 02:21:26.223302: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877c900 of size 256 next 855\n",
      "2025-09-23 02:21:26.223303: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877ca00 of size 256 next 856\n",
      "2025-09-23 02:21:26.223305: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877cb00 of size 256 next 857\n",
      "2025-09-23 02:21:26.223306: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877cc00 of size 256 next 858\n",
      "2025-09-23 02:21:26.223307: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877cd00 of size 256 next 859\n",
      "2025-09-23 02:21:26.223308: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877ce00 of size 256 next 860\n",
      "2025-09-23 02:21:26.223310: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877cf00 of size 256 next 861\n",
      "2025-09-23 02:21:26.223311: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877d000 of size 256 next 866\n",
      "2025-09-23 02:21:26.223312: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877d100 of size 256 next 867\n",
      "2025-09-23 02:21:26.223313: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877d200 of size 256 next 868\n",
      "2025-09-23 02:21:26.223314: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877d300 of size 256 next 869\n",
      "2025-09-23 02:21:26.223316: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877d400 of size 256 next 870\n",
      "2025-09-23 02:21:26.223317: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877d500 of size 256 next 871\n",
      "2025-09-23 02:21:26.223318: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877d600 of size 256 next 872\n",
      "2025-09-23 02:21:26.223320: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877d700 of size 256 next 873\n",
      "2025-09-23 02:21:26.223321: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877d800 of size 4096 next 764\n",
      "2025-09-23 02:21:26.223322: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131877e800 of size 73728 next 650\n",
      "2025-09-23 02:21:26.223323: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318790800 of size 456704 next 18446744073709551615\n",
      "2025-09-23 02:21:26.223325: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 16777216\n",
      "2025-09-23 02:21:26.223326: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318800000 of size 230400 next 651\n",
      "2025-09-23 02:21:26.223328: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318838400 of size 230400 next 679\n",
      "2025-09-23 02:21:26.223329: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318870800 of size 230400 next 666\n",
      "2025-09-23 02:21:26.223330: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13188a8c00 of size 230400 next 665\n",
      "2025-09-23 02:21:26.223332: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13188e1000 of size 230400 next 668\n",
      "2025-09-23 02:21:26.223333: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318919400 of size 61440 next 702\n",
      "2025-09-23 02:21:26.223334: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318928400 of size 73728 next 707\n",
      "2025-09-23 02:21:26.223335: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893a400 of size 1280 next 805\n",
      "2025-09-23 02:21:26.223337: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893a900 of size 1280 next 806\n",
      "2025-09-23 02:21:26.223338: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893ae00 of size 1280 next 807\n",
      "2025-09-23 02:21:26.223339: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893b300 of size 1280 next 808\n",
      "2025-09-23 02:21:26.223341: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893b800 of size 256 next 811\n",
      "2025-09-23 02:21:26.223342: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893b900 of size 256 next 812\n",
      "2025-09-23 02:21:26.223343: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893ba00 of size 256 next 813\n",
      "2025-09-23 02:21:26.223344: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893bb00 of size 256 next 814\n",
      "2025-09-23 02:21:26.223345: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893bc00 of size 256 next 815\n",
      "2025-09-23 02:21:26.223347: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893bd00 of size 4096 next 816\n",
      "2025-09-23 02:21:26.223348: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893cd00 of size 4096 next 817\n",
      "2025-09-23 02:21:26.223349: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893dd00 of size 4096 next 818\n",
      "2025-09-23 02:21:26.223350: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893ed00 of size 4096 next 819\n",
      "2025-09-23 02:21:26.223352: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893fd00 of size 256 next 820\n",
      "2025-09-23 02:21:26.223353: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893fe00 of size 256 next 821\n",
      "2025-09-23 02:21:26.223354: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131893ff00 of size 256 next 822\n",
      "2025-09-23 02:21:26.223355: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318940000 of size 256 next 823\n",
      "2025-09-23 02:21:26.223356: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318940100 of size 256 next 824\n",
      "2025-09-23 02:21:26.223358: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318940200 of size 256 next 825\n",
      "2025-09-23 02:21:26.223359: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318940300 of size 256 next 826\n",
      "2025-09-23 02:21:26.223360: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318940400 of size 256 next 827\n",
      "2025-09-23 02:21:26.223361: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318940500 of size 12032 next 716\n",
      "2025-09-23 02:21:26.223363: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318943400 of size 58368 next 644\n",
      "2025-09-23 02:21:26.223364: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318951800 of size 1382400 next 642\n",
      "2025-09-23 02:21:26.223366: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aa3000 of size 230400 next 680\n",
      "2025-09-23 02:21:26.223367: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318adb400 of size 36864 next 736\n",
      "2025-09-23 02:21:26.223368: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ae4400 of size 8192 next 828\n",
      "2025-09-23 02:21:26.223370: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ae6400 of size 8192 next 829\n",
      "2025-09-23 02:21:26.223371: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ae8400 of size 8192 next 830\n",
      "2025-09-23 02:21:26.223373: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aea400 of size 256 next 831\n",
      "2025-09-23 02:21:26.223374: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aea500 of size 256 next 832\n",
      "2025-09-23 02:21:26.223375: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aea600 of size 256 next 833\n",
      "2025-09-23 02:21:26.223376: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aea700 of size 256 next 834\n",
      "2025-09-23 02:21:26.223378: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aea800 of size 256 next 835\n",
      "2025-09-23 02:21:26.223379: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aea900 of size 256 next 836\n",
      "2025-09-23 02:21:26.223380: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aeaa00 of size 256 next 837\n",
      "2025-09-23 02:21:26.223381: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aeab00 of size 256 next 838\n",
      "2025-09-23 02:21:26.223383: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aeac00 of size 2304 next 839\n",
      "2025-09-23 02:21:26.223384: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aeb500 of size 2304 next 840\n",
      "2025-09-23 02:21:26.223385: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aebe00 of size 2304 next 841\n",
      "2025-09-23 02:21:26.223386: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aec700 of size 3328 next 720\n",
      "2025-09-23 02:21:26.223387: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aed400 of size 73728 next 719\n",
      "2025-09-23 02:21:26.223389: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318aff400 of size 73728 next 725\n",
      "2025-09-23 02:21:26.223390: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b11400 of size 36864 next 755\n",
      "2025-09-23 02:21:26.223391: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b1a400 of size 36864 next 740\n",
      "2025-09-23 02:21:26.223392: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b23400 of size 73728 next 739\n",
      "2025-09-23 02:21:26.223394: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b35400 of size 73728 next 745\n",
      "2025-09-23 02:21:26.223395: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b47400 of size 8192 next 885\n",
      "2025-09-23 02:21:26.223396: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b49400 of size 8192 next 886\n",
      "2025-09-23 02:21:26.223397: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b4b400 of size 8192 next 887\n",
      "2025-09-23 02:21:26.223399: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b4d400 of size 256 next 888\n",
      "2025-09-23 02:21:26.223400: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b4d500 of size 256 next 889\n",
      "2025-09-23 02:21:26.223401: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b4d600 of size 256 next 890\n",
      "2025-09-23 02:21:26.223402: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b4d700 of size 256 next 891\n",
      "2025-09-23 02:21:26.223404: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b4d800 of size 256 next 892\n",
      "2025-09-23 02:21:26.223405: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b4d900 of size 256 next 893\n",
      "2025-09-23 02:21:26.223406: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b4da00 of size 256 next 894\n",
      "2025-09-23 02:21:26.223408: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b4db00 of size 256 next 895\n",
      "2025-09-23 02:21:26.223409: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b4dc00 of size 8192 next 896\n",
      "2025-09-23 02:21:26.223410: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b4fc00 of size 8192 next 897\n",
      "2025-09-23 02:21:26.223411: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b51c00 of size 8192 next 898\n",
      "2025-09-23 02:21:26.223414: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b53c00 of size 8192 next 899\n",
      "2025-09-23 02:21:26.223416: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b55c00 of size 256 next 900\n",
      "2025-09-23 02:21:26.223417: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b55d00 of size 256 next 901\n",
      "2025-09-23 02:21:26.223419: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b55e00 of size 256 next 902\n",
      "2025-09-23 02:21:26.223420: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b55f00 of size 256 next 903\n",
      "2025-09-23 02:21:26.223421: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b56000 of size 256 next 904\n",
      "2025-09-23 02:21:26.223422: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b56100 of size 256 next 905\n",
      "2025-09-23 02:21:26.223424: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b56200 of size 256 next 906\n",
      "2025-09-23 02:21:26.223425: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b56300 of size 256 next 907\n",
      "2025-09-23 02:21:26.223426: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b56400 of size 2304 next 908\n",
      "2025-09-23 02:21:26.223427: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b56d00 of size 2304 next 909\n",
      "2025-09-23 02:21:26.223428: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b57600 of size 2304 next 910\n",
      "2025-09-23 02:21:26.223430: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b57f00 of size 2304 next 911\n",
      "2025-09-23 02:21:26.223431: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b58800 of size 256 next 912\n",
      "2025-09-23 02:21:26.223432: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b58900 of size 256 next 913\n",
      "2025-09-23 02:21:26.223434: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b58a00 of size 256 next 914\n",
      "2025-09-23 02:21:26.223435: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b58b00 of size 256 next 915\n",
      "2025-09-23 02:21:26.223436: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b58c00 of size 256 next 916\n",
      "2025-09-23 02:21:26.223437: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b58d00 of size 256 next 917\n",
      "2025-09-23 02:21:26.223439: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b58e00 of size 256 next 918\n",
      "2025-09-23 02:21:26.223440: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b58f00 of size 256 next 919\n",
      "2025-09-23 02:21:26.223441: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b59000 of size 256 next 924\n",
      "2025-09-23 02:21:26.223442: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b59100 of size 256 next 925\n",
      "2025-09-23 02:21:26.223444: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b59200 of size 256 next 926\n",
      "2025-09-23 02:21:26.223445: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b59300 of size 256 next 759\n",
      "2025-09-23 02:21:26.223446: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b59400 of size 73728 next 758\n",
      "2025-09-23 02:21:26.223447: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b6b400 of size 8192 next 862\n",
      "2025-09-23 02:21:26.223449: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b6d400 of size 8192 next 863\n",
      "2025-09-23 02:21:26.223450: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b6f400 of size 8192 next 864\n",
      "2025-09-23 02:21:26.223451: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b71400 of size 8192 next 865\n",
      "2025-09-23 02:21:26.223452: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b73400 of size 2304 next 874\n",
      "2025-09-23 02:21:26.223453: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b73d00 of size 2304 next 875\n",
      "2025-09-23 02:21:26.223455: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b74600 of size 2304 next 876\n",
      "2025-09-23 02:21:26.223456: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b74f00 of size 256 next 877\n",
      "2025-09-23 02:21:26.223459: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b75000 of size 256 next 878\n",
      "2025-09-23 02:21:26.223460: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b75100 of size 256 next 879\n",
      "2025-09-23 02:21:26.223462: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b75200 of size 256 next 880\n",
      "2025-09-23 02:21:26.223463: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b75300 of size 256 next 881\n",
      "2025-09-23 02:21:26.223464: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b75400 of size 256 next 882\n",
      "2025-09-23 02:21:26.223466: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b75500 of size 256 next 883\n",
      "2025-09-23 02:21:26.223467: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b75600 of size 256 next 884\n",
      "2025-09-23 02:21:26.223468: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b75700 of size 15616 next 769\n",
      "2025-09-23 02:21:26.223477: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b79400 of size 57344 next 768\n",
      "2025-09-23 02:21:26.223480: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b87400 of size 8192 next 920\n",
      "2025-09-23 02:21:26.223483: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b89400 of size 8192 next 921\n",
      "2025-09-23 02:21:26.223485: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b8b400 of size 8192 next 922\n",
      "2025-09-23 02:21:26.223486: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b8d400 of size 8192 next 923\n",
      "2025-09-23 02:21:26.223488: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b8f400 of size 256 next 927\n",
      "2025-09-23 02:21:26.223489: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b8f500 of size 256 next 928\n",
      "2025-09-23 02:21:26.223491: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b8f600 of size 256 next 929\n",
      "2025-09-23 02:21:26.223492: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b8f700 of size 256 next 930\n",
      "2025-09-23 02:21:26.223493: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b8f800 of size 8192 next 931\n",
      "2025-09-23 02:21:26.223495: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b91800 of size 8192 next 932\n",
      "2025-09-23 02:21:26.223496: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b93800 of size 8192 next 933\n",
      "2025-09-23 02:21:26.223497: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b95800 of size 8192 next 934\n",
      "2025-09-23 02:21:26.223499: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b97800 of size 256 next 935\n",
      "2025-09-23 02:21:26.223500: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b97900 of size 256 next 936\n",
      "2025-09-23 02:21:26.223501: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b97a00 of size 256 next 937\n",
      "2025-09-23 02:21:26.223502: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b97b00 of size 256 next 938\n",
      "2025-09-23 02:21:26.223503: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b97c00 of size 256 next 939\n",
      "2025-09-23 02:21:26.223505: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b97d00 of size 256 next 940\n",
      "2025-09-23 02:21:26.223506: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b97e00 of size 256 next 941\n",
      "2025-09-23 02:21:26.223507: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b97f00 of size 256 next 942\n",
      "2025-09-23 02:21:26.223508: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b98000 of size 2304 next 943\n",
      "2025-09-23 02:21:26.223510: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b98900 of size 2304 next 944\n",
      "2025-09-23 02:21:26.223511: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b99200 of size 2304 next 945\n",
      "2025-09-23 02:21:26.223512: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b99b00 of size 2304 next 946\n",
      "2025-09-23 02:21:26.223513: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b9a400 of size 256 next 947\n",
      "2025-09-23 02:21:26.223515: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b9a500 of size 256 next 948\n",
      "2025-09-23 02:21:26.223516: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b9a600 of size 256 next 949\n",
      "2025-09-23 02:21:26.223517: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b9a700 of size 256 next 950\n",
      "2025-09-23 02:21:26.223518: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b9a800 of size 256 next 951\n",
      "2025-09-23 02:21:26.223520: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b9a900 of size 256 next 952\n",
      "2025-09-23 02:21:26.223521: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b9aa00 of size 256 next 953\n",
      "2025-09-23 02:21:26.223522: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b9ab00 of size 256 next 954\n",
      "2025-09-23 02:21:26.223523: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b9ac00 of size 8192 next 955\n",
      "2025-09-23 02:21:26.223524: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b9cc00 of size 8192 next 956\n",
      "2025-09-23 02:21:26.223526: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318b9ec00 of size 8192 next 957\n",
      "2025-09-23 02:21:26.223527: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba0c00 of size 8192 next 958\n",
      "2025-09-23 02:21:26.223528: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba2c00 of size 256 next 959\n",
      "2025-09-23 02:21:26.223529: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba2d00 of size 256 next 960\n",
      "2025-09-23 02:21:26.223531: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba2e00 of size 256 next 961\n",
      "2025-09-23 02:21:26.223532: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba2f00 of size 256 next 962\n",
      "2025-09-23 02:21:26.223598: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba3000 of size 256 next 963\n",
      "2025-09-23 02:21:26.223607: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba3100 of size 256 next 964\n",
      "2025-09-23 02:21:26.223609: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba3200 of size 256 next 965\n",
      "2025-09-23 02:21:26.223610: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba3300 of size 256 next 966\n",
      "2025-09-23 02:21:26.223612: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba3400 of size 8192 next 967\n",
      "2025-09-23 02:21:26.223613: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba5400 of size 8192 next 968\n",
      "2025-09-23 02:21:26.223614: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba7400 of size 8192 next 969\n",
      "2025-09-23 02:21:26.223616: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ba9400 of size 8192 next 970\n",
      "2025-09-23 02:21:26.223617: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bab400 of size 256 next 971\n",
      "2025-09-23 02:21:26.223618: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bab500 of size 256 next 972\n",
      "2025-09-23 02:21:26.223619: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bab600 of size 256 next 973\n",
      "2025-09-23 02:21:26.223620: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bab700 of size 256 next 974\n",
      "2025-09-23 02:21:26.223622: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bab800 of size 256 next 975\n",
      "2025-09-23 02:21:26.223623: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bab900 of size 256 next 976\n",
      "2025-09-23 02:21:26.223624: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318baba00 of size 256 next 977\n",
      "2025-09-23 02:21:26.223625: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318babb00 of size 256 next 978\n",
      "2025-09-23 02:21:26.223627: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318babc00 of size 2304 next 979\n",
      "2025-09-23 02:21:26.223628: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bac500 of size 2304 next 980\n",
      "2025-09-23 02:21:26.223629: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bace00 of size 2304 next 981\n",
      "2025-09-23 02:21:26.223630: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bad700 of size 2304 next 982\n",
      "2025-09-23 02:21:26.223631: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bae000 of size 256 next 983\n",
      "2025-09-23 02:21:26.223632: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bae100 of size 256 next 984\n",
      "2025-09-23 02:21:26.223634: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bae200 of size 256 next 985\n",
      "2025-09-23 02:21:26.223635: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bae300 of size 256 next 986\n",
      "2025-09-23 02:21:26.223636: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bae400 of size 256 next 987\n",
      "2025-09-23 02:21:26.223637: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bae500 of size 256 next 988\n",
      "2025-09-23 02:21:26.223638: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bae600 of size 256 next 989\n",
      "2025-09-23 02:21:26.223640: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bae700 of size 256 next 990\n",
      "2025-09-23 02:21:26.223641: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bae800 of size 8192 next 991\n",
      "2025-09-23 02:21:26.223642: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bb0800 of size 8192 next 992\n",
      "2025-09-23 02:21:26.223643: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bb2800 of size 8192 next 993\n",
      "2025-09-23 02:21:26.223644: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bb4800 of size 8192 next 994\n",
      "2025-09-23 02:21:26.223646: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bb6800 of size 256 next 995\n",
      "2025-09-23 02:21:26.223647: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bb6900 of size 256 next 996\n",
      "2025-09-23 02:21:26.223648: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bb6a00 of size 256 next 997\n",
      "2025-09-23 02:21:26.223650: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bb6b00 of size 256 next 998\n",
      "2025-09-23 02:21:26.223651: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bb6c00 of size 256 next 999\n",
      "2025-09-23 02:21:26.223652: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bb6d00 of size 256 next 1000\n",
      "2025-09-23 02:21:26.223653: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bb6e00 of size 256 next 1001\n",
      "2025-09-23 02:21:26.223654: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bb6f00 of size 256 next 1002\n",
      "2025-09-23 02:21:26.223656: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bb7000 of size 16384 next 1003\n",
      "2025-09-23 02:21:26.223657: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bbb000 of size 16384 next 1004\n",
      "2025-09-23 02:21:26.223658: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bbf000 of size 16384 next 1005\n",
      "2025-09-23 02:21:26.223659: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bc3000 of size 16384 next 1006\n",
      "2025-09-23 02:21:26.223661: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bc7000 of size 512 next 1007\n",
      "2025-09-23 02:21:26.223663: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bc7200 of size 512 next 1008\n",
      "2025-09-23 02:21:26.223664: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bc7400 of size 512 next 1009\n",
      "2025-09-23 02:21:26.223665: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bc7600 of size 512 next 1010\n",
      "2025-09-23 02:21:26.223666: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bc7800 of size 512 next 1011\n",
      "2025-09-23 02:21:26.223681: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bc7a00 of size 512 next 1012\n",
      "2025-09-23 02:21:26.223684: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bc7c00 of size 512 next 1013\n",
      "2025-09-23 02:21:26.223686: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bc7e00 of size 512 next 1014\n",
      "2025-09-23 02:21:26.223687: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bc8000 of size 4608 next 1015\n",
      "2025-09-23 02:21:26.223688: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bc9200 of size 4608 next 1016\n",
      "2025-09-23 02:21:26.223690: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bca400 of size 4608 next 1017\n",
      "2025-09-23 02:21:26.223691: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bcb600 of size 4608 next 1018\n",
      "2025-09-23 02:21:26.223692: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bcc800 of size 512 next 1019\n",
      "2025-09-23 02:21:26.223693: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bcca00 of size 512 next 1020\n",
      "2025-09-23 02:21:26.223695: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bccc00 of size 512 next 1021\n",
      "2025-09-23 02:21:26.223696: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bcce00 of size 512 next 1022\n",
      "2025-09-23 02:21:26.223697: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bcd000 of size 512 next 1023\n",
      "2025-09-23 02:21:26.223698: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bcd200 of size 512 next 1024\n",
      "2025-09-23 02:21:26.223699: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bcd400 of size 512 next 1025\n",
      "2025-09-23 02:21:26.223701: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bcd600 of size 512 next 1026\n",
      "2025-09-23 02:21:26.223702: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bcd800 of size 16384 next 1027\n",
      "2025-09-23 02:21:26.223703: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bd1800 of size 16384 next 1028\n",
      "2025-09-23 02:21:26.223705: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bd5800 of size 256 next 1029\n",
      "2025-09-23 02:21:26.223706: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bd5900 of size 256 next 1030\n",
      "2025-09-23 02:21:26.223707: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bd5a00 of size 16384 next 1031\n",
      "2025-09-23 02:21:26.223708: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bd9a00 of size 16384 next 1032\n",
      "2025-09-23 02:21:26.223709: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bdda00 of size 256 next 1033\n",
      "2025-09-23 02:21:26.223711: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bddb00 of size 256 next 1034\n",
      "2025-09-23 02:21:26.223713: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bddc00 of size 16384 next 1035\n",
      "2025-09-23 02:21:26.223715: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318be1c00 of size 16384 next 1036\n",
      "2025-09-23 02:21:26.223716: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318be5c00 of size 512 next 1037\n",
      "2025-09-23 02:21:26.223718: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318be5e00 of size 512 next 1038\n",
      "2025-09-23 02:21:26.223719: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318be6000 of size 16384 next 1039\n",
      "2025-09-23 02:21:26.223721: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bea000 of size 16384 next 1040\n",
      "2025-09-23 02:21:26.223722: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bee000 of size 512 next 1041\n",
      "2025-09-23 02:21:26.223723: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bee200 of size 512 next 1042\n",
      "2025-09-23 02:21:26.223726: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bee400 of size 256 next 1047\n",
      "2025-09-23 02:21:26.223727: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bee500 of size 256 next 1048\n",
      "2025-09-23 02:21:26.223729: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bee600 of size 256 next 1049\n",
      "2025-09-23 02:21:26.223730: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bee700 of size 256 next 1050\n",
      "2025-09-23 02:21:26.223731: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bee800 of size 256 next 1051\n",
      "2025-09-23 02:21:26.223732: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bee900 of size 256 next 1052\n",
      "2025-09-23 02:21:26.223734: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318beea00 of size 256 next 1053\n",
      "2025-09-23 02:21:26.223735: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318beeb00 of size 256 next 1054\n",
      "2025-09-23 02:21:26.223736: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318beec00 of size 1024 next 1059\n",
      "2025-09-23 02:21:26.223737: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bef000 of size 1024 next 1060\n",
      "2025-09-23 02:21:26.223739: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bef400 of size 1024 next 1061\n",
      "2025-09-23 02:21:26.223740: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bef800 of size 1024 next 1062\n",
      "2025-09-23 02:21:26.223741: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318befc00 of size 1024 next 1063\n",
      "2025-09-23 02:21:26.223742: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bf0000 of size 1024 next 1064\n",
      "2025-09-23 02:21:26.223743: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bf0400 of size 1024 next 1065\n",
      "2025-09-23 02:21:26.223745: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bf0800 of size 1024 next 1066\n",
      "2025-09-23 02:21:26.223746: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bf0c00 of size 15360 next 659\n",
      "2025-09-23 02:21:26.223747: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318bf4800 of size 1382400 next 658\n",
      "2025-09-23 02:21:26.223749: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318d46000 of size 1382400 next 673\n",
      "2025-09-23 02:21:26.223750: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318e97800 of size 50176 next 1138\n",
      "2025-09-23 02:21:26.223752: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ea3c00 of size 1024 next 1139\n",
      "2025-09-23 02:21:26.223753: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ea4000 of size 1024 next 1140\n",
      "2025-09-23 02:21:26.223754: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ea4400 of size 50176 next 1141\n",
      "2025-09-23 02:21:26.223755: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318eb0800 of size 50176 next 1142\n",
      "2025-09-23 02:21:26.223757: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ebcc00 of size 1024 next 1143\n",
      "2025-09-23 02:21:26.223758: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ebd000 of size 1024 next 1144\n",
      "2025-09-23 02:21:26.223759: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ebd400 of size 50176 next 1145\n",
      "2025-09-23 02:21:26.223760: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ec9800 of size 50176 next 1146\n",
      "2025-09-23 02:21:26.223762: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ed5c00 of size 50176 next 1147\n",
      "2025-09-23 02:21:26.223763: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ee2000 of size 50176 next 1148\n",
      "2025-09-23 02:21:26.223764: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318eee400 of size 256 next 1149\n",
      "2025-09-23 02:21:26.223765: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318eee500 of size 256 next 1150\n",
      "2025-09-23 02:21:26.223766: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318eee600 of size 256 next 1151\n",
      "2025-09-23 02:21:26.223768: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318eee700 of size 256 next 1152\n",
      "2025-09-23 02:21:26.223769: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318eee800 of size 256 next 1153\n",
      "2025-09-23 02:21:26.223770: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318eee900 of size 256 next 1154\n",
      "2025-09-23 02:21:26.223771: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318eeea00 of size 256 next 1155\n",
      "2025-09-23 02:21:26.223773: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318eeeb00 of size 256 next 1156\n",
      "2025-09-23 02:21:26.223774: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318eeec00 of size 50176 next 1157\n",
      "2025-09-23 02:21:26.223775: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318efb000 of size 50176 next 1158\n",
      "2025-09-23 02:21:26.223776: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f07400 of size 50176 next 1159\n",
      "2025-09-23 02:21:26.223777: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f13800 of size 50176 next 1160\n",
      "2025-09-23 02:21:26.223779: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f1fc00 of size 1024 next 1161\n",
      "2025-09-23 02:21:26.223780: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f20000 of size 1024 next 1162\n",
      "2025-09-23 02:21:26.223781: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f20400 of size 1024 next 1163\n",
      "2025-09-23 02:21:26.223783: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f20800 of size 1024 next 1164\n",
      "2025-09-23 02:21:26.223791: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f20c00 of size 1024 next 1165\n",
      "2025-09-23 02:21:26.223794: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f21000 of size 1024 next 1166\n",
      "2025-09-23 02:21:26.223796: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f21400 of size 1024 next 1167\n",
      "2025-09-23 02:21:26.223797: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f21800 of size 1024 next 1168\n",
      "2025-09-23 02:21:26.223799: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f21c00 of size 8192 next 1169\n",
      "2025-09-23 02:21:26.223800: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f23c00 of size 8192 next 1170\n",
      "2025-09-23 02:21:26.223801: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f25c00 of size 8192 next 1171\n",
      "2025-09-23 02:21:26.223803: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f27c00 of size 8192 next 1172\n",
      "2025-09-23 02:21:26.223804: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f29c00 of size 1024 next 1173\n",
      "2025-09-23 02:21:26.223805: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f2a000 of size 1024 next 1174\n",
      "2025-09-23 02:21:26.223806: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f2a400 of size 1024 next 1175\n",
      "2025-09-23 02:21:26.223808: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f2a800 of size 1024 next 1176\n",
      "2025-09-23 02:21:26.223809: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f2ac00 of size 1024 next 1177\n",
      "2025-09-23 02:21:26.223810: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f2b000 of size 1024 next 1178\n",
      "2025-09-23 02:21:26.223811: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f2b400 of size 1024 next 1179\n",
      "2025-09-23 02:21:26.223812: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f2b800 of size 1024 next 1180\n",
      "2025-09-23 02:21:26.223814: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f2bc00 of size 50176 next 1181\n",
      "2025-09-23 02:21:26.223815: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f38000 of size 50176 next 1182\n",
      "2025-09-23 02:21:26.223817: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f44400 of size 256 next 1183\n",
      "2025-09-23 02:21:26.223818: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f44500 of size 256 next 1184\n",
      "2025-09-23 02:21:26.223819: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f44600 of size 50176 next 1185\n",
      "2025-09-23 02:21:26.223821: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f50a00 of size 50176 next 1186\n",
      "2025-09-23 02:21:26.223822: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f5ce00 of size 256 next 1187\n",
      "2025-09-23 02:21:26.223823: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f5cf00 of size 256 next 1188\n",
      "2025-09-23 02:21:26.223825: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f5d000 of size 50176 next 1189\n",
      "2025-09-23 02:21:26.223826: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f69400 of size 50176 next 1190\n",
      "2025-09-23 02:21:26.223827: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f75800 of size 1024 next 1191\n",
      "2025-09-23 02:21:26.223829: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f75c00 of size 1024 next 1192\n",
      "2025-09-23 02:21:26.223830: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f76000 of size 50176 next 1193\n",
      "2025-09-23 02:21:26.223832: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f82400 of size 50176 next 1194\n",
      "2025-09-23 02:21:26.223833: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f8e800 of size 1024 next 1195\n",
      "2025-09-23 02:21:26.223834: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f8ec00 of size 1024 next 1196\n",
      "2025-09-23 02:21:26.223835: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f8f000 of size 50176 next 1197\n",
      "2025-09-23 02:21:26.223837: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318f9b400 of size 50176 next 1198\n",
      "2025-09-23 02:21:26.223838: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fa7800 of size 50176 next 1199\n",
      "2025-09-23 02:21:26.223839: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fb3c00 of size 50176 next 1200\n",
      "2025-09-23 02:21:26.223841: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fc0000 of size 256 next 1201\n",
      "2025-09-23 02:21:26.223842: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fc0100 of size 256 next 1202\n",
      "2025-09-23 02:21:26.223843: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fc0200 of size 256 next 1203\n",
      "2025-09-23 02:21:26.223844: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fc0300 of size 256 next 1204\n",
      "2025-09-23 02:21:26.223846: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fc0400 of size 256 next 1205\n",
      "2025-09-23 02:21:26.223847: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fc0500 of size 256 next 1206\n",
      "2025-09-23 02:21:26.223848: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fc0600 of size 256 next 1207\n",
      "2025-09-23 02:21:26.223849: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fc0700 of size 256 next 1208\n",
      "2025-09-23 02:21:26.223851: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fc0800 of size 50176 next 1209\n",
      "2025-09-23 02:21:26.223852: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fccc00 of size 50176 next 1210\n",
      "2025-09-23 02:21:26.223853: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fd9000 of size 50176 next 1211\n",
      "2025-09-23 02:21:26.223854: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318fe5400 of size 50176 next 1212\n",
      "2025-09-23 02:21:26.223856: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ff1800 of size 1024 next 1213\n",
      "2025-09-23 02:21:26.223857: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ff1c00 of size 1024 next 1214\n",
      "2025-09-23 02:21:26.223858: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ff2000 of size 1024 next 1215\n",
      "2025-09-23 02:21:26.223860: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ff2400 of size 1024 next 1216\n",
      "2025-09-23 02:21:26.223861: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ff2800 of size 1024 next 1217\n",
      "2025-09-23 02:21:26.223862: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ff2c00 of size 1024 next 1218\n",
      "2025-09-23 02:21:26.223863: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ff3000 of size 1024 next 1219\n",
      "2025-09-23 02:21:26.223864: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ff3400 of size 1024 next 1220\n",
      "2025-09-23 02:21:26.223866: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ff3800 of size 8192 next 1221\n",
      "2025-09-23 02:21:26.223867: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ff5800 of size 8192 next 1222\n",
      "2025-09-23 02:21:26.223868: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ff7800 of size 8192 next 1223\n",
      "2025-09-23 02:21:26.223869: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ff9800 of size 8192 next 1224\n",
      "2025-09-23 02:21:26.223871: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ffb800 of size 1024 next 1225\n",
      "2025-09-23 02:21:26.223872: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ffbc00 of size 1024 next 1226\n",
      "2025-09-23 02:21:26.223873: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ffc000 of size 1024 next 1227\n",
      "2025-09-23 02:21:26.223874: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ffc400 of size 1024 next 1228\n",
      "2025-09-23 02:21:26.223875: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ffc800 of size 1024 next 1229\n",
      "2025-09-23 02:21:26.223877: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ffcc00 of size 1024 next 1230\n",
      "2025-09-23 02:21:26.223878: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ffd000 of size 1024 next 1231\n",
      "2025-09-23 02:21:26.223879: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ffd400 of size 1024 next 1232\n",
      "2025-09-23 02:21:26.223880: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1318ffd800 of size 50176 next 1233\n",
      "2025-09-23 02:21:26.223882: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319009c00 of size 50176 next 1234\n",
      "2025-09-23 02:21:26.223883: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319016000 of size 256 next 1235\n",
      "2025-09-23 02:21:26.223884: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319016100 of size 256 next 1236\n",
      "2025-09-23 02:21:26.223885: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319016200 of size 50176 next 1237\n",
      "2025-09-23 02:21:26.223886: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319022600 of size 50176 next 1238\n",
      "2025-09-23 02:21:26.223888: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131902ea00 of size 256 next 1239\n",
      "2025-09-23 02:21:26.223889: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131902eb00 of size 256 next 1240\n",
      "2025-09-23 02:21:26.223890: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131902ec00 of size 50176 next 1241\n",
      "2025-09-23 02:21:26.223892: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131903b000 of size 50176 next 1242\n",
      "2025-09-23 02:21:26.223893: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319047400 of size 1024 next 1243\n",
      "2025-09-23 02:21:26.223894: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319047800 of size 1024 next 1244\n",
      "2025-09-23 02:21:26.223895: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319047c00 of size 50176 next 1245\n",
      "2025-09-23 02:21:26.223897: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319054000 of size 50176 next 1246\n",
      "2025-09-23 02:21:26.223898: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319060400 of size 1024 next 1247\n",
      "2025-09-23 02:21:26.223899: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319060800 of size 1024 next 1248\n",
      "2025-09-23 02:21:26.223901: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319060c00 of size 50176 next 1249\n",
      "2025-09-23 02:21:26.223902: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131906d000 of size 50176 next 1250\n",
      "2025-09-23 02:21:26.223903: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319079400 of size 50176 next 1251\n",
      "2025-09-23 02:21:26.223904: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319085800 of size 50176 next 1252\n",
      "2025-09-23 02:21:26.223905: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319091c00 of size 256 next 1253\n",
      "2025-09-23 02:21:26.223907: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319091d00 of size 256 next 1254\n",
      "2025-09-23 02:21:26.223908: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319091e00 of size 256 next 1255\n",
      "2025-09-23 02:21:26.223909: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319091f00 of size 256 next 1256\n",
      "2025-09-23 02:21:26.223910: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319092000 of size 256 next 1257\n",
      "2025-09-23 02:21:26.223912: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319092100 of size 256 next 1258\n",
      "2025-09-23 02:21:26.223913: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319092200 of size 256 next 1259\n",
      "2025-09-23 02:21:26.223914: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319092300 of size 256 next 1260\n",
      "2025-09-23 02:21:26.223915: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319092400 of size 50176 next 1261\n",
      "2025-09-23 02:21:26.223916: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131909e800 of size 50176 next 1262\n",
      "2025-09-23 02:21:26.223918: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190aac00 of size 50176 next 1263\n",
      "2025-09-23 02:21:26.223919: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190b7000 of size 50176 next 1264\n",
      "2025-09-23 02:21:26.223920: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190c3400 of size 1024 next 1265\n",
      "2025-09-23 02:21:26.223922: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190c3800 of size 1024 next 1266\n",
      "2025-09-23 02:21:26.223923: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190c3c00 of size 1024 next 1267\n",
      "2025-09-23 02:21:26.223924: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190c4000 of size 1024 next 1268\n",
      "2025-09-23 02:21:26.223925: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190c4400 of size 1024 next 1269\n",
      "2025-09-23 02:21:26.223927: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190c4800 of size 1024 next 1270\n",
      "2025-09-23 02:21:26.223928: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190c4c00 of size 1024 next 1271\n",
      "2025-09-23 02:21:26.223929: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190c5000 of size 1024 next 1272\n",
      "2025-09-23 02:21:26.223930: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190c5400 of size 8192 next 1273\n",
      "2025-09-23 02:21:26.223931: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190c7400 of size 8192 next 1274\n",
      "2025-09-23 02:21:26.223933: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190c9400 of size 8192 next 1275\n",
      "2025-09-23 02:21:26.223934: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190cb400 of size 8192 next 1276\n",
      "2025-09-23 02:21:26.223935: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190cd400 of size 1024 next 1277\n",
      "2025-09-23 02:21:26.223936: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190cd800 of size 1024 next 1278\n",
      "2025-09-23 02:21:26.223937: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190cdc00 of size 1024 next 1279\n",
      "2025-09-23 02:21:26.223939: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190ce000 of size 1024 next 1280\n",
      "2025-09-23 02:21:26.223940: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190ce400 of size 1024 next 1281\n",
      "2025-09-23 02:21:26.223941: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190ce800 of size 1024 next 1282\n",
      "2025-09-23 02:21:26.223943: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190cec00 of size 1024 next 1283\n",
      "2025-09-23 02:21:26.223944: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190cf000 of size 1024 next 1284\n",
      "2025-09-23 02:21:26.223945: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190cf400 of size 50176 next 1285\n",
      "2025-09-23 02:21:26.223947: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190db800 of size 50176 next 1286\n",
      "2025-09-23 02:21:26.223948: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190e7c00 of size 256 next 1287\n",
      "2025-09-23 02:21:26.223949: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190e7d00 of size 256 next 1288\n",
      "2025-09-23 02:21:26.223950: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190e7e00 of size 50176 next 1289\n",
      "2025-09-23 02:21:26.223952: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13190f4200 of size 50176 next 1290\n",
      "2025-09-23 02:21:26.223953: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319100600 of size 256 next 1291\n",
      "2025-09-23 02:21:26.223954: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319100700 of size 256 next 1292\n",
      "2025-09-23 02:21:26.223956: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319100800 of size 50176 next 1293\n",
      "2025-09-23 02:21:26.223957: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131910cc00 of size 50176 next 1294\n",
      "2025-09-23 02:21:26.223958: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319119000 of size 1024 next 1295\n",
      "2025-09-23 02:21:26.223959: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319119400 of size 1024 next 1296\n",
      "2025-09-23 02:21:26.223961: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319119800 of size 50176 next 1297\n",
      "2025-09-23 02:21:26.223962: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319125c00 of size 50176 next 1298\n",
      "2025-09-23 02:21:26.223963: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319132000 of size 1024 next 1299\n",
      "2025-09-23 02:21:26.223965: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319132400 of size 1024 next 1300\n",
      "2025-09-23 02:21:26.223966: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319132800 of size 50176 next 1301\n",
      "2025-09-23 02:21:26.223967: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131913ec00 of size 50176 next 1302\n",
      "2025-09-23 02:21:26.223968: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131914b000 of size 50176 next 1303\n",
      "2025-09-23 02:21:26.223970: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319157400 of size 50176 next 1304\n",
      "2025-09-23 02:21:26.223971: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319163800 of size 256 next 1305\n",
      "2025-09-23 02:21:26.223972: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319163900 of size 256 next 1306\n",
      "2025-09-23 02:21:26.223974: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319163a00 of size 256 next 1307\n",
      "2025-09-23 02:21:26.223975: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319163b00 of size 256 next 1308\n",
      "2025-09-23 02:21:26.223976: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319163c00 of size 256 next 1309\n",
      "2025-09-23 02:21:26.223977: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319163d00 of size 256 next 1310\n",
      "2025-09-23 02:21:26.223978: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319163e00 of size 256 next 1311\n",
      "2025-09-23 02:21:26.223980: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319163f00 of size 256 next 1312\n",
      "2025-09-23 02:21:26.223981: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319164000 of size 677376 next 1313\n",
      "2025-09-23 02:21:26.223983: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319209600 of size 677376 next 1314\n",
      "2025-09-23 02:21:26.223984: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13192aec00 of size 677376 next 1315\n",
      "2025-09-23 02:21:26.223985: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319354200 of size 677376 next 1316\n",
      "2025-09-23 02:21:26.223986: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13193f9800 of size 1536 next 1317\n",
      "2025-09-23 02:21:26.223988: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13193f9e00 of size 1536 next 1318\n",
      "2025-09-23 02:21:26.223989: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13193fa400 of size 1536 next 1319\n",
      "2025-09-23 02:21:26.223990: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13193faa00 of size 1536 next 1320\n",
      "2025-09-23 02:21:26.223992: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13193fb000 of size 1536 next 1321\n",
      "2025-09-23 02:21:26.223993: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13193fb600 of size 1536 next 1322\n",
      "2025-09-23 02:21:26.223994: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13193fbc00 of size 1536 next 1323\n",
      "2025-09-23 02:21:26.223996: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13193fc200 of size 1536 next 1324\n",
      "2025-09-23 02:21:26.223997: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13193fc800 of size 112896 next 1325\n",
      "2025-09-23 02:21:26.223998: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319418100 of size 112896 next 1326\n",
      "2025-09-23 02:21:26.223999: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319433a00 of size 512 next 1327\n",
      "2025-09-23 02:21:26.224001: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319433c00 of size 512 next 1328\n",
      "2025-09-23 02:21:26.224002: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319433e00 of size 112896 next 1329\n",
      "2025-09-23 02:21:26.224003: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131944f700 of size 112896 next 1330\n",
      "2025-09-23 02:21:26.224005: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131946b000 of size 512 next 1331\n",
      "2025-09-23 02:21:26.224006: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131946b200 of size 512 next 1332\n",
      "2025-09-23 02:21:26.224007: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131946b400 of size 112896 next 1333\n",
      "2025-09-23 02:21:26.224008: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319486d00 of size 112896 next 1334\n",
      "2025-09-23 02:21:26.224010: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13194a2600 of size 1536 next 1335\n",
      "2025-09-23 02:21:26.224011: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13194a2c00 of size 1536 next 1336\n",
      "2025-09-23 02:21:26.224012: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13194a3200 of size 112896 next 1337\n",
      "2025-09-23 02:21:26.224013: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13194beb00 of size 112896 next 1338\n",
      "2025-09-23 02:21:26.224015: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13194da400 of size 1536 next 1339\n",
      "2025-09-23 02:21:26.224016: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13194daa00 of size 1536 next 1340\n",
      "2025-09-23 02:21:26.224017: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13194db000 of size 107520 next 1341\n",
      "2025-09-23 02:21:26.224018: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13194f5400 of size 107520 next 1342\n",
      "2025-09-23 02:21:26.224020: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131950f800 of size 107520 next 1343\n",
      "2025-09-23 02:21:26.224021: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319529c00 of size 107520 next 1344\n",
      "2025-09-23 02:21:26.224022: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319544000 of size 512 next 1345\n",
      "2025-09-23 02:21:26.224023: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319544200 of size 512 next 1346\n",
      "2025-09-23 02:21:26.224024: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319544400 of size 512 next 1347\n",
      "2025-09-23 02:21:26.224026: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319544600 of size 512 next 1348\n",
      "2025-09-23 02:21:26.224029: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319544800 of size 512 next 1349\n",
      "2025-09-23 02:21:26.224030: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319544a00 of size 512 next 1350\n",
      "2025-09-23 02:21:26.224031: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319544c00 of size 512 next 1351\n",
      "2025-09-23 02:21:26.224033: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319544e00 of size 512 next 1352\n",
      "2025-09-23 02:21:26.224034: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319545000 of size 1382400 next 1353\n",
      "2025-09-23 02:21:26.224036: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319696800 of size 1480704 next 18446744073709551615\n",
      "2025-09-23 02:21:26.224044: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 33554432\n",
      "2025-09-23 02:21:26.224047: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319800000 of size 1382400 next 1355\n",
      "2025-09-23 02:21:26.224050: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319951800 of size 1382400 next 1356\n",
      "2025-09-23 02:21:26.224052: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319aa3000 of size 2048 next 1357\n",
      "2025-09-23 02:21:26.224054: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319aa3800 of size 2048 next 1358\n",
      "2025-09-23 02:21:26.224056: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319aa4000 of size 2048 next 1359\n",
      "2025-09-23 02:21:26.224057: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319aa4800 of size 2048 next 1360\n",
      "2025-09-23 02:21:26.224058: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319aa5000 of size 2048 next 1361\n",
      "2025-09-23 02:21:26.224060: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319aa5800 of size 2048 next 1362\n",
      "2025-09-23 02:21:26.224061: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319aa6000 of size 2048 next 1363\n",
      "2025-09-23 02:21:26.224062: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319aa6800 of size 2048 next 1364\n",
      "2025-09-23 02:21:26.224063: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319aa7000 of size 230400 next 1365\n",
      "2025-09-23 02:21:26.224065: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319adf400 of size 230400 next 1366\n",
      "2025-09-23 02:21:26.224066: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319b17800 of size 512 next 1367\n",
      "2025-09-23 02:21:26.224068: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319b17a00 of size 512 next 1368\n",
      "2025-09-23 02:21:26.224069: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319b17c00 of size 230400 next 1369\n",
      "2025-09-23 02:21:26.224071: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319b50000 of size 230400 next 1370\n",
      "2025-09-23 02:21:26.224072: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319b88400 of size 512 next 1371\n",
      "2025-09-23 02:21:26.224074: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319b88600 of size 512 next 1372\n",
      "2025-09-23 02:21:26.224075: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319b88800 of size 230400 next 1373\n",
      "2025-09-23 02:21:26.224076: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319bc0c00 of size 230400 next 1374\n",
      "2025-09-23 02:21:26.224077: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319bf9000 of size 2048 next 1375\n",
      "2025-09-23 02:21:26.224079: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319bf9800 of size 2048 next 1376\n",
      "2025-09-23 02:21:26.224080: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319bfa000 of size 230400 next 1377\n",
      "2025-09-23 02:21:26.224081: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319c32400 of size 230400 next 1378\n",
      "2025-09-23 02:21:26.224082: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319c6a800 of size 2048 next 1379\n",
      "2025-09-23 02:21:26.224083: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319c6b000 of size 2048 next 1380\n",
      "2025-09-23 02:21:26.224085: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319c6b800 of size 153600 next 1381\n",
      "2025-09-23 02:21:26.224090: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319c91000 of size 153600 next 1382\n",
      "2025-09-23 02:21:26.224100: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319cb6800 of size 153600 next 1383\n",
      "2025-09-23 02:21:26.224103: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319cdc000 of size 153600 next 1384\n",
      "2025-09-23 02:21:26.224105: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319d01800 of size 512 next 1385\n",
      "2025-09-23 02:21:26.224106: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319d01a00 of size 512 next 1386\n",
      "2025-09-23 02:21:26.224107: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319d01c00 of size 512 next 1387\n",
      "2025-09-23 02:21:26.224108: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319d01e00 of size 512 next 1388\n",
      "2025-09-23 02:21:26.224110: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319d02000 of size 512 next 1389\n",
      "2025-09-23 02:21:26.224111: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319d02200 of size 512 next 1390\n",
      "2025-09-23 02:21:26.224112: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319d02400 of size 512 next 1391\n",
      "2025-09-23 02:21:26.224113: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319d02600 of size 512 next 1392\n",
      "2025-09-23 02:21:26.224114: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319d02800 of size 1382400 next 1393\n",
      "2025-09-23 02:21:26.224116: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319e54000 of size 1382400 next 1394\n",
      "2025-09-23 02:21:26.224117: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1319fa5800 of size 1382400 next 1395\n",
      "2025-09-23 02:21:26.224118: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a0f7000 of size 1382400 next 1396\n",
      "2025-09-23 02:21:26.224119: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a248800 of size 2048 next 1397\n",
      "2025-09-23 02:21:26.224120: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a249000 of size 2048 next 1398\n",
      "2025-09-23 02:21:26.224122: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a249800 of size 2048 next 1399\n",
      "2025-09-23 02:21:26.224123: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a24a000 of size 2048 next 1400\n",
      "2025-09-23 02:21:26.224124: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a24a800 of size 2048 next 1401\n",
      "2025-09-23 02:21:26.224125: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a24b000 of size 2048 next 1402\n",
      "2025-09-23 02:21:26.224126: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a24b800 of size 2048 next 1403\n",
      "2025-09-23 02:21:26.224128: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a24c000 of size 2048 next 1404\n",
      "2025-09-23 02:21:26.224129: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a24c800 of size 230400 next 1405\n",
      "2025-09-23 02:21:26.224130: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a284c00 of size 230400 next 1406\n",
      "2025-09-23 02:21:26.224131: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a2bd000 of size 512 next 1407\n",
      "2025-09-23 02:21:26.224132: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a2bd200 of size 512 next 1408\n",
      "2025-09-23 02:21:26.224134: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a2bd400 of size 230400 next 1409\n",
      "2025-09-23 02:21:26.224135: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a2f5800 of size 230400 next 1410\n",
      "2025-09-23 02:21:26.224136: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a32dc00 of size 512 next 1411\n",
      "2025-09-23 02:21:26.224137: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a32de00 of size 512 next 1412\n",
      "2025-09-23 02:21:26.224138: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a32e000 of size 230400 next 1413\n",
      "2025-09-23 02:21:26.224140: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a366400 of size 230400 next 1414\n",
      "2025-09-23 02:21:26.224141: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a39e800 of size 2048 next 1415\n",
      "2025-09-23 02:21:26.224142: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a39f000 of size 2048 next 1416\n",
      "2025-09-23 02:21:26.224144: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a39f800 of size 230400 next 1417\n",
      "2025-09-23 02:21:26.224145: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a3d7c00 of size 230400 next 1418\n",
      "2025-09-23 02:21:26.224146: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a410000 of size 2048 next 1419\n",
      "2025-09-23 02:21:26.224147: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a410800 of size 2048 next 1420\n",
      "2025-09-23 02:21:26.224148: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a411000 of size 153600 next 1421\n",
      "2025-09-23 02:21:26.224150: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a436800 of size 153600 next 1422\n",
      "2025-09-23 02:21:26.224151: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a45c000 of size 153600 next 1423\n",
      "2025-09-23 02:21:26.224152: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a481800 of size 153600 next 1424\n",
      "2025-09-23 02:21:26.224153: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a4a7000 of size 512 next 1425\n",
      "2025-09-23 02:21:26.224154: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a4a7200 of size 512 next 1426\n",
      "2025-09-23 02:21:26.224156: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a4a7400 of size 512 next 1427\n",
      "2025-09-23 02:21:26.224157: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a4a7600 of size 512 next 1428\n",
      "2025-09-23 02:21:26.224158: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a4a7800 of size 512 next 1429\n",
      "2025-09-23 02:21:26.224159: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a4a7a00 of size 512 next 1430\n",
      "2025-09-23 02:21:26.224160: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a4a7c00 of size 512 next 1431\n",
      "2025-09-23 02:21:26.224161: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a4a7e00 of size 512 next 1432\n",
      "2025-09-23 02:21:26.224163: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a4a8000 of size 1382400 next 1433\n",
      "2025-09-23 02:21:26.224164: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a5f9800 of size 1382400 next 1434\n",
      "2025-09-23 02:21:26.224165: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a74b000 of size 1382400 next 1435\n",
      "2025-09-23 02:21:26.224166: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a89c800 of size 1382400 next 1436\n",
      "2025-09-23 02:21:26.224168: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a9ee000 of size 2048 next 1437\n",
      "2025-09-23 02:21:26.224169: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a9ee800 of size 2048 next 1438\n",
      "2025-09-23 02:21:26.224170: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a9ef000 of size 2048 next 1439\n",
      "2025-09-23 02:21:26.224171: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a9ef800 of size 2048 next 1440\n",
      "2025-09-23 02:21:26.224172: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a9f0000 of size 2048 next 1441\n",
      "2025-09-23 02:21:26.224174: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a9f0800 of size 2048 next 1442\n",
      "2025-09-23 02:21:26.224175: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a9f1000 of size 2048 next 1443\n",
      "2025-09-23 02:21:26.224176: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a9f1800 of size 2048 next 1444\n",
      "2025-09-23 02:21:26.224177: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131a9f2000 of size 230400 next 1445\n",
      "2025-09-23 02:21:26.224178: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aa2a400 of size 230400 next 1446\n",
      "2025-09-23 02:21:26.224181: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aa62800 of size 512 next 1447\n",
      "2025-09-23 02:21:26.224182: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aa62a00 of size 512 next 1448\n",
      "2025-09-23 02:21:26.224183: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aa62c00 of size 230400 next 1449\n",
      "2025-09-23 02:21:26.224184: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aa9b000 of size 230400 next 1450\n",
      "2025-09-23 02:21:26.224185: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aad3400 of size 512 next 1451\n",
      "2025-09-23 02:21:26.224187: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aad3600 of size 512 next 1452\n",
      "2025-09-23 02:21:26.224188: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aad3800 of size 230400 next 1453\n",
      "2025-09-23 02:21:26.224189: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ab0bc00 of size 230400 next 1454\n",
      "2025-09-23 02:21:26.224191: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ab44000 of size 2048 next 1455\n",
      "2025-09-23 02:21:26.224193: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ab44800 of size 2048 next 1456\n",
      "2025-09-23 02:21:26.224195: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ab45000 of size 230400 next 1457\n",
      "2025-09-23 02:21:26.224196: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ab7d400 of size 230400 next 1458\n",
      "2025-09-23 02:21:26.224198: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131abb5800 of size 2048 next 1459\n",
      "2025-09-23 02:21:26.224199: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131abb6000 of size 2048 next 1460\n",
      "2025-09-23 02:21:26.224200: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131abb6800 of size 153600 next 1461\n",
      "2025-09-23 02:21:26.224203: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131abdc000 of size 153600 next 1462\n",
      "2025-09-23 02:21:26.224204: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac01800 of size 153600 next 1463\n",
      "2025-09-23 02:21:26.224206: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac27000 of size 153600 next 1464\n",
      "2025-09-23 02:21:26.224207: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac4c800 of size 512 next 1465\n",
      "2025-09-23 02:21:26.224208: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac4ca00 of size 512 next 1466\n",
      "2025-09-23 02:21:26.224209: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac4cc00 of size 512 next 1467\n",
      "2025-09-23 02:21:26.224211: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac4ce00 of size 512 next 1468\n",
      "2025-09-23 02:21:26.224212: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac4d000 of size 512 next 1469\n",
      "2025-09-23 02:21:26.224213: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac4d200 of size 512 next 1470\n",
      "2025-09-23 02:21:26.224214: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac4d400 of size 512 next 1471\n",
      "2025-09-23 02:21:26.224216: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac4d600 of size 512 next 1472\n",
      "2025-09-23 02:21:26.224217: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac4d800 of size 51200 next 1473\n",
      "2025-09-23 02:21:26.224218: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac5a000 of size 51200 next 1474\n",
      "2025-09-23 02:21:26.224219: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac66800 of size 51200 next 1475\n",
      "2025-09-23 02:21:26.224221: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac73000 of size 51200 next 1476\n",
      "2025-09-23 02:21:26.224222: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac7f800 of size 768 next 1477\n",
      "2025-09-23 02:21:26.224223: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac7fb00 of size 768 next 1478\n",
      "2025-09-23 02:21:26.224225: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac7fe00 of size 768 next 1479\n",
      "2025-09-23 02:21:26.224226: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac80100 of size 768 next 1480\n",
      "2025-09-23 02:21:26.224227: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac80400 of size 768 next 1481\n",
      "2025-09-23 02:21:26.224229: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac80700 of size 768 next 1482\n",
      "2025-09-23 02:21:26.224230: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac80a00 of size 768 next 1483\n",
      "2025-09-23 02:21:26.224231: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac80d00 of size 768 next 1484\n",
      "2025-09-23 02:21:26.224232: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac81000 of size 5888 next 1485\n",
      "2025-09-23 02:21:26.224234: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac82700 of size 5888 next 1486\n",
      "2025-09-23 02:21:26.224235: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac83e00 of size 5888 next 1487\n",
      "2025-09-23 02:21:26.224244: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac85500 of size 5888 next 1488\n",
      "2025-09-23 02:21:26.224246: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac86c00 of size 768 next 1489\n",
      "2025-09-23 02:21:26.224248: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac86f00 of size 768 next 1490\n",
      "2025-09-23 02:21:26.224249: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac87200 of size 768 next 1491\n",
      "2025-09-23 02:21:26.224250: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac87500 of size 768 next 1492\n",
      "2025-09-23 02:21:26.224252: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac87800 of size 768 next 1493\n",
      "2025-09-23 02:21:26.224253: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac87b00 of size 768 next 1494\n",
      "2025-09-23 02:21:26.224254: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac87e00 of size 768 next 1495\n",
      "2025-09-23 02:21:26.224255: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac88100 of size 768 next 1496\n",
      "2025-09-23 02:21:26.224257: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac88400 of size 25600 next 1497\n",
      "2025-09-23 02:21:26.224258: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac8e800 of size 25600 next 1498\n",
      "2025-09-23 02:21:26.224260: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac94c00 of size 256 next 1499\n",
      "2025-09-23 02:21:26.224261: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac94d00 of size 256 next 1500\n",
      "2025-09-23 02:21:26.224262: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac94e00 of size 25600 next 1501\n",
      "2025-09-23 02:21:26.224263: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ac9b200 of size 25600 next 1502\n",
      "2025-09-23 02:21:26.224265: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aca1600 of size 256 next 1503\n",
      "2025-09-23 02:21:26.224266: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aca1700 of size 256 next 1504\n",
      "2025-09-23 02:21:26.224267: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aca1800 of size 25600 next 1505\n",
      "2025-09-23 02:21:26.224269: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aca7c00 of size 25600 next 1506\n",
      "2025-09-23 02:21:26.224270: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acae000 of size 768 next 1507\n",
      "2025-09-23 02:21:26.224271: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acae300 of size 768 next 1508\n",
      "2025-09-23 02:21:26.224272: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acae600 of size 25600 next 1509\n",
      "2025-09-23 02:21:26.224275: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acb4a00 of size 25600 next 1510\n",
      "2025-09-23 02:21:26.224277: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acbae00 of size 768 next 1511\n",
      "2025-09-23 02:21:26.224278: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acbb100 of size 768 next 1512\n",
      "2025-09-23 02:21:26.224279: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acbb400 of size 61440 next 1513\n",
      "2025-09-23 02:21:26.224281: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acca400 of size 61440 next 1514\n",
      "2025-09-23 02:21:26.224282: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acd9400 of size 61440 next 1515\n",
      "2025-09-23 02:21:26.224284: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ace8400 of size 61440 next 1516\n",
      "2025-09-23 02:21:26.224285: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acf7400 of size 512 next 1517\n",
      "2025-09-23 02:21:26.224286: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acf7600 of size 512 next 1518\n",
      "2025-09-23 02:21:26.224288: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acf7800 of size 512 next 1519\n",
      "2025-09-23 02:21:26.224289: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acf7a00 of size 512 next 1520\n",
      "2025-09-23 02:21:26.224290: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acf7c00 of size 512 next 1521\n",
      "2025-09-23 02:21:26.224291: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acf7e00 of size 512 next 1522\n",
      "2025-09-23 02:21:26.224293: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acf8000 of size 512 next 1523\n",
      "2025-09-23 02:21:26.224294: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acf8200 of size 512 next 1524\n",
      "2025-09-23 02:21:26.224295: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131acf8400 of size 73728 next 1525\n",
      "2025-09-23 02:21:26.224296: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad0a400 of size 73728 next 1526\n",
      "2025-09-23 02:21:26.224297: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad1c400 of size 73728 next 1527\n",
      "2025-09-23 02:21:26.224299: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad2e400 of size 73728 next 1528\n",
      "2025-09-23 02:21:26.224300: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad40400 of size 768 next 1529\n",
      "2025-09-23 02:21:26.224301: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad40700 of size 768 next 1530\n",
      "2025-09-23 02:21:26.224302: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad40a00 of size 768 next 1531\n",
      "2025-09-23 02:21:26.224304: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad40d00 of size 768 next 1532\n",
      "2025-09-23 02:21:26.224305: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad41000 of size 768 next 1533\n",
      "2025-09-23 02:21:26.224306: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad41300 of size 768 next 1534\n",
      "2025-09-23 02:21:26.224307: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad41600 of size 768 next 1535\n",
      "2025-09-23 02:21:26.224308: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad41900 of size 768 next 1536\n",
      "2025-09-23 02:21:26.224310: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad41c00 of size 6912 next 1537\n",
      "2025-09-23 02:21:26.224311: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad43700 of size 6912 next 1538\n",
      "2025-09-23 02:21:26.224312: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad45200 of size 6912 next 1539\n",
      "2025-09-23 02:21:26.224313: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad46d00 of size 6912 next 1540\n",
      "2025-09-23 02:21:26.224315: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad48800 of size 768 next 1541\n",
      "2025-09-23 02:21:26.224316: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad48b00 of size 768 next 1542\n",
      "2025-09-23 02:21:26.224317: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad48e00 of size 768 next 1543\n",
      "2025-09-23 02:21:26.224318: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad49100 of size 768 next 1544\n",
      "2025-09-23 02:21:26.224319: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad49400 of size 768 next 1545\n",
      "2025-09-23 02:21:26.224321: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad49700 of size 768 next 1546\n",
      "2025-09-23 02:21:26.224322: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad49a00 of size 768 next 1547\n",
      "2025-09-23 02:21:26.224323: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad49d00 of size 768 next 1548\n",
      "2025-09-23 02:21:26.224324: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad4a000 of size 36864 next 1549\n",
      "2025-09-23 02:21:26.224325: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad53000 of size 36864 next 1550\n",
      "2025-09-23 02:21:26.224327: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad5c000 of size 256 next 1551\n",
      "2025-09-23 02:21:26.224328: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad5c100 of size 256 next 1552\n",
      "2025-09-23 02:21:26.224329: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad5c200 of size 36864 next 1553\n",
      "2025-09-23 02:21:26.224330: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad65200 of size 36864 next 1554\n",
      "2025-09-23 02:21:26.224332: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad6e200 of size 256 next 1555\n",
      "2025-09-23 02:21:26.224333: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad6e300 of size 256 next 1556\n",
      "2025-09-23 02:21:26.224334: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad6e400 of size 36864 next 1557\n",
      "2025-09-23 02:21:26.224335: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad77400 of size 36864 next 1558\n",
      "2025-09-23 02:21:26.224337: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad80400 of size 768 next 1559\n",
      "2025-09-23 02:21:26.224338: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad80700 of size 768 next 1560\n",
      "2025-09-23 02:21:26.224339: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad80a00 of size 36864 next 1561\n",
      "2025-09-23 02:21:26.224341: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad89a00 of size 36864 next 1562\n",
      "2025-09-23 02:21:26.224342: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad92a00 of size 768 next 1563\n",
      "2025-09-23 02:21:26.224343: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad92d00 of size 768 next 1564\n",
      "2025-09-23 02:21:26.224344: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ad93000 of size 73728 next 1565\n",
      "2025-09-23 02:21:26.224346: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ada5000 of size 73728 next 1566\n",
      "2025-09-23 02:21:26.224347: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131adb7000 of size 73728 next 1567\n",
      "2025-09-23 02:21:26.224348: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131adc9000 of size 73728 next 1568\n",
      "2025-09-23 02:21:26.224349: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131addb000 of size 512 next 1569\n",
      "2025-09-23 02:21:26.224350: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131addb200 of size 512 next 1570\n",
      "2025-09-23 02:21:26.224352: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131addb400 of size 512 next 1571\n",
      "2025-09-23 02:21:26.224353: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131addb600 of size 512 next 1572\n",
      "2025-09-23 02:21:26.224354: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131addb800 of size 512 next 1573\n",
      "2025-09-23 02:21:26.224355: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131addba00 of size 512 next 1574\n",
      "2025-09-23 02:21:26.224357: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131addbc00 of size 512 next 1575\n",
      "2025-09-23 02:21:26.224358: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131addbe00 of size 512 next 1576\n",
      "2025-09-23 02:21:26.224359: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131addc000 of size 73728 next 1577\n",
      "2025-09-23 02:21:26.224360: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131adee000 of size 73728 next 1578\n",
      "2025-09-23 02:21:26.224361: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae00000 of size 73728 next 1579\n",
      "2025-09-23 02:21:26.224363: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae12000 of size 73728 next 1580\n",
      "2025-09-23 02:21:26.224364: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae24000 of size 768 next 1581\n",
      "2025-09-23 02:21:26.224365: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae24300 of size 768 next 1582\n",
      "2025-09-23 02:21:26.224366: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae24600 of size 768 next 1583\n",
      "2025-09-23 02:21:26.224368: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae24900 of size 768 next 1584\n",
      "2025-09-23 02:21:26.224369: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae24c00 of size 768 next 1585\n",
      "2025-09-23 02:21:26.224370: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae24f00 of size 768 next 1586\n",
      "2025-09-23 02:21:26.224371: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae25200 of size 768 next 1587\n",
      "2025-09-23 02:21:26.224373: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae25500 of size 768 next 1588\n",
      "2025-09-23 02:21:26.224374: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae25800 of size 6912 next 1589\n",
      "2025-09-23 02:21:26.224375: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae27300 of size 6912 next 1590\n",
      "2025-09-23 02:21:26.224376: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae28e00 of size 6912 next 1591\n",
      "2025-09-23 02:21:26.224378: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae2a900 of size 6912 next 1592\n",
      "2025-09-23 02:21:26.224379: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae2c400 of size 768 next 1593\n",
      "2025-09-23 02:21:26.224380: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae2c700 of size 768 next 1594\n",
      "2025-09-23 02:21:26.224381: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae2ca00 of size 768 next 1595\n",
      "2025-09-23 02:21:26.224382: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae2cd00 of size 768 next 1596\n",
      "2025-09-23 02:21:26.224384: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae2d000 of size 768 next 1597\n",
      "2025-09-23 02:21:26.224385: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae2d300 of size 768 next 1598\n",
      "2025-09-23 02:21:26.224386: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae2d600 of size 768 next 1599\n",
      "2025-09-23 02:21:26.224388: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae2d900 of size 768 next 1600\n",
      "2025-09-23 02:21:26.224389: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae2dc00 of size 36864 next 1601\n",
      "2025-09-23 02:21:26.224390: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae36c00 of size 36864 next 1602\n",
      "2025-09-23 02:21:26.224391: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae3fc00 of size 256 next 1603\n",
      "2025-09-23 02:21:26.224393: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae3fd00 of size 256 next 1604\n",
      "2025-09-23 02:21:26.224394: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae3fe00 of size 36864 next 1605\n",
      "2025-09-23 02:21:26.224395: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae48e00 of size 36864 next 1606\n",
      "2025-09-23 02:21:26.224397: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae51e00 of size 256 next 1607\n",
      "2025-09-23 02:21:26.224398: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae51f00 of size 256 next 1608\n",
      "2025-09-23 02:21:26.224401: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae52000 of size 36864 next 1609\n",
      "2025-09-23 02:21:26.224403: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae5b000 of size 36864 next 1610\n",
      "2025-09-23 02:21:26.224404: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae64000 of size 768 next 1611\n",
      "2025-09-23 02:21:26.224405: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae64300 of size 768 next 1612\n",
      "2025-09-23 02:21:26.224407: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae64600 of size 36864 next 1613\n",
      "2025-09-23 02:21:26.224408: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae6d600 of size 36864 next 1614\n",
      "2025-09-23 02:21:26.224409: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae76600 of size 768 next 1615\n",
      "2025-09-23 02:21:26.224410: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae76900 of size 768 next 1616\n",
      "2025-09-23 02:21:26.224412: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae76c00 of size 73728 next 1617\n",
      "2025-09-23 02:21:26.224413: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae88c00 of size 73728 next 1618\n",
      "2025-09-23 02:21:26.224414: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131ae9ac00 of size 73728 next 1619\n",
      "2025-09-23 02:21:26.224415: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aeacc00 of size 73728 next 1620\n",
      "2025-09-23 02:21:26.224416: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aebec00 of size 512 next 1621\n",
      "2025-09-23 02:21:26.224418: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aebee00 of size 512 next 1622\n",
      "2025-09-23 02:21:26.224419: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aebf000 of size 512 next 1623\n",
      "2025-09-23 02:21:26.224420: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aebf200 of size 512 next 1624\n",
      "2025-09-23 02:21:26.224421: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aebf400 of size 512 next 1625\n",
      "2025-09-23 02:21:26.224423: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aebf600 of size 512 next 1626\n",
      "2025-09-23 02:21:26.224424: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aebf800 of size 512 next 1627\n",
      "2025-09-23 02:21:26.224425: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aebfa00 of size 512 next 1628\n",
      "2025-09-23 02:21:26.224426: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aebfc00 of size 73728 next 1629\n",
      "2025-09-23 02:21:26.224427: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aed1c00 of size 73728 next 1630\n",
      "2025-09-23 02:21:26.224429: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aee3c00 of size 73728 next 1631\n",
      "2025-09-23 02:21:26.224430: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131aef5c00 of size 73728 next 1632\n",
      "2025-09-23 02:21:26.224431: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af07c00 of size 768 next 1633\n",
      "2025-09-23 02:21:26.224432: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af07f00 of size 768 next 1634\n",
      "2025-09-23 02:21:26.224434: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af08200 of size 768 next 1635\n",
      "2025-09-23 02:21:26.224435: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af08500 of size 768 next 1636\n",
      "2025-09-23 02:21:26.224436: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af08800 of size 768 next 1637\n",
      "2025-09-23 02:21:26.224438: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af08b00 of size 768 next 1638\n",
      "2025-09-23 02:21:26.224439: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af08e00 of size 768 next 1639\n",
      "2025-09-23 02:21:26.224440: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af09100 of size 768 next 1640\n",
      "2025-09-23 02:21:26.224442: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af09400 of size 6912 next 1641\n",
      "2025-09-23 02:21:26.224443: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af0af00 of size 6912 next 1642\n",
      "2025-09-23 02:21:26.224444: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af0ca00 of size 6912 next 1643\n",
      "2025-09-23 02:21:26.224445: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af0e500 of size 6912 next 1644\n",
      "2025-09-23 02:21:26.224447: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af10000 of size 768 next 1645\n",
      "2025-09-23 02:21:26.224448: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af10300 of size 768 next 1646\n",
      "2025-09-23 02:21:26.224449: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af10600 of size 768 next 1647\n",
      "2025-09-23 02:21:26.224450: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af10900 of size 768 next 1648\n",
      "2025-09-23 02:21:26.224451: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af10c00 of size 768 next 1649\n",
      "2025-09-23 02:21:26.224453: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af10f00 of size 768 next 1650\n",
      "2025-09-23 02:21:26.224454: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af11200 of size 768 next 1651\n",
      "2025-09-23 02:21:26.224455: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af11500 of size 768 next 1652\n",
      "2025-09-23 02:21:26.224456: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af11800 of size 36864 next 1653\n",
      "2025-09-23 02:21:26.224458: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af1a800 of size 36864 next 1654\n",
      "2025-09-23 02:21:26.224459: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af23800 of size 256 next 1655\n",
      "2025-09-23 02:21:26.224460: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af23900 of size 256 next 1656\n",
      "2025-09-23 02:21:26.224462: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af23a00 of size 36864 next 1657\n",
      "2025-09-23 02:21:26.224463: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af2ca00 of size 36864 next 1658\n",
      "2025-09-23 02:21:26.224464: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af35a00 of size 256 next 1659\n",
      "2025-09-23 02:21:26.224465: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af35b00 of size 256 next 1660\n",
      "2025-09-23 02:21:26.224467: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af35c00 of size 36864 next 1661\n",
      "2025-09-23 02:21:26.224468: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af3ec00 of size 36864 next 1662\n",
      "2025-09-23 02:21:26.224469: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af47c00 of size 768 next 1663\n",
      "2025-09-23 02:21:26.224470: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af47f00 of size 768 next 1664\n",
      "2025-09-23 02:21:26.224472: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af48200 of size 36864 next 1665\n",
      "2025-09-23 02:21:26.224473: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af51200 of size 36864 next 1666\n",
      "2025-09-23 02:21:26.224474: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af5a200 of size 768 next 1667\n",
      "2025-09-23 02:21:26.224475: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af5a500 of size 768 next 1668\n",
      "2025-09-23 02:21:26.224476: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af5a800 of size 73728 next 1669\n",
      "2025-09-23 02:21:26.224478: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af6c800 of size 73728 next 1670\n",
      "2025-09-23 02:21:26.224479: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af7e800 of size 73728 next 1671\n",
      "2025-09-23 02:21:26.224480: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131af90800 of size 73728 next 1672\n",
      "2025-09-23 02:21:26.224481: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afa2800 of size 512 next 1673\n",
      "2025-09-23 02:21:26.224483: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afa2a00 of size 512 next 1674\n",
      "2025-09-23 02:21:26.224484: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afa2c00 of size 512 next 1675\n",
      "2025-09-23 02:21:26.224485: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afa2e00 of size 512 next 1676\n",
      "2025-09-23 02:21:26.224486: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afa3000 of size 512 next 1677\n",
      "2025-09-23 02:21:26.224487: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afa3200 of size 512 next 1678\n",
      "2025-09-23 02:21:26.224489: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afa3400 of size 512 next 1679\n",
      "2025-09-23 02:21:26.224490: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afa3600 of size 512 next 1680\n",
      "2025-09-23 02:21:26.224491: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afa3800 of size 43008 next 1681\n",
      "2025-09-23 02:21:26.224493: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afae000 of size 43008 next 1682\n",
      "2025-09-23 02:21:26.224494: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afb8800 of size 43008 next 1683\n",
      "2025-09-23 02:21:26.224495: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afc3000 of size 43008 next 1684\n",
      "2025-09-23 02:21:26.224497: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afcd800 of size 512 next 1685\n",
      "2025-09-23 02:21:26.224505: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afcda00 of size 512 next 1686\n",
      "2025-09-23 02:21:26.224508: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afcdc00 of size 512 next 1687\n",
      "2025-09-23 02:21:26.224509: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afcde00 of size 512 next 1688\n",
      "2025-09-23 02:21:26.224510: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afce000 of size 512 next 1689\n",
      "2025-09-23 02:21:26.224512: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afce200 of size 512 next 1690\n",
      "2025-09-23 02:21:26.224513: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afce400 of size 512 next 1691\n",
      "2025-09-23 02:21:26.224514: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afce600 of size 512 next 1692\n",
      "2025-09-23 02:21:26.224516: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afce800 of size 57344 next 1693\n",
      "2025-09-23 02:21:26.224517: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afdc800 of size 57344 next 1694\n",
      "2025-09-23 02:21:26.224518: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afea800 of size 256 next 1695\n",
      "2025-09-23 02:21:26.224520: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afea900 of size 256 next 1696\n",
      "2025-09-23 02:21:26.224521: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afeaa00 of size 256 next 1697\n",
      "2025-09-23 02:21:26.224522: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afeab00 of size 256 next 1698\n",
      "2025-09-23 02:21:26.224523: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afeac00 of size 256 next 1699\n",
      "2025-09-23 02:21:26.224525: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afead00 of size 256 next 1700\n",
      "2025-09-23 02:21:26.224526: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afeae00 of size 3840 next 1701\n",
      "2025-09-23 02:21:26.224527: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afebd00 of size 3840 next 1702\n",
      "2025-09-23 02:21:26.224529: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afecc00 of size 256 next 1703\n",
      "2025-09-23 02:21:26.224530: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afecd00 of size 256 next 1704\n",
      "2025-09-23 02:21:26.224531: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afece00 of size 256 next 1705\n",
      "2025-09-23 02:21:26.224533: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afecf00 of size 256 next 1706\n",
      "2025-09-23 02:21:26.224534: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afed000 of size 256 next 1707\n",
      "2025-09-23 02:21:26.224535: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afed100 of size 256 next 1708\n",
      "2025-09-23 02:21:26.224536: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afed200 of size 256 next 1709\n",
      "2025-09-23 02:21:26.224538: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afed300 of size 256 next 1710\n",
      "2025-09-23 02:21:26.224539: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afed400 of size 256 next 1711\n",
      "2025-09-23 02:21:26.224540: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afed500 of size 256 next 1712\n",
      "2025-09-23 02:21:26.224541: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afed600 of size 256 next 1713\n",
      "2025-09-23 02:21:26.224542: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afed700 of size 256 next 1714\n",
      "2025-09-23 02:21:26.224544: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afed800 of size 256 next 1715\n",
      "2025-09-23 02:21:26.224545: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afed900 of size 256 next 1716\n",
      "2025-09-23 02:21:26.224546: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afeda00 of size 256 next 1717\n",
      "2025-09-23 02:21:26.224547: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afedb00 of size 256 next 1718\n",
      "2025-09-23 02:21:26.224548: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afedc00 of size 256 next 1719\n",
      "2025-09-23 02:21:26.224550: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afedd00 of size 256 next 1720\n",
      "2025-09-23 02:21:26.224551: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afede00 of size 256 next 1721\n",
      "2025-09-23 02:21:26.224552: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afedf00 of size 256 next 1722\n",
      "2025-09-23 02:21:26.224553: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afee000 of size 256 next 1723\n",
      "2025-09-23 02:21:26.224554: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afee100 of size 256 next 1724\n",
      "2025-09-23 02:21:26.224556: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afee200 of size 256 next 1725\n",
      "2025-09-23 02:21:26.224557: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afee300 of size 256 next 1726\n",
      "2025-09-23 02:21:26.224558: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afee400 of size 256 next 1727\n",
      "2025-09-23 02:21:26.224559: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afee500 of size 256 next 1728\n",
      "2025-09-23 02:21:26.224561: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afee600 of size 256 next 1729\n",
      "2025-09-23 02:21:26.224562: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afee700 of size 256 next 1730\n",
      "2025-09-23 02:21:26.224563: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afee800 of size 256 next 1731\n",
      "2025-09-23 02:21:26.224564: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afee900 of size 256 next 1732\n",
      "2025-09-23 02:21:26.224566: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afeea00 of size 256 next 2009\n",
      "2025-09-23 02:21:26.224567: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afeeb00 of size 512 next 2008\n",
      "2025-09-23 02:21:26.224568: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afeed00 of size 256 next 1733\n",
      "2025-09-23 02:21:26.224569: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131afeee00 of size 6741504 next 1974\n",
      "2025-09-23 02:21:26.224571: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b65cc00 of size 1024 next 2347\n",
      "2025-09-23 02:21:26.224573: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b65d000 of size 4096 next 1912\n",
      "2025-09-23 02:21:26.224574: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b65e000 of size 2048 next 654\n",
      "2025-09-23 02:21:26.224576: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b65e800 of size 36096 next 2232\n",
      "2025-09-23 02:21:26.224577: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b667500 of size 1024 next 1918\n",
      "2025-09-23 02:21:26.224578: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b667900 of size 1024 next 1776\n",
      "2025-09-23 02:21:26.224580: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b667d00 of size 1024 next 2467\n",
      "2025-09-23 02:21:26.224581: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b668100 of size 1024 next 1946\n",
      "2025-09-23 02:21:26.224582: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b668500 of size 1024 next 2291\n",
      "2025-09-23 02:21:26.224584: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b668900 of size 1024 next 741\n",
      "2025-09-23 02:21:26.224585: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b668d00 of size 1024 next 2282\n",
      "2025-09-23 02:21:26.224586: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b669100 of size 2048 next 1966\n",
      "2025-09-23 02:21:26.224588: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b669900 of size 49408 next 378\n",
      "2025-09-23 02:21:26.224589: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b675a00 of size 2048 next 2645\n",
      "2025-09-23 02:21:26.224590: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b676200 of size 1024 next 2415\n",
      "2025-09-23 02:21:26.224591: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b676600 of size 4096 next 2108\n",
      "2025-09-23 02:21:26.224592: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b677600 of size 1024 next 2189\n",
      "2025-09-23 02:21:26.224594: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b677a00 of size 36864 next 2242\n",
      "2025-09-23 02:21:26.224595: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b680a00 of size 2048 next 401\n",
      "2025-09-23 02:21:26.224597: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b681200 of size 46080 next 2081\n",
      "2025-09-23 02:21:26.224598: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b68c600 of size 1024 next 2040\n",
      "2025-09-23 02:21:26.224599: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b68ca00 of size 1024 next 2240\n",
      "2025-09-23 02:21:26.224600: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b68ce00 of size 55808 next 2437\n",
      "2025-09-23 02:21:26.224602: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b69a800 of size 512 next 2179\n",
      "2025-09-23 02:21:26.224603: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b69aa00 of size 256 next 2144\n",
      "2025-09-23 02:21:26.224604: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b69ab00 of size 256 next 1792\n",
      "2025-09-23 02:21:26.224605: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b69ac00 of size 256 next 2354\n",
      "2025-09-23 02:21:26.224607: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b69ad00 of size 256 next 2301\n",
      "2025-09-23 02:21:26.224608: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b69ae00 of size 76800 next 2097\n",
      "2025-09-23 02:21:26.224609: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ada00 of size 185600 next 2593\n",
      "2025-09-23 02:21:26.224611: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6daf00 of size 1536 next 2432\n",
      "2025-09-23 02:21:26.224612: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6db500 of size 768 next 2491\n",
      "2025-09-23 02:21:26.224614: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6db800 of size 256 next 1807\n",
      "2025-09-23 02:21:26.224615: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6db900 of size 256 next 2275\n",
      "2025-09-23 02:21:26.224616: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6dba00 of size 2560 next 2085\n",
      "2025-09-23 02:21:26.224617: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6dc400 of size 512 next 2726\n",
      "2025-09-23 02:21:26.224619: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6dc600 of size 27648 next 1887\n",
      "2025-09-23 02:21:26.224620: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6e3200 of size 1536 next 505\n",
      "2025-09-23 02:21:26.224621: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 131b6e3800 of size 256 next 2584\n",
      "2025-09-23 02:21:26.224623: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6e3900 of size 4352 next 520\n",
      "2025-09-23 02:21:26.224624: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6e4a00 of size 32256 next 1866\n",
      "2025-09-23 02:21:26.224627: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ec800 of size 768 next 2431\n",
      "2025-09-23 02:21:26.224628: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ecb00 of size 256 next 1851\n",
      "2025-09-23 02:21:26.224630: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ecc00 of size 256 next 2628\n",
      "2025-09-23 02:21:26.224631: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ecd00 of size 256 next 2360\n",
      "2025-09-23 02:21:26.224632: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ece00 of size 256 next 1876\n",
      "2025-09-23 02:21:26.224633: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ecf00 of size 256 next 1970\n",
      "2025-09-23 02:21:26.224635: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ed000 of size 256 next 2378\n",
      "2025-09-23 02:21:26.224636: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ed100 of size 256 next 2177\n",
      "2025-09-23 02:21:26.224637: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ed200 of size 256 next 2687\n",
      "2025-09-23 02:21:26.224638: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ed300 of size 256 next 1763\n",
      "2025-09-23 02:21:26.224640: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ed400 of size 256 next 2693\n",
      "2025-09-23 02:21:26.224641: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ed500 of size 256 next 559\n",
      "2025-09-23 02:21:26.224642: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ed600 of size 256 next 2186\n",
      "2025-09-23 02:21:26.224643: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ed700 of size 1024 next 2145\n",
      "2025-09-23 02:21:26.224645: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6edb00 of size 14336 next 2686\n",
      "2025-09-23 02:21:26.224646: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6f1300 of size 8192 next 2759\n",
      "2025-09-23 02:21:26.224648: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6f3300 of size 8704 next 2312\n",
      "2025-09-23 02:21:26.224649: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6f5500 of size 1024 next 1748\n",
      "2025-09-23 02:21:26.224650: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6f5900 of size 256 next 2070\n",
      "2025-09-23 02:21:26.224652: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6f5a00 of size 256 next 700\n",
      "2025-09-23 02:21:26.224653: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6f5b00 of size 256 next 2129\n",
      "2025-09-23 02:21:26.224654: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6f5c00 of size 256 next 131\n",
      "2025-09-23 02:21:26.224655: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 131b6f5d00 of size 256 next 2322\n",
      "2025-09-23 02:21:26.224657: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6f5e00 of size 512 next 1814\n",
      "2025-09-23 02:21:26.224658: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6f6000 of size 18432 next 2051\n",
      "2025-09-23 02:21:26.224660: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6fa800 of size 18432 next 2460\n",
      "2025-09-23 02:21:26.224661: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ff000 of size 256 next 2735\n",
      "2025-09-23 02:21:26.224662: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ff100 of size 256 next 1975\n",
      "2025-09-23 02:21:26.224664: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b6ff200 of size 149248 next 2258\n",
      "2025-09-23 02:21:26.224667: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b723900 of size 1024 next 1756\n",
      "2025-09-23 02:21:26.224668: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b723d00 of size 256 next 1969\n",
      "2025-09-23 02:21:26.224669: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b723e00 of size 256 next 2048\n",
      "2025-09-23 02:21:26.224671: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b723f00 of size 256 next 2207\n",
      "2025-09-23 02:21:26.224672: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b724000 of size 256 next 2025\n",
      "2025-09-23 02:21:26.224681: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b724100 of size 256 next 2259\n",
      "2025-09-23 02:21:26.224684: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b724200 of size 256 next 613\n",
      "2025-09-23 02:21:26.224686: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b724300 of size 256 next 2010\n",
      "2025-09-23 02:21:26.224688: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b724400 of size 256 next 1881\n",
      "2025-09-23 02:21:26.224690: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b724500 of size 85760 next 2406\n",
      "2025-09-23 02:21:26.224692: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 131b739400 of size 512 next 2440\n",
      "2025-09-23 02:21:26.224693: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b739600 of size 4096 next 1865\n",
      "2025-09-23 02:21:26.224694: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b73a600 of size 2048 next 2429\n",
      "2025-09-23 02:21:26.224696: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b73ae00 of size 97792 next 2136\n",
      "2025-09-23 02:21:26.224697: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b752c00 of size 512 next 608\n",
      "2025-09-23 02:21:26.224698: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b752e00 of size 338688 next 2485\n",
      "2025-09-23 02:21:26.224702: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b7a5900 of size 115200 next 2335\n",
      "2025-09-23 02:21:26.224703: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b7c1b00 of size 36864 next 2418\n",
      "2025-09-23 02:21:26.224705: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b7cab00 of size 12800 next 1827\n",
      "2025-09-23 02:21:26.224713: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b7cdd00 of size 36864 next 1886\n",
      "2025-09-23 02:21:26.224716: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b7d6d00 of size 168704 next 18446744073709551615\n",
      "2025-09-23 02:21:26.224719: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 67108864\n",
      "2025-09-23 02:21:26.224721: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131b800000 of size 7175424 next 2531\n",
      "2025-09-23 02:21:26.224722: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bed7d00 of size 1024 next 1780\n",
      "2025-09-23 02:21:26.224724: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bed8100 of size 69888 next 2464\n",
      "2025-09-23 02:21:26.224725: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bee9200 of size 1024 next 1738\n",
      "2025-09-23 02:21:26.224727: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bee9600 of size 1024 next 2263\n",
      "2025-09-23 02:21:26.224728: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bee9a00 of size 1024 next 2521\n",
      "2025-09-23 02:21:26.224729: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bee9e00 of size 256 next 2178\n",
      "2025-09-23 02:21:26.224731: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bee9f00 of size 256 next 2124\n",
      "2025-09-23 02:21:26.224732: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131beea000 of size 256 next 2361\n",
      "2025-09-23 02:21:26.224733: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131beea100 of size 256 next 2044\n",
      "2025-09-23 02:21:26.224734: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131beea200 of size 131072 next 2678\n",
      "2025-09-23 02:21:26.224736: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf0a200 of size 256 next 2524\n",
      "2025-09-23 02:21:26.224737: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf0a300 of size 256 next 2018\n",
      "2025-09-23 02:21:26.224738: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf0a400 of size 1024 next 1920\n",
      "2025-09-23 02:21:26.224739: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf0a800 of size 102400 next 2363\n",
      "2025-09-23 02:21:26.224741: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf23800 of size 256 next 2359\n",
      "2025-09-23 02:21:26.224742: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf23900 of size 256 next 1794\n",
      "2025-09-23 02:21:26.224744: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf23a00 of size 76800 next 2772\n",
      "2025-09-23 02:21:26.224745: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf36600 of size 181248 next 2649\n",
      "2025-09-23 02:21:26.224746: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf62a00 of size 768 next 2542\n",
      "2025-09-23 02:21:26.224748: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf62d00 of size 256 next 2302\n",
      "2025-09-23 02:21:26.224749: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf62e00 of size 256 next 1940\n",
      "2025-09-23 02:21:26.224750: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf62f00 of size 32512 next 2715\n",
      "2025-09-23 02:21:26.224751: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf6ae00 of size 768 next 605\n",
      "2025-09-23 02:21:26.224753: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf6b100 of size 35840 next 2202\n",
      "2025-09-23 02:21:26.224754: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf73d00 of size 1024 next 2196\n",
      "2025-09-23 02:21:26.224756: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf74100 of size 40960 next 2103\n",
      "2025-09-23 02:21:26.224757: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf7e100 of size 256 next 2317\n",
      "2025-09-23 02:21:26.224758: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf7e200 of size 256 next 2519\n",
      "2025-09-23 02:21:26.224760: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131bf7e300 of size 6422528 next 1754\n",
      "2025-09-23 02:21:26.224761: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131c59e300 of size 6422528 next 2002\n",
      "2025-09-23 02:21:26.224762: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131cbbe300 of size 6422528 next 2350\n",
      "2025-09-23 02:21:26.224763: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131d1de300 of size 7393536 next 2000\n",
      "2025-09-23 02:21:26.224765: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131d8eb400 of size 256 next 2001\n",
      "2025-09-23 02:21:26.224766: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131d8eb500 of size 4608 next 2095\n",
      "2025-09-23 02:21:26.224767: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131d8ec700 of size 256 next 42\n",
      "2025-09-23 02:21:26.224769: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131d8ec800 of size 6144 next 2132\n",
      "2025-09-23 02:21:26.224770: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131d8ee000 of size 256 next 2139\n",
      "2025-09-23 02:21:26.224771: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131d8ee100 of size 3840 next 1890\n",
      "2025-09-23 02:21:26.224773: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131d8ef000 of size 1024 next 2658\n",
      "2025-09-23 02:21:26.224774: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131d8ef400 of size 615424 next 2699\n",
      "2025-09-23 02:21:26.224775: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131d985800 of size 512 next 2685\n",
      "2025-09-23 02:21:26.224777: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131d985a00 of size 768 next 2569\n",
      "2025-09-23 02:21:26.224778: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131d985d00 of size 6422528 next 1898\n",
      "2025-09-23 02:21:26.224780: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131dfa5d00 of size 25535232 next 18446744073709551615\n",
      "2025-09-23 02:21:26.224781: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 134217728\n",
      "2025-09-23 02:21:26.224782: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 131f800000 of size 256 next 2022\n",
      "2025-09-23 02:21:26.224784: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131f800100 of size 512 next 2024\n",
      "2025-09-23 02:21:26.224785: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131f800300 of size 256 next 2004\n",
      "2025-09-23 02:21:26.224786: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 131f800400 of size 12845056 next 2257\n",
      "2025-09-23 02:21:26.224788: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1320440400 of size 12845056 next 2436\n",
      "2025-09-23 02:21:26.224789: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1321080400 of size 12845056 next 1878\n",
      "2025-09-23 02:21:26.224791: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1321cc0400 of size 12845056 next 2568\n",
      "2025-09-23 02:21:26.224792: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1322900400 of size 12845056 next 2554\n",
      "2025-09-23 02:21:26.224793: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1323540400 of size 12845056 next 2278\n",
      "2025-09-23 02:21:26.224794: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1324180400 of size 6422528 next 2306\n",
      "2025-09-23 02:21:26.224796: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13247a0400 of size 19267584 next 2725\n",
      "2025-09-23 02:21:26.224797: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1325a00400 of size 6422528 next 2723\n",
      "2025-09-23 02:21:26.224798: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1326020400 of size 25033728 next 18446744073709551615\n",
      "2025-09-23 02:21:26.224799: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 268435456\n",
      "2025-09-23 02:21:26.224801: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1329200000 of size 25690112 next 2561\n",
      "2025-09-23 02:21:26.224802: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 132aa80000 of size 25690112 next 2107\n",
      "2025-09-23 02:21:26.224803: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 132c300000 of size 25690112 next 2761\n",
      "2025-09-23 02:21:26.224805: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 132db80000 of size 12845056 next 2079\n",
      "2025-09-23 02:21:26.224806: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 132e7c0000 of size 12845056 next 2102\n",
      "2025-09-23 02:21:26.224807: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 132f400000 of size 6422528 next 1741\n",
      "2025-09-23 02:21:26.224808: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 132fa20000 of size 19267584 next 2382\n",
      "2025-09-23 02:21:26.224810: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1330c80000 of size 6422528 next 2441\n",
      "2025-09-23 02:21:26.224811: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13312a0000 of size 25690112 next 2274\n",
      "2025-09-23 02:21:26.224812: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1332b20000 of size 25690112 next 2700\n",
      "2025-09-23 02:21:26.224813: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13343a0000 of size 25690112 next 2670\n",
      "2025-09-23 02:21:26.224815: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1335c20000 of size 25690112 next 2580\n",
      "2025-09-23 02:21:26.224816: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13374a0000 of size 30801920 next 18446744073709551615\n",
      "2025-09-23 02:21:26.224817: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 536870912\n",
      "2025-09-23 02:21:26.224818: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1339200000 of size 25690112 next 1938\n",
      "2025-09-23 02:21:26.224820: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 133aa80000 of size 25690112 next 2222\n",
      "2025-09-23 02:21:26.224821: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 133c300000 of size 25690112 next 1993\n",
      "2025-09-23 02:21:26.224822: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 133db80000 of size 25690112 next 2261\n",
      "2025-09-23 02:21:26.224823: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 133f400000 of size 25690112 next 1951\n",
      "2025-09-23 02:21:26.224825: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1340c80000 of size 25690112 next 2148\n",
      "2025-09-23 02:21:26.224826: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1342500000 of size 25690112 next 1818\n",
      "2025-09-23 02:21:26.224827: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1343d80000 of size 25690112 next 1950\n",
      "2025-09-23 02:21:26.224828: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1345600000 of size 25690112 next 542\n",
      "2025-09-23 02:21:26.224830: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1346e80000 of size 25690112 next 2233\n",
      "2025-09-23 02:21:26.224831: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1348700000 of size 12845056 next 2204\n",
      "2025-09-23 02:21:26.224832: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1349340000 of size 12845056 next 2625\n",
      "2025-09-23 02:21:26.224833: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1349f80000 of size 12845056 next 1955\n",
      "2025-09-23 02:21:26.224835: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 134abc0000 of size 6422528 next 2484\n",
      "2025-09-23 02:21:26.224836: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 134b1e0000 of size 19267584 next 1808\n",
      "2025-09-23 02:21:26.224837: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 134c440000 of size 6422528 next 2497\n",
      "2025-09-23 02:21:26.224838: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 134ca60000 of size 25690112 next 2224\n",
      "2025-09-23 02:21:26.224840: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 134e2e0000 of size 25690112 next 2117\n",
      "2025-09-23 02:21:26.224841: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 134fb60000 of size 25690112 next 2716\n",
      "2025-09-23 02:21:26.224842: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13513e0000 of size 25690112 next 2181\n",
      "2025-09-23 02:21:26.224843: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1352c60000 of size 25690112 next 2750\n",
      "2025-09-23 02:21:26.224844: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13544e0000 of size 25690112 next 2617\n",
      "2025-09-23 02:21:26.224846: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1355d60000 of size 25690112 next 2596\n",
      "2025-09-23 02:21:26.224847: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13575e0000 of size 29491200 next 18446744073709551615\n",
      "2025-09-23 02:21:26.224848: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 1073741824\n",
      "2025-09-23 02:21:26.224850: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1359200000 of size 89915392 next 2546\n",
      "2025-09-23 02:21:26.224851: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 135e7c0000 of size 89915392 next 2458\n",
      "2025-09-23 02:21:26.224852: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1363d80000 of size 89915392 next 2527\n",
      "2025-09-23 02:21:26.224855: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1369340000 of size 89915392 next 1832\n",
      "2025-09-23 02:21:26.224857: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 136e900000 of size 89915392 next 2614\n",
      "2025-09-23 02:21:26.224858: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1373ec0000 of size 89915392 next 726\n",
      "2025-09-23 02:21:26.224859: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1379480000 of size 89915392 next 2221\n",
      "2025-09-23 02:21:26.224861: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 137ea40000 of size 89915392 next 2666\n",
      "2025-09-23 02:21:26.224862: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1384000000 of size 89915392 next 2463\n",
      "2025-09-23 02:21:26.224863: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13895c0000 of size 89915392 next 2020\n",
      "2025-09-23 02:21:26.224864: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 138eb80000 of size 174587904 next 18446744073709551615\n",
      "2025-09-23 02:21:26.224866: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 2147483648\n",
      "2025-09-23 02:21:26.224867: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1399200000 of size 192675840 next 1994\n",
      "2025-09-23 02:21:26.224869: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13a49c0000 of size 16056320 next 2690\n",
      "2025-09-23 02:21:26.224870: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13a5910000 of size 64225280 next 1813\n",
      "2025-09-23 02:21:26.224871: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13a9650000 of size 64225280 next 1864\n",
      "2025-09-23 02:21:26.224873: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13ad390000 of size 768 next 2623\n",
      "2025-09-23 02:21:26.224874: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13ad390300 of size 768 next 2368\n",
      "2025-09-23 02:21:26.224876: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13ad390600 of size 768 next 2342\n",
      "2025-09-23 02:21:26.224884: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13ad390900 of size 768 next 309\n",
      "2025-09-23 02:21:26.224887: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13ad390c00 of size 64225280 next 2435\n",
      "2025-09-23 02:21:26.224889: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13b10d0c00 of size 768 next 2094\n",
      "2025-09-23 02:21:26.224891: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13b10d0f00 of size 768 next 2203\n",
      "2025-09-23 02:21:26.224892: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13b10d1200 of size 768 next 2604\n",
      "2025-09-23 02:21:26.224894: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13b10d1500 of size 768 next 2620\n",
      "2025-09-23 02:21:26.224895: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13b10d1800 of size 64225280 next 2654\n",
      "2025-09-23 02:21:26.224896: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13b4e11800 of size 64225280 next 2711\n",
      "2025-09-23 02:21:26.224898: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13b8b51800 of size 64225280 next 1797\n",
      "2025-09-23 02:21:26.224899: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13bc891800 of size 64225280 next 2086\n",
      "2025-09-23 02:21:26.224900: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13c05d1800 of size 64225280 next 2507\n",
      "2025-09-23 02:21:26.224902: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13c4311800 of size 64225280 next 2426\n",
      "2025-09-23 02:21:26.224903: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13c8051800 of size 768 next 2769\n",
      "2025-09-23 02:21:26.224904: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13c8051b00 of size 768 next 2559\n",
      "2025-09-23 02:21:26.224906: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13c8051e00 of size 768 next 2062\n",
      "2025-09-23 02:21:26.224907: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13c8052100 of size 768 next 2270\n",
      "2025-09-23 02:21:26.224910: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13c8052400 of size 64225280 next 2141\n",
      "2025-09-23 02:21:26.224911: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13cbd92400 of size 64225280 next 2534\n",
      "2025-09-23 02:21:26.224913: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13cfad2400 of size 5120 next 1899\n",
      "2025-09-23 02:21:26.224921: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13cfad3800 of size 5120 next 2305\n",
      "2025-09-23 02:21:26.224924: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13cfad4c00 of size 1280 next 2775\n",
      "2025-09-23 02:21:26.224927: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13cfad5100 of size 1280 next 2413\n",
      "2025-09-23 02:21:26.224929: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13cfad5600 of size 5120 next 1971\n",
      "2025-09-23 02:21:26.224930: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13cfad6a00 of size 5120 next 2655\n",
      "2025-09-23 02:21:26.224932: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13cfad7e00 of size 64225280 next 2180\n",
      "2025-09-23 02:21:26.224933: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13d3817e00 of size 64225280 next 2443\n",
      "2025-09-23 02:21:26.224935: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13d7557e00 of size 38535168 next 478\n",
      "2025-09-23 02:21:26.224937: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13d9a17e00 of size 38535168 next 1812\n",
      "2025-09-23 02:21:26.224938: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13dbed7e00 of size 38535168 next 2746\n",
      "2025-09-23 02:21:26.224939: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13de397e00 of size 38535168 next 2762\n",
      "2025-09-23 02:21:26.224941: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e0857e00 of size 512 next 1791\n",
      "2025-09-23 02:21:26.224942: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e0858000 of size 512 next 2311\n",
      "2025-09-23 02:21:26.224944: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e0858200 of size 512 next 757\n",
      "2025-09-23 02:21:26.224945: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e0858400 of size 19267584 next 1821\n",
      "2025-09-23 02:21:26.224947: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1ab8400 of size 768 next 1976\n",
      "2025-09-23 02:21:26.224948: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1ab8700 of size 768 next 2193\n",
      "2025-09-23 02:21:26.224949: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1ab8a00 of size 768 next 119\n",
      "2025-09-23 02:21:26.224951: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1ab8d00 of size 768 next 2452\n",
      "2025-09-23 02:21:26.224952: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1ab9000 of size 768 next 2455\n",
      "2025-09-23 02:21:26.224953: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1ab9300 of size 768 next 2271\n",
      "2025-09-23 02:21:26.224954: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1ab9600 of size 768 next 641\n",
      "2025-09-23 02:21:26.224956: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1ab9900 of size 768 next 1804\n",
      "2025-09-23 02:21:26.224957: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1ab9c00 of size 768 next 2376\n",
      "2025-09-23 02:21:26.224958: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1ab9f00 of size 768 next 1873\n",
      "2025-09-23 02:21:26.224959: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1aba200 of size 768 next 2626\n",
      "2025-09-23 02:21:26.224961: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1aba500 of size 6144 next 1883\n",
      "2025-09-23 02:21:26.224962: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1abbd00 of size 6144 next 1985\n",
      "2025-09-23 02:21:26.224963: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1abd500 of size 1536 next 2457\n",
      "2025-09-23 02:21:26.224965: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1abdb00 of size 1536 next 2066\n",
      "2025-09-23 02:21:26.224966: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1abe100 of size 6144 next 2112\n",
      "2025-09-23 02:21:26.224967: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1abf900 of size 6144 next 2098\n",
      "2025-09-23 02:21:26.224968: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e1ac1100 of size 57766656 next 2269\n",
      "2025-09-23 02:21:26.224970: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e51d8400 of size 19267584 next 2256\n",
      "2025-09-23 02:21:26.224971: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13e6438400 of size 77070336 next 2722\n",
      "2025-09-23 02:21:26.224972: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13eadb8400 of size 77070336 next 2741\n",
      "2025-09-23 02:21:26.224973: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13ef738400 of size 77070336 next 428\n",
      "2025-09-23 02:21:26.224975: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13f40b8400 of size 77070336 next 1863\n",
      "2025-09-23 02:21:26.224976: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13f8a38400 of size 77070336 next 2755\n",
      "2025-09-23 02:21:26.224977: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 13fd3b8400 of size 77070336 next 2636\n",
      "2025-09-23 02:21:26.224978: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1401d38400 of size 77070336 next 2745\n",
      "2025-09-23 02:21:26.224979: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14066b8400 of size 77070336 next 2220\n",
      "2025-09-23 02:21:26.224981: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 140b038400 of size 77070336 next 2592\n",
      "2025-09-23 02:21:26.224982: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 140f9b8400 of size 77070336 next 2023\n",
      "2025-09-23 02:21:26.224984: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1414338400 of size 82607104 next 18446744073709551615\n",
      "2025-09-23 02:21:26.224985: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 4294967296\n",
      "2025-09-23 02:21:26.224987: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1419200000 of size 25690112 next 231\n",
      "2025-09-23 02:21:26.224988: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 141aa80000 of size 25690112 next 2768\n",
      "2025-09-23 02:21:26.224990: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 141c300000 of size 25690112 next 2012\n",
      "2025-09-23 02:21:26.224991: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 141db80000 of size 25690112 next 2039\n",
      "2025-09-23 02:21:26.224992: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 141f400000 of size 25690112 next 1745\n",
      "2025-09-23 02:21:26.224994: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1420c80000 of size 25690112 next 1923\n",
      "2025-09-23 02:21:26.224995: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1422500000 of size 25690112 next 498\n",
      "2025-09-23 02:21:26.224996: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1423d80000 of size 12845056 next 2395\n",
      "2025-09-23 02:21:26.224997: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14249c0000 of size 12845056 next 2346\n",
      "2025-09-23 02:21:26.224999: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1425600000 of size 12845056 next 2126\n",
      "2025-09-23 02:21:26.225000: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1426240000 of size 6422528 next 105\n",
      "2025-09-23 02:21:26.225001: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1426860000 of size 19267584 next 554\n",
      "2025-09-23 02:21:26.225003: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1427ac0000 of size 6422528 next 1744\n",
      "2025-09-23 02:21:26.225004: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14280e0000 of size 25690112 next 710\n",
      "2025-09-23 02:21:26.225005: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1429960000 of size 28901888 next 2694\n",
      "2025-09-23 02:21:26.225014: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 142b4f0200 of size 4096 next 349\n",
      "2025-09-23 02:21:26.225017: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 142b4f1200 of size 4096 next 2213\n",
      "2025-09-23 02:21:26.225018: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 142b4f2200 of size 4096 next 2122\n",
      "2025-09-23 02:21:26.225020: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 142b4f3200 of size 32112640 next 1859\n",
      "2025-09-23 02:21:26.225021: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 142d393200 of size 32112640 next 2279\n",
      "2025-09-23 02:21:26.225022: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 142f233200 of size 32112640 next 2574\n",
      "2025-09-23 02:21:26.225024: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14310d3200 of size 512 next 1783\n",
      "2025-09-23 02:21:26.225025: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14310d3400 of size 16056320 next 2244\n",
      "2025-09-23 02:21:26.225027: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1432023400 of size 2048 next 626\n",
      "2025-09-23 02:21:26.225028: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1432023c00 of size 2048 next 2386\n",
      "2025-09-23 02:21:26.225029: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1432024400 of size 2048 next 2260\n",
      "2025-09-23 02:21:26.225031: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1432024c00 of size 2048 next 2355\n",
      "2025-09-23 02:21:26.225032: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1432025400 of size 2048 next 2191\n",
      "2025-09-23 02:21:26.225033: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1432025c00 of size 2048 next 2506\n",
      "2025-09-23 02:21:26.225035: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1432026400 of size 2048 next 1735\n",
      "2025-09-23 02:21:26.225036: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1432026c00 of size 2048 next 551\n",
      "2025-09-23 02:21:26.225037: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1432027400 of size 15360 next 2538\n",
      "2025-09-23 02:21:26.225039: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 143202b000 of size 15360 next 2740\n",
      "2025-09-23 02:21:26.225040: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 143202ec00 of size 3840 next 2490\n",
      "2025-09-23 02:21:26.225041: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 143202fb00 of size 3840 next 2147\n",
      "2025-09-23 02:21:26.225042: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1432030a00 of size 15360 next 1907\n",
      "2025-09-23 02:21:26.225044: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1432034600 of size 15360 next 2424\n",
      "2025-09-23 02:21:26.225045: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1432038200 of size 48083456 next 561\n",
      "2025-09-23 02:21:26.225047: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1434e13400 of size 16056320 next 2703\n",
      "2025-09-23 02:21:26.225048: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1435d63400 of size 192675840 next 2227\n",
      "2025-09-23 02:21:26.225050: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1441523400 of size 192675840 next 2206\n",
      "2025-09-23 02:21:26.225051: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 144cce3400 of size 192675840 next 2249\n",
      "2025-09-23 02:21:26.225052: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14584a3400 of size 192675840 next 2453\n",
      "2025-09-23 02:21:26.225054: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1463c63400 of size 192675840 next 2736\n",
      "2025-09-23 02:21:26.225055: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146f423400 of size 192675840 next 2078\n",
      "2025-09-23 02:21:26.225056: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 147abe3400 of size 192675840 next 2037\n",
      "2025-09-23 02:21:26.225058: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14863a3400 of size 32112640 next 2428\n",
      "2025-09-23 02:21:26.225059: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1488243400 of size 32112640 next 2734\n",
      "2025-09-23 02:21:26.225060: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148a0e3400 of size 32112640 next 1905\n",
      "2025-09-23 02:21:26.225061: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148bf83400 of size 512 next 2047\n",
      "2025-09-23 02:21:26.225063: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148bf83600 of size 16056320 next 2370\n",
      "2025-09-23 02:21:26.225064: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148ced3600 of size 2048 next 1820\n",
      "2025-09-23 02:21:26.225065: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148ced3e00 of size 2048 next 2034\n",
      "2025-09-23 02:21:26.225066: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148ced4600 of size 2048 next 2118\n",
      "2025-09-23 02:21:26.225068: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148ced4e00 of size 2048 next 2513\n",
      "2025-09-23 02:21:26.225069: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148ced5600 of size 2048 next 2237\n",
      "2025-09-23 02:21:26.225070: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148ced5e00 of size 2048 next 1854\n",
      "2025-09-23 02:21:26.225071: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148ced6600 of size 2048 next 1945\n",
      "2025-09-23 02:21:26.225072: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148ced6e00 of size 2048 next 2576\n",
      "2025-09-23 02:21:26.225074: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148ced7600 of size 15360 next 2622\n",
      "2025-09-23 02:21:26.225075: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148cedb200 of size 15360 next 569\n",
      "2025-09-23 02:21:26.225076: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148cedee00 of size 3840 next 185\n",
      "2025-09-23 02:21:26.225078: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148cedfd00 of size 3840 next 2343\n",
      "2025-09-23 02:21:26.225079: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148cee0c00 of size 3840 next 2528\n",
      "2025-09-23 02:21:26.225080: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148cee1b00 of size 15360 next 1871\n",
      "2025-09-23 02:21:26.225081: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148cee5700 of size 15360 next 1752\n",
      "2025-09-23 02:21:26.225083: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148cee9300 of size 32112640 next 2029\n",
      "2025-09-23 02:21:26.225084: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 148ed89300 of size 48070912 next 2508\n",
      "2025-09-23 02:21:26.225085: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1491b61400 of size 4096 next 2533\n",
      "2025-09-23 02:21:26.225087: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1491b62400 of size 4096 next 1998\n",
      "2025-09-23 02:21:26.225088: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1491b63400 of size 192675840 next 2500\n",
      "2025-09-23 02:21:26.225089: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 149d323400 of size 16056320 next 2479\n",
      "2025-09-23 02:21:26.225090: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 149e273400 of size 192675840 next 2121\n",
      "2025-09-23 02:21:26.225092: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14a9a33400 of size 192675840 next 2647\n",
      "2025-09-23 02:21:26.225093: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14b51f3400 of size 192675840 next 1852\n",
      "2025-09-23 02:21:26.225094: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14c09b3400 of size 192675840 next 90\n",
      "2025-09-23 02:21:26.225096: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14cc173400 of size 192675840 next 2352\n",
      "2025-09-23 02:21:26.225097: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14d7933400 of size 192675840 next 2231\n",
      "2025-09-23 02:21:26.225098: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14e30f3400 of size 192675840 next 2621\n",
      "2025-09-23 02:21:26.225099: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14ee8b3400 of size 32112640 next 2389\n",
      "2025-09-23 02:21:26.225100: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f0753400 of size 32112640 next 1919\n",
      "2025-09-23 02:21:26.225102: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f25f3400 of size 512 next 2074\n",
      "2025-09-23 02:21:26.225103: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f25f3600 of size 16056320 next 2243\n",
      "2025-09-23 02:21:26.225104: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f3543600 of size 80269312 next 2585\n",
      "2025-09-23 02:21:26.225106: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d0600 of size 768 next 2149\n",
      "2025-09-23 02:21:26.225107: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d0900 of size 256 next 705\n",
      "2025-09-23 02:21:26.225108: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d0a00 of size 256 next 417\n",
      "2025-09-23 02:21:26.225110: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d0b00 of size 256 next 2691\n",
      "2025-09-23 02:21:26.225111: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d0c00 of size 256 next 2563\n",
      "2025-09-23 02:21:26.225112: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d0d00 of size 256 next 2639\n",
      "2025-09-23 02:21:26.225114: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d0e00 of size 256 next 2294\n",
      "2025-09-23 02:21:26.225115: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d0f00 of size 768 next 2630\n",
      "2025-09-23 02:21:26.225116: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d1200 of size 768 next 2475\n",
      "2025-09-23 02:21:26.225117: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d1500 of size 256 next 2210\n",
      "2025-09-23 02:21:26.225119: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d1600 of size 256 next 2720\n",
      "2025-09-23 02:21:26.225120: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d1700 of size 256 next 2043\n",
      "2025-09-23 02:21:26.225121: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d1800 of size 256 next 1941\n",
      "2025-09-23 02:21:26.225122: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d1900 of size 256 next 1753\n",
      "2025-09-23 02:21:26.225124: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d1a00 of size 256 next 492\n",
      "2025-09-23 02:21:26.225125: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d1b00 of size 1536 next 2272\n",
      "2025-09-23 02:21:26.225126: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f81d2100 of size 25690112 next 1761\n",
      "2025-09-23 02:21:26.225127: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14f9a52100 of size 25690112 next 2073\n",
      "2025-09-23 02:21:26.225129: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14fb2d2100 of size 25690112 next 2007\n",
      "2025-09-23 02:21:26.225130: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14fcb52100 of size 25690112 next 2650\n",
      "2025-09-23 02:21:26.225131: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14fe3d2100 of size 12845056 next 2721\n",
      "2025-09-23 02:21:26.225133: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14ff012100 of size 12845056 next 2367\n",
      "2025-09-23 02:21:26.225134: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14ffc52100 of size 12845056 next 1929\n",
      "2025-09-23 02:21:26.225135: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1500892100 of size 6422528 next 2659\n",
      "2025-09-23 02:21:26.225137: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1500eb2100 of size 19267584 next 2631\n",
      "2025-09-23 02:21:26.225138: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1502112100 of size 6422528 next 1992\n",
      "2025-09-23 02:21:26.225139: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1502732100 of size 25690112 next 2400\n",
      "2025-09-23 02:21:26.225140: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1503fb2100 of size 25690112 next 2164\n",
      "2025-09-23 02:21:26.225142: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1505832100 of size 25690112 next 111\n",
      "2025-09-23 02:21:26.225143: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15070b2100 of size 25690112 next 2556\n",
      "2025-09-23 02:21:26.225144: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1508932100 of size 25690112 next 2515\n",
      "2025-09-23 02:21:26.225146: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 150a1b2100 of size 25690112 next 1740\n",
      "2025-09-23 02:21:26.225147: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 150ba32100 of size 25690112 next 2372\n",
      "2025-09-23 02:21:26.225148: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 150d2b2100 of size 25690112 next 2562\n",
      "2025-09-23 02:21:26.225149: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 150eb32100 of size 25690112 next 483\n",
      "2025-09-23 02:21:26.225151: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15103b2100 of size 25690112 next 2640\n",
      "2025-09-23 02:21:26.225152: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1511c32100 of size 25690112 next 2419\n",
      "2025-09-23 02:21:26.225153: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15134b2100 of size 25690112 next 2075\n",
      "2025-09-23 02:21:26.225154: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1514d32100 of size 12845056 next 2045\n",
      "2025-09-23 02:21:26.225156: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1515972100 of size 12845056 next 592\n",
      "2025-09-23 02:21:26.225157: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15165b2100 of size 12845056 next 2577\n",
      "2025-09-23 02:21:26.225158: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15171f2100 of size 6422528 next 2320\n",
      "2025-09-23 02:21:26.225159: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1517812100 of size 4096 next 2041\n",
      "2025-09-23 02:21:26.225160: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1517813100 of size 4096 next 2399\n",
      "2025-09-23 02:21:26.225163: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1517814100 of size 4096 next 2707\n",
      "2025-09-23 02:21:26.225165: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1517815100 of size 27176704 next 18446744073709551615\n",
      "2025-09-23 02:21:26.225167: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 8589934592\n",
      "2025-09-23 02:21:26.225176: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1519200000 of size 89915392 next 2059\n",
      "2025-09-23 02:21:26.225178: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 151e7c0000 of size 89915392 next 1801\n",
      "2025-09-23 02:21:26.225181: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1523d80000 of size 89915392 next 2153\n",
      "2025-09-23 02:21:26.225183: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1529340000 of size 89915392 next 2469\n",
      "2025-09-23 02:21:26.225184: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 152e900000 of size 22478848 next 1789\n",
      "2025-09-23 02:21:26.225186: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 152fe70000 of size 22478848 next 2488\n",
      "2025-09-23 02:21:26.225187: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15313e0000 of size 22478848 next 2403\n",
      "2025-09-23 02:21:26.225189: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1532950000 of size 256 next 2309\n",
      "2025-09-23 02:21:26.225190: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1532950100 of size 256 next 2401\n",
      "2025-09-23 02:21:26.225191: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1532950200 of size 11239424 next 1917\n",
      "2025-09-23 02:21:26.225193: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1533408200 of size 1024 next 2526\n",
      "2025-09-23 02:21:26.225194: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1533408600 of size 1024 next 2195\n",
      "2025-09-23 02:21:26.225196: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1533408a00 of size 1024 next 2019\n",
      "2025-09-23 02:21:26.225197: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1533408e00 of size 1024 next 300\n",
      "2025-09-23 02:21:26.225199: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1533409200 of size 1024 next 2099\n",
      "2025-09-23 02:21:26.225200: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1533409600 of size 1024 next 2480\n",
      "2025-09-23 02:21:26.225201: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1533409a00 of size 1024 next 570\n",
      "2025-09-23 02:21:26.225202: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1533409e00 of size 1024 next 1734\n",
      "2025-09-23 02:21:26.225203: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 153340a200 of size 1024 next 2169\n",
      "2025-09-23 02:21:26.225205: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 153340a600 of size 1024 next 1891\n",
      "2025-09-23 02:21:26.225206: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 153340aa00 of size 1024 next 2612\n",
      "2025-09-23 02:21:26.225207: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 153340ae00 of size 1024 next 1914\n",
      "2025-09-23 02:21:26.225208: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 153340b200 of size 1024 next 2013\n",
      "2025-09-23 02:21:26.225210: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 153340b600 of size 7168 next 1922\n",
      "2025-09-23 02:21:26.225211: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 153340d200 of size 7168 next 2615\n",
      "2025-09-23 02:21:26.225212: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 153340ee00 of size 1792 next 2262\n",
      "2025-09-23 02:21:26.225213: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 153340f500 of size 1792 next 2234\n",
      "2025-09-23 02:21:26.225215: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 153340fc00 of size 1792 next 1869\n",
      "2025-09-23 02:21:26.225216: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1533410300 of size 7168 next 152\n",
      "2025-09-23 02:21:26.225217: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1533411f00 of size 7168 next 1896\n",
      "2025-09-23 02:21:26.225218: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1533413b00 of size 33670912 next 1779\n",
      "2025-09-23 02:21:26.225220: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1535430200 of size 11239424 next 2388\n",
      "2025-09-23 02:21:26.225221: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1535ee8200 of size 89915392 next 2633\n",
      "2025-09-23 02:21:26.225223: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 153b4a8200 of size 89915392 next 1909\n",
      "2025-09-23 02:21:26.225224: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1540a68200 of size 89915392 next 2127\n",
      "2025-09-23 02:21:26.225225: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1546028200 of size 89915392 next 2131\n",
      "2025-09-23 02:21:26.225226: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 154b5e8200 of size 89915392 next 2733\n",
      "2025-09-23 02:21:26.225228: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1550ba8200 of size 89915392 next 2481\n",
      "2025-09-23 02:21:26.225229: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1556168200 of size 104366592 next 2607\n",
      "2025-09-23 02:21:26.225230: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 155c4f0400 of size 4096 next 2014\n",
      "2025-09-23 02:21:26.225231: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 155c4f1400 of size 4096 next 2362\n",
      "2025-09-23 02:21:26.225233: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 155c4f2400 of size 4096 next 2156\n",
      "2025-09-23 02:21:26.225234: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 155c4f3400 of size 192675840 next 2198\n",
      "2025-09-23 02:21:26.225235: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1567cb3400 of size 192675840 next 2541\n",
      "2025-09-23 02:21:26.225236: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1573473400 of size 192675840 next 2265\n",
      "2025-09-23 02:21:26.225238: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 157ec33400 of size 192675840 next 2068\n",
      "2025-09-23 02:21:26.225239: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 158a3f3400 of size 192675840 next 2555\n",
      "2025-09-23 02:21:26.225240: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1595bb3400 of size 192675840 next 2738\n",
      "2025-09-23 02:21:26.225242: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15a1373400 of size 317907968 next 463\n",
      "2025-09-23 02:21:26.225243: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b42a1800 of size 22478848 next 1972\n",
      "2025-09-23 02:21:26.225244: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b5811800 of size 22478848 next 2250\n",
      "2025-09-23 02:21:26.225245: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b6d81800 of size 22478848 next 1902\n",
      "2025-09-23 02:21:26.225247: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b82f1800 of size 11239424 next 178\n",
      "2025-09-23 02:21:26.225248: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8da9800 of size 1024 next 1991\n",
      "2025-09-23 02:21:26.225249: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8da9c00 of size 1024 next 669\n",
      "2025-09-23 02:21:26.225250: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8daa000 of size 1024 next 2398\n",
      "2025-09-23 02:21:26.225251: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8daa400 of size 1024 next 2319\n",
      "2025-09-23 02:21:26.225253: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8daa800 of size 1024 next 1798\n",
      "2025-09-23 02:21:26.225254: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8daac00 of size 1024 next 1995\n",
      "2025-09-23 02:21:26.225255: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8dab000 of size 1024 next 1781\n",
      "2025-09-23 02:21:26.225256: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8dab400 of size 7168 next 2327\n",
      "2025-09-23 02:21:26.225257: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8dad000 of size 7168 next 2276\n",
      "2025-09-23 02:21:26.225259: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8daec00 of size 1792 next 1816\n",
      "2025-09-23 02:21:26.225260: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8daf300 of size 1792 next 2109\n",
      "2025-09-23 02:21:26.225261: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8dafa00 of size 1792 next 2462\n",
      "2025-09-23 02:21:26.225262: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8db0100 of size 7168 next 2537\n",
      "2025-09-23 02:21:26.225263: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8db1d00 of size 7168 next 2719\n",
      "2025-09-23 02:21:26.225265: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15b8db3900 of size 33677056 next 1805\n",
      "2025-09-23 02:21:26.225266: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15badd1800 of size 11239424 next 2461\n",
      "2025-09-23 02:21:26.225267: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15bb889800 of size 89915392 next 2540\n",
      "2025-09-23 02:21:26.225268: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15c0e49800 of size 89915392 next 2739\n",
      "2025-09-23 02:21:26.225270: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15c6409800 of size 89915392 next 2732\n",
      "2025-09-23 02:21:26.225271: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15cb9c9800 of size 89915392 next 2247\n",
      "2025-09-23 02:21:26.225272: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15d0f89800 of size 89915392 next 2632\n",
      "2025-09-23 02:21:26.225273: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15d6549800 of size 89915392 next 1979\n",
      "2025-09-23 02:21:26.225274: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15dbb09800 of size 89915392 next 2296\n",
      "2025-09-23 02:21:26.225275: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15e10c9800 of size 89915392 next 2532\n",
      "2025-09-23 02:21:26.225276: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15e6689800 of size 89915392 next 2125\n",
      "2025-09-23 02:21:26.225278: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15ebc49800 of size 165374976 next 2763\n",
      "2025-09-23 02:21:26.225279: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15f5a00400 of size 768 next 65\n",
      "2025-09-23 02:21:26.225280: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15f5a00700 of size 2560 next 1901\n",
      "2025-09-23 02:21:26.225281: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15f5a01100 of size 77070336 next 2408\n",
      "2025-09-23 02:21:26.225282: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15fa381100 of size 77070336 next 1838\n",
      "2025-09-23 02:21:26.225284: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 15fed01100 of size 77070336 next 2344\n",
      "2025-09-23 02:21:26.225285: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1603681100 of size 38535168 next 1983\n",
      "2025-09-23 02:21:26.225286: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1605b41100 of size 38535168 next 2478\n",
      "2025-09-23 02:21:26.225287: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1608001100 of size 512 next 2190\n",
      "2025-09-23 02:21:26.225289: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1608001300 of size 38535168 next 687\n",
      "2025-09-23 02:21:26.225290: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160a4c1300 of size 512 next 2448\n",
      "2025-09-23 02:21:26.225291: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160a4c1500 of size 512 next 1800\n",
      "2025-09-23 02:21:26.225293: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160a4c1700 of size 512 next 2456\n",
      "2025-09-23 02:21:26.225294: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160a4c1900 of size 512 next 2657\n",
      "2025-09-23 02:21:26.225295: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160a4c1b00 of size 19267584 next 2751\n",
      "2025-09-23 02:21:26.225296: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b721b00 of size 768 next 71\n",
      "2025-09-23 02:21:26.225298: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b721e00 of size 768 next 681\n",
      "2025-09-23 02:21:26.225299: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b722100 of size 768 next 2318\n",
      "2025-09-23 02:21:26.225300: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b722400 of size 768 next 2579\n",
      "2025-09-23 02:21:26.225301: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b722700 of size 768 next 1749\n",
      "2025-09-23 02:21:26.225302: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b722a00 of size 768 next 2105\n",
      "2025-09-23 02:21:26.225303: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b722d00 of size 768 next 2669\n",
      "2025-09-23 02:21:26.225305: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b723000 of size 768 next 2641\n",
      "2025-09-23 02:21:26.225306: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b723300 of size 768 next 2539\n",
      "2025-09-23 02:21:26.225307: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b723600 of size 768 next 2330\n",
      "2025-09-23 02:21:26.225308: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b723900 of size 768 next 70\n",
      "2025-09-23 02:21:26.225309: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b723c00 of size 6144 next 2667\n",
      "2025-09-23 02:21:26.225311: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b725400 of size 6144 next 2742\n",
      "2025-09-23 02:21:26.225312: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b726c00 of size 1536 next 2756\n",
      "2025-09-23 02:21:26.225313: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b727200 of size 1536 next 1737\n",
      "2025-09-23 02:21:26.225315: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b727800 of size 1536 next 1772\n",
      "2025-09-23 02:21:26.225316: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b727e00 of size 6144 next 1739\n",
      "2025-09-23 02:21:26.225317: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b729600 of size 6144 next 529\n",
      "2025-09-23 02:21:26.225319: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160b72ae00 of size 57765120 next 460\n",
      "2025-09-23 02:21:26.225328: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 160ee41b00 of size 19267584 next 2498\n",
      "2025-09-23 02:21:26.225330: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16100a1b00 of size 77070336 next 1750\n",
      "2025-09-23 02:21:26.225332: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1614a21b00 of size 77070336 next 2629\n",
      "2025-09-23 02:21:26.225334: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16193a1b00 of size 77070336 next 2326\n",
      "2025-09-23 02:21:26.225335: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 161dd21b00 of size 77070336 next 2774\n",
      "2025-09-23 02:21:26.225336: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16226a1b00 of size 77070336 next 2553\n",
      "2025-09-23 02:21:26.225338: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1627021b00 of size 77070336 next 1747\n",
      "2025-09-23 02:21:26.225339: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 162b9a1b00 of size 77070336 next 1809\n",
      "2025-09-23 02:21:26.225340: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1630321b00 of size 77070336 next 2550\n",
      "2025-09-23 02:21:26.225341: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1634ca1b00 of size 77070336 next 1823\n",
      "2025-09-23 02:21:26.225343: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1639621b00 of size 77070336 next 1928\n",
      "2025-09-23 02:21:26.225344: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 163dfa1b00 of size 77070336 next 2061\n",
      "2025-09-23 02:21:26.225345: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1642921b00 of size 77070336 next 2747\n",
      "2025-09-23 02:21:26.225347: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16472a1b00 of size 77070336 next 2307\n",
      "2025-09-23 02:21:26.225348: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 164bc21b00 of size 77070336 next 202\n",
      "2025-09-23 02:21:26.225349: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16505a1b00 of size 38535168 next 2603\n",
      "2025-09-23 02:21:26.225351: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1652a61b00 of size 38535168 next 2176\n",
      "2025-09-23 02:21:26.225352: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1654f21b00 of size 38535168 next 2143\n",
      "2025-09-23 02:21:26.225353: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16573e1b00 of size 512 next 2046\n",
      "2025-09-23 02:21:26.225355: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16573e1d00 of size 19267584 next 2718\n",
      "2025-09-23 02:21:26.225356: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658641d00 of size 768 next 2192\n",
      "2025-09-23 02:21:26.225357: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658642000 of size 768 next 2289\n",
      "2025-09-23 02:21:26.225359: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658642300 of size 768 next 1913\n",
      "2025-09-23 02:21:26.225360: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658642600 of size 768 next 23\n",
      "2025-09-23 02:21:26.225361: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658642900 of size 768 next 2366\n",
      "2025-09-23 02:21:26.225363: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658642c00 of size 768 next 2496\n",
      "2025-09-23 02:21:26.225364: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658642f00 of size 768 next 2551\n",
      "2025-09-23 02:21:26.225365: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658643200 of size 768 next 2511\n",
      "2025-09-23 02:21:26.225366: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658643500 of size 768 next 2208\n",
      "2025-09-23 02:21:26.225368: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658643800 of size 768 next 2727\n",
      "2025-09-23 02:21:26.225369: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658643b00 of size 768 next 2410\n",
      "2025-09-23 02:21:26.225371: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658643e00 of size 6144 next 2235\n",
      "2025-09-23 02:21:26.225372: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658645600 of size 6144 next 1802\n",
      "2025-09-23 02:21:26.225373: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658646e00 of size 1536 next 2770\n",
      "2025-09-23 02:21:26.225375: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658647400 of size 1536 next 2084\n",
      "2025-09-23 02:21:26.225376: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658647a00 of size 1536 next 2433\n",
      "2025-09-23 02:21:26.225377: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658648000 of size 6144 next 2076\n",
      "2025-09-23 02:21:26.225378: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1658649800 of size 6144 next 2058\n",
      "2025-09-23 02:21:26.225380: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 165864b000 of size 57765120 next 2228\n",
      "2025-09-23 02:21:26.225381: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 165bd61d00 of size 19267584 next 2217\n",
      "2025-09-23 02:21:26.225382: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 165cfc1d00 of size 77070336 next 434\n",
      "2025-09-23 02:21:26.225383: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1661941d00 of size 77070336 next 1981\n",
      "2025-09-23 02:21:26.225385: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16662c1d00 of size 77070336 next 2760\n",
      "2025-09-23 02:21:26.225386: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 166ac41d00 of size 77070336 next 2494\n",
      "2025-09-23 02:21:26.225387: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 166f5c1d00 of size 77070336 next 1963\n",
      "2025-09-23 02:21:26.225389: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1673f41d00 of size 77070336 next 470\n",
      "2025-09-23 02:21:26.225390: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16788c1d00 of size 77070336 next 2252\n",
      "2025-09-23 02:21:26.225391: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 167d241d00 of size 77070336 next 459\n",
      "2025-09-23 02:21:26.225392: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1681bc1d00 of size 77070336 next 443\n",
      "2025-09-23 02:21:26.225393: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1686541d00 of size 77070336 next 1888\n",
      "2025-09-23 02:21:26.225395: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 168aec1d00 of size 77070336 next 2601\n",
      "2025-09-23 02:21:26.225396: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 168f841d00 of size 77070336 next 1978\n",
      "2025-09-23 02:21:26.225397: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16941c1d00 of size 77070336 next 2698\n",
      "2025-09-23 02:21:26.225399: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1698b41d00 of size 77070336 next 1835\n",
      "2025-09-23 02:21:26.225400: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 169d4c1d00 of size 38535168 next 624\n",
      "2025-09-23 02:21:26.225409: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 169f981d00 of size 38535168 next 2071\n",
      "2025-09-23 02:21:26.225411: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16a1e41d00 of size 38535168 next 2323\n",
      "2025-09-23 02:21:26.225413: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16a4301d00 of size 512 next 2248\n",
      "2025-09-23 02:21:26.225414: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16a4301f00 of size 512 next 2138\n",
      "2025-09-23 02:21:26.225415: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16a4302100 of size 512 next 86\n",
      "2025-09-23 02:21:26.225417: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16a4302300 of size 19267584 next 2676\n",
      "2025-09-23 02:21:26.225418: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16a5562300 of size 57802752 next 2525\n",
      "2025-09-23 02:21:26.225427: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16a8c82300 of size 19267584 next 1897\n",
      "2025-09-23 02:21:26.225430: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16a9ee2300 of size 44957696 next 390\n",
      "2025-09-23 02:21:26.225433: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16ac9c2300 of size 44957696 next 1885\n",
      "2025-09-23 02:21:26.225435: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16af4a2300 of size 44957696 next 660\n",
      "2025-09-23 02:21:26.225443: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16b1f82300 of size 512 next 2159\n",
      "2025-09-23 02:21:26.225446: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16b1f82500 of size 512 next 1828\n",
      "2025-09-23 02:21:26.225448: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16b1f82700 of size 512 next 2451\n",
      "2025-09-23 02:21:26.225449: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16b1f82900 of size 512 next 1962\n",
      "2025-09-23 02:21:26.225451: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 16b1f82b00 of size 18176 next 2522\n",
      "2025-09-23 02:21:26.225452: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16b1f87200 of size 256 next 2474\n",
      "2025-09-23 02:21:26.225453: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 16b1f87300 of size 9728 next 2035\n",
      "2025-09-23 02:21:26.225455: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16b1f89900 of size 3840 next 2776\n",
      "2025-09-23 02:21:26.225456: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16b1f8a800 of size 57344 next 1927\n",
      "2025-09-23 02:21:26.225457: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16b1f98800 of size 44957696 next 2597\n",
      "2025-09-23 02:21:26.225459: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16b4a78800 of size 44957696 next 2610\n",
      "2025-09-23 02:21:26.225460: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16b7558800 of size 44957696 next 2434\n",
      "2025-09-23 02:21:26.225461: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16ba038800 of size 85008384 next 2356\n",
      "2025-09-23 02:21:26.225463: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16bf14a800 of size 1024 next 2483\n",
      "2025-09-23 02:21:26.225464: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16bf14ac00 of size 1024 next 1829\n",
      "2025-09-23 02:21:26.225465: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16bf14b000 of size 1024 next 2072\n",
      "2025-09-23 02:21:26.225467: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16bf14b400 of size 1024 next 2466\n",
      "2025-09-23 02:21:26.225468: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16bf14b800 of size 1024 next 2215\n",
      "2025-09-23 02:21:26.225469: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16bf14bc00 of size 1024 next 2146\n",
      "2025-09-23 02:21:26.225471: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16bf14c000 of size 134873088 next 2157\n",
      "2025-09-23 02:21:26.225472: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16c71ec000 of size 134873088 next 2570\n",
      "2025-09-23 02:21:26.225475: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16cf28c000 of size 134873088 next 2214\n",
      "2025-09-23 02:21:26.225477: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16d732c000 of size 134873088 next 196\n",
      "2025-09-23 02:21:26.225478: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16df3cc000 of size 134873088 next 2504\n",
      "2025-09-23 02:21:26.225480: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16e746c000 of size 134873088 next 2371\n",
      "2025-09-23 02:21:26.225481: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16ef50c000 of size 134873088 next 1947\n",
      "2025-09-23 02:21:26.225482: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16f75ac000 of size 32112640 next 2590\n",
      "2025-09-23 02:21:26.225484: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16f944c000 of size 32112640 next 721\n",
      "2025-09-23 02:21:26.225485: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fb2ec000 of size 512 next 2285\n",
      "2025-09-23 02:21:26.225486: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fb2ec200 of size 32112640 next 2304\n",
      "2025-09-23 02:21:26.225488: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fd18c200 of size 512 next 763\n",
      "2025-09-23 02:21:26.225489: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fd18c400 of size 512 next 2420\n",
      "2025-09-23 02:21:26.225490: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fd18c600 of size 512 next 2357\n",
      "2025-09-23 02:21:26.225492: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fd18c800 of size 512 next 1799\n",
      "2025-09-23 02:21:26.225493: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fd18ca00 of size 16056320 next 1952\n",
      "2025-09-23 02:21:26.225502: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0dca00 of size 2048 next 2137\n",
      "2025-09-23 02:21:26.225504: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0dd200 of size 2048 next 2310\n",
      "2025-09-23 02:21:26.225506: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0dda00 of size 2048 next 2572\n",
      "2025-09-23 02:21:26.225507: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0de200 of size 2048 next 2246\n",
      "2025-09-23 02:21:26.225509: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0dea00 of size 2048 next 2674\n",
      "2025-09-23 02:21:26.225510: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0df200 of size 2048 next 2638\n",
      "2025-09-23 02:21:26.225511: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0dfa00 of size 2048 next 2026\n",
      "2025-09-23 02:21:26.225513: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0e0200 of size 2048 next 1850\n",
      "2025-09-23 02:21:26.225514: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0e0a00 of size 15360 next 1766\n",
      "2025-09-23 02:21:26.225515: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0e4600 of size 15360 next 1822\n",
      "2025-09-23 02:21:26.225516: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0e8200 of size 3840 next 2594\n",
      "2025-09-23 02:21:26.225518: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0e9100 of size 3840 next 1840\n",
      "2025-09-23 02:21:26.225519: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0ea000 of size 15360 next 2753\n",
      "2025-09-23 02:21:26.225520: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0edc00 of size 15360 next 2293\n",
      "2025-09-23 02:21:26.225521: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 16fe0f1800 of size 48083456 next 2445\n",
      "2025-09-23 02:21:26.225523: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1700ecca00 of size 16056320 next 1790\n",
      "2025-09-23 02:21:26.225524: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1701e1ca00 of size 261710336 next 1765\n",
      "2025-09-23 02:21:26.225525: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17117b2c00 of size 1024 next 1826\n",
      "2025-09-23 02:21:26.225527: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17117b3000 of size 1024 next 1853\n",
      "2025-09-23 02:21:26.225528: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17117b3400 of size 1024 next 2501\n",
      "2025-09-23 02:21:26.225529: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17117b3800 of size 3072 next 2502\n",
      "2025-09-23 02:21:26.225530: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17117b4400 of size 12845056 next 2493\n",
      "2025-09-23 02:21:26.225532: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17123f4400 of size 12845056 next 1837\n",
      "2025-09-23 02:21:26.225533: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1713034400 of size 12845056 next 2608\n",
      "2025-09-23 02:21:26.225535: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1713c74400 of size 12845056 next 631\n",
      "2025-09-23 02:21:26.225536: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17148b4400 of size 12845056 next 1911\n",
      "2025-09-23 02:21:26.225537: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17154f4400 of size 12845056 next 2765\n",
      "2025-09-23 02:21:26.225551: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1716134400 of size 12845056 next 2663\n",
      "2025-09-23 02:21:26.225554: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1716d74400 of size 12845056 next 2743\n",
      "2025-09-23 02:21:26.225556: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17179b4400 of size 25476096 next 18446744073709551615\n",
      "2025-09-23 02:21:26.225565: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 5322571776\n",
      "2025-09-23 02:21:26.225568: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1719200000 of size 6422528 next 2492\n",
      "2025-09-23 02:21:26.225570: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1719820000 of size 51380224 next 2348\n",
      "2025-09-23 02:21:26.225572: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 171c920000 of size 51380224 next 1895\n",
      "2025-09-23 02:21:26.225574: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 171fa20000 of size 51380224 next 2101\n",
      "2025-09-23 02:21:26.225575: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1722b20000 of size 51380224 next 2171\n",
      "2025-09-23 02:21:26.225576: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1725c20000 of size 51380224 next 2165\n",
      "2025-09-23 02:21:26.225578: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1728d20000 of size 51380224 next 1845\n",
      "2025-09-23 02:21:26.225579: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 172be20000 of size 51380224 next 1977\n",
      "2025-09-23 02:21:26.225580: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 172ef20000 of size 51380224 next 214\n",
      "2025-09-23 02:21:26.225582: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1732020000 of size 51380224 next 1961\n",
      "2025-09-23 02:21:26.225583: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1735120000 of size 96338432 next 2427\n",
      "2025-09-23 02:21:26.225585: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173ad00200 of size 1024 next 1847\n",
      "2025-09-23 02:21:26.225586: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173ad00600 of size 691200 next 2706\n",
      "2025-09-23 02:21:26.225587: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173ada9200 of size 691200 next 2589\n",
      "2025-09-23 02:21:26.225589: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173ae51e00 of size 691200 next 2709\n",
      "2025-09-23 02:21:26.225590: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173aefaa00 of size 691200 next 2588\n",
      "2025-09-23 02:21:26.225591: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173afa3600 of size 76800 next 141\n",
      "2025-09-23 02:21:26.225593: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173afb6200 of size 691200 next 489\n",
      "2025-09-23 02:21:26.225594: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b05ee00 of size 115200 next 2581\n",
      "2025-09-23 02:21:26.225595: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b07b000 of size 115200 next 2273\n",
      "2025-09-23 02:21:26.225596: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b097200 of size 36864 next 2668\n",
      "2025-09-23 02:21:26.225598: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b0a0200 of size 115200 next 1959\n",
      "2025-09-23 02:21:26.225599: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b0bc400 of size 76800 next 2446\n",
      "2025-09-23 02:21:26.225600: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b0cf000 of size 12800 next 2267\n",
      "2025-09-23 02:21:26.225602: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b0d2200 of size 18432 next 1839\n",
      "2025-09-23 02:21:26.225603: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b0d6a00 of size 36864 next 1806\n",
      "2025-09-23 02:21:26.225604: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b0dfa00 of size 18432 next 1743\n",
      "2025-09-23 02:21:26.225606: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b0e4200 of size 36864 next 49\n",
      "2025-09-23 02:21:26.225607: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b0ed200 of size 115200 next 2624\n",
      "2025-09-23 02:21:26.225608: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b109400 of size 691200 next 2549\n",
      "2025-09-23 02:21:26.225609: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b1b2000 of size 36864 next 2648\n",
      "2025-09-23 02:21:26.225611: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b1bb000 of size 18432 next 2150\n",
      "2025-09-23 02:21:26.225612: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b1bf800 of size 115200 next 1904\n",
      "2025-09-23 02:21:26.225613: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b1dba00 of size 115200 next 2529\n",
      "2025-09-23 02:21:26.225614: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b1f7c00 of size 76800 next 2069\n",
      "2025-09-23 02:21:26.225616: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b20a800 of size 36864 next 2701\n",
      "2025-09-23 02:21:26.225617: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b213800 of size 18432 next 2397\n",
      "2025-09-23 02:21:26.225618: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b218000 of size 76800 next 2288\n",
      "2025-09-23 02:21:26.225620: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b22ac00 of size 30720 next 1746\n",
      "2025-09-23 02:21:26.225623: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b232400 of size 56576 next 2111\n",
      "2025-09-23 02:21:26.225624: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b240100 of size 36864 next 689\n",
      "2025-09-23 02:21:26.225626: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b249100 of size 25600 next 2605\n",
      "2025-09-23 02:21:26.225627: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b24f500 of size 12800 next 1957\n",
      "2025-09-23 02:21:26.225628: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b252700 of size 18432 next 1811\n",
      "2025-09-23 02:21:26.225630: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b256f00 of size 30720 next 2618\n",
      "2025-09-23 02:21:26.225632: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b25e700 of size 8192 next 2425\n",
      "2025-09-23 02:21:26.225634: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b260700 of size 18432 next 2050\n",
      "2025-09-23 02:21:26.225635: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 173b264f00 of size 28672 next 1958\n",
      "2025-09-23 02:21:26.225637: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b26bf00 of size 18432 next 412\n",
      "2025-09-23 02:21:26.225638: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b270700 of size 25088 next 2209\n",
      "2025-09-23 02:21:26.225639: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b276900 of size 21504 next 1990\n",
      "2025-09-23 02:21:26.225648: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b27bd00 of size 12800 next 2444\n",
      "2025-09-23 02:21:26.225651: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b27ef00 of size 36864 next 1989\n",
      "2025-09-23 02:21:26.225653: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b287f00 of size 18432 next 2345\n",
      "2025-09-23 02:21:26.225655: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b28c700 of size 18432 next 1982\n",
      "2025-09-23 02:21:26.225656: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b290f00 of size 21504 next 1964\n",
      "2025-09-23 02:21:26.225657: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b296300 of size 25088 next 2472\n",
      "2025-09-23 02:21:26.225659: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b29c500 of size 25088 next 2402\n",
      "2025-09-23 02:21:26.225660: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2a2700 of size 36864 next 2212\n",
      "2025-09-23 02:21:26.225661: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2ab700 of size 25088 next 2239\n",
      "2025-09-23 02:21:26.225662: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2b1900 of size 25088 next 2033\n",
      "2025-09-23 02:21:26.225664: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2b7b00 of size 25088 next 2409\n",
      "2025-09-23 02:21:26.225665: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2bdd00 of size 4096 next 1833\n",
      "2025-09-23 02:21:26.225666: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2bed00 of size 4096 next 2016\n",
      "2025-09-23 02:21:26.225668: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2bfd00 of size 25088 next 1764\n",
      "2025-09-23 02:21:26.225669: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2c5f00 of size 4096 next 2174\n",
      "2025-09-23 02:21:26.225670: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2c6f00 of size 25088 next 2375\n",
      "2025-09-23 02:21:26.225672: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2cd100 of size 4096 next 2280\n",
      "2025-09-23 02:21:26.225673: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2ce100 of size 4096 next 2543\n",
      "2025-09-23 02:21:26.225674: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2cf100 of size 4096 next 2442\n",
      "2025-09-23 02:21:26.225675: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2d0100 of size 4096 next 2404\n",
      "2025-09-23 02:21:26.225677: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2d1100 of size 8192 next 2194\n",
      "2025-09-23 02:21:26.225678: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2d3100 of size 4096 next 2315\n",
      "2025-09-23 02:21:26.225679: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2d4100 of size 25088 next 2656\n",
      "2025-09-23 02:21:26.225680: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2da300 of size 25088 next 2712\n",
      "2025-09-23 02:21:26.225681: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2e0500 of size 25088 next 1778\n",
      "2025-09-23 02:21:26.225683: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2e6700 of size 25088 next 2211\n",
      "2025-09-23 02:21:26.225684: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2ec900 of size 25088 next 282\n",
      "2025-09-23 02:21:26.225693: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2f2b00 of size 4096 next 1861\n",
      "2025-09-23 02:21:26.225696: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2f3b00 of size 4096 next 1824\n",
      "2025-09-23 02:21:26.225698: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2f4b00 of size 4096 next 1872\n",
      "2025-09-23 02:21:26.225699: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2f5b00 of size 8192 next 2119\n",
      "2025-09-23 02:21:26.225700: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2f7b00 of size 25088 next 1867\n",
      "2025-09-23 02:21:26.225703: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b2fdd00 of size 25088 next 2080\n",
      "2025-09-23 02:21:26.225705: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b303f00 of size 4096 next 1848\n",
      "2025-09-23 02:21:26.225706: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b304f00 of size 4096 next 2161\n",
      "2025-09-23 02:21:26.225708: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b305f00 of size 25088 next 1980\n",
      "2025-09-23 02:21:26.225709: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b30c100 of size 25088 next 2090\n",
      "2025-09-23 02:21:26.225710: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b312300 of size 25088 next 537\n",
      "2025-09-23 02:21:26.225712: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b318500 of size 8192 next 74\n",
      "2025-09-23 02:21:26.225713: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b31a500 of size 25088 next 1931\n",
      "2025-09-23 02:21:26.225715: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b320700 of size 25088 next 1932\n",
      "2025-09-23 02:21:26.225716: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b326900 of size 25088 next 1997\n",
      "2025-09-23 02:21:26.225717: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b32cb00 of size 25088 next 2643\n",
      "2025-09-23 02:21:26.225719: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b332d00 of size 25088 next 334\n",
      "2025-09-23 02:21:26.225720: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b338f00 of size 25088 next 2162\n",
      "2025-09-23 02:21:26.225721: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b33f100 of size 4096 next 2449\n",
      "2025-09-23 02:21:26.225722: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b340100 of size 4096 next 2385\n",
      "2025-09-23 02:21:26.225724: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b341100 of size 25088 next 2316\n",
      "2025-09-23 02:21:26.225725: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b347300 of size 25088 next 2038\n",
      "2025-09-23 02:21:26.225726: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b34d500 of size 25088 next 2503\n",
      "2025-09-23 02:21:26.225727: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b353700 of size 25088 next 2308\n",
      "2025-09-23 02:21:26.225729: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b359900 of size 18432 next 2011\n",
      "2025-09-23 02:21:26.225730: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b35e100 of size 25088 next 2027\n",
      "2025-09-23 02:21:26.225731: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b364300 of size 4096 next 2598\n",
      "2025-09-23 02:21:26.225732: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b365300 of size 25088 next 2130\n",
      "2025-09-23 02:21:26.225733: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b36b500 of size 4096 next 2268\n",
      "2025-09-23 02:21:26.225735: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b36c500 of size 25088 next 2454\n",
      "2025-09-23 02:21:26.225736: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b372700 of size 25088 next 2358\n",
      "2025-09-23 02:21:26.225737: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b378900 of size 4096 next 1930\n",
      "2025-09-23 02:21:26.225746: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b379900 of size 25088 next 1759\n",
      "2025-09-23 02:21:26.225748: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b37fb00 of size 25088 next 2552\n",
      "2025-09-23 02:21:26.225750: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b385d00 of size 4096 next 1984\n",
      "2025-09-23 02:21:26.225751: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b386d00 of size 4096 next 2056\n",
      "2025-09-23 02:21:26.225752: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b387d00 of size 25088 next 2644\n",
      "2025-09-23 02:21:26.225754: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173b38df00 of size 12397312 next 1836\n",
      "2025-09-23 02:21:26.225755: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf60a00 of size 768 next 2679\n",
      "2025-09-23 02:21:26.225756: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf60d00 of size 256 next 1777\n",
      "2025-09-23 02:21:26.225758: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf60e00 of size 256 next 2064\n",
      "2025-09-23 02:21:26.225759: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf60f00 of size 256 next 2652\n",
      "2025-09-23 02:21:26.225760: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf61000 of size 256 next 239\n",
      "2025-09-23 02:21:26.225761: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf61100 of size 256 next 2151\n",
      "2025-09-23 02:21:26.225763: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf61200 of size 256 next 674\n",
      "2025-09-23 02:21:26.225764: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf61300 of size 768 next 2390\n",
      "2025-09-23 02:21:26.225765: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf61600 of size 768 next 2578\n",
      "2025-09-23 02:21:26.225766: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf61900 of size 256 next 2471\n",
      "2025-09-23 02:21:26.225767: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf61a00 of size 256 next 2336\n",
      "2025-09-23 02:21:26.225769: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf61b00 of size 256 next 1860\n",
      "2025-09-23 02:21:26.225770: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf61c00 of size 256 next 1936\n",
      "2025-09-23 02:21:26.225771: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf61d00 of size 256 next 1944\n",
      "2025-09-23 02:21:26.225772: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf61e00 of size 256 next 1877\n",
      "2025-09-23 02:21:26.225774: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf61f00 of size 1536 next 2321\n",
      "2025-09-23 02:21:26.225775: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 173bf62500 of size 89915392 next 2671\n",
      "2025-09-23 02:21:26.225776: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1741522500 of size 89915392 next 2377\n",
      "2025-09-23 02:21:26.225777: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1746ae2500 of size 89915392 next 1757\n",
      "2025-09-23 02:21:26.225779: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 174c0a2500 of size 89915392 next 2381\n",
      "2025-09-23 02:21:26.225780: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1751662500 of size 89915392 next 2053\n",
      "2025-09-23 02:21:26.225781: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1756c22500 of size 89915392 next 2696\n",
      "2025-09-23 02:21:26.225783: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 175c1e2500 of size 89915392 next 188\n",
      "2025-09-23 02:21:26.225784: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17617a2500 of size 89915392 next 2468\n",
      "2025-09-23 02:21:26.225785: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1766d62500 of size 89915392 next 2340\n",
      "2025-09-23 02:21:26.225787: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 176c322500 of size 22478848 next 127\n",
      "2025-09-23 02:21:26.225788: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 176d892500 of size 22478848 next 2134\n",
      "2025-09-23 02:21:26.225789: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 176ee02500 of size 22478848 next 2717\n",
      "2025-09-23 02:21:26.225790: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770372500 of size 11239424 next 2642\n",
      "2025-09-23 02:21:26.225792: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2a500 of size 1024 next 381\n",
      "2025-09-23 02:21:26.225793: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2a900 of size 1024 next 2264\n",
      "2025-09-23 02:21:26.225794: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2ad00 of size 1024 next 2333\n",
      "2025-09-23 02:21:26.225796: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2b100 of size 1024 next 1786\n",
      "2025-09-23 02:21:26.225797: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2b500 of size 1024 next 2646\n",
      "2025-09-23 02:21:26.225798: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2b900 of size 1024 next 82\n",
      "2025-09-23 02:21:26.225799: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2bd00 of size 1024 next 2373\n",
      "2025-09-23 02:21:26.225800: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2c100 of size 1024 next 1817\n",
      "2025-09-23 02:21:26.225802: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2c500 of size 1024 next 2205\n",
      "2025-09-23 02:21:26.225803: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2c900 of size 1024 next 2653\n",
      "2025-09-23 02:21:26.225804: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2cd00 of size 1024 next 2565\n",
      "2025-09-23 02:21:26.225805: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2d100 of size 1024 next 2266\n",
      "2025-09-23 02:21:26.225806: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2d500 of size 1024 next 2100\n",
      "2025-09-23 02:21:26.225808: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2d900 of size 1024 next 255\n",
      "2025-09-23 02:21:26.225809: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2dd00 of size 7168 next 2054\n",
      "2025-09-23 02:21:26.225810: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e2f900 of size 7168 next 329\n",
      "2025-09-23 02:21:26.225812: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e31500 of size 1792 next 2379\n",
      "2025-09-23 02:21:26.225813: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e31c00 of size 1792 next 2042\n",
      "2025-09-23 02:21:26.225814: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e32300 of size 1792 next 2705\n",
      "2025-09-23 02:21:26.225816: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e32a00 of size 7168 next 2158\n",
      "2025-09-23 02:21:26.225817: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e34600 of size 7168 next 2325\n",
      "2025-09-23 02:21:26.225818: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1770e36200 of size 33669888 next 1755\n",
      "2025-09-23 02:21:26.225820: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1772e52500 of size 11239424 next 2093\n",
      "2025-09-23 02:21:26.225821: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 177390a500 of size 89915392 next 2184\n",
      "2025-09-23 02:21:26.225822: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1778eca500 of size 89915392 next 2688\n",
      "2025-09-23 02:21:26.225824: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 177e48a500 of size 178218752 next 2172\n",
      "2025-09-23 02:21:26.225826: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e80c00 of size 768 next 2060\n",
      "2025-09-23 02:21:26.225827: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e80f00 of size 256 next 2619\n",
      "2025-09-23 02:21:26.225828: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e81000 of size 256 next 2510\n",
      "2025-09-23 02:21:26.225829: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e81100 of size 256 next 1742\n",
      "2025-09-23 02:21:26.225831: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e81200 of size 256 next 2771\n",
      "2025-09-23 02:21:26.225832: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e81300 of size 256 next 437\n",
      "2025-09-23 02:21:26.225833: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e81400 of size 256 next 251\n",
      "2025-09-23 02:21:26.225834: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e81500 of size 768 next 2083\n",
      "2025-09-23 02:21:26.225836: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e81800 of size 768 next 1849\n",
      "2025-09-23 02:21:26.225837: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e81b00 of size 256 next 2299\n",
      "2025-09-23 02:21:26.225838: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e81c00 of size 256 next 2329\n",
      "2025-09-23 02:21:26.225839: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e81d00 of size 256 next 2405\n",
      "2025-09-23 02:21:26.225841: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e81e00 of size 256 next 1996\n",
      "2025-09-23 02:21:26.225842: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e81f00 of size 512 next 744\n",
      "2025-09-23 02:21:26.225843: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e82100 of size 1536 next 1819\n",
      "2025-09-23 02:21:26.225845: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1788e82700 of size 89915392 next 2106\n",
      "2025-09-23 02:21:26.225846: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 178e442700 of size 89915392 next 1855\n",
      "2025-09-23 02:21:26.225847: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1793a02700 of size 89915392 next 1844\n",
      "2025-09-23 02:21:26.225848: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1798fc2700 of size 89915392 next 2135\n",
      "2025-09-23 02:21:26.225849: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 179e582700 of size 89915392 next 1937\n",
      "2025-09-23 02:21:26.225851: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17a3b42700 of size 89915392 next 2313\n",
      "2025-09-23 02:21:26.225852: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17a9102700 of size 89915392 next 1825\n",
      "2025-09-23 02:21:26.225853: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17ae6c2700 of size 89915392 next 1910\n",
      "2025-09-23 02:21:26.225854: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17b3c82700 of size 89915392 next 2200\n",
      "2025-09-23 02:21:26.225856: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17b9242700 of size 89915392 next 2290\n",
      "2025-09-23 02:21:26.225857: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17be802700 of size 89915392 next 1956\n",
      "2025-09-23 02:21:26.225858: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c3dc2700 of size 22478848 next 1788\n",
      "2025-09-23 02:21:26.225859: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c5332700 of size 22478848 next 2223\n",
      "2025-09-23 02:21:26.225861: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c68a2700 of size 22478848 next 1965\n",
      "2025-09-23 02:21:26.225862: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c7e12700 of size 256 next 2384\n",
      "2025-09-23 02:21:26.225863: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c7e12800 of size 256 next 2052\n",
      "2025-09-23 02:21:26.225864: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c7e12900 of size 11239424 next 1787\n",
      "2025-09-23 02:21:26.225866: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88ca900 of size 1536 next 1874\n",
      "2025-09-23 02:21:26.225867: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88caf00 of size 1536 next 1875\n",
      "2025-09-23 02:21:26.225868: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88cb500 of size 1536 next 2682\n",
      "2025-09-23 02:21:26.225870: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88cbb00 of size 1536 next 2123\n",
      "2025-09-23 02:21:26.225871: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88cc100 of size 1536 next 2128\n",
      "2025-09-23 02:21:26.225872: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88cc700 of size 1536 next 356\n",
      "2025-09-23 02:21:26.225881: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88ccd00 of size 1536 next 1954\n",
      "2025-09-23 02:21:26.225883: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88cd300 of size 1536 next 397\n",
      "2025-09-23 02:21:26.225885: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88cd900 of size 10752 next 1815\n",
      "2025-09-23 02:21:26.225886: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88d0300 of size 10752 next 2595\n",
      "2025-09-23 02:21:26.225888: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88d2d00 of size 2816 next 2187\n",
      "2025-09-23 02:21:26.225889: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88d3800 of size 2816 next 1924\n",
      "2025-09-23 02:21:26.225890: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88d4300 of size 2816 next 2606\n",
      "2025-09-23 02:21:26.225892: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88d4e00 of size 10752 next 2155\n",
      "2025-09-23 02:21:26.225893: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88d7800 of size 10752 next 1948\n",
      "2025-09-23 02:21:26.225895: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17c88da200 of size 33654528 next 2599\n",
      "2025-09-23 02:21:26.225896: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17ca8f2900 of size 11239424 next 2067\n",
      "2025-09-23 02:21:26.225898: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17cb3aa900 of size 178218752 next 2664\n",
      "2025-09-23 02:21:26.225899: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17d5da1000 of size 768 next 1921\n",
      "2025-09-23 02:21:26.225908: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17d5da1300 of size 512 next 2675\n",
      "2025-09-23 02:21:26.225912: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17d5da1500 of size 512 next 2116\n",
      "2025-09-23 02:21:26.225914: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17d5da1700 of size 512 next 2297\n",
      "2025-09-23 02:21:26.225916: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17d5da1900 of size 768 next 2300\n",
      "2025-09-23 02:21:26.225917: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17d5da1c00 of size 768 next 2708\n",
      "2025-09-23 02:21:26.225918: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17d5da1f00 of size 512 next 2332\n",
      "2025-09-23 02:21:26.225920: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17d5da2100 of size 512 next 1846\n",
      "2025-09-23 02:21:26.225921: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17d5da2300 of size 512 next 2175\n",
      "2025-09-23 02:21:26.225923: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17d5da2500 of size 1536 next 2028\n",
      "2025-09-23 02:21:26.225924: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17d5da2b00 of size 89915392 next 2298\n",
      "2025-09-23 02:21:26.225926: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17db362b00 of size 89915392 next 514\n",
      "2025-09-23 02:21:26.225927: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17e0922b00 of size 89915392 next 2163\n",
      "2025-09-23 02:21:26.225928: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17e5ee2b00 of size 89915392 next 2160\n",
      "2025-09-23 02:21:26.225930: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17eb4a2b00 of size 89915392 next 2731\n",
      "2025-09-23 02:21:26.225931: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17f0a62b00 of size 89915392 next 2637\n",
      "2025-09-23 02:21:26.225932: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17f6022b00 of size 89915392 next 2536\n",
      "2025-09-23 02:21:26.225934: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17fb5e2b00 of size 22478848 next 2611\n",
      "2025-09-23 02:21:26.225935: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17fcb52b00 of size 22478848 next 97\n",
      "2025-09-23 02:21:26.225937: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17fe0c2b00 of size 22478848 next 2634\n",
      "2025-09-23 02:21:26.225938: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 17ff632b00 of size 11239424 next 2088\n",
      "2025-09-23 02:21:26.225939: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000eab00 of size 1024 next 2476\n",
      "2025-09-23 02:21:26.225941: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000eaf00 of size 1024 next 1973\n",
      "2025-09-23 02:21:26.225942: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000eb300 of size 1024 next 2757\n",
      "2025-09-23 02:21:26.225944: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000eb700 of size 1024 next 2754\n",
      "2025-09-23 02:21:26.225945: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000ebb00 of size 1024 next 2324\n",
      "2025-09-23 02:21:26.225946: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000ebf00 of size 1024 next 1926\n",
      "2025-09-23 02:21:26.225947: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000ec300 of size 1024 next 1894\n",
      "2025-09-23 02:21:26.225949: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000ec700 of size 1024 next 2438\n",
      "2025-09-23 02:21:26.225950: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000ecb00 of size 1024 next 1884\n",
      "2025-09-23 02:21:26.225951: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000ecf00 of size 1024 next 2414\n",
      "2025-09-23 02:21:26.225952: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000ed300 of size 1024 next 2499\n",
      "2025-09-23 02:21:26.225954: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000ed700 of size 7168 next 2110\n",
      "2025-09-23 02:21:26.225955: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000ef300 of size 7168 next 2558\n",
      "2025-09-23 02:21:26.225956: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000f0f00 of size 1792 next 1953\n",
      "2025-09-23 02:21:26.225958: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000f1600 of size 1792 next 2487\n",
      "2025-09-23 02:21:26.225959: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000f1d00 of size 7168 next 2154\n",
      "2025-09-23 02:21:26.225960: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000f3900 of size 7168 next 2714\n",
      "2025-09-23 02:21:26.225962: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18000f5500 of size 33674752 next 1842\n",
      "2025-09-23 02:21:26.225963: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1802112b00 of size 11239424 next 2665\n",
      "2025-09-23 02:21:26.225965: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1802bcab00 of size 89915392 next 2091\n",
      "2025-09-23 02:21:26.225966: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 180818ab00 of size 89915392 next 2512\n",
      "2025-09-23 02:21:26.225967: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 180d74ab00 of size 89915392 next 2683\n",
      "2025-09-23 02:21:26.225968: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1812d0ab00 of size 89915392 next 2748\n",
      "2025-09-23 02:21:26.225970: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18182cab00 of size 158951168 next 2609\n",
      "2025-09-23 02:21:26.225973: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1821a61200 of size 512 next 2281\n",
      "2025-09-23 02:21:26.225974: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1821a61400 of size 512 next 1870\n",
      "2025-09-23 02:21:26.225976: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1821a61600 of size 25690112 next 1858\n",
      "2025-09-23 02:21:26.225977: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18232e1600 of size 25690112 next 2353\n",
      "2025-09-23 02:21:26.225979: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1824b61600 of size 25690112 next 2544\n",
      "2025-09-23 02:21:26.225980: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18263e1600 of size 25690112 next 1882\n",
      "2025-09-23 02:21:26.225982: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1827c61600 of size 25690112 next 2752\n",
      "2025-09-23 02:21:26.225983: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18294e1600 of size 25690112 next 2517\n",
      "2025-09-23 02:21:26.225985: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 182ad61600 of size 25690112 next 1830\n",
      "2025-09-23 02:21:26.225986: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 182c5e1600 of size 25690112 next 2695\n",
      "2025-09-23 02:21:26.225988: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 182de61600 of size 25691136 next 1775\n",
      "2025-09-23 02:21:26.225989: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 182f6e1a00 of size 1024 next 1793\n",
      "2025-09-23 02:21:26.225990: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 182f6e1e00 of size 51380224 next 2245\n",
      "2025-09-23 02:21:26.225992: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18327e1e00 of size 51380224 next 2412\n",
      "2025-09-23 02:21:26.225993: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18358e1e00 of size 51380224 next 2591\n",
      "2025-09-23 02:21:26.225995: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18389e1e00 of size 51380224 next 2586\n",
      "2025-09-23 02:21:26.225996: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 183bae1e00 of size 22478848 next 2166\n",
      "2025-09-23 02:21:26.225997: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 183d051e00 of size 22478848 next 2514\n",
      "2025-09-23 02:21:26.225998: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 183e5c1e00 of size 22478848 next 2236\n",
      "2025-09-23 02:21:26.226000: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 183fb31e00 of size 11239424 next 169\n",
      "2025-09-23 02:21:26.226001: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18405e9e00 of size 7168 next 2387\n",
      "2025-09-23 02:21:26.226003: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18405eba00 of size 7168 next 374\n",
      "2025-09-23 02:21:26.226004: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18405ed600 of size 1792 next 2082\n",
      "2025-09-23 02:21:26.226005: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18405edd00 of size 1792 next 575\n",
      "2025-09-23 02:21:26.226006: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18405ee400 of size 1792 next 2673\n",
      "2025-09-23 02:21:26.226008: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18405eeb00 of size 1792 next 2547\n",
      "2025-09-23 02:21:26.226009: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18405ef200 of size 7168 next 2337\n",
      "2025-09-23 02:21:26.226010: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18405f0e00 of size 7168 next 2182\n",
      "2025-09-23 02:21:26.226015: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18405f2a00 of size 33682432 next 2587\n",
      "2025-09-23 02:21:26.226016: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1842611e00 of size 11239424 next 2567\n",
      "2025-09-23 02:21:26.226018: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 18430c9e00 of size 89915392 next 2582\n",
      "2025-09-23 02:21:26.226019: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1848689e00 of size 89915392 next 2225\n",
      "2025-09-23 02:21:26.226020: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 184dc49e00 of size 144400896 next 18446744073709551615\n",
      "2025-09-23 02:21:26.226022: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2025-09-23 02:21:26.226025: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 717 Chunks of size 256 totalling 179.2KiB\n",
      "2025-09-23 02:21:26.226034: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 239 Chunks of size 512 totalling 119.5KiB\n",
      "2025-09-23 02:21:26.226037: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 189 Chunks of size 768 totalling 141.8KiB\n",
      "2025-09-23 02:21:26.226039: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 238 Chunks of size 1024 totalling 238.0KiB\n",
      "2025-09-23 02:21:26.226042: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 10 Chunks of size 1280 totalling 12.5KiB\n",
      "2025-09-23 02:21:26.226051: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 50 Chunks of size 1536 totalling 75.0KiB\n",
      "2025-09-23 02:21:26.226054: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 23 Chunks of size 1792 totalling 40.2KiB\n",
      "2025-09-23 02:21:26.226056: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 91 Chunks of size 2048 totalling 182.0KiB\n",
      "2025-09-23 02:21:26.226058: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 25 Chunks of size 2304 totalling 56.2KiB\n",
      "2025-09-23 02:21:26.226067: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 2560 totalling 7.5KiB\n",
      "2025-09-23 02:21:26.226070: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 2816 totalling 8.2KiB\n",
      "2025-09-23 02:21:26.226072: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 3072 totalling 9.0KiB\n",
      "2025-09-23 02:21:26.226074: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 3328 totalling 13.0KiB\n",
      "2025-09-23 02:21:26.226076: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 3584 totalling 7.0KiB\n",
      "2025-09-23 02:21:26.226078: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 13 Chunks of size 3840 totalling 48.8KiB\n",
      "2025-09-23 02:21:26.226079: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 46 Chunks of size 4096 totalling 184.0KiB\n",
      "2025-09-23 02:21:26.226081: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 4352 totalling 8.5KiB\n",
      "2025-09-23 02:21:26.226082: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 4608 totalling 27.0KiB\n",
      "2025-09-23 02:21:26.226083: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 5120 totalling 20.0KiB\n",
      "2025-09-23 02:21:26.226085: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 5888 totalling 34.5KiB\n",
      "2025-09-23 02:21:26.226086: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 14 Chunks of size 6144 totalling 84.0KiB\n",
      "2025-09-23 02:21:26.226088: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 16 Chunks of size 6912 totalling 108.0KiB\n",
      "2025-09-23 02:21:26.226090: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 21 Chunks of size 7168 totalling 147.0KiB\n",
      "2025-09-23 02:21:26.226091: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 7680 totalling 7.5KiB\n",
      "2025-09-23 02:21:26.226092: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 87 Chunks of size 8192 totalling 696.0KiB\n",
      "2025-09-23 02:21:26.226094: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 8704 totalling 8.5KiB\n",
      "2025-09-23 02:21:26.226095: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 9472 totalling 9.2KiB\n",
      "2025-09-23 02:21:26.226097: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 10240 totalling 10.0KiB\n",
      "2025-09-23 02:21:26.226099: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 10752 totalling 42.0KiB\n",
      "2025-09-23 02:21:26.226100: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 11776 totalling 11.5KiB\n",
      "2025-09-23 02:21:26.226102: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 12032 totalling 11.8KiB\n",
      "2025-09-23 02:21:26.226103: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 12288 totalling 12.0KiB\n",
      "2025-09-23 02:21:26.226105: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 12800 totalling 50.0KiB\n",
      "2025-09-23 02:21:26.226106: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 13312 totalling 13.0KiB\n",
      "2025-09-23 02:21:26.226108: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 14336 totalling 14.0KiB\n",
      "2025-09-23 02:21:26.226109: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 13 Chunks of size 15360 totalling 195.0KiB\n",
      "2025-09-23 02:21:26.226111: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 15616 totalling 15.2KiB\n",
      "2025-09-23 02:21:26.226112: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 16128 totalling 15.8KiB\n",
      "2025-09-23 02:21:26.226114: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 18 Chunks of size 16384 totalling 288.0KiB\n",
      "2025-09-23 02:21:26.226115: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 12 Chunks of size 18432 totalling 216.0KiB\n",
      "2025-09-23 02:21:26.226116: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 21504 totalling 42.0KiB\n",
      "2025-09-23 02:21:26.226118: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 35 Chunks of size 25088 totalling 857.5KiB\n",
      "2025-09-23 02:21:26.226127: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 13 Chunks of size 25600 totalling 325.0KiB\n",
      "2025-09-23 02:21:26.226130: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 27648 totalling 27.0KiB\n",
      "2025-09-23 02:21:26.226132: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 28672 totalling 168.0KiB\n",
      "2025-09-23 02:21:26.226133: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 30720 totalling 60.0KiB\n",
      "2025-09-23 02:21:26.226135: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 32256 totalling 31.5KiB\n",
      "2025-09-23 02:21:26.226136: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 32512 totalling 31.8KiB\n",
      "2025-09-23 02:21:26.226138: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 35840 totalling 35.0KiB\n",
      "2025-09-23 02:21:26.226139: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 36096 totalling 35.2KiB\n",
      "2025-09-23 02:21:26.226141: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 43 Chunks of size 36864 totalling 1.51MiB\n",
      "2025-09-23 02:21:26.226143: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 38912 totalling 38.0KiB\n",
      "2025-09-23 02:21:26.226144: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 40960 totalling 40.0KiB\n",
      "2025-09-23 02:21:26.226145: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 43008 totalling 252.0KiB\n",
      "2025-09-23 02:21:26.226147: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 46080 totalling 45.0KiB\n",
      "2025-09-23 02:21:26.226148: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 49408 totalling 48.2KiB\n",
      "2025-09-23 02:21:26.226150: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 118 Chunks of size 50176 totalling 5.65MiB\n",
      "2025-09-23 02:21:26.226152: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 51200 totalling 300.0KiB\n",
      "2025-09-23 02:21:26.226153: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 52224 totalling 51.0KiB\n",
      "2025-09-23 02:21:26.226155: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 55808 totalling 54.5KiB\n",
      "2025-09-23 02:21:26.226156: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 56576 totalling 55.2KiB\n",
      "2025-09-23 02:21:26.226158: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 57344 totalling 224.0KiB\n",
      "2025-09-23 02:21:26.226159: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 58368 totalling 57.0KiB\n",
      "2025-09-23 02:21:26.226161: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 61440 totalling 360.0KiB\n",
      "2025-09-23 02:21:26.226162: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 61696 totalling 60.2KiB\n",
      "2025-09-23 02:21:26.226164: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 69888 totalling 68.2KiB\n",
      "2025-09-23 02:21:26.226165: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 36 Chunks of size 73728 totalling 2.53MiB\n",
      "2025-09-23 02:21:26.226167: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 75776 totalling 148.0KiB\n",
      "2025-09-23 02:21:26.226168: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 76800 totalling 450.0KiB\n",
      "2025-09-23 02:21:26.226170: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 85760 totalling 83.8KiB\n",
      "2025-09-23 02:21:26.226171: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 97792 totalling 95.5KiB\n",
      "2025-09-23 02:21:26.226173: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 102400 totalling 100.0KiB\n",
      "2025-09-23 02:21:26.226174: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 107520 totalling 630.0KiB\n",
      "2025-09-23 02:21:26.226183: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 12 Chunks of size 112896 totalling 1.29MiB\n",
      "2025-09-23 02:21:26.226187: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 113152 totalling 110.5KiB\n",
      "2025-09-23 02:21:26.226189: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 7 Chunks of size 115200 totalling 787.5KiB\n",
      "2025-09-23 02:21:26.226190: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 131072 totalling 128.0KiB\n",
      "2025-09-23 02:21:26.226192: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 149248 totalling 145.8KiB\n",
      "2025-09-23 02:21:26.226194: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 14 Chunks of size 153600 totalling 2.05MiB\n",
      "2025-09-23 02:21:26.226195: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 168704 totalling 164.8KiB\n",
      "2025-09-23 02:21:26.226197: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 172032 totalling 168.0KiB\n",
      "2025-09-23 02:21:26.226198: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 181248 totalling 177.0KiB\n",
      "2025-09-23 02:21:26.226200: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 185600 totalling 181.2KiB\n",
      "2025-09-23 02:21:26.226201: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 225792 totalling 220.5KiB\n",
      "2025-09-23 02:21:26.226203: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 37 Chunks of size 230400 totalling 8.13MiB\n",
      "2025-09-23 02:21:26.226212: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 338688 totalling 330.8KiB\n",
      "2025-09-23 02:21:26.226215: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 456704 totalling 446.0KiB\n",
      "2025-09-23 02:21:26.226218: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 615424 totalling 601.0KiB\n",
      "2025-09-23 02:21:26.226220: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 677376 totalling 3.88MiB\n",
      "2025-09-23 02:21:26.226222: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 691200 totalling 3.96MiB\n",
      "2025-09-23 02:21:26.226224: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 17 Chunks of size 1382400 totalling 22.41MiB\n",
      "2025-09-23 02:21:26.226226: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1480704 totalling 1.41MiB\n",
      "2025-09-23 02:21:26.226227: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 16 Chunks of size 6422528 totalling 98.00MiB\n",
      "2025-09-23 02:21:26.226229: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 6741504 totalling 6.43MiB\n",
      "2025-09-23 02:21:26.226231: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 7175424 totalling 6.84MiB\n",
      "2025-09-23 02:21:26.226232: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 7393536 totalling 7.05MiB\n",
      "2025-09-23 02:21:26.226234: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 12 Chunks of size 11239424 totalling 128.62MiB\n",
      "2025-09-23 02:21:26.226243: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 12397312 totalling 11.82MiB\n",
      "2025-09-23 02:21:26.226246: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 28 Chunks of size 12845056 totalling 343.00MiB\n",
      "2025-09-23 02:21:26.226248: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 8 Chunks of size 16056320 totalling 122.50MiB\n",
      "2025-09-23 02:21:26.226250: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 13 Chunks of size 19267584 totalling 238.88MiB\n",
      "2025-09-23 02:21:26.226252: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 18 Chunks of size 22478848 totalling 385.88MiB\n",
      "2025-09-23 02:21:26.226254: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 25033728 totalling 23.87MiB\n",
      "2025-09-23 02:21:26.226255: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 25476096 totalling 24.30MiB\n",
      "2025-09-23 02:21:26.226257: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 25535232 totalling 24.35MiB\n",
      "2025-09-23 02:21:26.226259: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 56 Chunks of size 25690112 totalling 1.34GiB\n",
      "2025-09-23 02:21:26.226260: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 25691136 totalling 24.50MiB\n",
      "2025-09-23 02:21:26.226262: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 27176704 totalling 25.92MiB\n",
      "2025-09-23 02:21:26.226263: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 28901888 totalling 27.56MiB\n",
      "2025-09-23 02:21:26.226264: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 29491200 totalling 28.12MiB\n",
      "2025-09-23 02:21:26.226266: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 30801920 totalling 29.38MiB\n",
      "2025-09-23 02:21:26.226268: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 12 Chunks of size 32112640 totalling 367.50MiB\n",
      "2025-09-23 02:21:26.226269: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 33654528 totalling 32.09MiB\n",
      "2025-09-23 02:21:26.226278: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 33669888 totalling 32.11MiB\n",
      "2025-09-23 02:21:26.226281: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 33670912 totalling 32.11MiB\n",
      "2025-09-23 02:21:26.226284: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 33674752 totalling 32.11MiB\n",
      "2025-09-23 02:21:26.226285: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 33677056 totalling 32.12MiB\n",
      "2025-09-23 02:21:26.226287: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 33682432 totalling 32.12MiB\n",
      "2025-09-23 02:21:26.226289: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 13 Chunks of size 38535168 totalling 477.75MiB\n",
      "2025-09-23 02:21:26.226290: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 44957696 totalling 257.25MiB\n",
      "2025-09-23 02:21:26.226292: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 48070912 totalling 45.84MiB\n",
      "2025-09-23 02:21:26.226293: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 48083456 totalling 91.71MiB\n",
      "2025-09-23 02:21:26.226295: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 13 Chunks of size 51380224 totalling 637.00MiB\n",
      "2025-09-23 02:21:26.226296: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 57765120 totalling 110.18MiB\n",
      "2025-09-23 02:21:26.226299: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 57766656 totalling 55.09MiB\n",
      "2025-09-23 02:21:26.226301: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 57802752 totalling 55.12MiB\n",
      "2025-09-23 02:21:26.226303: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 13 Chunks of size 64225280 totalling 796.25MiB\n",
      "2025-09-23 02:21:26.226304: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 41 Chunks of size 77070336 totalling 2.94GiB\n",
      "2025-09-23 02:21:26.226306: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 80269312 totalling 76.55MiB\n",
      "2025-09-23 02:21:26.226307: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 82607104 totalling 78.78MiB\n",
      "2025-09-23 02:21:26.226309: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 85008384 totalling 81.07MiB\n",
      "2025-09-23 02:21:26.226318: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 64 Chunks of size 89915392 totalling 5.36GiB\n",
      "2025-09-23 02:21:26.226321: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 96338432 totalling 91.88MiB\n",
      "2025-09-23 02:21:26.226324: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 104366592 totalling 99.53MiB\n",
      "2025-09-23 02:21:26.226325: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 7 Chunks of size 134873088 totalling 900.38MiB\n",
      "2025-09-23 02:21:26.226334: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 144400896 totalling 137.71MiB\n",
      "2025-09-23 02:21:26.226337: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 158951168 totalling 151.59MiB\n",
      "2025-09-23 02:21:26.226340: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 165374976 totalling 157.71MiB\n",
      "2025-09-23 02:21:26.226342: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 174587904 totalling 166.50MiB\n",
      "2025-09-23 02:21:26.226343: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 178218752 totalling 339.92MiB\n",
      "2025-09-23 02:21:26.226345: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 22 Chunks of size 192675840 totalling 3.95GiB\n",
      "2025-09-23 02:21:26.226347: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 261710336 totalling 249.59MiB\n",
      "2025-09-23 02:21:26.226348: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 317907968 totalling 303.18MiB\n",
      "2025-09-23 02:21:26.226350: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 20.95GiB\n",
      "2025-09-23 02:21:26.226352: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 22500343808 memory_limit_: 22500343808 available bytes: 0 curr_region_allocation_bytes_: 34359738368\n",
      "2025-09-23 02:21:26.226356: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                     22500343808\n",
      "InUse:                     22500271360\n",
      "MaxInUse:                  22500271360\n",
      "NumAllocs:                       34883\n",
      "MaxAllocSize:               1259334912\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-09-23 02:21:26.226385: W tensorflow/tsl/framework/bfc_allocator.cc:497] ****************************************************************************************************\n",
      "2025-09-23 02:21:26.226405: W tensorflow/core/framework/op_kernel.cc:1816] RESOURCE_EXHAUSTED: failed to allocate memory\n",
      "[train_one_cfg.py ERROR]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/c/Downloads/DL_TENSOR_PJS/Capston_2025/Multi-EffNet/Deep_Learning/train_one_cfg.py\", line 106, in <module>\n",
      "    _ = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, verbose=0, callbacks=[BestSaver(out_dir)])\n",
      "  File \"/home/four/anaconda3/envs/TF213_Torch/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/four/anaconda3/envs/TF213_Torch/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:\n",
      "\n",
      "Detected at node 'sub_2' defined at (most recent call last):\n",
      "    File \"/mnt/c/Downloads/DL_TENSOR_PJS/Capston_2025/Multi-EffNet/Deep_Learning/train_one_cfg.py\", line 106, in <module>\n",
      "      _ = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, verbose=0, callbacks=[BestSaver(out_dir)])\n",
      "    File \"/home/four/anaconda3/envs/TF213_Torch/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/four/anaconda3/envs/TF213_Torch/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1742, in fit\n",
      "      tmp_logs = self.train_function(iterator)\n",
      "    File \"/home/four/anaconda3/envs/TF213_Torch/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"/home/four/anaconda3/envs/TF213_Torch/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/home/four/anaconda3/envs/TF213_Torch/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n",
      "      outputs = model.train_step(data)\n",
      "    File \"/home/four/anaconda3/envs/TF213_Torch/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1084, in train_step\n",
      "      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n",
      "    File \"/home/four/anaconda3/envs/TF213_Torch/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 543, in minimize\n",
      "      grads_and_vars = self.compute_gradients(loss, var_list, tape)\n",
      "    File \"/home/four/anaconda3/envs/TF213_Torch/lib/python3.10/site-packages/keras/src/mixed_precision/loss_scale_optimizer.py\", line 1256, in compute_gradients\n",
      "      grads_and_vars = self._optimizer.compute_gradients(\n",
      "    File \"/home/four/anaconda3/envs/TF213_Torch/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 276, in compute_gradients\n",
      "      grads = tape.gradient(loss, var_list)\n",
      "Node: 'sub_2'\n",
      "failed to allocate memory\n",
      "\t [[{{node sub_2}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      " [Op:__inference_train_function_90533]\n",
      "\n",
      "\n",
      "[Subprocess Error] status!=ok : {'status': 'error', 'message': 'Graph execution error:\\n\\nDetected at node \\'sub_2\\' defined at (most recent call last):\\n    File \"/mnt/c/Downloads/DL_TENSOR_PJS/Capston_2025/Multi-EffNet/Deep_Learning/train_one_cfg.py\", line 106, in <module>\\n      _ = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, verbose=0, callbacks=[BestSaver(out_dir)])\\n    File \"/home/four/anaconda3/envs/TF213_Torch/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\\n      return fn(*args, **kwargs)\\n    File \"/home/four/anaconda3/envs/TF213_Torch/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1742, in fit\\n      tmp_logs = self.train_function(iterator)\\n    File \"/home/four/anaconda3/envs/TF213_Torch/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1338, in train_function\\n      return step_function(self, iterator)\\n    File \"/home/four/anaconda3/envs/TF213_Torch/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1322, in step_function\\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\\n    File \"/home/four/anaconda3/envs/TF213_Torch/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1303, in run_step\\n      outputs = model.train_step(data)\\n    File \"/home/four/anaconda3/envs/TF213_Torch/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1084, in train_step\\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\\n    File \"/home/four/anaconda3/envs/TF213_Torch/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 543, in minimize\\n      grads_and_vars = self.compute_gradients(loss, var_list, tape)\\n    File \"/home/four/anaconda3/envs/TF213_Torch/lib/python3.10/site-packages/keras/src/mixed_precision/loss_scale_optimizer.py\", line 1256, in compute_gradients\\n      grads_and_vars = self._optimizer.compute_gradients(\\n    File \"/home/four/anaconda3/envs/TF213_Torch/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 276, in compute_gradients\\n      grads = tape.gradient(loss, var_list)\\nNode: \\'sub_2\\'\\nfailed to allocate memory\\n\\t [[{{node sub_2}}]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn\\'t available when running in Eager mode.\\n [Op:__inference_train_function_90533]'}\n",
      "\n",
      "[Run-START] g02_39138b04\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 24, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 24, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 02:21:28.097620: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 02:21:28.119662: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 02:21:28.537079: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 02:21:29.346505: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:21:29.357153: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:21:29.357421: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:21:29.357879: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:21:35.221150: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:21:35.221399: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:21:35.221581: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:21:35.303740: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:21:35.303912: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:21:35.303928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 02:21:35.304015: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:21:35.304047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 02:21:54.055640: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 02:21:54.583184: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 02:21:54.941230: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd31116ae40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 02:21:54.941277: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 02:21:54.943954: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 02:21:55.003856: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=4.6394 -> experiments/Step_00/nas_runs/g02_39138b04/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4556 loss=1.7879 -> experiments/Step_00/nas_runs/g02_39138b04/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8500 loss=0.4631 -> experiments/Step_00/nas_runs/g02_39138b04/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9352 loss=0.1756 -> experiments/Step_00/nas_runs/g02_39138b04/best_model.keras\n",
      "\n",
      "[Run-DONE ] g02_39138b04 | time=169.3s | acc=0.9352 | loss=0.1756 | params=3,815,871\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g02_11efc741\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 02:24:55.147488: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 02:24:55.169709: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 02:24:55.595232: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 02:24:56.330263: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:24:56.341751: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:24:56.341951: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:24:56.342439: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:25:02.270860: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:25:02.271054: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:25:02.271193: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:25:02.352998: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:25:02.353227: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:25:02.353246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 02:25:02.353388: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:25:02.353432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 02:25:15.384658: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 02:25:15.949327: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 02:25:16.369840: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d484a0e680 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 02:25:16.369871: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 02:25:16.372969: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 02:25:16.434754: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0648 loss=6.1461 -> experiments/Step_00/nas_runs/g02_11efc741/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.3648 loss=2.9532 -> experiments/Step_00/nas_runs/g02_11efc741/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.5574 loss=2.2649 -> experiments/Step_00/nas_runs/g02_11efc741/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.7648 loss=1.0448 -> experiments/Step_00/nas_runs/g02_11efc741/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9630 loss=0.1250 -> experiments/Step_00/nas_runs/g02_11efc741/best_model.keras\n",
      "\n",
      "[Run-DONE ] g02_11efc741 | time=120.7s | acc=0.9630 | loss=0.1250 | params=4,401,055\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g02_9e5abace\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 02:27:27.831751: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 02:27:27.853950: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 02:27:28.293684: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 02:27:29.006840: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:27:29.017809: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:27:29.017958: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:27:29.018313: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:27:34.834655: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:27:34.834856: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:27:34.834994: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:27:34.924908: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:27:34.925119: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:27:34.925142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 02:27:34.925317: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:27:34.925360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 02:27:48.907676: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 02:27:49.588089: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 02:27:50.184974: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa72c006c30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 02:27:50.185006: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 02:27:50.188087: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 02:27:50.278018: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.8139 -> experiments/Step_00/nas_runs/g02_9e5abace/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.5889 loss=1.1709 -> experiments/Step_00/nas_runs/g02_9e5abace/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.8185 loss=0.5541 -> experiments/Step_00/nas_runs/g02_9e5abace/best_model.keras\n",
      "\n",
      "[Run-DONE ] g02_9e5abace | time=242.6s | acc=0.8185 | loss=0.5541 | params=670,599\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Gen 2] Leaderboard (Top 11)\n",
      " rank    hash8  fitness      acc     loss  params        sec\n",
      "    1 11efc741 0.946494 0.962963 0.125050 4401055 120.675175\n",
      "    2 6531be99 0.939145 0.955556 0.120880 1895663 145.151026\n",
      "    3 a93de1bf 0.914797 0.933333 0.237686 1691599 168.442827\n",
      "    4 39138b04 0.914442 0.935185 0.175605 3815871 169.277411\n",
      "    5 fe8d833c 0.897694 0.918519 0.192434 1663935 191.609801\n",
      "    6 4eb9f618 0.889014 0.909259 0.288303 2664871 175.799131\n",
      "    7 449f5166 0.887429 0.909259 0.268159 6671863 151.585911\n",
      "    8 de747bc2 0.876275 0.898148 0.314928 3119127 187.537631\n",
      "    9 c0796665 0.867942 0.890741 0.347701 4749727 180.491383\n",
      "   10 9e5abace 0.793586 0.818519 0.554057  670599 242.615065\n",
      "   11 8762eff1 0.739975 0.770370 0.844574 4317295 260.776118\n",
      "[GC] Gen 2: removed 3 run dirs (non-top4)\n",
      "     g02_c0796665, g02_9e5abace, g02_8762eff1\n",
      "\n",
      "========= Generation 3 START (pop=12) =========\n",
      "\n",
      "[Run-START] g03_a4edcdb8\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 02:31:50.285832: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 02:31:50.306130: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 02:31:50.815184: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 02:31:51.533023: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:31:51.544303: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:31:51.544524: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:31:51.544902: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:31:57.587123: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:31:57.587392: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:31:57.587581: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:31:57.667973: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:31:57.668198: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:31:57.668218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 02:31:57.668404: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:31:57.668451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 02:32:16.492495: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 02:32:16.939441: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 02:32:17.234475: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4ca8003380 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 02:32:17.234503: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 02:32:17.238119: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 02:32:17.302973: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.4727 -> experiments/Step_00/nas_runs/g03_a4edcdb8/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.8648 loss=0.5074 -> experiments/Step_00/nas_runs/g03_a4edcdb8/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9870 loss=0.0455 -> experiments/Step_00/nas_runs/g03_a4edcdb8/best_model.keras\n",
      "\n",
      "[Run-DONE ] g03_a4edcdb8 | time=153.3s | acc=0.9870 | loss=0.0455 | params=2,253,639\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g03_78dd026a\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 6, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 6, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 02:34:54.203417: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 02:34:54.226172: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 02:34:54.686375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 02:34:55.367817: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:34:55.378722: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:34:55.378920: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:34:55.379323: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:35:01.409672: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:35:01.409911: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:35:01.410046: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:35:01.492759: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:35:01.492936: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:35:01.492955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 02:35:01.493055: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:35:01.493086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 02:35:18.029424: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 02:35:18.682063: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 02:35:19.006962: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7feae0002300 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 02:35:19.006992: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 02:35:19.010260: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 02:35:19.075613: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.2093 -> experiments/Step_00/nas_runs/g03_78dd026a/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.8093 loss=0.6152 -> experiments/Step_00/nas_runs/g03_78dd026a/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9741 loss=0.0837 -> experiments/Step_00/nas_runs/g03_78dd026a/best_model.keras\n",
      "\n",
      "[Run-DONE ] g03_78dd026a | time=141.6s | acc=0.9741 | loss=0.0837 | params=2,360,239\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g03_03a4d654\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 24, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 24, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 02:37:49.264789: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 02:37:49.285783: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 02:37:49.741444: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 02:37:50.496780: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:37:50.508635: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:37:50.508856: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:37:50.509239: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:37:56.480335: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:37:56.480546: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:37:56.480670: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:37:56.567648: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:37:56.567923: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:37:56.567945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 02:37:56.568320: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:37:56.568367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 02:38:17.792867: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 02:38:18.422532: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 02:38:18.917940: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f34b0012490 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 02:38:18.917970: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 02:38:18.921152: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 02:38:18.994191: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.3453 -> experiments/Step_00/nas_runs/g03_03a4d654/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.5056 loss=1.8708 -> experiments/Step_00/nas_runs/g03_03a4d654/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8352 loss=0.5311 -> experiments/Step_00/nas_runs/g03_03a4d654/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.8796 loss=0.3978 -> experiments/Step_00/nas_runs/g03_03a4d654/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9556 loss=0.1325 -> experiments/Step_00/nas_runs/g03_03a4d654/best_model.keras\n",
      "\n",
      "[Run-DONE ] g03_03a4d654 | time=219.6s | acc=0.9556 | loss=0.1325 | params=6,383,191\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g03_0bc91b4a\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 02:42:29.705071: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 02:42:29.725355: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 02:42:30.203211: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 02:42:30.890668: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:42:30.901142: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:42:30.901462: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:42:30.902155: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:42:36.746540: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:42:36.746728: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:42:36.746846: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:42:36.902920: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:42:36.903118: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:42:36.903137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 02:42:36.903285: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:42:36.903329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 02:42:56.094025: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 02:42:56.513699: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 02:42:56.759839: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f52340024e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 02:42:56.759881: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 02:42:56.763585: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 02:42:56.828583: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.5346 -> experiments/Step_00/nas_runs/g03_0bc91b4a/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.5444 loss=1.5183 -> experiments/Step_00/nas_runs/g03_0bc91b4a/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8704 loss=0.3842 -> experiments/Step_00/nas_runs/g03_0bc91b4a/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9685 loss=0.1019 -> experiments/Step_00/nas_runs/g03_0bc91b4a/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9778 loss=0.0688 -> experiments/Step_00/nas_runs/g03_0bc91b4a/best_model.keras\n",
      "\n",
      "[Run-DONE ] g03_0bc91b4a | time=158.1s | acc=0.9778 | loss=0.0688 | params=1,909,623\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g03_1ddbcc4e\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 32, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 32, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 02:45:40.454654: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 02:45:40.475553: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 02:45:40.905436: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 02:45:41.630999: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:45:41.641474: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:45:41.641664: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:45:41.642046: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:45:47.562582: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:45:47.562821: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:45:47.562953: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:45:47.646070: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:45:47.646200: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:45:47.646214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 02:45:47.646297: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:45:47.646330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 02:46:07.243860: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 02:46:07.723812: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 02:46:08.058856: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555617d8b520 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 02:46:08.058914: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 02:46:08.080903: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 02:46:08.141155: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.6253 -> experiments/Step_00/nas_runs/g03_1ddbcc4e/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.1833 loss=3.8528 -> experiments/Step_00/nas_runs/g03_1ddbcc4e/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8926 loss=0.3369 -> experiments/Step_00/nas_runs/g03_1ddbcc4e/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9370 loss=0.1871 -> experiments/Step_00/nas_runs/g03_1ddbcc4e/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9389 loss=0.1671 -> experiments/Step_00/nas_runs/g03_1ddbcc4e/best_model.keras\n",
      "\n",
      "[Run-DONE ] g03_1ddbcc4e | time=172.8s | acc=0.9389 | loss=0.1671 | params=1,318,807\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g03_0ab33cb7\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 32, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 6, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 32, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 6, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 02:48:59.038062: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 02:48:59.060472: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 02:48:59.564564: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 02:49:00.233352: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:49:00.244177: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:49:00.244359: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:49:00.244756: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:49:06.058994: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:49:06.059212: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:49:06.059383: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:49:06.137366: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:49:06.137538: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:49:06.137555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 02:49:06.137638: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:49:06.137672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 02:49:29.290701: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 02:49:30.130400: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 02:49:30.913781: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0d94014d30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 02:49:30.913811: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 02:49:30.916715: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 02:49:30.991575: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.8134 -> experiments/Step_00/nas_runs/g03_0ab33cb7/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.2593 loss=3.6454 -> experiments/Step_00/nas_runs/g03_0ab33cb7/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.4148 loss=3.2843 -> experiments/Step_00/nas_runs/g03_0ab33cb7/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.7056 loss=1.0577 -> experiments/Step_00/nas_runs/g03_0ab33cb7/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.7833 loss=0.7273 -> experiments/Step_00/nas_runs/g03_0ab33cb7/best_model.keras\n",
      "\n",
      "[Run-DONE ] g03_0ab33cb7 | time=400.5s | acc=0.7833 | loss=0.7273 | params=2,365,303\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g03_a73bad9c\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 02:56:19.823574: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 02:56:19.843987: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 02:56:20.316339: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 02:56:20.999048: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:56:21.009806: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:56:21.010039: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:56:21.010388: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:56:26.933971: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:56:26.934151: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:56:26.934250: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:56:27.018121: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:56:27.018355: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:56:27.018373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 02:56:27.018502: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 02:56:27.018544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 02:56:45.984700: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 02:56:46.844212: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 02:56:47.454243: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9860003500 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 02:56:47.454280: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 02:56:47.457587: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 02:56:47.523587: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.7066 -> experiments/Step_00/nas_runs/g03_a73bad9c/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.2278 loss=7.3129 -> experiments/Step_00/nas_runs/g03_a73bad9c/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.4481 loss=1.7766 -> experiments/Step_00/nas_runs/g03_a73bad9c/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.4944 loss=2.1900 -> experiments/Step_00/nas_runs/g03_a73bad9c/best_model.keras\n",
      "\n",
      "[Run-DONE ] g03_a73bad9c | time=366.3s | acc=0.4944 | loss=2.1900 | params=1,637,343\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g03_90c38ac1\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 03:02:54.099227: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 03:02:54.119968: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 03:02:54.567011: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 03:02:55.233214: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:02:55.244166: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:02:55.244369: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:02:55.244776: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:03:00.133197: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:03:00.133370: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:03:00.133494: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:03:00.220486: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:03:00.220665: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:03:00.220684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 03:03:00.220784: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:03:00.220818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 03:03:14.675279: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 03:03:15.408126: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 03:03:15.940061: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f48f0006020 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 03:03:15.940098: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 03:03:15.943520: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 03:03:16.008376: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.4522 -> experiments/Step_00/nas_runs/g03_90c38ac1/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4870 loss=1.4872 -> experiments/Step_00/nas_runs/g03_90c38ac1/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.8685 loss=0.6673 -> experiments/Step_00/nas_runs/g03_90c38ac1/best_model.keras\n",
      "\n",
      "[Run-DONE ] g03_90c38ac1 | time=263.4s | acc=0.8685 | loss=0.6673 | params=2,831,743\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Gen 3] Leaderboard (Top 12)\n",
      " rank    hash8  fitness      acc     loss  params        sec\n",
      "    1 a4edcdb8 0.969450 0.987037 0.045545 2253639 153.330601\n",
      "    2 0bc91b4a 0.960054 0.977778 0.068818 1909623 158.137564\n",
      "    3 78dd026a 0.957549 0.974074 0.083672 2360239 141.646964\n",
      "    4 11efc741 0.946494 0.962963 0.125050 4401055 120.675175\n",
      "    5 6531be99 0.939145 0.955556 0.120880 1895663 145.151026\n",
      "    6 03a4d654 0.927216 0.955556 0.132515 6383191 219.568524\n",
      "    7 1ddbcc4e 0.920295 0.938889 0.167093 1318807 172.755237\n",
      "    8 a93de1bf 0.914797 0.933333 0.237686 1691599 168.442827\n",
      "    9 39138b04 0.914442 0.935185 0.175605 3815871 169.277411\n",
      "   10 90c38ac1 0.839342 0.868519 0.667327 2831743 263.448175\n",
      "   11 0ab33cb7 0.740914 0.783333 0.727293 2365303 400.538194\n",
      "   12 a73bad9c 0.456179 0.494444 2.190010 1637343 366.278141\n",
      "[GC] Gen 3: removed 5 run dirs (non-top4)\n",
      "     g03_03a4d654, g03_1ddbcc4e, g03_90c38ac1, g03_0ab33cb7, g03_a73bad9c\n",
      "\n",
      "========= Generation 4 START (pop=12) =========\n",
      "\n",
      "[Run-START] g04_94cda7fe\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 03:07:46.754932: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 03:07:46.775907: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 03:07:47.216758: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 03:07:47.942792: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:07:47.953220: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:07:47.953384: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:07:47.953767: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:07:53.641139: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:07:53.641374: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:07:53.641566: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:07:53.726283: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:07:53.726453: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:07:53.726468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 03:07:53.726558: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:07:53.726590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 03:08:12.077855: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 03:08:12.612999: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 03:08:12.996947: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c8430bf50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 03:08:12.996983: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 03:08:13.000086: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 03:08:13.077227: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.4925 -> experiments/Step_00/nas_runs/g04_94cda7fe/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.8204 loss=0.5808 -> experiments/Step_00/nas_runs/g04_94cda7fe/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.9537 loss=0.1666 -> experiments/Step_00/nas_runs/g04_94cda7fe/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9870 loss=0.0447 -> experiments/Step_00/nas_runs/g04_94cda7fe/best_model.keras\n",
      "\n",
      "[Run-DONE ] g04_94cda7fe | time=158.3s | acc=0.9870 | loss=0.0447 | params=2,300,175\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g04_040a5cec\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 80, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 80, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 03:10:56.332668: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 03:10:56.358598: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 03:10:56.799858: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 03:10:57.505890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:10:57.516396: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:10:57.516574: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:10:57.516961: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:11:03.385837: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:11:03.386011: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:11:03.386104: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:11:03.479054: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:11:03.479219: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:11:03.479239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 03:11:03.479333: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:11:03.479364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 03:11:17.415656: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 03:11:18.109735: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 03:11:18.579893: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f594c001c70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 03:11:18.579924: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 03:11:18.583011: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 03:11:18.650731: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.1519 loss=6.6587 -> experiments/Step_00/nas_runs/g04_040a5cec/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.6074 loss=1.2404 -> experiments/Step_00/nas_runs/g04_040a5cec/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.7648 loss=0.6783 -> experiments/Step_00/nas_runs/g04_040a5cec/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.8963 loss=0.2783 -> experiments/Step_00/nas_runs/g04_040a5cec/best_model.keras\n",
      "\n",
      "[Run-DONE ] g04_040a5cec | time=145.4s | acc=0.8963 | loss=0.2783 | params=5,120,079\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g04_76ad6eba\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 4, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 4, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 03:14:01.768932: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 03:14:01.791450: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 03:14:02.235543: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 03:14:02.907996: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:14:02.919532: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:14:02.919736: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:14:02.920132: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:14:09.138370: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:14:09.138691: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:14:09.139233: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:14:09.218830: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:14:09.218961: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:14:09.218976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 03:14:09.219065: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:14:09.219097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 03:14:28.644620: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 03:14:29.353819: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 03:14:29.922661: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f11a0004ff0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 03:14:29.922696: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 03:14:29.925848: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 03:14:30.034114: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.5746 -> experiments/Step_00/nas_runs/g04_76ad6eba/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4519 loss=2.0558 -> experiments/Step_00/nas_runs/g04_76ad6eba/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.7333 loss=0.8885 -> experiments/Step_00/nas_runs/g04_76ad6eba/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9296 loss=0.2094 -> experiments/Step_00/nas_runs/g04_76ad6eba/best_model.keras\n",
      "\n",
      "[Run-DONE ] g04_76ad6eba | time=287.6s | acc=0.9296 | loss=0.2094 | params=2,468,415\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g04_a33863db\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 24, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 24, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 03:19:21.768988: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 03:19:21.791364: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 03:19:22.268843: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 03:19:22.973519: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:19:22.983957: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:19:22.984134: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:19:22.984466: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:19:29.002023: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:19:29.002168: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:19:29.002260: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:19:29.078770: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:19:29.078941: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:19:29.078957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 03:19:29.079054: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:19:29.079090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 03:19:44.519491: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 03:19:45.296597: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 03:19:45.960861: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa6a0002ea0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 03:19:45.960888: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 03:19:45.963945: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 03:19:46.031362: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.3491 -> experiments/Step_00/nas_runs/g04_a33863db/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4222 loss=1.7935 -> experiments/Step_00/nas_runs/g04_a33863db/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.6259 loss=1.4478 -> experiments/Step_00/nas_runs/g04_a33863db/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.7648 loss=0.7793 -> experiments/Step_00/nas_runs/g04_a33863db/best_model.keras\n",
      "\n",
      "[Run-DONE ] g04_a33863db | time=279.4s | acc=0.7648 | loss=0.7793 | params=6,086,327\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g04_96694748\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 03:24:46.793026: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 03:24:46.814334: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 03:24:47.245984: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 03:24:48.063236: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:24:48.074616: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:24:48.074793: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:24:48.075162: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:24:53.969574: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:24:53.969806: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:24:53.969966: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:24:54.093094: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:24:54.093292: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:24:54.093310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 03:24:54.093433: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:24:54.093475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 03:25:09.858338: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 03:25:10.562506: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 03:25:11.130804: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4fd0003380 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 03:25:11.130835: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 03:25:11.133856: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 03:25:11.203942: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.6121 -> experiments/Step_00/nas_runs/g04_96694748/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4889 loss=1.4763 -> experiments/Step_00/nas_runs/g04_96694748/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.5148 loss=2.8429 -> experiments/Step_00/nas_runs/g04_96694748/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9278 loss=0.1910 -> experiments/Step_00/nas_runs/g04_96694748/best_model.keras\n",
      "\n",
      "[Run-DONE ] g04_96694748 | time=268.8s | acc=0.9278 | loss=0.1910 | params=2,055,663\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g04_bc37f200\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 6, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 6, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 03:29:45.867376: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 03:29:45.888539: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 03:29:46.372937: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 03:29:47.064483: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:29:47.075592: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:29:47.075840: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:29:47.076234: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:29:53.125303: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:29:53.125538: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:29:53.125673: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:29:53.219678: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:29:53.219864: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:29:53.219894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 03:29:53.220050: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:29:53.220087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 03:30:07.330874: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 03:30:07.973704: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 03:30:08.455832: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f25e9a1a5d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 03:30:08.455853: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 03:30:08.458527: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 03:30:08.523413: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.1000 loss=3.1596 -> experiments/Step_00/nas_runs/g04_bc37f200/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.7667 loss=0.7686 -> experiments/Step_00/nas_runs/g04_bc37f200/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.8796 loss=0.3311 -> experiments/Step_00/nas_runs/g04_bc37f200/best_model.keras\n",
      "\n",
      "[Run-DONE ] g04_bc37f200 | time=191.9s | acc=0.8796 | loss=0.3311 | params=3,182,127\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g04_b59a7c99\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 80, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 6, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 80, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 6, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 03:33:32.339109: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 03:33:32.359884: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 03:33:32.844675: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 03:33:33.529186: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:33:33.539530: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:33:33.539659: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:33:33.540005: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:33:39.781034: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:33:39.781168: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:33:39.781259: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:33:39.867666: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:33:39.867799: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:33:39.867813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 03:33:39.867895: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:33:39.867927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 03:33:56.809937: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 03:33:57.397208: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 03:33:57.845097: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d5a2268040 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 03:33:57.845136: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 03:33:57.848160: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 03:33:57.909053: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=4.1864 -> experiments/Step_00/nas_runs/g04_b59a7c99/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.7148 loss=0.8996 -> experiments/Step_00/nas_runs/g04_b59a7c99/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.8519 loss=0.4945 -> experiments/Step_00/nas_runs/g04_b59a7c99/best_model.keras\n",
      "\n",
      "[Run-DONE ] g04_b59a7c99 | time=184.7s | acc=0.8519 | loss=0.4945 | params=3,822,431\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g04_72bac83e\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 80, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 80, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 03:37:15.005890: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 03:37:15.030054: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 03:37:15.456799: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 03:37:16.194513: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:37:16.204921: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:37:16.205106: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:37:16.205524: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:37:22.006310: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:37:22.006547: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:37:22.006725: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:37:22.090588: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:37:22.091332: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:37:22.091357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 03:37:22.091811: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:37:22.091867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 03:37:37.348096: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 03:37:38.008222: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 03:37:38.440225: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff0700070b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 03:37:38.440259: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 03:37:38.443100: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 03:37:38.512374: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=5.4219 -> experiments/Step_00/nas_runs/g04_72bac83e/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.1667 loss=3.2139 -> experiments/Step_00/nas_runs/g04_72bac83e/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.4852 loss=2.1278 -> experiments/Step_00/nas_runs/g04_72bac83e/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.5815 loss=1.6513 -> experiments/Step_00/nas_runs/g04_72bac83e/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.6315 loss=1.2915 -> experiments/Step_00/nas_runs/g04_72bac83e/best_model.keras\n",
      "\n",
      "[Run-DONE ] g04_72bac83e | time=241.0s | acc=0.6315 | loss=1.2915 | params=2,223,935\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Gen 4] Leaderboard (Top 12)\n",
      " rank    hash8  fitness      acc     loss  params        sec\n",
      "    1 a4edcdb8 0.969450 0.987037 0.045545 2253639 153.330601\n",
      "    2 94cda7fe 0.968906 0.987037 0.044747 2300175 158.312761\n",
      "    3 0bc91b4a 0.960054 0.977778 0.068818 1909623 158.137564\n",
      "    4 78dd026a 0.957549 0.974074 0.083672 2360239 141.646964\n",
      "    5 11efc741 0.946494 0.962963 0.125050 4401055 120.675175\n",
      "    6 96694748 0.898846 0.927778 0.190952 2055663 268.765994\n",
      "    7 76ad6eba 0.898401 0.929630 0.209355 2468415 287.601867\n",
      "    8 040a5cec 0.876633 0.896296 0.278300 5120079 145.427832\n",
      "    9 bc37f200 0.857262 0.879630 0.331110 3182127 191.858764\n",
      "   10 b59a7c99 0.829563 0.851852 0.494527 3822431 184.665205\n",
      "   11 a33863db 0.730788 0.764815 0.779308 6086327 279.400461\n",
      "   12 72bac83e 0.605162 0.631481 1.291487 2223935 240.952847\n",
      "[GC] Gen 4: removed 7 run dirs (non-top4)\n",
      "     g04_96694748, g04_76ad6eba, g04_040a5cec, g04_bc37f200, g04_b59a7c99, g04_a33863db, g04_72bac83e\n",
      "\n",
      "========= Generation 5 START (pop=12) =========\n",
      "\n",
      "[Run-START] g05_1e378a81\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 32, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 32, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 03:41:40.535514: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 03:41:40.557000: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 03:41:40.978370: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 03:41:41.752606: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:41:41.764918: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:41:41.766425: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:41:41.768718: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:41:47.792651: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:41:47.793056: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:41:47.793317: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:41:47.880774: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:41:47.882504: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:41:47.882529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 03:41:47.882934: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:41:47.882986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 03:42:00.016660: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 03:42:00.575639: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 03:42:01.041913: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4ec9ade3b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 03:42:01.041942: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 03:42:01.044489: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 03:42:01.171357: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.8377 -> experiments/Step_00/nas_runs/g05_1e378a81/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.7315 loss=0.8625 -> experiments/Step_00/nas_runs/g05_1e378a81/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.8963 loss=0.3398 -> experiments/Step_00/nas_runs/g05_1e378a81/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9667 loss=0.1084 -> experiments/Step_00/nas_runs/g05_1e378a81/best_model.keras\n",
      "\n",
      "[Run-DONE ] g05_1e378a81 | time=183.9s | acc=0.9667 | loss=0.1084 | params=1,066,815\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g05_8bf79464\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 03:45:04.802724: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 03:45:04.824537: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 03:45:05.334320: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 03:45:06.048611: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:45:06.058742: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:45:06.058923: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:45:06.059509: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:45:11.964972: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:45:11.965177: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:45:11.965301: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:45:12.046773: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:45:12.046961: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:45:12.046981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 03:45:12.047100: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:45:12.047136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 03:45:32.881612: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 03:45:33.398371: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 03:45:33.765116: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa5b0006f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 03:45:33.765150: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 03:45:33.768289: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 03:45:33.834588: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.3290 -> experiments/Step_00/nas_runs/g05_8bf79464/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.9185 loss=0.3186 -> experiments/Step_00/nas_runs/g05_8bf79464/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9648 loss=0.1205 -> experiments/Step_00/nas_runs/g05_8bf79464/best_model.keras\n",
      "\n",
      "[Run-DONE ] g05_8bf79464 | time=195.7s | acc=0.9648 | loss=0.1205 | params=2,744,527\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g05_3cef5e95\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 6, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 6, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 03:48:59.431604: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 03:48:59.453415: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 03:48:59.894394: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 03:49:00.571255: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:49:00.581985: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:49:00.582197: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:49:00.582709: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:49:06.086483: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:49:06.086663: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:49:06.086787: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:49:06.169878: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:49:06.170050: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:49:06.170069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 03:49:06.170163: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:49:06.170195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 03:49:31.456909: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 03:49:32.033015: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 03:49:32.594049: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9a7c005c20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 03:49:32.594086: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 03:49:32.597731: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 03:49:32.659551: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.2529 -> experiments/Step_00/nas_runs/g05_3cef5e95/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.6648 loss=0.9453 -> experiments/Step_00/nas_runs/g05_3cef5e95/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.9111 loss=0.2199 -> experiments/Step_00/nas_runs/g05_3cef5e95/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9648 loss=0.1318 -> experiments/Step_00/nas_runs/g05_3cef5e95/best_model.keras\n",
      "\n",
      "[Run-DONE ] g05_3cef5e95 | time=255.5s | acc=0.9648 | loss=0.1318 | params=4,382,223\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g05_1d47f319\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 03:54:16.406034: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 03:54:16.429493: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 03:54:16.862198: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 03:54:17.638505: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:54:17.649368: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:54:17.649592: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:54:17.650004: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:54:23.586060: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:54:23.586248: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:54:23.586366: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:54:23.669538: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:54:23.669670: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:54:23.669684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 03:54:23.669769: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:54:23.669800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 03:54:40.108124: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 03:54:40.532406: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 03:54:40.816938: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0a60002730 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 03:54:40.816970: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 03:54:40.819681: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 03:54:40.884998: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.4772 -> experiments/Step_00/nas_runs/g05_1d47f319/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.2519 loss=2.8196 -> experiments/Step_00/nas_runs/g05_1d47f319/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.7148 loss=0.8279 -> experiments/Step_00/nas_runs/g05_1d47f319/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9426 loss=0.1773 -> experiments/Step_00/nas_runs/g05_1d47f319/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9741 loss=0.0962 -> experiments/Step_00/nas_runs/g05_1d47f319/best_model.keras\n",
      "\n",
      "[Run-DONE ] g05_1d47f319 | time=150.4s | acc=0.9741 | loss=0.0962 | params=706,431\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g05_a07cf1d8\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 6, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 6, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 03:57:07.710589: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 03:57:07.731129: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 03:57:08.174986: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 03:57:08.873446: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:57:08.884922: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:57:08.885158: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:57:08.885559: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:57:14.024157: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:57:14.024368: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:57:14.024530: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:57:14.211104: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:57:14.211265: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:57:14.211284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 03:57:14.211372: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:57:14.211408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 03:57:29.268033: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 03:57:29.794740: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 03:57:30.149154: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe18c005980 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 03:57:30.149182: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 03:57:30.152185: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 03:57:30.217426: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.4257 -> experiments/Step_00/nas_runs/g05_a07cf1d8/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.8519 loss=0.4882 -> experiments/Step_00/nas_runs/g05_a07cf1d8/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.9204 loss=0.2606 -> experiments/Step_00/nas_runs/g05_a07cf1d8/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9463 loss=0.1865 -> experiments/Step_00/nas_runs/g05_a07cf1d8/best_model.keras\n",
      "\n",
      "[Run-DONE ] g05_a07cf1d8 | time=136.6s | acc=0.9463 | loss=0.1865 | params=3,136,847\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g05_06f7d8df\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 24, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 6, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 24, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 6, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 03:59:57.702305: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 03:59:57.723271: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 03:59:58.153540: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 03:59:58.918528: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:59:58.930150: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:59:58.931599: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 03:59:58.932109: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:00:04.840314: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:00:04.840530: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:00:04.840675: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:00:04.942958: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:00:04.943234: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:00:04.943253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 04:00:04.943655: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:00:04.943696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 04:00:20.401495: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 04:00:20.889023: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 04:00:21.209181: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5644cb21f360 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 04:00:21.209207: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 04:00:21.212532: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 04:00:21.279191: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.3036 -> experiments/Step_00/nas_runs/g05_06f7d8df/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4463 loss=1.7995 -> experiments/Step_00/nas_runs/g05_06f7d8df/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.7204 loss=0.9506 -> experiments/Step_00/nas_runs/g05_06f7d8df/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9759 loss=0.0835 -> experiments/Step_00/nas_runs/g05_06f7d8df/best_model.keras\n",
      "\n",
      "[Run-DONE ] g05_06f7d8df | time=137.7s | acc=0.9759 | loss=0.0835 | params=2,213,639\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g05_217a6eee\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 32, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 32, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 04:02:45.902983: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 04:02:45.923809: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 04:02:46.348443: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 04:02:47.053094: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:02:47.064056: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:02:47.064268: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:02:47.064707: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:02:52.823612: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:02:52.823741: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:02:52.823833: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:02:52.907930: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:02:52.908056: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:02:52.908071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 04:02:52.908162: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:02:52.908198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 04:03:14.386849: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 04:03:15.412380: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 04:03:16.220122: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff32800f750 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 04:03:16.220165: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 04:03:16.223704: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 04:03:16.290471: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.5275 -> experiments/Step_00/nas_runs/g05_217a6eee/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.1926 loss=3.3311 -> experiments/Step_00/nas_runs/g05_217a6eee/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.4519 loss=2.4497 -> experiments/Step_00/nas_runs/g05_217a6eee/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.4611 loss=2.8010 -> experiments/Step_00/nas_runs/g05_217a6eee/best_model.keras\n",
      "\n",
      "[Run-DONE ] g05_217a6eee | time=606.8s | acc=0.4611 | loss=2.8010 | params=2,050,463\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g05_039f8ee9\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 32, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 6, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 32, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 6, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 04:13:28.518956: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 04:13:28.540991: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 04:13:28.985328: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 04:13:29.630771: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:13:29.641683: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:13:29.641919: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:13:29.642342: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:13:35.450824: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:13:35.451038: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:13:35.451161: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:13:35.544476: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:13:35.544723: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:13:35.544743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 04:13:35.544874: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:13:35.544915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 04:13:49.996954: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 04:13:50.719175: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 04:13:51.373783: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff884018170 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 04:13:51.373812: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 04:13:51.376835: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 04:13:51.444590: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.8067 -> experiments/Step_00/nas_runs/g05_039f8ee9/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.3037 loss=2.7817 -> experiments/Step_00/nas_runs/g05_039f8ee9/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.6352 loss=3.2062 -> experiments/Step_00/nas_runs/g05_039f8ee9/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.7852 loss=0.6501 -> experiments/Step_00/nas_runs/g05_039f8ee9/best_model.keras\n",
      "\n",
      "[Run-DONE ] g05_039f8ee9 | time=289.9s | acc=0.7852 | loss=0.6502 | params=6,904,175\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Gen 5] Leaderboard (Top 12)\n",
      " rank    hash8  fitness      acc     loss  params        sec\n",
      "    1 a4edcdb8 0.969450 0.987037 0.045545 2253639 153.330601\n",
      "    2 94cda7fe 0.968906 0.987037 0.044747 2300175 158.312761\n",
      "    3 0bc91b4a 0.960054 0.977778 0.068818 1909623 158.137564\n",
      "    4 06f7d8df 0.959938 0.975926 0.083531 2213639 137.738158\n",
      "    5 1d47f319 0.958324 0.974074 0.096220  706431 150.437407\n",
      "    6 78dd026a 0.957549 0.974074 0.083672 2360239 141.646964\n",
      "    7 1e378a81 0.947212 0.966667 0.108393 1066815 183.876453\n",
      "    8 8bf79464 0.942500 0.964815 0.120518 2744527 195.702701\n",
      "    9 3cef5e95 0.934880 0.964815 0.131845 4382223 255.526916\n",
      "   10 a07cf1d8 0.929500 0.946296 0.186498 3136847 136.590518\n",
      "   11 039f8ee9 0.749294 0.785185 0.650151 6904175 289.867202\n",
      "   12 217a6eee 0.398385 0.461111 2.800961 2050463 606.752684\n",
      "[GC] Gen 5: removed 7 run dirs (non-top4)\n",
      "     g05_1d47f319, g05_1e378a81, g05_8bf79464, g05_3cef5e95, g05_a07cf1d8, g05_039f8ee9, g05_217a6eee\n",
      "\n",
      "========= Generation 6 START (pop=12) =========\n",
      "\n",
      "[Run-START] g06_a78d3cba\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 04:19:02.387264: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 04:19:02.408070: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 04:19:02.905882: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 04:19:03.699784: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:19:03.710176: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:19:03.710310: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:19:03.710652: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:19:09.689760: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:19:09.689932: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:19:09.690033: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:19:09.767402: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:19:09.767574: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:19:09.767598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 04:19:09.767699: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:19:09.767731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 04:19:28.421865: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 04:19:28.972794: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 04:19:29.324263: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d513e75010 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 04:19:29.324296: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 04:19:29.327420: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 04:19:29.394011: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0704 loss=3.2878 -> experiments/Step_00/nas_runs/g06_a78d3cba/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.8574 loss=0.5056 -> experiments/Step_00/nas_runs/g06_a78d3cba/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.9296 loss=0.2239 -> experiments/Step_00/nas_runs/g06_a78d3cba/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9815 loss=0.0505 -> experiments/Step_00/nas_runs/g06_a78d3cba/best_model.keras\n",
      "\n",
      "[Run-DONE ] g06_a78d3cba | time=158.5s | acc=0.9815 | loss=0.0505 | params=1,843,503\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g06_f05b8eff\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 04:22:09.468311: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 04:22:09.489077: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 04:22:09.970289: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 04:22:10.717993: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:22:10.728628: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:22:10.728953: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:22:10.729578: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:22:16.909622: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:22:16.909818: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:22:16.909966: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:22:16.997031: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:22:16.997203: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:22:16.997219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 04:22:16.997305: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:22:16.997337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 04:22:34.519905: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 04:22:35.072015: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 04:22:35.412889: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdd1400f2a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 04:22:35.412921: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 04:22:35.416109: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 04:22:35.481307: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.3026 -> experiments/Step_00/nas_runs/g06_f05b8eff/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.7889 loss=0.8385 -> experiments/Step_00/nas_runs/g06_f05b8eff/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8463 loss=0.4272 -> experiments/Step_00/nas_runs/g06_f05b8eff/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9278 loss=0.2299 -> experiments/Step_00/nas_runs/g06_f05b8eff/best_model.keras\n",
      "\n",
      "[Run-DONE ] g06_f05b8eff | time=154.9s | acc=0.9278 | loss=0.2299 | params=1,864,135\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g06_da2e4232\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 6, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 6, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 04:25:11.544530: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 04:25:11.566672: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 04:25:12.092164: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 04:25:12.762632: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:25:12.773927: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:25:12.774134: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:25:12.774525: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:25:18.779248: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:25:18.779516: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:25:18.779749: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:25:18.860045: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:25:18.860256: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:25:18.860274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 04:25:18.860400: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:25:18.860437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 04:25:33.293594: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 04:25:33.802934: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 04:25:34.164838: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563fb22481b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 04:25:34.164882: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 04:25:34.168539: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 04:25:34.234691: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.4399 -> experiments/Step_00/nas_runs/g06_da2e4232/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.6204 loss=1.0492 -> experiments/Step_00/nas_runs/g06_da2e4232/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.6667 loss=1.2174 -> experiments/Step_00/nas_runs/g06_da2e4232/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9537 loss=0.1287 -> experiments/Step_00/nas_runs/g06_da2e4232/best_model.keras\n",
      "\n",
      "[Run-DONE ] g06_da2e4232 | time=145.9s | acc=0.9537 | loss=0.1287 | params=1,978,303\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g06_4899672a\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 56, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 56, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 04:28:04.153980: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 04:28:04.175065: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 04:28:04.615757: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 04:28:05.344474: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:28:05.356462: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:28:05.356666: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:28:05.357064: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:28:11.162428: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:28:11.162786: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:28:11.164240: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:28:11.286489: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:28:11.286635: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:28:11.286651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 04:28:11.286741: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:28:11.286776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 04:28:25.433476: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 04:28:26.000710: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 04:28:26.367911: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3baa32f4d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 04:28:26.367942: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 04:28:26.370916: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 04:28:26.432722: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.9977 -> experiments/Step_00/nas_runs/g06_4899672a/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.3556 loss=2.3119 -> experiments/Step_00/nas_runs/g06_4899672a/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.7074 loss=0.9546 -> experiments/Step_00/nas_runs/g06_4899672a/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.7815 loss=0.7606 -> experiments/Step_00/nas_runs/g06_4899672a/best_model.keras\n",
      "\n",
      "[Run-DONE ] g06_4899672a | time=165.9s | acc=0.7815 | loss=0.7606 | params=3,120,391\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g06_dfeb827c\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 04:31:21.880823: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 04:31:21.901858: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 04:31:22.341661: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 04:31:23.377827: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:31:23.389287: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:31:23.389521: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:31:23.389966: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:31:29.125971: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:31:29.126173: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:31:29.126305: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:31:29.311702: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:31:29.311900: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:31:29.311922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 04:31:29.312114: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:31:29.312157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 04:31:48.439622: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 04:31:49.090042: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 04:31:49.535511: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb0c0003320 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 04:31:49.535545: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 04:31:49.538471: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 04:31:49.603539: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.7168 -> experiments/Step_00/nas_runs/g06_dfeb827c/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.7519 loss=0.7308 -> experiments/Step_00/nas_runs/g06_dfeb827c/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.8352 loss=0.5151 -> experiments/Step_00/nas_runs/g06_dfeb827c/best_model.keras\n",
      "\n",
      "[Run-DONE ] g06_dfeb827c | time=190.2s | acc=0.8352 | loss=0.5151 | params=2,451,679\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g06_f3ed7eb1\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 04:35:06.870649: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 04:35:06.897841: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 04:35:07.346540: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 04:35:07.973238: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:35:07.984049: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:35:07.984271: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:35:07.984650: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:35:13.803492: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:35:13.803656: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:35:13.803778: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:35:13.887660: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:35:13.887842: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:35:13.887857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 04:35:13.887948: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:35:13.887981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 04:35:25.311034: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 04:35:25.946632: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 04:35:26.405178: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcd7c004720 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 04:35:26.405210: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 04:35:26.408487: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 04:35:26.476744: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0981 loss=3.8119 -> experiments/Step_00/nas_runs/g06_f3ed7eb1/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.1944 loss=6.9240 -> experiments/Step_00/nas_runs/g06_f3ed7eb1/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.7352 loss=0.8184 -> experiments/Step_00/nas_runs/g06_f3ed7eb1/best_model.keras\n",
      "\n",
      "[Run-DONE ] g06_f3ed7eb1 | time=151.5s | acc=0.7352 | loss=0.8184 | params=2,383,431\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g06_cc4927df\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 24, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 24, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 04:38:03.068909: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 04:38:03.089759: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 04:38:03.535664: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 04:38:04.302935: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:38:04.312997: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:38:04.313206: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:38:04.313607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:38:10.217363: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:38:10.217588: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:38:10.217718: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:38:10.303391: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:38:10.303561: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:38:10.303579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 04:38:10.303692: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:38:10.303728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 04:38:32.625240: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 04:38:33.226545: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 04:38:33.628132: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7efb740048e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 04:38:33.628161: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 04:38:33.631514: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 04:38:33.697312: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0963 loss=3.7765 -> experiments/Step_00/nas_runs/g06_cc4927df/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4759 loss=1.6870 -> experiments/Step_00/nas_runs/g06_cc4927df/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.6519 loss=1.1892 -> experiments/Step_00/nas_runs/g06_cc4927df/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9222 loss=0.2813 -> experiments/Step_00/nas_runs/g06_cc4927df/best_model.keras\n",
      "\n",
      "[Run-DONE ] g06_cc4927df | time=205.3s | acc=0.9222 | loss=0.2813 | params=2,119,967\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g06_c2046ad2\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 04:42:03.636624: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 04:42:03.658528: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 04:42:04.118342: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 04:42:04.880884: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:42:04.891648: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:42:04.891887: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:42:04.892360: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:42:10.947791: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:42:10.948516: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:42:10.948735: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:42:11.034694: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:42:11.034832: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:42:11.034846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 04:42:11.034933: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:42:11.034964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 04:42:23.227886: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 04:42:23.924713: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 04:42:24.441696: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f833c00f360 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 04:42:24.441726: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 04:42:24.445191: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 04:42:24.510118: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=4.3420 -> experiments/Step_00/nas_runs/g06_c2046ad2/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.2741 loss=2.4278 -> experiments/Step_00/nas_runs/g06_c2046ad2/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.4685 loss=2.2879 -> experiments/Step_00/nas_runs/g06_c2046ad2/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.5370 loss=1.9448 -> experiments/Step_00/nas_runs/g06_c2046ad2/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.7630 loss=0.6864 -> experiments/Step_00/nas_runs/g06_c2046ad2/best_model.keras\n",
      "\n",
      "[Run-DONE ] g06_c2046ad2 | time=229.9s | acc=0.7630 | loss=0.6864 | params=4,303,855\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Gen 6] Leaderboard (Top 12)\n",
      " rank    hash8  fitness      acc     loss  params        sec\n",
      "    1 a4edcdb8 0.969450 0.987037 0.045545 2253639 153.330601\n",
      "    2 94cda7fe 0.968906 0.987037 0.044747 2300175 158.312761\n",
      "    3 a78d3cba 0.963793 0.981481 0.050534 1843503 158.452260\n",
      "    4 0bc91b4a 0.960054 0.977778 0.068818 1909623 158.137564\n",
      "    5 06f7d8df 0.959938 0.975926 0.083531 2213639 137.738158\n",
      "    6 da2e4232 0.937131 0.953704 0.128686 1978303 145.946646\n",
      "    7 f05b8eff 0.910420 0.927778 0.229877 1864135 154.941257\n",
      "    8 cc4927df 0.899572 0.922222 0.281293 2119967 205.298495\n",
      "    9 dfeb827c 0.813714 0.835185 0.515112 2451679 190.199457\n",
      "   10 4899672a 0.761775 0.781482 0.760586 3120391 165.865864\n",
      "   11 c2046ad2 0.735668 0.762963 0.686397 4303855 229.909207\n",
      "   12 f3ed7eb1 0.717648 0.735185 0.818394 2383431 151.534270\n",
      "[GC] Gen 6: removed 7 run dirs (non-top4)\n",
      "     g06_da2e4232, g06_f05b8eff, g06_cc4927df, g06_dfeb827c, g06_4899672a, g06_c2046ad2, g06_f3ed7eb1\n",
      "\n",
      "========= Generation 7 START (pop=12) =========\n",
      "\n",
      "[Run-START] g07_789a3427\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 04:46:28.016872: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 04:46:28.038142: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 04:46:28.480379: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 04:46:29.213987: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:46:29.224735: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:46:29.224946: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:46:29.225315: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:46:35.265688: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:46:35.266150: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:46:35.266359: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:46:35.454627: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:46:35.454794: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:46:35.454809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 04:46:35.454897: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:46:35.454933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 04:46:56.097479: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 04:46:56.693091: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 04:46:57.196642: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6ddb7c2230 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 04:46:57.196669: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 04:46:57.199536: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 04:46:57.266432: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.5498 -> experiments/Step_00/nas_runs/g07_789a3427/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.0759 loss=3.7119 -> experiments/Step_00/nas_runs/g07_789a3427/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8148 loss=0.6593 -> experiments/Step_00/nas_runs/g07_789a3427/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.8444 loss=0.4821 -> experiments/Step_00/nas_runs/g07_789a3427/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.8907 loss=0.3709 -> experiments/Step_00/nas_runs/g07_789a3427/best_model.keras\n",
      "\n",
      "[Run-DONE ] g07_789a3427 | time=271.7s | acc=0.8907 | loss=0.3709 | params=1,455,951\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g07_fe5d4b90\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 04:52:15.008920: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 04:52:15.030482: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 04:52:15.474842: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 04:52:18.243416: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:52:18.254654: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:52:18.254916: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:52:18.255288: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:53:12.822268: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:53:12.822504: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:53:12.822632: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:53:12.908911: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:53:12.909127: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:53:12.909148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 04:53:12.909281: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:53:12.909319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 04:53:29.961472: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 04:53:30.470838: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 04:53:30.803527: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d4a7b96cc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 04:53:30.803561: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 04:53:30.807150: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 04:53:30.872082: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.2479 -> experiments/Step_00/nas_runs/g07_fe5d4b90/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.6222 loss=1.3126 -> experiments/Step_00/nas_runs/g07_fe5d4b90/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.9333 loss=0.1915 -> experiments/Step_00/nas_runs/g07_fe5d4b90/best_model.keras\n",
      "\n",
      "[Run-DONE ] g07_fe5d4b90 | time=143.1s | acc=0.9333 | loss=0.1915 | params=1,423,727\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g07_2b93e257\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 4, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 4, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 04:56:38.611679: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 04:56:38.633152: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 04:56:39.142883: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 04:56:40.967177: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:56:40.978599: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:56:40.984608: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:56:40.990601: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:57:02.833875: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:57:02.834102: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:57:02.834242: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:57:02.913660: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:57:02.913868: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:57:02.913890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 04:57:02.914254: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 04:57:02.914303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 04:57:24.629156: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 04:57:25.101896: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 04:57:25.422121: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe948003740 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 04:57:25.422164: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 04:57:25.425381: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 04:57:25.495313: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.0124 -> experiments/Step_00/nas_runs/g07_2b93e257/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.6481 loss=1.0939 -> experiments/Step_00/nas_runs/g07_2b93e257/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.9056 loss=0.2461 -> experiments/Step_00/nas_runs/g07_2b93e257/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9556 loss=0.1592 -> experiments/Step_00/nas_runs/g07_2b93e257/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9833 loss=0.0683 -> experiments/Step_00/nas_runs/g07_2b93e257/best_model.keras\n",
      "\n",
      "[Run-DONE ] g07_2b93e257 | time=170.6s | acc=0.9833 | loss=0.0683 | params=3,354,263\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g07_017544fa\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 05:00:26.486167: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 05:00:26.506047: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 05:00:26.934643: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 05:00:27.735490: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:00:27.746338: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:00:27.746497: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:00:27.746935: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:00:33.696629: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:00:33.696835: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:00:33.696971: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:00:33.787948: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:00:33.788087: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:00:33.788101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 05:00:33.788189: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:00:33.788221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 05:00:50.226022: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 05:00:50.676805: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 05:00:51.010765: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff2f8006580 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 05:00:51.010793: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 05:00:51.014310: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 05:00:51.080962: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0796 loss=3.3924 -> experiments/Step_00/nas_runs/g07_017544fa/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.5722 loss=1.2672 -> experiments/Step_00/nas_runs/g07_017544fa/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.8907 loss=0.3110 -> experiments/Step_00/nas_runs/g07_017544fa/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9500 loss=0.1590 -> experiments/Step_00/nas_runs/g07_017544fa/best_model.keras\n",
      "\n",
      "[Run-DONE ] g07_017544fa | time=138.7s | acc=0.9500 | loss=0.1590 | params=674,143\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g07_5f1824aa\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 80, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 80, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 05:03:05.259232: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 05:03:05.280415: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 05:03:05.741285: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 05:03:06.436826: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:03:06.447496: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:03:06.447667: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:03:06.448047: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:03:12.417455: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:03:12.417715: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:03:12.417867: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:03:12.495184: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:03:12.495344: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:03:12.495362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 05:03:12.495481: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:03:12.495515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 05:03:29.923180: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 05:03:30.396595: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 05:03:30.702903: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa9e7063c70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 05:03:30.702935: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 05:03:30.706311: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 05:03:30.771369: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.4466 -> experiments/Step_00/nas_runs/g07_5f1824aa/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.7463 loss=0.8055 -> experiments/Step_00/nas_runs/g07_5f1824aa/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.7889 loss=0.5714 -> experiments/Step_00/nas_runs/g07_5f1824aa/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.8315 loss=0.5205 -> experiments/Step_00/nas_runs/g07_5f1824aa/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9630 loss=0.1126 -> experiments/Step_00/nas_runs/g07_5f1824aa/best_model.keras\n",
      "\n",
      "[Run-DONE ] g07_5f1824aa | time=144.8s | acc=0.9630 | loss=0.1126 | params=1,743,503\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g07_5dc2d986\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 4, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 4, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 05:05:55.788471: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 05:05:55.809997: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 05:05:56.267001: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 05:05:57.064732: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:05:57.075909: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:05:57.076087: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:05:57.076484: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:06:03.036034: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:06:03.036254: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:06:03.036394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:06:03.120474: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:06:03.120698: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:06:03.120717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 05:06:03.120870: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:06:03.120918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 05:06:16.370875: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 05:06:16.887195: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 05:06:17.223254: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2e5c002960 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 05:06:17.223288: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 05:06:17.226895: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 05:06:17.293020: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.1178 -> experiments/Step_00/nas_runs/g07_5dc2d986/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.8815 loss=0.4022 -> experiments/Step_00/nas_runs/g07_5dc2d986/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9815 loss=0.0591 -> experiments/Step_00/nas_runs/g07_5dc2d986/best_model.keras\n",
      "\n",
      "[Run-DONE ] g07_5dc2d986 | time=114.2s | acc=0.9815 | loss=0.0591 | params=3,306,295\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g07_fffc4291\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 48, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 48, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 05:08:22.218499: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 05:08:22.241354: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 05:08:22.660368: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 05:08:23.353573: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:08:23.364515: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:08:23.364730: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:08:23.365128: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:08:29.064076: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:08:29.064255: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:08:29.064358: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:08:29.145703: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:08:29.145933: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:08:29.145953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 05:08:29.146087: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:08:29.146125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 05:08:48.087046: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 05:08:48.559406: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 05:08:48.886996: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdb540032a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 05:08:48.887033: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 05:08:48.890115: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 05:08:48.956038: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.4939 -> experiments/Step_00/nas_runs/g07_fffc4291/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.9593 loss=0.2677 -> experiments/Step_00/nas_runs/g07_fffc4291/best_model.keras\n",
      "\n",
      "[Run-DONE ] g07_fffc4291 | time=160.4s | acc=0.9593 | loss=0.2677 | params=2,248,559\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g07_e4cf1066\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 6, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 6, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 05:11:32.277794: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 05:11:32.298288: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 05:11:32.748576: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 05:11:33.560000: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:11:33.572305: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:11:33.572542: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:11:33.572899: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:11:39.530874: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:11:39.531013: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:11:39.531107: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:11:39.614894: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:11:39.615030: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:11:39.615045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 05:11:39.615130: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:11:39.615164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 05:11:58.964858: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 05:11:59.440558: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 05:11:59.831238: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fae9c0065a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 05:11:59.831265: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 05:11:59.834703: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 05:11:59.901535: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.4640 -> experiments/Step_00/nas_runs/g07_e4cf1066/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.3111 loss=2.7977 -> experiments/Step_00/nas_runs/g07_e4cf1066/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.7500 loss=0.9642 -> experiments/Step_00/nas_runs/g07_e4cf1066/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.7907 loss=0.7310 -> experiments/Step_00/nas_runs/g07_e4cf1066/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.8130 loss=0.6356 -> experiments/Step_00/nas_runs/g07_e4cf1066/best_model.keras\n",
      "\n",
      "[Run-DONE ] g07_e4cf1066 | time=171.9s | acc=0.8130 | loss=0.6356 | params=4,968,615\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Gen 7] Leaderboard (Top 12)\n",
      " rank    hash8  fitness      acc     loss  params        sec\n",
      "    1 a4edcdb8 0.969450 0.987037 0.045545 2253639 153.330601\n",
      "    2 94cda7fe 0.968906 0.987037 0.044747 2300175 158.312761\n",
      "    3 5dc2d986 0.966754 0.981481 0.059053 3306295 114.210136\n",
      "    4 a78d3cba 0.963793 0.981481 0.050534 1843503 158.452260\n",
      "    5 2b93e257 0.962923 0.983333 0.068316 3354263 170.556137\n",
      "    6 0bc91b4a 0.960054 0.977778 0.068818 1909623 158.137564\n",
      "    7 5f1824aa 0.946735 0.962963 0.112611 1743503 144.846789\n",
      "    8 fffc4291 0.940967 0.959259 0.267662 2248559 160.432918\n",
      "    9 017544fa 0.935459 0.950000 0.159025  674143 138.664601\n",
      "   10 fe5d4b90 0.917598 0.933333 0.191477 1423727 143.120244\n",
      "   11 789a3427 0.862117 0.890741 0.370913 1455951 271.681802\n",
      "   12 e4cf1066 0.790799 0.812963 0.635579 4968615 171.948549\n",
      "[GC] Gen 7: removed 7 run dirs (non-top4)\n",
      "     g07_2b93e257, g07_5f1824aa, g07_fffc4291, g07_017544fa, g07_fe5d4b90, g07_789a3427, g07_e4cf1066\n",
      "\n",
      "========= Generation 8 START (pop=12) =========\n",
      "\n",
      "[Run-START] g08_e27017f9\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 05:15:16.086622: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 05:15:16.107205: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 05:15:16.579224: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 05:15:17.330191: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:15:17.343096: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:15:17.349591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:15:17.351628: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:15:23.215701: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:15:23.215911: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:15:23.216042: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:15:23.299434: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:15:23.299606: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:15:23.299625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 05:15:23.299719: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:15:23.299749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 05:15:35.071247: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 05:15:35.593630: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 05:15:35.971011: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7ef8005020 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 05:15:35.971039: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 05:15:35.975660: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 05:15:36.076151: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.1000 loss=3.3169 -> experiments/Step_00/nas_runs/g08_e27017f9/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.9111 loss=0.4081 -> experiments/Step_00/nas_runs/g08_e27017f9/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9833 loss=0.0807 -> experiments/Step_00/nas_runs/g08_e27017f9/best_model.keras\n",
      "\n",
      "[Run-DONE ] g08_e27017f9 | time=106.7s | acc=0.9833 | loss=0.0807 | params=1,751,631\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g08_1be62739\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 05:17:24.525328: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 05:17:24.550136: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 05:17:25.013270: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 05:17:25.728172: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:17:25.739792: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:17:25.740043: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:17:25.740607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:17:31.866579: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:17:31.866704: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:17:31.866798: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:17:31.951461: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:17:31.951816: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:17:31.951842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 05:17:31.952048: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:17:31.952083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 05:17:46.286241: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 05:17:46.794614: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 05:17:47.116215: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f341c005190 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 05:17:47.116244: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 05:17:47.144105: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 05:17:47.426980: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.1489 -> experiments/Step_00/nas_runs/g08_1be62739/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.8222 loss=0.4923 -> experiments/Step_00/nas_runs/g08_1be62739/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8259 loss=0.4948 -> experiments/Step_00/nas_runs/g08_1be62739/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9667 loss=0.1143 -> experiments/Step_00/nas_runs/g08_1be62739/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9667 loss=0.1093 -> experiments/Step_00/nas_runs/g08_1be62739/best_model.keras\n",
      "\n",
      "[Run-DONE ] g08_1be62739 | time=124.0s | acc=0.9667 | loss=0.1093 | params=1,429,935\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g08_32e20554\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 05:19:49.997822: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 05:19:50.019900: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 05:19:50.437874: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 05:19:51.179279: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:19:51.190546: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:19:51.190771: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:19:51.191175: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:19:56.924714: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:19:56.924923: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:19:56.925049: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:19:57.011708: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:19:57.011880: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:19:57.011894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 05:19:57.011991: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:19:57.012023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 05:20:12.821908: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 05:20:13.275939: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 05:20:13.613755: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cd862f0c80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 05:20:13.613785: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 05:20:13.617097: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 05:20:13.687666: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.5592 -> experiments/Step_00/nas_runs/g08_32e20554/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.5315 loss=1.3373 -> experiments/Step_00/nas_runs/g08_32e20554/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.9519 loss=0.1322 -> experiments/Step_00/nas_runs/g08_32e20554/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9907 loss=0.0547 -> experiments/Step_00/nas_runs/g08_32e20554/best_model.keras\n",
      "\n",
      "[Run-DONE ] g08_32e20554 | time=132.6s | acc=0.9907 | loss=0.0547 | params=1,566,663\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g08_e0e55b9c\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 05:22:26.333837: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 05:22:26.356929: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 05:22:26.840583: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 05:22:27.522342: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:22:27.533113: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:22:27.533345: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:22:27.533767: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:22:33.525306: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:22:33.525512: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:22:33.525630: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:22:33.606892: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:22:33.607110: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:22:33.607129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 05:22:33.607253: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:22:33.607290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 05:22:49.305069: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 05:22:49.790841: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 05:22:50.161303: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d9ad429130 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 05:22:50.161334: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 05:22:50.164656: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 05:22:50.226370: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.2410 -> experiments/Step_00/nas_runs/g08_e0e55b9c/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.6389 loss=1.1008 -> experiments/Step_00/nas_runs/g08_e0e55b9c/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8944 loss=0.3633 -> experiments/Step_00/nas_runs/g08_e0e55b9c/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9685 loss=0.1219 -> experiments/Step_00/nas_runs/g08_e0e55b9c/best_model.keras\n",
      "\n",
      "[Run-DONE ] g08_e0e55b9c | time=135.3s | acc=0.9685 | loss=0.1219 | params=2,851,663\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g08_d3ecd682\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 05:25:13.620061: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 05:25:13.643681: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 05:25:14.083562: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 05:25:14.768980: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:25:14.780518: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:25:14.780711: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:25:14.781057: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:25:20.584091: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:25:20.584294: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:25:20.584435: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:25:20.662381: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:25:20.662600: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:25:20.662621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 05:25:20.662753: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:25:20.662793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 05:25:35.182693: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 05:25:35.946315: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 05:25:36.667357: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560718f26aa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 05:25:36.667388: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 05:25:36.671137: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 05:25:36.737386: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.1056 loss=2.6102 -> experiments/Step_00/nas_runs/g08_d3ecd682/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.2333 loss=2.5852 -> experiments/Step_00/nas_runs/g08_d3ecd682/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.4722 loss=1.7263 -> experiments/Step_00/nas_runs/g08_d3ecd682/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.5481 loss=1.5094 -> experiments/Step_00/nas_runs/g08_d3ecd682/best_model.keras\n",
      "\n",
      "[Run-DONE ] g08_d3ecd682 | time=304.9s | acc=0.5481 | loss=1.5094 | params=1,583,951\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g08_b1be27be\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 05:30:42.037765: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 05:30:42.065709: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 05:30:42.489307: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 05:30:43.278678: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:30:43.289651: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:30:43.289880: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:30:43.290304: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:30:49.503399: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:30:49.503830: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:30:49.504014: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:30:49.594025: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:30:49.594186: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:30:49.594204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 05:30:49.594321: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:30:49.594361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 05:31:08.702102: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 05:31:09.097075: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 05:31:09.352462: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5608caad3f70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 05:31:09.352491: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 05:31:09.356623: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 05:31:09.422114: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.7471 -> experiments/Step_00/nas_runs/g08_b1be27be/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4833 loss=1.9816 -> experiments/Step_00/nas_runs/g08_b1be27be/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8611 loss=0.3982 -> experiments/Step_00/nas_runs/g08_b1be27be/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9204 loss=0.2462 -> experiments/Step_00/nas_runs/g08_b1be27be/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9889 loss=0.0416 -> experiments/Step_00/nas_runs/g08_b1be27be/best_model.keras\n",
      "\n",
      "[Run-DONE ] g08_b1be27be | time=160.8s | acc=0.9889 | loss=0.0416 | params=654,223\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g08_88f8c158\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 80, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 4, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 80, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 4, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 05:33:44.940855: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 05:33:44.961198: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 05:33:45.403016: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 05:33:46.093323: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:33:46.104412: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:33:46.104741: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:33:46.105363: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:33:52.142850: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:33:52.143019: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:33:52.143141: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:33:52.228320: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:33:52.228501: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:33:52.228517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 05:33:52.228609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:33:52.228642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 05:34:18.488417: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 05:34:18.955010: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 05:34:19.245138: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5590def96ab0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 05:34:19.245168: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 05:34:19.247714: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 05:34:19.309601: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.4445 -> experiments/Step_00/nas_runs/g08_88f8c158/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.5074 loss=1.4520 -> experiments/Step_00/nas_runs/g08_88f8c158/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8093 loss=0.5617 -> experiments/Step_00/nas_runs/g08_88f8c158/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9056 loss=0.2980 -> experiments/Step_00/nas_runs/g08_88f8c158/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9444 loss=0.1763 -> experiments/Step_00/nas_runs/g08_88f8c158/best_model.keras\n",
      "\n",
      "[Run-DONE ] g08_88f8c158 | time=210.8s | acc=0.9444 | loss=0.1763 | params=3,956,639\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g08_1e02153f\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 72, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 72, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 05:38:10.608964: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 05:38:10.632147: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 05:38:11.080818: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 05:38:11.804468: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:38:11.815610: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:38:11.815922: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:38:11.816386: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:38:18.061895: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:38:18.062035: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:38:18.062183: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:38:18.166383: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:38:18.166633: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:38:18.166655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 05:38:18.166774: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:38:18.166808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 05:38:35.673151: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 05:38:36.173626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 05:38:36.499440: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f17080037d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 05:38:36.499469: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 05:38:36.503150: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 05:38:36.573162: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.9757 -> experiments/Step_00/nas_runs/g08_1e02153f/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4481 loss=2.0314 -> experiments/Step_00/nas_runs/g08_1e02153f/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.7167 loss=1.3402 -> experiments/Step_00/nas_runs/g08_1e02153f/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9463 loss=0.1760 -> experiments/Step_00/nas_runs/g08_1e02153f/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9648 loss=0.0931 -> experiments/Step_00/nas_runs/g08_1e02153f/best_model.keras\n",
      "\n",
      "[Run-DONE ] g08_1e02153f | time=153.1s | acc=0.9648 | loss=0.0931 | params=2,243,383\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Gen 8] Leaderboard (Top 12)\n",
      " rank    hash8  fitness      acc     loss  params        sec\n",
      "    1 32e20554 0.975911 0.990741 0.054681 1566663 132.626005\n",
      "    2 b1be27be 0.972153 0.988889 0.041636  654223 160.818027\n",
      "    3 e27017f9 0.970914 0.983333 0.080747 1751631 106.679139\n",
      "    4 a4edcdb8 0.969450 0.987037 0.045545 2253639 153.330601\n",
      "    5 94cda7fe 0.968906 0.987037 0.044747 2300175 158.312761\n",
      "    6 5dc2d986 0.966754 0.981481 0.059053 3306295 114.210136\n",
      "    7 a78d3cba 0.963793 0.981481 0.050534 1843503 158.452260\n",
      "    8 1be62739 0.952834 0.966667 0.109293 1429935 124.027180\n",
      "    9 e0e55b9c 0.952135 0.968518 0.121937 2851663 135.313410\n",
      "   10 1e02153f 0.947260 0.964815 0.093137 2243383 153.115976\n",
      "   11 88f8c158 0.919408 0.944444 0.176344 3956639 210.799699\n",
      "   12 d3ecd682 0.516074 0.548148 1.509413 1583951 304.906369\n",
      "[GC] Gen 8: removed 5 run dirs (non-top4)\n",
      "     g08_1be62739, g08_e0e55b9c, g08_1e02153f, g08_88f8c158, g08_d3ecd682\n",
      "\n",
      "========= Generation 9 START (pop=12) =========\n",
      "\n",
      "[Run-START] g09_c3a64779\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 05:41:11.675239: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 05:41:11.695996: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 05:41:12.244218: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 05:41:12.928623: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:41:12.939895: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:41:12.940124: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:41:12.940675: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:41:18.951338: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:41:18.951481: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:41:18.951571: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:41:19.029465: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:41:19.029667: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:41:19.029690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 05:41:19.029868: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:41:19.029911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 05:41:33.419671: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 05:41:33.905615: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 05:41:34.225834: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb4a8c648d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 05:41:34.225865: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 05:41:34.228502: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 05:41:34.292673: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=4.1851 -> experiments/Step_00/nas_runs/g09_c3a64779/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4519 loss=1.8253 -> experiments/Step_00/nas_runs/g09_c3a64779/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8889 loss=0.3104 -> experiments/Step_00/nas_runs/g09_c3a64779/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9593 loss=0.1200 -> experiments/Step_00/nas_runs/g09_c3a64779/best_model.keras\n",
      "\n",
      "[Run-DONE ] g09_c3a64779 | time=128.5s | acc=0.9593 | loss=0.1200 | params=1,252,623\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g09_1731ab5d\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 05:43:40.832741: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 05:43:40.856381: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 05:43:41.338380: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 05:43:42.006913: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:43:42.017459: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:43:42.017598: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:43:42.017930: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:43:48.251550: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:43:48.251756: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:43:48.251888: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:43:48.480481: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:43:48.480650: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:43:48.480669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 05:43:48.480771: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:43:48.480802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 05:44:02.352526: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 05:44:02.848297: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 05:44:03.173856: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2310087b00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 05:44:03.173900: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 05:44:03.176599: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 05:44:03.248722: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.5023 -> experiments/Step_00/nas_runs/g09_1731ab5d/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.5204 loss=1.4133 -> experiments/Step_00/nas_runs/g09_1731ab5d/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8148 loss=0.6261 -> experiments/Step_00/nas_runs/g09_1731ab5d/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9444 loss=0.1920 -> experiments/Step_00/nas_runs/g09_1731ab5d/best_model.keras\n",
      "\n",
      "[Run-DONE ] g09_1731ab5d | time=121.4s | acc=0.9444 | loss=0.1920 | params=1,069,135\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g09_e70f04a0\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 88, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 88, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 05:46:02.104034: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 05:46:02.125442: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 05:46:02.563165: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 05:46:03.226368: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:46:03.236970: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:46:03.237144: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:46:03.237535: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:46:09.436764: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:46:09.436943: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:46:09.437041: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:46:09.516593: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:46:09.516792: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:46:09.516815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 05:46:09.516981: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:46:09.517024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 05:46:28.304372: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 05:46:28.856378: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 05:46:29.231313: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f87f085ff00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 05:46:29.231342: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 05:46:29.233960: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 05:46:29.297083: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.9194 -> experiments/Step_00/nas_runs/g09_e70f04a0/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.3685 loss=1.8519 -> experiments/Step_00/nas_runs/g09_e70f04a0/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.5074 loss=2.1764 -> experiments/Step_00/nas_runs/g09_e70f04a0/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.5926 loss=2.5391 -> experiments/Step_00/nas_runs/g09_e70f04a0/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.7926 loss=0.6444 -> experiments/Step_00/nas_runs/g09_e70f04a0/best_model.keras\n",
      "\n",
      "[Run-DONE ] g09_e70f04a0 | time=256.3s | acc=0.7926 | loss=0.6444 | params=1,211,615\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g09_327e8f69\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 4, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 4, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 05:50:43.405140: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 05:50:43.427037: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 05:50:43.869983: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 05:50:44.643047: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:50:44.653693: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:50:44.653865: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:50:44.654205: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:50:50.862008: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:50:50.862180: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:50:50.862328: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:50:50.947740: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:50:50.947903: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:50:50.947928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 05:50:50.948056: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:50:50.948090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 05:51:09.349780: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 05:51:09.809192: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 05:51:10.114414: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557f4225be20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 05:51:10.114448: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 05:51:10.117053: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 05:51:10.178308: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.6425 -> experiments/Step_00/nas_runs/g09_327e8f69/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.5444 loss=1.5089 -> experiments/Step_00/nas_runs/g09_327e8f69/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.6722 loss=1.2243 -> experiments/Step_00/nas_runs/g09_327e8f69/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.7278 loss=1.0330 -> experiments/Step_00/nas_runs/g09_327e8f69/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.8926 loss=0.3409 -> experiments/Step_00/nas_runs/g09_327e8f69/best_model.keras\n",
      "\n",
      "[Run-DONE ] g09_327e8f69 | time=146.1s | acc=0.8926 | loss=0.3409 | params=1,418,287\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g09_62d79081\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 6, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 6, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 05:53:36.067762: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 05:53:36.088714: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 05:53:36.614597: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 05:53:37.309338: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:53:37.320374: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:53:37.320574: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:53:37.320983: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:53:43.542808: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:53:43.543082: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:53:43.543249: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:53:43.621351: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:53:43.621580: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:53:43.621595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 05:53:43.621712: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:53:43.621744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 05:54:04.384741: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 05:54:04.952938: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 05:54:05.374187: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2588003890 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 05:54:05.374223: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 05:54:05.377203: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 05:54:05.443013: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.4242 -> experiments/Step_00/nas_runs/g09_62d79081/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.5000 loss=1.4216 -> experiments/Step_00/nas_runs/g09_62d79081/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.6222 loss=1.4187 -> experiments/Step_00/nas_runs/g09_62d79081/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.7870 loss=0.8191 -> experiments/Step_00/nas_runs/g09_62d79081/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.8222 loss=0.5841 -> experiments/Step_00/nas_runs/g09_62d79081/best_model.keras\n",
      "\n",
      "[Run-DONE ] g09_62d79081 | time=246.0s | acc=0.8222 | loss=0.5841 | params=2,082,047\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g09_5c6bcaef\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 05:58:17.119459: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 05:58:17.143115: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 05:58:17.624224: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 05:58:18.379683: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:58:18.391398: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:58:18.391825: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:58:18.392411: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:58:24.794206: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:58:24.794372: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:58:24.794499: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:58:24.881777: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:58:24.881968: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:58:24.881990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 05:58:24.882169: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 05:58:24.882208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 05:58:38.480099: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 05:58:38.867379: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 05:58:39.110004: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f16a4002ed0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 05:58:39.110034: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 05:58:39.113535: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 05:58:39.177828: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.3086 -> experiments/Step_00/nas_runs/g09_5c6bcaef/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.6222 loss=1.1372 -> experiments/Step_00/nas_runs/g09_5c6bcaef/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.9130 loss=0.3166 -> experiments/Step_00/nas_runs/g09_5c6bcaef/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9537 loss=0.1487 -> experiments/Step_00/nas_runs/g09_5c6bcaef/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9796 loss=0.0852 -> experiments/Step_00/nas_runs/g09_5c6bcaef/best_model.keras\n",
      "\n",
      "[Run-DONE ] g09_5c6bcaef | time=116.5s | acc=0.9796 | loss=0.0852 | params=2,161,159\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g09_8f104279\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 4, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 4, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 06:00:40.016721: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 06:00:40.042899: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 06:00:40.474480: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 06:00:41.153864: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:00:41.165103: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:00:41.165281: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:00:41.165634: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:00:47.032793: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:00:47.033030: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:00:47.033172: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:00:47.117167: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:00:47.117341: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:00:47.117359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 06:00:47.117450: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:00:47.117481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 06:00:58.830225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 06:00:59.268743: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 06:00:59.563377: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbd1000e330 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 06:00:59.563405: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 06:00:59.566415: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 06:00:59.632973: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.9310 -> experiments/Step_00/nas_runs/g09_8f104279/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4889 loss=1.5456 -> experiments/Step_00/nas_runs/g09_8f104279/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.7593 loss=0.7551 -> experiments/Step_00/nas_runs/g09_8f104279/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9741 loss=0.1317 -> experiments/Step_00/nas_runs/g09_8f104279/best_model.keras\n",
      "\n",
      "[Run-DONE ] g09_8f104279 | time=110.7s | acc=0.9741 | loss=0.1317 | params=1,838,607\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g09_365dbac8\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 6, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 6, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 06:02:52.579409: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 06:02:52.601226: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 06:02:53.043304: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 06:02:53.754736: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:02:53.765957: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:02:53.766098: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:02:53.766431: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:02:59.714453: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:02:59.714677: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:02:59.714815: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:02:59.794981: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:02:59.795115: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:02:59.795130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 06:02:59.795216: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:02:59.795248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 06:03:15.936423: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 06:03:16.389789: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 06:03:16.696012: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fabd8001890 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 06:03:16.696044: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 06:03:16.699514: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 06:03:16.762952: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.3227 -> experiments/Step_00/nas_runs/g09_365dbac8/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.7352 loss=0.7598 -> experiments/Step_00/nas_runs/g09_365dbac8/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.7944 loss=0.6984 -> experiments/Step_00/nas_runs/g09_365dbac8/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9630 loss=0.1275 -> experiments/Step_00/nas_runs/g09_365dbac8/best_model.keras\n",
      "\n",
      "[Run-DONE ] g09_365dbac8 | time=147.1s | acc=0.9630 | loss=0.1275 | params=1,257,463\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Gen 9] Leaderboard (Top 12)\n",
      " rank    hash8  fitness      acc     loss  params        sec\n",
      "    1 32e20554 0.975911 0.990741 0.054681 1566663 132.626005\n",
      "    2 b1be27be 0.972153 0.988889 0.041636  654223 160.818027\n",
      "    3 e27017f9 0.970914 0.983333 0.080747 1751631 106.679139\n",
      "    4 a4edcdb8 0.969450 0.987037 0.045545 2253639 153.330601\n",
      "    5 5c6bcaef 0.965820 0.979630 0.085198 2161159 116.489023\n",
      "    6 8f104279 0.961166 0.974074 0.131733 1838607 110.697753\n",
      "    7 365dbac8 0.946992 0.962963 0.127459 1257463 147.140207\n",
      "    8 c3a64779 0.945160 0.959259 0.120040 1252623 128.471484\n",
      "    9 1731ab5d 0.931234 0.944444 0.192036 1069135 121.413360\n",
      "   10 327e8f69 0.876563 0.892593 0.340918 1418287 146.113185\n",
      "   11 62d79081 0.795542 0.822222 0.584066 2082047 245.979056\n",
      "   12 e70f04a0 0.765751 0.792593 0.644357 1211615 256.295056\n",
      "[GC] Gen 9: removed 8 run dirs (non-top4)\n",
      "     g09_5c6bcaef, g09_8f104279, g09_365dbac8, g09_c3a64779, g09_1731ab5d, g09_327e8f69, g09_62d79081, g09_e70f04a0\n",
      "\n",
      "========= Generation 10 START (pop=12) =========\n",
      "\n",
      "[Run-START] g10_c2b0b6f2\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 06:05:44.923908: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 06:05:44.947171: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 06:05:45.384173: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 06:05:46.115964: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:05:46.126755: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:05:46.126955: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:05:46.127384: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:05:52.244307: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:05:52.244495: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:05:52.244596: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:05:52.326246: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:05:52.326457: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:05:52.326475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 06:05:52.326594: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:05:52.326629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 06:06:05.020503: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 06:06:05.514565: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 06:06:05.824975: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc61f8941b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 06:06:05.825008: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 06:06:05.827568: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 06:06:05.890304: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.4477 -> experiments/Step_00/nas_runs/g10_c2b0b6f2/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.5426 loss=1.5860 -> experiments/Step_00/nas_runs/g10_c2b0b6f2/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8815 loss=0.3506 -> experiments/Step_00/nas_runs/g10_c2b0b6f2/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9444 loss=0.1660 -> experiments/Step_00/nas_runs/g10_c2b0b6f2/best_model.keras\n",
      "\n",
      "[Run-DONE ] g10_c2b0b6f2 | time=114.9s | acc=0.9444 | loss=0.1660 | params=1,900,143\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g10_7795712a\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 4, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 4, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 06:08:03.800511: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 06:08:03.822161: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 06:08:04.304138: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 06:08:04.977918: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:08:04.988626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:08:04.988853: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:08:04.989256: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:08:10.087157: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:08:10.087328: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:08:10.087420: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:08:10.172149: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:08:10.172310: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:08:10.172325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 06:08:10.172418: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:08:10.172454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 06:08:33.026413: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 06:08:33.660279: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 06:08:34.118626: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc5e0002b80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 06:08:34.118660: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 06:08:34.121484: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 06:08:34.185854: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=4.2722 -> experiments/Step_00/nas_runs/g10_7795712a/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4389 loss=2.8356 -> experiments/Step_00/nas_runs/g10_7795712a/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.6611 loss=1.0933 -> experiments/Step_00/nas_runs/g10_7795712a/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.8833 loss=0.3404 -> experiments/Step_00/nas_runs/g10_7795712a/best_model.keras\n",
      "\n",
      "[Run-DONE ] g10_7795712a | time=271.1s | acc=0.8833 | loss=0.3404 | params=1,165,175\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g10_61f5703d\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 06:13:03.507642: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 06:13:03.528428: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 06:13:03.977089: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 06:13:04.645133: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:13:04.655663: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:13:04.655802: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:13:04.656141: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:13:10.557804: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:13:10.558217: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:13:10.558382: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:13:10.647182: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:13:10.647360: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:13:10.647375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 06:13:10.647459: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:13:10.647500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 06:13:26.551905: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 06:13:26.993389: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 06:13:27.281883: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561f208f1ee0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 06:13:27.281911: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 06:13:27.284959: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 06:13:27.351269: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.5375 -> experiments/Step_00/nas_runs/g10_61f5703d/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4148 loss=2.0327 -> experiments/Step_00/nas_runs/g10_61f5703d/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8185 loss=0.6897 -> experiments/Step_00/nas_runs/g10_61f5703d/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9241 loss=0.2275 -> experiments/Step_00/nas_runs/g10_61f5703d/best_model.keras\n",
      "\n",
      "[Run-DONE ] g10_61f5703d | time=141.3s | acc=0.9241 | loss=0.2275 | params=2,144,207\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g10_d624c9a4\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 06:15:52.815185: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 06:15:52.836317: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 06:15:53.277973: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 06:15:54.029482: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:15:54.040377: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:15:54.040687: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:15:54.041101: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:16:00.082514: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:16:00.082752: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:16:00.082888: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:16:00.176943: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:16:00.177124: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:16:00.177143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 06:16:00.177267: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:16:00.177303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 06:16:16.578338: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 06:16:17.084994: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 06:16:17.381681: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f0c8740f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 06:16:17.381711: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 06:16:17.384833: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 06:16:17.449806: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.3061 -> experiments/Step_00/nas_runs/g10_d624c9a4/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4667 loss=1.4699 -> experiments/Step_00/nas_runs/g10_d624c9a4/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.9426 loss=0.2046 -> experiments/Step_00/nas_runs/g10_d624c9a4/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9778 loss=0.0693 -> experiments/Step_00/nas_runs/g10_d624c9a4/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9815 loss=0.0823 -> experiments/Step_00/nas_runs/g10_d624c9a4/best_model.keras\n",
      "\n",
      "[Run-DONE ] g10_d624c9a4 | time=136.2s | acc=0.9815 | loss=0.0823 | params=965,855\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g10_e6d06147\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 06:18:31.560572: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 06:18:31.581742: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 06:18:32.009026: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 06:18:32.833072: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:18:32.843801: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:18:32.844007: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:18:32.844380: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:18:38.651712: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:18:38.651909: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:18:38.652031: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:18:38.761418: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:18:38.761639: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:18:38.761657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 06:18:38.761781: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:18:38.761818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 06:18:52.705668: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 06:18:53.261200: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 06:18:53.635120: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0178005dd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 06:18:53.635154: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 06:18:53.638666: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 06:18:53.702831: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.1093 loss=2.9736 -> experiments/Step_00/nas_runs/g10_e6d06147/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.3944 loss=2.8425 -> experiments/Step_00/nas_runs/g10_e6d06147/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9556 loss=0.1510 -> experiments/Step_00/nas_runs/g10_e6d06147/best_model.keras\n",
      "\n",
      "[Run-DONE ] g10_e6d06147 | time=171.1s | acc=0.9556 | loss=0.1510 | params=2,640,719\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g10_d4e1ebac\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 06:21:51.856193: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 06:21:51.879089: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 06:21:52.357205: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 06:21:53.038058: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:21:53.049337: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:21:53.049513: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:21:53.049904: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:21:59.291001: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:21:59.291253: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:21:59.291435: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:21:59.372453: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:21:59.372687: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:21:59.372707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 06:21:59.372838: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:21:59.372875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 06:22:17.144863: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 06:22:17.678941: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 06:22:18.030352: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3e6571efd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 06:22:18.030384: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 06:22:18.033154: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 06:22:18.095586: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.9812 -> experiments/Step_00/nas_runs/g10_d4e1ebac/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.6852 loss=0.9814 -> experiments/Step_00/nas_runs/g10_d4e1ebac/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.7815 loss=0.8646 -> experiments/Step_00/nas_runs/g10_d4e1ebac/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9519 loss=0.1556 -> experiments/Step_00/nas_runs/g10_d4e1ebac/best_model.keras\n",
      "\n",
      "[Run-DONE ] g10_d4e1ebac | time=152.7s | acc=0.9519 | loss=0.1556 | params=3,269,847\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g10_5e878984\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 80, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 80, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 06:24:55.247099: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 06:24:55.273714: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 06:24:55.735998: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 06:24:56.508055: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:24:56.520567: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:24:56.520746: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:24:56.521168: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:25:02.157816: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:25:02.158088: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:25:02.158340: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:25:02.237379: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:25:02.237609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:25:02.237633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 06:25:02.237795: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:25:02.237839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 06:25:18.810854: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 06:25:19.398612: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 06:25:19.756344: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f72c0004ff0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 06:25:19.756373: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 06:25:19.767573: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 06:25:19.937031: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.1698 -> experiments/Step_00/nas_runs/g10_5e878984/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.7148 loss=0.9537 -> experiments/Step_00/nas_runs/g10_5e878984/best_model.keras\n",
      "\n",
      "[Run-DONE ] g10_5e878984 | time=168.4s | acc=0.7148 | loss=0.9537 | params=3,471,535\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g10_8d55322b\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 06:28:15.256228: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 06:28:15.277190: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 06:28:15.819287: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 06:28:16.592316: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:28:16.603674: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:28:16.603912: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:28:16.604306: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:28:23.343003: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:28:23.343223: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:28:23.343375: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:28:23.432121: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:28:23.432381: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:28:23.432404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 06:28:23.432580: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:28:23.432621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 06:28:39.721215: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 06:28:40.603010: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 06:28:41.361322: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562813849770 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 06:28:41.361359: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 06:28:41.364538: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 06:28:41.430001: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0907 loss=3.2780 -> experiments/Step_00/nas_runs/g10_8d55322b/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.1926 loss=4.3998 -> experiments/Step_00/nas_runs/g10_8d55322b/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.3481 loss=2.9314 -> experiments/Step_00/nas_runs/g10_8d55322b/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.6963 loss=0.9206 -> experiments/Step_00/nas_runs/g10_8d55322b/best_model.keras\n",
      "\n",
      "[Run-DONE ] g10_8d55322b | time=366.1s | acc=0.6963 | loss=0.9206 | params=3,203,079\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Gen 10] Leaderboard (Top 12)\n",
      " rank    hash8  fitness      acc     loss  params        sec\n",
      "    1 32e20554 0.975911 0.990741 0.054681 1566663 132.626005\n",
      "    2 b1be27be 0.972153 0.988889 0.041636  654223 160.818027\n",
      "    3 e27017f9 0.970914 0.983333 0.080747 1751631 106.679139\n",
      "    4 a4edcdb8 0.969450 0.987037 0.045545 2253639 153.330601\n",
      "    5 d624c9a4 0.966898 0.981481 0.082280  965855 136.174079\n",
      "    6 e6d06147 0.935806 0.955556 0.150961 2640719 171.092286\n",
      "    7 d4e1ebac 0.933312 0.951852 0.155595 3269847 152.696540\n",
      "    8 c2b0b6f2 0.931055 0.944444 0.166043 1900143 114.887783\n",
      "    9 61f5703d 0.907800 0.924074 0.227482 2144207 141.298416\n",
      "   10 7795712a 0.855062 0.883333 0.340367 1165175 271.064730\n",
      "   11 5e878984 0.694504 0.714815 0.953687 3471535 168.393242\n",
      "   12 8d55322b 0.656482 0.696296 0.920606 3203079 366.108790\n",
      "[GC] Gen 10: removed 8 run dirs (non-top4)\n",
      "     g10_d624c9a4, g10_e6d06147, g10_d4e1ebac, g10_c2b0b6f2, g10_61f5703d, g10_7795712a, g10_5e878984, g10_8d55322b\n",
      "\n",
      "========= Generation 11 START (pop=12) =========\n",
      "\n",
      "[Run-START] g11_adeaedc4\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 06:34:57.207804: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 06:34:57.228825: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 06:34:57.686863: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 06:34:58.541514: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:34:58.553029: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:34:58.553345: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:34:58.553873: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:35:04.653896: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:35:04.654147: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:35:04.654322: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:35:04.732810: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:35:04.733060: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:35:04.733079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 06:35:04.733246: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:35:04.733281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 06:35:26.233481: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 06:35:26.846309: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 06:35:27.285345: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc848010360 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 06:35:27.285373: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 06:35:27.288949: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 06:35:27.354864: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.5144 -> experiments/Step_00/nas_runs/g11_adeaedc4/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4574 loss=1.6494 -> experiments/Step_00/nas_runs/g11_adeaedc4/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.5963 loss=1.5692 -> experiments/Step_00/nas_runs/g11_adeaedc4/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.6463 loss=1.6301 -> experiments/Step_00/nas_runs/g11_adeaedc4/best_model.keras\n",
      "\n",
      "[Run-DONE ] g11_adeaedc4 | time=311.1s | acc=0.6463 | loss=1.6301 | params=1,848,895\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g11_00ad3b1d\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 6, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 6, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 06:40:42.628873: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 06:40:42.649106: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 06:40:43.072206: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 06:40:43.817718: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:40:43.828722: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:40:43.829960: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:40:43.830566: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:40:49.638231: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:40:49.638449: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:40:49.638622: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:40:49.715139: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:40:49.715459: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:40:49.715486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 06:40:49.715683: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:40:49.715727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 06:41:17.455265: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 06:41:17.947464: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 06:41:18.377559: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fef84004200 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 06:41:18.377591: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 06:41:18.381090: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 06:41:18.443170: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.3614 -> experiments/Step_00/nas_runs/g11_00ad3b1d/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.2500 loss=2.9336 -> experiments/Step_00/nas_runs/g11_00ad3b1d/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8167 loss=0.6242 -> experiments/Step_00/nas_runs/g11_00ad3b1d/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9130 loss=0.2191 -> experiments/Step_00/nas_runs/g11_00ad3b1d/best_model.keras\n",
      "\n",
      "[Run-DONE ] g11_00ad3b1d | time=287.5s | acc=0.9130 | loss=0.2191 | params=2,348,511\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g11_a994c92d\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 06:46:14.365110: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 06:46:14.386041: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 06:46:14.820786: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 06:46:15.686958: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:46:15.697667: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:46:15.697850: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:46:15.698186: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:46:21.740606: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:46:21.740780: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:46:21.740916: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:46:21.828542: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:46:21.828681: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:46:21.828696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 06:46:21.828786: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:46:21.828819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 06:46:39.233718: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 06:46:39.739225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 06:46:40.069118: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7feff00071b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 06:46:40.069152: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 06:46:40.071933: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 06:46:40.136971: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.6710 -> experiments/Step_00/nas_runs/g11_a994c92d/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.5037 loss=2.2922 -> experiments/Step_00/nas_runs/g11_a994c92d/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.6981 loss=1.0808 -> experiments/Step_00/nas_runs/g11_a994c92d/best_model.keras\n",
      "\n",
      "[Run-DONE ] g11_a994c92d | time=168.0s | acc=0.6981 | loss=1.0808 | params=1,215,623\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g11_9704ebeb\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 06:49:25.589829: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 06:49:25.611627: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 06:49:26.076753: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 06:49:26.746038: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:49:26.756976: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:49:26.757186: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:49:26.757624: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:49:32.654925: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:49:32.655111: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:49:32.655221: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:49:32.737630: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:49:32.737765: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:49:32.737784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 06:49:32.737870: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:49:32.737901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 06:49:52.302019: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 06:49:52.826120: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 06:49:53.219796: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9c4c007bd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 06:49:53.219830: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 06:49:53.223020: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 06:49:53.289424: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.9516 -> experiments/Step_00/nas_runs/g11_9704ebeb/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4389 loss=1.8457 -> experiments/Step_00/nas_runs/g11_9704ebeb/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.6815 loss=1.3046 -> experiments/Step_00/nas_runs/g11_9704ebeb/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9056 loss=0.2823 -> experiments/Step_00/nas_runs/g11_9704ebeb/best_model.keras\n",
      "\n",
      "[Run-DONE ] g11_9704ebeb | time=219.5s | acc=0.9056 | loss=0.2823 | params=972,719\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g11_f4214a20\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 6, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 6, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 06:53:28.414148: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 06:53:28.437265: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 06:53:28.856015: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 06:53:29.669467: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:53:29.681815: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:53:29.682072: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:53:29.682527: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:53:35.633359: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:53:35.633682: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:53:35.633893: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:53:35.718796: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:53:35.718978: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:53:35.718994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 06:53:35.719088: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:53:35.719119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 06:53:57.730515: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 06:53:58.238612: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 06:53:58.575972: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f51e800fbc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 06:53:58.576021: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 06:53:58.579219: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 06:53:58.678506: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.3080 -> experiments/Step_00/nas_runs/g11_f4214a20/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.5370 loss=1.7753 -> experiments/Step_00/nas_runs/g11_f4214a20/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.7981 loss=0.6216 -> experiments/Step_00/nas_runs/g11_f4214a20/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9074 loss=0.2942 -> experiments/Step_00/nas_runs/g11_f4214a20/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9500 loss=0.1680 -> experiments/Step_00/nas_runs/g11_f4214a20/best_model.keras\n",
      "\n",
      "[Run-DONE ] g11_f4214a20 | time=176.8s | acc=0.9500 | loss=0.1680 | params=2,272,863\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g11_47cf04a5\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 88, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 88, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 06:57:04.385923: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 06:57:04.406934: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 06:57:04.994198: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 06:57:05.769878: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:57:05.782321: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:57:05.784994: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:57:05.786959: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:57:11.309220: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:57:11.309411: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:57:11.309509: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:57:11.397338: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:57:11.398373: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:57:11.398396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 06:57:11.398609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:57:11.398650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 06:57:23.259426: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 06:57:23.728695: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 06:57:24.039060: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3a86ea0e40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 06:57:24.039089: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 06:57:24.042114: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 06:57:24.105642: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.4070 -> experiments/Step_00/nas_runs/g11_47cf04a5/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.8148 loss=0.5727 -> experiments/Step_00/nas_runs/g11_47cf04a5/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8537 loss=0.3913 -> experiments/Step_00/nas_runs/g11_47cf04a5/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9519 loss=0.1490 -> experiments/Step_00/nas_runs/g11_47cf04a5/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9685 loss=0.0830 -> experiments/Step_00/nas_runs/g11_47cf04a5/best_model.keras\n",
      "\n",
      "[Run-DONE ] g11_47cf04a5 | time=108.6s | acc=0.9685 | loss=0.0830 | params=934,559\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g11_8894d60d\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 80, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 6, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 80, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 6, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 06:59:11.424194: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 06:59:11.448116: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 06:59:11.878285: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 06:59:12.541170: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:59:12.552562: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:59:12.552817: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:59:12.553254: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:59:17.118167: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:59:17.118293: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:59:17.118381: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:59:17.202577: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:59:17.202714: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:59:17.202729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 06:59:17.202811: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 06:59:17.202844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 06:59:33.475621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 06:59:34.201316: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 06:59:34.694769: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9d74005070 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 06:59:34.694799: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 06:59:34.698900: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 06:59:34.767293: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.4074 -> experiments/Step_00/nas_runs/g11_8894d60d/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4574 loss=1.9532 -> experiments/Step_00/nas_runs/g11_8894d60d/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.4648 loss=2.4974 -> experiments/Step_00/nas_runs/g11_8894d60d/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.7481 loss=0.9644 -> experiments/Step_00/nas_runs/g11_8894d60d/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.8093 loss=0.4980 -> experiments/Step_00/nas_runs/g11_8894d60d/best_model.keras\n",
      "\n",
      "[Run-DONE ] g11_8894d60d | time=235.8s | acc=0.8093 | loss=0.4980 | params=3,356,215\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g11_2f8fc98a\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 6, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 6, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 07:03:46.204253: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 07:03:46.225102: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 07:03:46.685096: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 07:03:47.520230: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:03:47.531151: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:03:47.531363: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:03:47.532459: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:03:52.649789: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:03:52.650149: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:03:52.650369: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:03:52.737609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:03:52.737801: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:03:52.737816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 07:03:52.737909: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:03:52.737945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 07:04:12.383845: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 07:04:12.923192: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 07:04:13.282637: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0a0c002c20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 07:04:13.282667: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 07:04:13.286201: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 07:04:13.431137: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.8336 -> experiments/Step_00/nas_runs/g11_2f8fc98a/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.7241 loss=0.8382 -> experiments/Step_00/nas_runs/g11_2f8fc98a/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.9389 loss=0.1864 -> experiments/Step_00/nas_runs/g11_2f8fc98a/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9741 loss=0.0935 -> experiments/Step_00/nas_runs/g11_2f8fc98a/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9796 loss=0.0723 -> experiments/Step_00/nas_runs/g11_2f8fc98a/best_model.keras\n",
      "\n",
      "[Run-DONE ] g11_2f8fc98a | time=198.3s | acc=0.9796 | loss=0.0723 | params=2,299,447\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Gen 11] Leaderboard (Top 12)\n",
      " rank    hash8  fitness      acc     loss  params        sec\n",
      "    1 32e20554 0.975911 0.990741 0.054681 1566663 132.626005\n",
      "    2 b1be27be 0.972153 0.988889 0.041636  654223 160.818027\n",
      "    3 e27017f9 0.970914 0.983333 0.080747 1751631 106.679139\n",
      "    4 a4edcdb8 0.969450 0.987037 0.045545 2253639 153.330601\n",
      "    5 2f8fc98a 0.957498 0.979630 0.072320 2299447 198.318284\n",
      "    6 47cf04a5 0.956725 0.968518 0.082978  934559 108.589680\n",
      "    7 f4214a20 0.930046 0.950000 0.167982 2272863 176.815018\n",
      "    8 9704ebeb 0.882635 0.905556 0.282322  972719 219.480186\n",
      "    9 00ad3b1d 0.881865 0.912963 0.219077 2348511 287.498148\n",
      "   10 8894d60d 0.782323 0.809259 0.497956 3356215 235.802962\n",
      "   11 a994c92d 0.680135 0.698148 1.080842 1215623 167.977965\n",
      "   12 adeaedc4 0.613333 0.646296 1.630084 1848895 311.145602\n",
      "[GC] Gen 11: removed 8 run dirs (non-top4)\n",
      "     g11_2f8fc98a, g11_47cf04a5, g11_f4214a20, g11_9704ebeb, g11_00ad3b1d, g11_8894d60d, g11_a994c92d, g11_adeaedc4\n",
      "\n",
      "========= Generation 12 START (pop=12) =========\n",
      "\n",
      "[Run-START] g12_5afff4d7\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 56, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 56, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 07:07:34.461450: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 07:07:34.482188: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 07:07:34.955927: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 07:07:35.660549: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:07:35.672015: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:07:35.672270: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:07:35.672692: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:07:41.468208: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:07:41.468435: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:07:41.468587: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:07:41.551140: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:07:41.551320: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:07:41.551341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 07:07:41.551444: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:07:41.551476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 07:07:53.877973: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 07:07:54.426650: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 07:07:54.757488: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff454002770 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 07:07:54.757518: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 07:07:54.760607: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 07:07:54.826753: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.5340 -> experiments/Step_00/nas_runs/g12_5afff4d7/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.6944 loss=0.9137 -> experiments/Step_00/nas_runs/g12_5afff4d7/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.9574 loss=0.1887 -> experiments/Step_00/nas_runs/g12_5afff4d7/best_model.keras\n",
      "\n",
      "[Run-DONE ] g12_5afff4d7 | time=124.7s | acc=0.9574 | loss=0.1887 | params=2,930,263\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g12_40d00893\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 80, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 80, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 07:10:09.321077: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 07:10:09.342470: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 07:10:09.781306: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 07:10:10.579771: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:10:10.590890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:10:10.591072: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:10:10.591459: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:10:16.583669: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:10:16.583892: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:10:16.584114: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:10:16.711759: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:10:16.711984: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:10:16.712002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 07:10:16.712124: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:10:16.712165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 07:10:29.515072: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 07:10:30.188930: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 07:10:30.689982: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdcb00098e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 07:10:30.690011: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 07:10:30.693556: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 07:10:30.759537: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=5.0915 -> experiments/Step_00/nas_runs/g12_40d00893/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.2611 loss=7.1568 -> experiments/Step_00/nas_runs/g12_40d00893/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.4519 loss=2.8726 -> experiments/Step_00/nas_runs/g12_40d00893/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.8111 loss=0.5431 -> experiments/Step_00/nas_runs/g12_40d00893/best_model.keras\n",
      "\n",
      "[Run-DONE ] g12_40d00893 | time=184.7s | acc=0.8111 | loss=0.5431 | params=3,869,119\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g12_66f8321d\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 32, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 80, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 32, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 80, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 07:13:48.356813: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 07:13:48.382163: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 07:13:48.821287: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 07:13:49.500071: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:13:49.511517: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:13:49.511731: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:13:49.512145: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:13:55.854825: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:13:55.855048: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:13:55.855173: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:13:55.939199: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:13:55.939444: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:13:55.939463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 07:13:55.939590: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:13:55.939634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 07:14:11.337244: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 07:14:11.961509: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 07:14:12.470239: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fada8002cf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 07:14:12.470274: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 07:14:12.473158: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 07:14:12.538448: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.3572 -> experiments/Step_00/nas_runs/g12_66f8321d/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4389 loss=1.9176 -> experiments/Step_00/nas_runs/g12_66f8321d/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.7500 loss=0.7735 -> experiments/Step_00/nas_runs/g12_66f8321d/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.8370 loss=0.4673 -> experiments/Step_00/nas_runs/g12_66f8321d/best_model.keras\n",
      "\n",
      "[Run-DONE ] g12_66f8321d | time=222.9s | acc=0.8370 | loss=0.4673 | params=1,166,431\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g12_4a28a04c\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 56, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 56, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 07:17:54.424936: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 07:17:54.447524: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 07:17:54.928069: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 07:17:55.587354: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:17:55.597697: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:17:55.597936: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:17:55.598352: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:18:00.549055: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:18:00.549856: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:18:00.584279: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:18:00.785065: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:18:00.785205: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:18:00.785220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 07:18:00.785309: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:18:00.785343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 07:18:24.352060: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 07:18:24.810782: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 07:18:25.097213: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9e5f60d740 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 07:18:25.097237: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 07:18:25.099779: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 07:18:25.179299: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.6261 -> experiments/Step_00/nas_runs/g12_4a28a04c/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.3000 loss=2.3763 -> experiments/Step_00/nas_runs/g12_4a28a04c/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8667 loss=0.4160 -> experiments/Step_00/nas_runs/g12_4a28a04c/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9796 loss=0.0696 -> experiments/Step_00/nas_runs/g12_4a28a04c/best_model.keras\n",
      "\n",
      "[Run-DONE ] g12_4a28a04c | time=188.3s | acc=0.9796 | loss=0.0696 | params=1,966,975\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g12_0d25cdba\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 07:21:40.596854: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 07:21:40.622400: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 07:21:41.068194: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 07:21:41.882945: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:21:41.894156: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:21:41.894339: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:21:41.894742: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:21:47.932400: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:21:47.932649: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:21:47.932860: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:21:48.015071: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:21:48.015208: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:21:48.015223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 07:21:48.015310: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:21:48.015341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 07:22:07.283705: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 07:22:07.699953: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 07:22:08.016684: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3ad8005080 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 07:22:08.016716: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 07:22:08.021239: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 07:22:08.134245: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.3869 -> experiments/Step_00/nas_runs/g12_0d25cdba/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.6907 loss=0.9751 -> experiments/Step_00/nas_runs/g12_0d25cdba/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8370 loss=0.4711 -> experiments/Step_00/nas_runs/g12_0d25cdba/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9815 loss=0.0716 -> experiments/Step_00/nas_runs/g12_0d25cdba/best_model.keras\n",
      "\n",
      "[Run-DONE ] g12_0d25cdba | time=158.1s | acc=0.9815 | loss=0.0716 | params=1,327,799\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g12_f828905b\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 32, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 32, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 07:24:44.513385: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 07:24:44.534699: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 07:24:44.999904: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 07:24:45.721717: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:24:45.732130: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:24:45.732383: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:24:45.732833: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:24:51.534958: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:24:51.535260: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:24:51.535462: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:24:51.621932: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:24:51.622218: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:24:51.622239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 07:24:51.622454: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:24:51.622494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 07:25:10.932751: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 07:25:11.634353: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 07:25:12.143218: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556ed7878850 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 07:25:12.143254: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 07:25:12.146349: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 07:25:12.212200: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.4889 -> experiments/Step_00/nas_runs/g12_f828905b/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.5796 loss=1.3572 -> experiments/Step_00/nas_runs/g12_f828905b/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.6222 loss=1.8221 -> experiments/Step_00/nas_runs/g12_f828905b/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.6926 loss=0.9925 -> experiments/Step_00/nas_runs/g12_f828905b/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9315 loss=0.1947 -> experiments/Step_00/nas_runs/g12_f828905b/best_model.keras\n",
      "\n",
      "[Run-DONE ] g12_f828905b | time=270.9s | acc=0.9315 | loss=0.1947 | params=2,544,679\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g12_bacc8eaf\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 48, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 48, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 07:29:47.697498: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 07:29:47.719843: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 07:29:48.163200: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 07:29:49.006146: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:29:49.016968: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:29:49.017181: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:29:49.017614: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:29:55.050724: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:29:55.050953: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:29:55.051100: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:29:55.137436: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:29:55.137869: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:29:55.137896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 07:29:55.138162: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:29:55.138204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 07:30:09.344890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 07:30:09.837190: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 07:30:10.179747: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55710b977750 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 07:30:10.179775: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 07:30:10.183399: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 07:30:10.249924: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.6791 -> experiments/Step_00/nas_runs/g12_bacc8eaf/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.8000 loss=0.5779 -> experiments/Step_00/nas_runs/g12_bacc8eaf/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9407 loss=0.1831 -> experiments/Step_00/nas_runs/g12_bacc8eaf/best_model.keras\n",
      "\n",
      "[Run-DONE ] g12_bacc8eaf | time=130.9s | acc=0.9407 | loss=0.1831 | params=2,484,863\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g12_a4f5de12\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 07:32:27.537810: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 07:32:27.558720: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 07:32:28.027224: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 07:32:28.700374: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:32:28.711758: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:32:28.711967: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:32:28.712388: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:32:34.731996: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:32:34.732188: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:32:34.732333: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:32:34.816365: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:32:34.816543: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:32:34.816561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 07:32:34.816655: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:32:34.816690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 07:32:54.385854: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 07:32:54.894067: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 07:32:55.185735: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564cfe133ef0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 07:32:55.185768: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 07:32:55.188926: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 07:32:55.249134: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=4.1386 -> experiments/Step_00/nas_runs/g12_a4f5de12/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.7278 loss=0.9640 -> experiments/Step_00/nas_runs/g12_a4f5de12/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.7315 loss=0.9675 -> experiments/Step_00/nas_runs/g12_a4f5de12/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9796 loss=0.0814 -> experiments/Step_00/nas_runs/g12_a4f5de12/best_model.keras\n",
      "\n",
      "[Run-DONE ] g12_a4f5de12 | time=165.9s | acc=0.9796 | loss=0.0814 | params=4,895,255\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Gen 12] Leaderboard (Top 12)\n",
      " rank    hash8  fitness      acc     loss  params        sec\n",
      "    1 32e20554 0.975911 0.990741 0.054681 1566663 132.626005\n",
      "    2 b1be27be 0.972153 0.988889 0.041636  654223 160.818027\n",
      "    3 e27017f9 0.970914 0.983333 0.080747 1751631 106.679139\n",
      "    4 a4edcdb8 0.969450 0.987037 0.045545 2253639 153.330601\n",
      "    5 0d25cdba 0.964348 0.981481 0.071641 1327799 158.056322\n",
      "    6 4a28a04c 0.958829 0.979630 0.069550 1966975 188.338869\n",
      "    7 a4f5de12 0.958141 0.979630 0.081356 4895255 165.931144\n",
      "    8 5afff4d7 0.942012 0.957407 0.188748 2930263 124.652747\n",
      "    9 bacc8eaf 0.925162 0.940741 0.183063 2484863 130.940994\n",
      "   10 f828905b 0.901851 0.931481 0.194673 2544679 270.853588\n",
      "   11 66f8321d 0.813580 0.837037 0.467301 1166431 222.908615\n",
      "   12 40d00893 0.788775 0.811111 0.543067 3869119 184.666285\n",
      "[GC] Gen 12: removed 8 run dirs (non-top4)\n",
      "     g12_0d25cdba, g12_4a28a04c, g12_a4f5de12, g12_5afff4d7, g12_bacc8eaf, g12_f828905b, g12_66f8321d, g12_40d00893\n",
      "\n",
      "========= Generation 13 START (pop=12) =========\n",
      "\n",
      "[Run-START] g13_2026944f\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 07:36:01.260275: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 07:36:01.281519: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 07:36:01.737917: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 07:36:02.446731: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:36:02.457760: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:36:02.458019: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:36:02.458480: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:36:08.276223: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:36:08.276408: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:36:08.276545: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:36:08.584479: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:36:08.584644: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:36:08.584663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 07:36:08.584750: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:36:08.584782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 07:36:20.573730: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 07:36:21.034654: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 07:36:21.324462: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd1ec005f80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 07:36:21.324495: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 07:36:21.327728: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 07:36:21.393111: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.3761 -> experiments/Step_00/nas_runs/g13_2026944f/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.7778 loss=0.6139 -> experiments/Step_00/nas_runs/g13_2026944f/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9722 loss=0.0983 -> experiments/Step_00/nas_runs/g13_2026944f/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9907 loss=0.0331 -> experiments/Step_00/nas_runs/g13_2026944f/best_model.keras\n",
      "\n",
      "[Run-DONE ] g13_2026944f | time=110.2s | acc=0.9907 | loss=0.0331 | params=1,128,927\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g13_9ca306c6\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 07:38:11.636226: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 07:38:11.658921: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 07:38:12.129064: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 07:38:12.804803: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:38:12.815454: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:38:12.815588: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:38:12.815929: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:38:18.658702: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:38:18.658845: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:38:18.658941: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:38:18.738387: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:38:18.738608: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:38:18.738626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 07:38:18.738756: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:38:18.738792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 07:38:42.804262: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 07:38:43.290816: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 07:38:43.634397: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560da31839f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 07:38:43.634430: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 07:38:43.638265: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 07:38:43.704852: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.8865 -> experiments/Step_00/nas_runs/g13_9ca306c6/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4667 loss=1.8385 -> experiments/Step_00/nas_runs/g13_9ca306c6/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.9722 loss=0.0964 -> experiments/Step_00/nas_runs/g13_9ca306c6/best_model.keras\n",
      "\n",
      "[Run-DONE ] g13_9ca306c6 | time=195.4s | acc=0.9722 | loss=0.0964 | params=3,729,119\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g13_ecafd453\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 07:42:15.952321: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 07:42:15.975910: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 07:42:16.458706: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 07:42:17.159197: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:42:17.171175: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:42:17.171382: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:42:17.171789: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:42:23.374649: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:42:23.374884: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:42:23.375033: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:42:23.458335: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:42:23.458564: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:42:23.458584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 07:42:23.458726: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:42:23.458765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 07:42:42.311671: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 07:42:42.812415: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 07:42:43.126943: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6950005070 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 07:42:43.126972: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 07:42:43.131305: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 07:42:43.289836: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.1130 loss=3.3622 -> experiments/Step_00/nas_runs/g13_ecafd453/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.6148 loss=1.3681 -> experiments/Step_00/nas_runs/g13_ecafd453/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.9130 loss=0.2871 -> experiments/Step_00/nas_runs/g13_ecafd453/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9574 loss=0.1126 -> experiments/Step_00/nas_runs/g13_ecafd453/best_model.keras\n",
      "\n",
      "[Run-DONE ] g13_ecafd453 | time=169.4s | acc=0.9574 | loss=0.1126 | params=2,397,583\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g13_7691e93f\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 07:45:34.627818: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 07:45:34.649039: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 07:45:35.116733: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 07:45:35.964566: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:45:35.975780: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:45:35.976086: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:45:35.976561: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:45:41.870887: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:45:41.871212: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:45:41.871385: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:45:41.957676: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:45:41.957890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:45:41.957909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 07:45:41.958047: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:45:41.958083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 07:46:00.354246: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 07:46:01.023066: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 07:46:01.392089: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd0b08ea8a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 07:46:01.392116: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 07:46:01.395253: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 07:46:01.457600: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.1093 loss=3.2491 -> experiments/Step_00/nas_runs/g13_7691e93f/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.2426 loss=4.4193 -> experiments/Step_00/nas_runs/g13_7691e93f/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.5333 loss=2.2976 -> experiments/Step_00/nas_runs/g13_7691e93f/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9370 loss=0.2077 -> experiments/Step_00/nas_runs/g13_7691e93f/best_model.keras\n",
      "\n",
      "[Run-DONE ] g13_7691e93f | time=166.2s | acc=0.9370 | loss=0.2077 | params=4,824,399\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g13_076341a5\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 07:49:02.778227: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 07:49:02.798974: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 07:49:03.265968: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 07:49:03.925962: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:49:03.937370: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:49:03.937628: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:49:03.938082: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:49:09.853927: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:49:09.854164: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:49:09.854317: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:49:09.930959: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:49:09.931136: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:49:09.931152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 07:49:09.931236: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:49:09.931270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 07:49:25.713066: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 07:49:26.175839: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 07:49:26.460390: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa318010180 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 07:49:26.460419: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 07:49:26.463520: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 07:49:26.530778: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.9330 -> experiments/Step_00/nas_runs/g13_076341a5/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.6944 loss=0.9296 -> experiments/Step_00/nas_runs/g13_076341a5/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8944 loss=0.3320 -> experiments/Step_00/nas_runs/g13_076341a5/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9907 loss=0.0370 -> experiments/Step_00/nas_runs/g13_076341a5/best_model.keras\n",
      "\n",
      "[Run-DONE ] g13_076341a5 | time=136.5s | acc=0.9907 | loss=0.0370 | params=1,910,695\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g13_d444bcb9\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 07:51:45.929674: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 07:51:45.951868: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 07:51:46.416698: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 07:51:47.156641: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:51:47.168050: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:51:47.168240: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:51:47.168594: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:51:53.299335: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:51:53.299555: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:51:53.299702: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:51:53.436641: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:51:53.436850: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:51:53.436872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 07:51:53.437598: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:51:53.437649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 07:52:08.103324: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 07:52:08.564629: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 07:52:08.846120: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0bfc006e50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 07:52:08.846151: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 07:52:08.849698: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 07:52:08.918114: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.6840 -> experiments/Step_00/nas_runs/g13_d444bcb9/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.3963 loss=1.8567 -> experiments/Step_00/nas_runs/g13_d444bcb9/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.5926 loss=1.4972 -> experiments/Step_00/nas_runs/g13_d444bcb9/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9278 loss=0.2153 -> experiments/Step_00/nas_runs/g13_d444bcb9/best_model.keras\n",
      "\n",
      "[Run-DONE ] g13_d444bcb9 | time=129.1s | acc=0.9278 | loss=0.2153 | params=953,663\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g13_d5209a69\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 07:54:15.357607: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 07:54:15.381109: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 07:54:15.845861: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 07:54:16.516186: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:54:16.527651: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:54:16.527911: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:54:16.528384: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:54:22.671312: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:54:22.671659: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:54:22.671953: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:54:22.756420: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:54:22.756661: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:54:22.756688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 07:54:22.756932: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:54:22.756973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 07:54:37.036425: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 07:54:37.608857: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 07:54:37.970412: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f5550004ff0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 07:54:37.970441: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 07:54:37.974908: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 07:54:38.041216: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.1352 loss=4.6577 -> experiments/Step_00/nas_runs/g13_d5209a69/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.9056 loss=0.2779 -> experiments/Step_00/nas_runs/g13_d5209a69/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9500 loss=0.1526 -> experiments/Step_00/nas_runs/g13_d5209a69/best_model.keras\n",
      "\n",
      "[Run-DONE ] g13_d5209a69 | time=121.2s | acc=0.9500 | loss=0.1526 | params=5,936,831\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g13_251288a5\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 80, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 80, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 07:56:56.546613: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 07:56:56.570331: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 07:56:57.029625: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 07:56:57.817772: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:56:57.829632: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:56:57.830078: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:56:57.830476: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:57:03.885620: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:57:03.885845: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:57:03.885988: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:57:03.976556: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:57:03.976737: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:57:03.976753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 07:57:03.976846: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 07:57:03.976878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 07:57:24.541117: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 07:57:25.056463: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 07:57:25.386702: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5651e9589d30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 07:57:25.386736: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 07:57:25.389627: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 07:57:25.465832: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.6146 -> experiments/Step_00/nas_runs/g13_251288a5/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4037 loss=2.3654 -> experiments/Step_00/nas_runs/g13_251288a5/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.6981 loss=1.1241 -> experiments/Step_00/nas_runs/g13_251288a5/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9241 loss=0.2184 -> experiments/Step_00/nas_runs/g13_251288a5/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9352 loss=0.1633 -> experiments/Step_00/nas_runs/g13_251288a5/best_model.keras\n",
      "\n",
      "[Run-DONE ] g13_251288a5 | time=208.2s | acc=0.9352 | loss=0.1633 | params=1,231,775\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Gen 13] Leaderboard (Top 12)\n",
      " rank    hash8  fitness      acc     loss  params        sec\n",
      "    1 2026944f 0.978592 0.990741 0.033059 1128927 110.193583\n",
      "    2 32e20554 0.975911 0.990741 0.054681 1566663 132.626005\n",
      "    3 076341a5 0.975181 0.990741 0.036963 1910695 136.492071\n",
      "    4 b1be27be 0.972153 0.988889 0.041636  654223 160.818027\n",
      "    5 e27017f9 0.970914 0.983333 0.080747 1751631 106.679139\n",
      "    6 a4edcdb8 0.969450 0.987037 0.045545 2253639 153.330601\n",
      "    7 9ca306c6 0.948954 0.972222 0.096416 3729119 195.391579\n",
      "    8 ecafd453 0.938067 0.957407 0.112563 2397583 169.433253\n",
      "    9 d5209a69 0.931948 0.950000 0.152610 5936831 121.156482\n",
      "   10 7691e93f 0.915593 0.937037 0.207696 4824399 166.195461\n",
      "   11 d444bcb9 0.913913 0.927778 0.215279  953663 129.110062\n",
      "   12 251288a5 0.913130 0.935185 0.163334 1231775 208.235085\n",
      "[GC] Gen 13: removed 6 run dirs (non-top4)\n",
      "     g13_9ca306c6, g13_ecafd453, g13_d5209a69, g13_7691e93f, g13_d444bcb9, g13_251288a5\n",
      "\n",
      "========= Generation 14 START (pop=12) =========\n",
      "\n",
      "[Run-START] g14_1a483e19\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 08:00:50.478949: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 08:00:50.500254: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 08:00:50.953195: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 08:00:51.655535: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:00:51.666290: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:00:51.666476: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:00:51.666802: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:00:57.567963: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:00:57.568122: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:00:57.568290: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:00:57.659129: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:00:57.659354: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:00:57.659378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 08:00:57.659565: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:00:57.659610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 08:01:12.121115: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 08:01:12.599351: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 08:01:12.897038: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55703de948e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 08:01:12.897067: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 08:01:12.900504: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 08:01:12.965913: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.8351 -> experiments/Step_00/nas_runs/g14_1a483e19/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.7278 loss=0.9387 -> experiments/Step_00/nas_runs/g14_1a483e19/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8907 loss=0.3484 -> experiments/Step_00/nas_runs/g14_1a483e19/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9500 loss=0.1408 -> experiments/Step_00/nas_runs/g14_1a483e19/best_model.keras\n",
      "\n",
      "[Run-DONE ] g14_1a483e19 | time=124.0s | acc=0.9500 | loss=0.1408 | params=2,771,783\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g14_01898cbd\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 08:03:21.580523: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 08:03:21.601635: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 08:03:22.018931: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 08:03:22.745308: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:03:22.788349: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:03:22.788777: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:03:22.798446: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:03:28.890216: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:03:28.891073: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:03:28.891343: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:03:29.083351: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:03:29.083525: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:03:29.083544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 08:03:29.083675: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:03:29.083716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 08:03:46.087633: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 08:03:46.542315: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 08:03:46.871720: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f04ec8e8e80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 08:03:46.871748: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 08:03:46.874849: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 08:03:46.939365: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.4757 -> experiments/Step_00/nas_runs/g14_01898cbd/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.5407 loss=1.6375 -> experiments/Step_00/nas_runs/g14_01898cbd/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.7389 loss=0.9174 -> experiments/Step_00/nas_runs/g14_01898cbd/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9759 loss=0.1570 -> experiments/Step_00/nas_runs/g14_01898cbd/best_model.keras\n",
      "\n",
      "[Run-DONE ] g14_01898cbd | time=148.7s | acc=0.9759 | loss=0.1570 | params=1,417,903\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g14_c61e2cb6\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 08:06:13.672713: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 08:06:13.693648: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 08:06:14.147414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 08:06:14.880141: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:06:14.891620: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:06:14.892001: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:06:14.892389: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:06:21.029536: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:06:21.029755: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:06:21.029892: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:06:21.117773: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:06:21.117953: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:06:21.117972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 08:06:21.118076: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:06:21.118108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 08:06:40.330430: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 08:06:40.875827: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 08:06:41.240806: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff4f4002fe0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 08:06:41.240839: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 08:06:41.255443: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 08:06:41.453811: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.0297 -> experiments/Step_00/nas_runs/g14_c61e2cb6/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4407 loss=1.6332 -> experiments/Step_00/nas_runs/g14_c61e2cb6/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.5537 loss=2.1325 -> experiments/Step_00/nas_runs/g14_c61e2cb6/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.8926 loss=0.3529 -> experiments/Step_00/nas_runs/g14_c61e2cb6/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9333 loss=0.1968 -> experiments/Step_00/nas_runs/g14_c61e2cb6/best_model.keras\n",
      "\n",
      "[Run-DONE ] g14_c61e2cb6 | time=170.1s | acc=0.9333 | loss=0.1968 | params=3,665,167\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g14_e120559e\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 08:09:47.468683: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 08:09:47.493234: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 08:09:47.953186: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 08:09:48.634730: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:09:48.645309: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:09:48.645495: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:09:48.645897: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:09:54.822354: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:09:54.824054: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:09:54.824307: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:09:54.909731: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:09:54.909942: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:09:54.909962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 08:09:54.910087: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:09:54.910129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 08:10:11.434845: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 08:10:11.912044: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 08:10:12.200223: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d2a5323750 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 08:10:12.200254: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 08:10:12.203853: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 08:10:12.270266: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.3971 -> experiments/Step_00/nas_runs/g14_e120559e/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.8796 loss=0.4173 -> experiments/Step_00/nas_runs/g14_e120559e/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.9852 loss=0.0840 -> experiments/Step_00/nas_runs/g14_e120559e/best_model.keras\n",
      "\n",
      "[Run-DONE ] g14_e120559e | time=138.5s | acc=0.9852 | loss=0.0840 | params=1,582,519\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g14_9ab80f05\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 80, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 6, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 80, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 6, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 08:12:29.759522: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 08:12:29.783031: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 08:12:30.205120: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 08:12:30.961758: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:12:30.972513: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:12:30.972720: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:12:30.973501: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:12:36.754536: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:12:36.754834: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:12:36.755021: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:12:36.842850: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:12:36.843027: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:12:36.843042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 08:12:36.843180: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:12:36.843213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 08:12:50.696661: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 08:12:51.134126: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 08:12:51.445249: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff004001a30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 08:12:51.445274: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 08:12:51.448314: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 08:12:51.518263: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.3337 -> experiments/Step_00/nas_runs/g14_9ab80f05/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4056 loss=2.4192 -> experiments/Step_00/nas_runs/g14_9ab80f05/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8333 loss=0.5425 -> experiments/Step_00/nas_runs/g14_9ab80f05/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9000 loss=0.3088 -> experiments/Step_00/nas_runs/g14_9ab80f05/best_model.keras\n",
      "\n",
      "[Run-DONE ] g14_9ab80f05 | time=130.3s | acc=0.9000 | loss=0.3088 | params=2,171,791\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g14_a6f6b899\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 6, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 6, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 08:15:07.641592: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 08:15:07.663111: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 08:15:08.063210: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 08:15:08.761913: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:15:08.773014: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:15:08.773225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:15:08.774109: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:15:14.865487: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:15:14.865653: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:15:14.865771: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:15:14.950038: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:15:14.950244: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:15:14.950265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 08:15:14.950382: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:15:14.950417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 08:15:36.956289: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 08:15:37.419366: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 08:15:37.714918: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f786800f470 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 08:15:37.714948: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 08:15:37.718032: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 08:15:37.782711: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=4.2813 -> experiments/Step_00/nas_runs/g14_a6f6b899/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.3907 loss=1.8965 -> experiments/Step_00/nas_runs/g14_a6f6b899/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.7963 loss=0.6577 -> experiments/Step_00/nas_runs/g14_a6f6b899/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.8167 loss=0.5207 -> experiments/Step_00/nas_runs/g14_a6f6b899/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.8889 loss=0.3331 -> experiments/Step_00/nas_runs/g14_a6f6b899/best_model.keras\n",
      "\n",
      "[Run-DONE ] g14_a6f6b899 | time=185.0s | acc=0.8889 | loss=0.3331 | params=3,370,831\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g14_73b881bf\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 24, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 4, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 24, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 4, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 08:18:56.099097: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 08:18:56.119845: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 08:18:56.561974: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 08:18:57.434682: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:18:57.446421: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:18:57.446658: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:18:57.447099: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:19:03.522098: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:19:03.522417: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:19:03.522603: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:19:03.616085: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:19:03.616345: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:19:03.616364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 08:19:03.616521: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:19:03.616557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 08:19:28.083848: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 08:19:28.916907: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 08:19:29.527312: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2b70010ab0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 08:19:29.527344: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 08:19:29.530420: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 08:19:29.595746: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.5567 -> experiments/Step_00/nas_runs/g14_73b881bf/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.3019 loss=3.0646 -> experiments/Step_00/nas_runs/g14_73b881bf/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.4759 loss=2.5379 -> experiments/Step_00/nas_runs/g14_73b881bf/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.6981 loss=1.1281 -> experiments/Step_00/nas_runs/g14_73b881bf/best_model.keras\n",
      "\n",
      "[Run-DONE ] g14_73b881bf | time=435.7s | acc=0.6981 | loss=1.1281 | params=1,770,311\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g14_acbc5a63\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 08:26:51.369304: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 08:26:51.392695: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 08:26:51.828433: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 08:26:52.494311: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:26:52.505016: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:26:52.505183: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:26:52.505571: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:26:58.739945: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:26:58.740151: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:26:58.740314: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:26:58.835418: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:26:58.835595: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:26:58.835613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 08:26:58.835729: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:26:58.835768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 08:27:17.435953: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 08:27:17.957920: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 08:27:18.270996: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff5804bcc90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 08:27:18.271022: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 08:27:18.273572: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 08:27:18.337816: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=4.0947 -> experiments/Step_00/nas_runs/g14_acbc5a63/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.3870 loss=2.6012 -> experiments/Step_00/nas_runs/g14_acbc5a63/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.5519 loss=2.1451 -> experiments/Step_00/nas_runs/g14_acbc5a63/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.8796 loss=0.3629 -> experiments/Step_00/nas_runs/g14_acbc5a63/best_model.keras\n",
      "\n",
      "[Run-DONE ] g14_acbc5a63 | time=235.4s | acc=0.8796 | loss=0.3629 | params=1,443,671\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Gen 14] Leaderboard (Top 12)\n",
      " rank    hash8  fitness      acc     loss  params        sec\n",
      "    1 2026944f 0.978592 0.990741 0.033059 1128927 110.193583\n",
      "    2 32e20554 0.975911 0.990741 0.054681 1566663 132.626005\n",
      "    3 076341a5 0.975181 0.990741 0.036963 1910695 136.492071\n",
      "    4 b1be27be 0.972153 0.988889 0.041636  654223 160.818027\n",
      "    5 e120559e 0.969754 0.985185 0.084023 1582519 138.488153\n",
      "    6 01898cbd 0.959638 0.975926 0.157044 1417903 148.703943\n",
      "    7 1a483e19 0.934826 0.950000 0.140761 2771783 124.022795\n",
      "    8 c61e2cb6 0.912661 0.933333 0.196846 3665167 170.069624\n",
      "    9 9ab80f05 0.884798 0.900000 0.308793 2171791 130.299965\n",
      "   10 a6f6b899 0.867022 0.888889 0.333130 3370831 184.964419\n",
      "   11 acbc5a63 0.854648 0.879630 0.362903 1443671 235.381709\n",
      "   12 73b881bf 0.652808 0.698148 1.128104 1770311 435.699533\n",
      "[GC] Gen 14: removed 8 run dirs (non-top4)\n",
      "     g14_e120559e, g14_01898cbd, g14_1a483e19, g14_c61e2cb6, g14_9ab80f05, g14_a6f6b899, g14_acbc5a63, g14_73b881bf\n",
      "\n",
      "========= Generation 15 START (pop=12) =========\n",
      "\n",
      "[Run-START] g15_58d5702f\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 08:31:14.293044: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 08:31:14.314577: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 08:31:14.776319: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 08:31:15.509637: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:31:15.520304: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:31:15.520554: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:31:15.521072: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:31:21.552460: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:31:21.552720: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:31:21.552884: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:31:21.639223: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:31:21.639394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:31:21.639413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 08:31:21.639500: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:31:21.639531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 08:31:34.824799: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 08:31:35.260524: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 08:31:35.536479: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f798c006940 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 08:31:35.536509: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 08:31:35.540044: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 08:31:35.618473: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0833 loss=3.6490 -> experiments/Step_00/nas_runs/g15_58d5702f/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.7037 loss=0.8817 -> experiments/Step_00/nas_runs/g15_58d5702f/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.9778 loss=0.0752 -> experiments/Step_00/nas_runs/g15_58d5702f/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9907 loss=0.0366 -> experiments/Step_00/nas_runs/g15_58d5702f/best_model.keras\n",
      "\n",
      "[Run-DONE ] g15_58d5702f | time=113.2s | acc=0.9907 | loss=0.0366 | params=1,024,991\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g15_83677037\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 08:33:27.086799: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 08:33:27.107664: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 08:33:27.555189: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 08:33:28.319072: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:33:28.333458: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:33:28.335846: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:33:28.336309: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:33:34.469063: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:33:34.469331: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:33:34.469491: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:33:34.641241: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:33:34.643186: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:33:34.643236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 08:33:34.643549: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:33:34.643630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 08:33:50.707727: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 08:33:51.167229: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 08:33:51.437317: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5568b5695ce0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 08:33:51.437347: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 08:33:51.440456: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 08:33:51.521464: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.3452 -> experiments/Step_00/nas_runs/g15_83677037/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.7426 loss=0.8166 -> experiments/Step_00/nas_runs/g15_83677037/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9722 loss=0.0836 -> experiments/Step_00/nas_runs/g15_83677037/best_model.keras\n",
      "\n",
      "[Run-DONE ] g15_83677037 | time=132.2s | acc=0.9722 | loss=0.0836 | params=832,031\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g15_f4ba14c5\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 08:35:59.281504: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 08:35:59.305016: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 08:35:59.750254: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 08:36:00.665300: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:36:00.676774: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:36:00.677141: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:36:00.677620: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:36:06.726566: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:36:06.728205: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:36:06.731797: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:36:06.822941: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:36:06.823173: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:36:06.823192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 08:36:06.823343: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:36:06.823375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 08:36:25.407610: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 08:36:25.830602: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 08:36:26.091499: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56084b9816f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 08:36:26.091555: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 08:36:26.094620: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 08:36:26.160071: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.5795 -> experiments/Step_00/nas_runs/g15_f4ba14c5/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.6204 loss=1.0736 -> experiments/Step_00/nas_runs/g15_f4ba14c5/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8426 loss=0.4427 -> experiments/Step_00/nas_runs/g15_f4ba14c5/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9667 loss=0.1250 -> experiments/Step_00/nas_runs/g15_f4ba14c5/best_model.keras\n",
      "\n",
      "[Run-DONE ] g15_f4ba14c5 | time=155.6s | acc=0.9667 | loss=0.1250 | params=1,115,223\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g15_3eeb1c0c\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 08:38:59.377866: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 08:38:59.400372: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 08:38:59.857933: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 08:39:00.707449: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:39:00.718640: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:39:00.718856: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:39:00.719260: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:39:06.561138: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:39:06.561317: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:39:06.561421: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:39:06.638724: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:39:06.638929: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:39:06.638947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 08:39:06.639056: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:39:06.639092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 08:39:23.674239: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 08:39:24.102694: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 08:39:24.419308: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f487000f5b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 08:39:24.419335: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 08:39:24.422366: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 08:39:24.487812: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.4818 -> experiments/Step_00/nas_runs/g15_3eeb1c0c/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.3296 loss=2.4062 -> experiments/Step_00/nas_runs/g15_3eeb1c0c/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8185 loss=0.4918 -> experiments/Step_00/nas_runs/g15_3eeb1c0c/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9241 loss=0.2337 -> experiments/Step_00/nas_runs/g15_3eeb1c0c/best_model.keras\n",
      "\n",
      "[Run-DONE ] g15_3eeb1c0c | time=150.0s | acc=0.9241 | loss=0.2337 | params=517,039\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g15_44b40972\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 80, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 80, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 08:41:48.329787: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 08:41:48.350989: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 08:41:48.781046: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 08:41:49.699643: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:41:49.710831: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:41:49.711153: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:41:49.711635: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:41:55.685397: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:41:55.685666: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:41:55.685858: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:41:55.765214: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:41:55.765474: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:41:55.765493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 08:41:55.765696: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:41:55.765735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 08:42:10.361367: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 08:42:10.884655: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 08:42:11.193962: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3d48002fe0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 08:42:11.193989: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 08:42:11.200477: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 08:42:11.333785: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.6747 -> experiments/Step_00/nas_runs/g15_44b40972/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.3407 loss=1.7406 -> experiments/Step_00/nas_runs/g15_44b40972/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.9611 loss=0.1123 -> experiments/Step_00/nas_runs/g15_44b40972/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9741 loss=0.0833 -> experiments/Step_00/nas_runs/g15_44b40972/best_model.keras\n",
      "\n",
      "[Run-DONE ] g15_44b40972 | time=125.9s | acc=0.9741 | loss=0.0833 | params=1,188,039\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g15_8390083c\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 08:44:15.198967: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 08:44:15.220706: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 08:44:15.661453: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 08:44:16.353439: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:44:16.364653: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:44:16.364818: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:44:16.365209: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:44:22.341143: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:44:22.343057: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:44:22.344510: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:44:22.425489: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:44:22.425651: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:44:22.425667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 08:44:22.425759: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:44:22.425793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 08:44:38.342062: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 08:44:38.854253: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 08:44:39.182033: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564726f5d6a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 08:44:39.182074: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 08:44:39.185973: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 08:44:39.277071: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.4628 -> experiments/Step_00/nas_runs/g15_8390083c/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.2704 loss=2.6630 -> experiments/Step_00/nas_runs/g15_8390083c/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.9519 loss=0.1339 -> experiments/Step_00/nas_runs/g15_8390083c/best_model.keras\n",
      "\n",
      "[Run-DONE ] g15_8390083c | time=138.0s | acc=0.9519 | loss=0.1339 | params=2,327,687\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g15_178815be\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 4, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 4, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 08:47:00.705480: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 08:47:00.731522: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 08:47:01.167518: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 08:47:02.095278: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:47:02.105757: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:47:02.106006: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:47:02.106446: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:47:07.735461: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:47:07.735630: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:47:07.735761: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:47:07.945890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:47:07.946130: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:47:07.946156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 08:47:07.946268: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:47:07.946302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 08:47:25.293090: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 08:47:25.822334: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 08:47:26.142173: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcd0c0047a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 08:47:26.142203: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 08:47:26.145389: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 08:47:26.210268: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.1000 loss=3.5537 -> experiments/Step_00/nas_runs/g15_178815be/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4167 loss=3.1335 -> experiments/Step_00/nas_runs/g15_178815be/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.7815 loss=0.6116 -> experiments/Step_00/nas_runs/g15_178815be/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9222 loss=0.2191 -> experiments/Step_00/nas_runs/g15_178815be/best_model.keras\n",
      "\n",
      "[Run-DONE ] g15_178815be | time=148.3s | acc=0.9222 | loss=0.2191 | params=2,513,639\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g15_79950bd4\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 08:49:58.042584: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 08:49:58.065896: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 08:49:58.575464: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 08:49:59.258108: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:49:59.269270: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:49:59.269441: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:49:59.269789: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:50:05.277240: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:50:05.278047: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:50:05.278440: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:50:05.362492: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:50:05.362778: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:50:05.362798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 08:50:05.362963: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:50:05.363000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 08:50:23.630645: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 08:50:24.160591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 08:50:24.497535: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d8528a0f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 08:50:24.497571: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 08:50:24.500557: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 08:50:24.561256: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.1148 loss=3.0369 -> experiments/Step_00/nas_runs/g15_79950bd4/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.5222 loss=1.7300 -> experiments/Step_00/nas_runs/g15_79950bd4/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.8185 loss=0.5885 -> experiments/Step_00/nas_runs/g15_79950bd4/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.8463 loss=0.4460 -> experiments/Step_00/nas_runs/g15_79950bd4/best_model.keras\n",
      "\n",
      "[Run-DONE ] g15_79950bd4 | time=155.2s | acc=0.8463 | loss=0.4460 | params=3,443,231\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Gen 15] Leaderboard (Top 12)\n",
      " rank    hash8  fitness      acc     loss  params        sec\n",
      "    1 2026944f 0.978592 0.990741 0.033059 1128927 110.193583\n",
      "    2 58d5702f 0.978396 0.990741 0.036645 1024991 113.195752\n",
      "    3 32e20554 0.975911 0.990741 0.054681 1566663 132.626005\n",
      "    4 076341a5 0.975181 0.990741 0.036963 1910695 136.492071\n",
      "    5 b1be27be 0.972153 0.988889 0.041636  654223 160.818027\n",
      "    6 44b40972 0.960295 0.974074 0.083269 1188039 125.907704\n",
      "    7 83677037 0.958173 0.972222 0.083636  832031 132.175435\n",
      "    8 f4ba14c5 0.949991 0.966667 0.124989 1115223 155.609094\n",
      "    9 8390083c 0.935720 0.951852 0.133892 2327687 138.038593\n",
      "   10 3eeb1c0c 0.908560 0.924074 0.233745  517039 149.972987\n",
      "   11 178815be 0.904883 0.922222 0.219066 2513639 148.255768\n",
      "   12 79950bd4 0.827329 0.846296 0.445987 3443231 155.237880\n",
      "[GC] Gen 15: removed 7 run dirs (non-top4)\n",
      "     g15_44b40972, g15_83677037, g15_f4ba14c5, g15_8390083c, g15_3eeb1c0c, g15_178815be, g15_79950bd4\n",
      "\n",
      "========= Generation 16 START (pop=12) =========\n",
      "\n",
      "[Run-START] g16_db3df50e\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 80, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 80, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 08:53:07.102885: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 08:53:07.124775: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 08:53:07.596295: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 08:53:08.299562: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:53:08.310109: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:53:08.310283: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:53:08.310791: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:53:14.445327: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:53:14.445669: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:53:14.445883: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:53:14.534589: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:53:14.534786: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:53:14.534808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 08:53:14.534977: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:53:14.535021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 08:53:27.477416: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 08:53:27.979399: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 08:53:28.303896: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f14b13eeff0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 08:53:28.303923: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 08:53:28.306920: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 08:53:28.369431: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.6170 -> experiments/Step_00/nas_runs/g16_db3df50e/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.3407 loss=2.5474 -> experiments/Step_00/nas_runs/g16_db3df50e/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8704 loss=0.4053 -> experiments/Step_00/nas_runs/g16_db3df50e/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9370 loss=0.1937 -> experiments/Step_00/nas_runs/g16_db3df50e/best_model.keras\n",
      "\n",
      "[Run-DONE ] g16_db3df50e | time=116.5s | acc=0.9370 | loss=0.1937 | params=1,368,527\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g16_dafee455\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 80, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 80, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 08:55:24.201058: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 08:55:24.222692: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 08:55:24.656169: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 08:55:25.330466: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:55:25.341828: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:55:25.342048: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:55:25.342541: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:55:31.305301: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:55:31.305541: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:55:31.305717: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:55:31.390695: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:55:31.390829: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:55:31.390844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 08:55:31.390928: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:55:31.390961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 08:55:45.168775: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 08:55:45.510476: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 08:55:45.716467: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6e0c8f8df0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 08:55:45.716502: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 08:55:45.719221: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 08:55:45.784445: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.7461 -> experiments/Step_00/nas_runs/g16_dafee455/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.1704 loss=2.7750 -> experiments/Step_00/nas_runs/g16_dafee455/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.7944 loss=0.6711 -> experiments/Step_00/nas_runs/g16_dafee455/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9759 loss=0.0903 -> experiments/Step_00/nas_runs/g16_dafee455/best_model.keras\n",
      "\n",
      "[Run-DONE ] g16_dafee455 | time=119.5s | acc=0.9759 | loss=0.0903 | params=1,674,823\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g16_aa01e112\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 72, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 88, \"repeats\": 4, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 72, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 88, \"repeats\": 4, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 08:57:47.322595: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 08:57:47.350365: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 08:57:47.867562: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 08:57:48.544245: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:57:48.555039: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:57:48.555208: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:57:48.555611: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:57:54.436639: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:57:54.436839: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:57:54.437000: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:57:54.518799: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:57:54.518929: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:57:54.518943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 08:57:54.519027: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 08:57:54.519059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 08:58:13.176839: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 08:58:13.556473: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 08:58:13.795753: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f893c003a20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 08:58:13.795782: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 08:58:13.799341: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 08:58:13.864434: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.5859 -> experiments/Step_00/nas_runs/g16_aa01e112/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.3352 loss=2.2459 -> experiments/Step_00/nas_runs/g16_aa01e112/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.9037 loss=0.2706 -> experiments/Step_00/nas_runs/g16_aa01e112/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9463 loss=0.1390 -> experiments/Step_00/nas_runs/g16_aa01e112/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9481 loss=0.1426 -> experiments/Step_00/nas_runs/g16_aa01e112/best_model.keras\n",
      "\n",
      "[Run-DONE ] g16_aa01e112 | time=158.1s | acc=0.9481 | loss=0.1427 | params=2,433,967\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g16_becf31b3\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 09:00:53.470054: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 09:00:53.492794: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 09:00:53.930999: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 09:00:54.723240: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:00:54.734756: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:00:54.735020: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:00:54.735466: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:01:00.644014: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:01:00.644239: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:01:00.644378: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:01:00.733427: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:01:00.733605: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:01:00.733619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 09:01:00.733748: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:01:00.733780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 09:01:18.357138: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 09:01:18.794544: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 09:01:19.065241: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f5b04012650 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 09:01:19.065279: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 09:01:19.068479: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 09:01:19.245984: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.5805 -> experiments/Step_00/nas_runs/g16_becf31b3/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4833 loss=1.5613 -> experiments/Step_00/nas_runs/g16_becf31b3/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.9389 loss=0.1792 -> experiments/Step_00/nas_runs/g16_becf31b3/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9611 loss=0.0901 -> experiments/Step_00/nas_runs/g16_becf31b3/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9685 loss=0.1107 -> experiments/Step_00/nas_runs/g16_becf31b3/best_model.keras\n",
      "\n",
      "[Run-DONE ] g16_becf31b3 | time=147.0s | acc=0.9685 | loss=0.1107 | params=908,679\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g16_adcf3b58\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 09:03:43.507313: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 09:03:43.529313: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 09:03:43.992898: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 09:03:44.738526: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:03:44.749788: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:03:44.750029: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:03:44.750495: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:03:50.684977: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:03:50.685215: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:03:50.685348: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:03:50.766963: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:03:50.767140: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:03:50.767161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 09:03:50.767265: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:03:50.767298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 09:04:06.719097: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 09:04:07.260749: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 09:04:07.613528: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f772d2d3c60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 09:04:07.613562: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 09:04:07.616334: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 09:04:07.677684: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.4028 -> experiments/Step_00/nas_runs/g16_adcf3b58/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.9593 loss=0.2510 -> experiments/Step_00/nas_runs/g16_adcf3b58/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9648 loss=0.1002 -> experiments/Step_00/nas_runs/g16_adcf3b58/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9667 loss=0.1095 -> experiments/Step_00/nas_runs/g16_adcf3b58/best_model.keras\n",
      "\n",
      "[Run-DONE ] g16_adcf3b58 | time=137.8s | acc=0.9667 | loss=0.1095 | params=3,229,999\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g16_cad6285e\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 09:06:32.288270: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 09:06:32.314133: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 09:06:32.770344: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 09:06:34.957697: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:06:34.968865: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:06:34.969059: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:06:34.969447: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:06:42.037842: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:06:42.038084: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:06:42.038226: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:06:42.119121: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:06:42.119299: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:06:42.119314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 09:06:42.119408: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:06:42.119445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 09:06:58.721602: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 09:06:59.218034: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 09:06:59.569393: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f23dc003d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 09:06:59.569419: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 09:06:59.572547: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 09:06:59.649286: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.2846 -> experiments/Step_00/nas_runs/g16_cad6285e/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.9130 loss=0.4596 -> experiments/Step_00/nas_runs/g16_cad6285e/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.9630 loss=0.1283 -> experiments/Step_00/nas_runs/g16_cad6285e/best_model.keras\n",
      "\n",
      "[Run-DONE ] g16_cad6285e | time=138.4s | acc=0.9630 | loss=0.1283 | params=1,522,599\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g16_eddb0ee3\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 6, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 6, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 09:09:18.223917: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 09:09:18.247762: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 09:09:18.728436: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 09:09:19.492679: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:09:19.504060: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:09:19.504291: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:09:19.504687: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:09:25.390009: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:09:25.390268: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:09:25.390438: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:09:25.473149: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:09:25.473350: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:09:25.473368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 09:09:25.473481: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:09:25.473518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 09:09:44.874132: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 09:09:45.689104: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 09:09:46.488702: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6be0001970 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 09:09:46.488736: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 09:09:46.491850: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 09:09:46.558868: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.5094 -> experiments/Step_00/nas_runs/g16_eddb0ee3/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.2333 loss=4.2061 -> experiments/Step_00/nas_runs/g16_eddb0ee3/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.7556 loss=0.8403 -> experiments/Step_00/nas_runs/g16_eddb0ee3/best_model.keras\n",
      "\n",
      "[Run-DONE ] g16_eddb0ee3 | time=443.6s | acc=0.7556 | loss=0.8403 | params=4,248,455\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g16_0da407ee\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 32, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 32, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 09:17:26.183052: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 09:17:26.205424: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 09:17:26.697245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 09:17:27.461191: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:17:27.471668: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:17:27.471842: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:17:27.472231: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:17:33.705744: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:17:33.706478: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:17:33.706675: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:17:33.791019: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:17:33.791189: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:17:33.791208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 09:17:33.791298: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:17:33.791330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 09:17:48.896370: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 09:17:49.537146: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 09:17:50.036203: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9da8003c90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 09:17:50.036243: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 09:17:50.039477: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 09:17:50.139490: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=4.2976 -> experiments/Step_00/nas_runs/g16_0da407ee/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.3852 loss=2.6460 -> experiments/Step_00/nas_runs/g16_0da407ee/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.7463 loss=0.7649 -> experiments/Step_00/nas_runs/g16_0da407ee/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9000 loss=0.3646 -> experiments/Step_00/nas_runs/g16_0da407ee/best_model.keras\n",
      "\n",
      "[Run-DONE ] g16_0da407ee | time=215.5s | acc=0.9000 | loss=0.3646 | params=1,573,071\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Gen 16] Leaderboard (Top 12)\n",
      " rank    hash8  fitness      acc     loss  params        sec\n",
      "    1 2026944f 0.978592 0.990741 0.033059 1128927 110.193583\n",
      "    2 58d5702f 0.978396 0.990741 0.036645 1024991 113.195752\n",
      "    3 32e20554 0.975911 0.990741 0.054681 1566663 132.626005\n",
      "    4 076341a5 0.975181 0.990741 0.036963 1910695 136.492071\n",
      "    5 dafee455 0.962303 0.975926 0.090250 1674823 119.478624\n",
      "    6 becf31b3 0.952910 0.968518 0.110695  908679 147.000659\n",
      "    7 adcf3b58 0.949655 0.966667 0.109463 3229999 137.817972\n",
      "    8 cad6285e 0.947597 0.962963 0.128252 1522599 138.434262\n",
      "    9 aa01e112 0.929899 0.948148 0.142650 2433967 158.147632\n",
      "   10 db3df50e 0.924021 0.937037 0.193715 1368527 116.473713\n",
      "   11 0da407ee 0.876880 0.900000 0.364644 1573071 215.467148\n",
      "   12 eddb0ee3 0.706948 0.755556 0.840344 4248455 443.589573\n",
      "[GC] Gen 16: removed 8 run dirs (non-top4)\n",
      "     g16_dafee455, g16_becf31b3, g16_adcf3b58, g16_cad6285e, g16_aa01e112, g16_db3df50e, g16_0da407ee, g16_eddb0ee3\n",
      "\n",
      "========= Generation 17 START (pop=12) =========\n",
      "\n",
      "[Run-START] g17_3ff0aa80\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 09:21:26.713807: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 09:21:26.734734: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 09:21:27.198237: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 09:21:27.914396: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:21:27.925027: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:21:27.925252: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:21:27.925706: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:21:33.979742: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:21:33.979952: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:21:33.980090: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:21:34.059885: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:21:34.060050: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:21:34.060068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 09:21:34.060188: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:21:34.060234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 09:21:49.651032: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 09:21:50.238840: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 09:21:50.658796: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f16680025d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 09:21:50.658826: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 09:21:50.661539: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 09:21:50.727566: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.5292 -> experiments/Step_00/nas_runs/g17_3ff0aa80/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.7056 loss=0.9518 -> experiments/Step_00/nas_runs/g17_3ff0aa80/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.9074 loss=0.2526 -> experiments/Step_00/nas_runs/g17_3ff0aa80/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9685 loss=0.1124 -> experiments/Step_00/nas_runs/g17_3ff0aa80/best_model.keras\n",
      "\n",
      "[Run-DONE ] g17_3ff0aa80 | time=175.1s | acc=0.9685 | loss=0.1124 | params=1,033,383\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g17_f1d453f1\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 88, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 16, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 88, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 09:24:44.868266: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 09:24:44.889888: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 09:24:45.332802: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 09:24:45.990856: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:24:46.001775: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:24:46.001989: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:24:46.002459: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:24:52.025601: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:24:52.025877: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:24:52.026063: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:24:52.118123: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:24:52.118371: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:24:52.118393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 09:24:52.118550: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:24:52.118582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 09:25:04.830913: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 09:25:05.327598: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 09:25:05.715348: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc5cc002040 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 09:25:05.715375: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 09:25:05.719032: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 09:25:05.785056: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.6746 -> experiments/Step_00/nas_runs/g17_f1d453f1/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4204 loss=2.3314 -> experiments/Step_00/nas_runs/g17_f1d453f1/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.6630 loss=1.5815 -> experiments/Step_00/nas_runs/g17_f1d453f1/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9093 loss=0.2632 -> experiments/Step_00/nas_runs/g17_f1d453f1/best_model.keras\n",
      "\n",
      "[Run-DONE ] g17_f1d453f1 | time=127.8s | acc=0.9093 | loss=0.2632 | params=756,527\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g17_5ee6f37e\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 09:27:10.415892: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 09:27:10.438427: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 09:27:10.882235: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 09:27:11.584793: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:27:11.595865: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:27:11.596103: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:27:11.596510: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:27:17.278770: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:27:17.279171: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:27:17.279382: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:27:17.565237: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:27:17.565453: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:27:17.565473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 09:27:17.565599: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:27:17.565639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 09:27:27.975852: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 09:27:28.634363: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 09:27:29.034856: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f831000ae30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 09:27:29.034888: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 09:27:29.037978: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 09:27:29.104834: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.1556 loss=3.1121 -> experiments/Step_00/nas_runs/g17_5ee6f37e/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4148 loss=2.4499 -> experiments/Step_00/nas_runs/g17_5ee6f37e/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.6185 loss=1.2309 -> experiments/Step_00/nas_runs/g17_5ee6f37e/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.8296 loss=0.4880 -> experiments/Step_00/nas_runs/g17_5ee6f37e/best_model.keras\n",
      "\n",
      "[Run-DONE ] g17_5ee6f37e | time=113.4s | acc=0.8296 | loss=0.4880 | params=1,863,439\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g17_f466053f\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 09:29:23.024447: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 09:29:23.046607: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 09:29:23.498184: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 09:29:24.325719: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:29:24.336612: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:29:24.336799: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:29:24.337145: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:29:30.169435: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:29:30.169768: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:29:30.169974: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:29:30.249884: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:29:30.250029: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:29:30.250044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 09:29:30.250131: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:29:30.250161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 09:29:43.427971: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 09:29:43.966711: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 09:29:44.388850: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f55bc002d60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 09:29:44.388880: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 09:29:44.391939: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 09:29:44.458397: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0926 loss=3.3465 -> experiments/Step_00/nas_runs/g17_f466053f/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4444 loss=2.6890 -> experiments/Step_00/nas_runs/g17_f466053f/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8204 loss=0.5064 -> experiments/Step_00/nas_runs/g17_f466053f/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9481 loss=0.1410 -> experiments/Step_00/nas_runs/g17_f466053f/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9704 loss=0.1100 -> experiments/Step_00/nas_runs/g17_f466053f/best_model.keras\n",
      "\n",
      "[Run-DONE ] g17_f466053f | time=119.4s | acc=0.9704 | loss=0.1100 | params=2,315,759\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g17_371e9d53\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 09:31:45.400043: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 09:31:45.422669: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 09:31:45.865513: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 09:31:46.646099: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:31:46.657039: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:31:46.657288: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:31:46.657669: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:31:51.300230: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:31:51.300393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:31:51.300510: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:31:51.385847: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:31:51.386098: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:31:51.386112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 09:31:51.386208: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:31:51.386244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 09:32:13.319369: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 09:32:13.987128: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 09:32:14.552494: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x565249709580 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 09:32:14.552529: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 09:32:14.555621: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 09:32:14.620663: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.2749 -> experiments/Step_00/nas_runs/g17_371e9d53/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.6556 loss=0.9593 -> experiments/Step_00/nas_runs/g17_371e9d53/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9370 loss=0.2003 -> experiments/Step_00/nas_runs/g17_371e9d53/best_model.keras\n",
      "\n",
      "[Run-DONE ] g17_371e9d53 | time=241.6s | acc=0.9370 | loss=0.2003 | params=1,701,463\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g17_e878a3fe\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 6, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 6, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 09:36:20.866758: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 09:36:20.890220: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 09:36:21.323906: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 09:36:22.189238: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:36:22.201893: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:36:22.202221: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:36:22.202872: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:36:28.075879: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:36:28.076137: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:36:28.076322: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:36:28.161461: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:36:28.161676: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:36:28.161694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 09:36:28.161867: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:36:28.161903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 09:36:47.340609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 09:36:47.813252: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 09:36:48.204418: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8fec005570 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 09:36:48.204453: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 09:36:48.237247: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 09:36:48.299165: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.0399 -> experiments/Step_00/nas_runs/g17_e878a3fe/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.5056 loss=1.8927 -> experiments/Step_00/nas_runs/g17_e878a3fe/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.9037 loss=0.3462 -> experiments/Step_00/nas_runs/g17_e878a3fe/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9204 loss=0.2379 -> experiments/Step_00/nas_runs/g17_e878a3fe/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9463 loss=0.1426 -> experiments/Step_00/nas_runs/g17_e878a3fe/best_model.keras\n",
      "\n",
      "[Run-DONE ] g17_e878a3fe | time=163.1s | acc=0.9463 | loss=0.1427 | params=3,965,671\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g17_6fd458ae\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 4, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 4, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 09:39:46.097369: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 09:39:46.119589: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 09:39:46.556195: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 09:39:47.345567: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:39:47.358598: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:39:47.358899: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:39:47.359284: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:39:53.158741: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:39:53.158952: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:39:53.159095: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:39:53.243921: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:39:53.244054: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:39:53.244069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 09:39:53.244154: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:39:53.244184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 09:40:04.701043: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 09:40:05.322600: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 09:40:05.920243: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9d30006a20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 09:40:05.920275: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 09:40:05.923667: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 09:40:05.987884: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.1093 loss=5.5533 -> experiments/Step_00/nas_runs/g17_6fd458ae/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.2037 loss=7.4769 -> experiments/Step_00/nas_runs/g17_6fd458ae/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.3759 loss=3.7984 -> experiments/Step_00/nas_runs/g17_6fd458ae/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.5389 loss=2.4428 -> experiments/Step_00/nas_runs/g17_6fd458ae/best_model.keras\n",
      "\n",
      "[Run-DONE ] g17_6fd458ae | time=157.2s | acc=0.5389 | loss=2.4428 | params=2,373,087\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g17_07ccf074\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 80, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 96, \"repeats\": 6, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 80, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 96, \"repeats\": 6, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 09:42:47.339613: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 09:42:47.361220: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 09:42:47.801854: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 09:42:48.658941: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:42:48.671641: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:42:48.671895: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:42:48.672440: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:42:54.206509: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:42:54.206713: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:42:54.206849: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:42:54.293437: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:42:54.293606: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:42:54.293625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 09:42:54.293773: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:42:54.293809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 09:43:16.443159: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 09:43:17.374565: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 09:43:18.134109: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe3ac004a00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 09:43:18.134150: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 09:43:18.138080: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 09:43:18.300111: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.9733 -> experiments/Step_00/nas_runs/g17_07ccf074/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.2222 loss=8.1463 -> experiments/Step_00/nas_runs/g17_07ccf074/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.4148 loss=3.7994 -> experiments/Step_00/nas_runs/g17_07ccf074/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.6037 loss=1.5975 -> experiments/Step_00/nas_runs/g17_07ccf074/best_model.keras\n",
      "\n",
      "[Run-DONE ] g17_07ccf074 | time=484.4s | acc=0.6037 | loss=1.5975 | params=3,348,583\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Gen 17] Leaderboard (Top 12)\n",
      " rank    hash8  fitness      acc     loss  params        sec\n",
      "    1 2026944f 0.978592 0.990741 0.033059 1128927 110.193583\n",
      "    2 58d5702f 0.978396 0.990741 0.036645 1024991 113.195752\n",
      "    3 32e20554 0.975911 0.990741 0.054681 1566663 132.626005\n",
      "    4 076341a5 0.975181 0.990741 0.036963 1910695 136.492071\n",
      "    5 f466053f 0.956111 0.970370 0.110017 2315759 119.433395\n",
      "    6 3ff0aa80 0.949970 0.968518 0.112356 1033383 175.146819\n",
      "    7 e878a3fe 0.926017 0.946296 0.142651 3965671 163.138129\n",
      "    8 371e9d53 0.911177 0.937037 0.200350 1701463 241.581386\n",
      "    9 f1d453f1 0.895721 0.909259 0.263163  756527 127.819054\n",
      "   10 5ee6f37e 0.816424 0.829630 0.488031 1863439 113.421141\n",
      "   11 07ccf074 0.551911 0.603704 1.597466 3348583 484.438440\n",
      "   12 6fd458ae 0.520794 0.538889 2.442816 2373087 157.213050\n",
      "[GC] Gen 17: removed 8 run dirs (non-top4)\n",
      "     g17_f466053f, g17_3ff0aa80, g17_e878a3fe, g17_371e9d53, g17_f1d453f1, g17_5ee6f37e, g17_07ccf074, g17_6fd458ae\n",
      "\n",
      "========= Generation 18 START (pop=12) =========\n",
      "\n",
      "[Run-START] g18_108caa13\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 09:51:41.314409: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 09:51:41.334853: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 09:51:41.754230: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 09:51:42.500705: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:51:42.514013: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:51:42.514184: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:51:42.514580: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:51:48.230589: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:51:48.230856: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:51:48.231035: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:51:48.319824: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:51:48.320075: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:51:48.320097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 09:51:48.320268: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:51:48.320306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 09:52:05.757310: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 09:52:06.255505: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 09:52:06.584588: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558a136eea30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 09:52:06.584623: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 09:52:06.588275: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 09:52:06.653972: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.4014 -> experiments/Step_00/nas_runs/g18_108caa13/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.7130 loss=0.8751 -> experiments/Step_00/nas_runs/g18_108caa13/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8500 loss=0.4984 -> experiments/Step_00/nas_runs/g18_108caa13/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9852 loss=0.0676 -> experiments/Step_00/nas_runs/g18_108caa13/best_model.keras\n",
      "\n",
      "[Run-DONE ] g18_108caa13 | time=155.1s | acc=0.9852 | loss=0.0676 | params=1,542,279\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g18_bccb60b9\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 4, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 6, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 4, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 09:54:44.517702: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 09:54:44.539288: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 09:54:44.998225: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 09:54:45.835224: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:54:45.848985: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:54:45.849313: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:54:45.849777: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:54:51.522089: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:54:51.522285: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:54:51.522441: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:54:51.614420: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:54:51.614621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:54:51.614645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 09:54:51.614778: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:54:51.614819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 09:55:10.013124: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 09:55:10.493318: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 09:55:10.861712: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6350095250 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 09:55:10.861748: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 09:55:10.865035: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 09:55:10.932842: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.7046 -> experiments/Step_00/nas_runs/g18_bccb60b9/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.3630 loss=2.3536 -> experiments/Step_00/nas_runs/g18_bccb60b9/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.6389 loss=2.0072 -> experiments/Step_00/nas_runs/g18_bccb60b9/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.8796 loss=0.3501 -> experiments/Step_00/nas_runs/g18_bccb60b9/best_model.keras\n",
      "\n",
      "[Run-DONE ] g18_bccb60b9 | time=160.2s | acc=0.8796 | loss=0.3501 | params=3,479,559\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g18_ad914044\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 6, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 6, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 09:58:05.725640: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 09:58:05.748567: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 09:58:06.238210: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 09:58:06.897086: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:58:06.909258: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:58:06.909597: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:58:06.910044: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:58:13.034361: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:58:13.034608: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:58:13.034971: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:58:13.128678: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:58:13.128907: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:58:13.128924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 09:58:13.129066: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 09:58:13.129099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 09:58:29.623433: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 09:58:30.280564: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 09:58:30.726889: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7efb08122530 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 09:58:30.726919: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 09:58:30.730103: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 09:58:30.795072: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.5310 -> experiments/Step_00/nas_runs/g18_ad914044/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4037 loss=1.8758 -> experiments/Step_00/nas_runs/g18_ad914044/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.6463 loss=1.4055 -> experiments/Step_00/nas_runs/g18_ad914044/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.7407 loss=0.8058 -> experiments/Step_00/nas_runs/g18_ad914044/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.7444 loss=0.8296 -> experiments/Step_00/nas_runs/g18_ad914044/best_model.keras\n",
      "\n",
      "[Run-DONE ] g18_ad914044 | time=228.7s | acc=0.7444 | loss=0.8296 | params=2,201,503\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g18_9ee6a5b2\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 10:02:24.502860: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 10:02:24.525086: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 10:02:24.971373: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 10:02:25.718634: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:02:25.732252: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:02:25.732519: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:02:25.732906: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:02:32.136007: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:02:32.136351: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:02:32.136497: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:02:32.345240: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:02:32.345425: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:02:32.345442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 10:02:32.345529: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:02:32.345561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 10:02:47.604600: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 10:02:48.017111: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 10:02:48.303172: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc22c013060 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 10:02:48.303207: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 10:02:48.306776: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 10:02:48.373216: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.4094 -> experiments/Step_00/nas_runs/g18_9ee6a5b2/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.6389 loss=1.1958 -> experiments/Step_00/nas_runs/g18_9ee6a5b2/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8185 loss=0.5013 -> experiments/Step_00/nas_runs/g18_9ee6a5b2/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9833 loss=0.0614 -> experiments/Step_00/nas_runs/g18_9ee6a5b2/best_model.keras\n",
      "\n",
      "[Run-DONE ] g18_9ee6a5b2 | time=129.7s | acc=0.9833 | loss=0.0614 | params=861,111\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g18_89c9f8d8\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 10:04:54.339969: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 10:04:54.360519: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 10:04:54.824282: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 10:04:55.507790: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:04:55.520575: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:04:55.520860: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:04:55.521310: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:05:01.415034: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:05:01.415244: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:05:01.415378: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:05:01.494990: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:05:01.495161: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:05:01.495180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 10:05:01.495309: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:05:01.495348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 10:05:21.480738: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 10:05:22.112570: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 10:05:22.523920: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9014003a70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 10:05:22.523953: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 10:05:22.527663: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 10:05:22.593936: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.6455 -> experiments/Step_00/nas_runs/g18_89c9f8d8/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.3259 loss=2.5798 -> experiments/Step_00/nas_runs/g18_89c9f8d8/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.3704 loss=3.3554 -> experiments/Step_00/nas_runs/g18_89c9f8d8/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.7556 loss=0.7454 -> experiments/Step_00/nas_runs/g18_89c9f8d8/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.8093 loss=0.5929 -> experiments/Step_00/nas_runs/g18_89c9f8d8/best_model.keras\n",
      "\n",
      "[Run-DONE ] g18_89c9f8d8 | time=300.2s | acc=0.8093 | loss=0.5929 | params=1,682,991\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g18_0493ce24\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 10:10:24.011549: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 10:10:24.033256: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 10:10:24.472741: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 10:10:25.204394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:10:25.218247: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:10:25.218417: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:10:25.218827: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:10:30.752419: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:10:30.752627: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:10:30.752760: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:10:30.917605: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:10:30.917802: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:10:30.917826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 10:10:30.918001: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:10:30.918038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 10:10:42.382249: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 10:10:42.792294: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 10:10:43.064491: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa800009d00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 10:10:43.064542: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 10:10:43.068250: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 10:10:43.136426: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.8766 -> experiments/Step_00/nas_runs/g18_0493ce24/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4833 loss=1.6952 -> experiments/Step_00/nas_runs/g18_0493ce24/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.7667 loss=0.6360 -> experiments/Step_00/nas_runs/g18_0493ce24/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9352 loss=0.1883 -> experiments/Step_00/nas_runs/g18_0493ce24/best_model.keras\n",
      "\n",
      "[Run-DONE ] g18_0493ce24 | time=109.4s | acc=0.9352 | loss=0.1883 | params=482,423\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g18_26928f6c\n",
      "{\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 10:12:29.415685: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 10:12:29.435938: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 10:12:29.850234: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 10:12:30.539219: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:12:30.550228: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:12:30.550373: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:12:30.550712: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:12:38.159055: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:12:38.159285: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:12:38.159460: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:12:38.252862: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:12:38.253078: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:12:38.253098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 10:12:38.253216: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:12:38.253255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 10:12:51.149511: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 10:12:51.897303: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 10:12:52.483563: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb0a0005190 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 10:12:52.483596: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 10:12:52.512409: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 10:12:52.814937: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0833 loss=3.1205 -> experiments/Step_00/nas_runs/g18_26928f6c/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.4333 loss=1.9400 -> experiments/Step_00/nas_runs/g18_26928f6c/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.6907 loss=1.0694 -> experiments/Step_00/nas_runs/g18_26928f6c/best_model.keras\n",
      "\n",
      "[Run-DONE ] g18_26928f6c | time=201.0s | acc=0.6907 | loss=1.0694 | params=1,162,375\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g18_a5a01c20\n",
      "{\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 10:16:13.153691: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 10:16:13.175277: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 10:16:13.641304: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 10:16:14.495314: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:16:14.506395: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:16:14.506637: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:16:14.507035: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:16:20.253546: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:16:20.253717: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:16:20.253847: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:16:20.354816: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:16:20.354950: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:16:20.354964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 10:16:20.355046: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:16:20.355078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 10:16:33.496830: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 10:16:33.921699: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 10:16:34.225520: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d8ab88cd60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 10:16:34.225545: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 10:16:34.228993: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 10:16:34.295064: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.4483 -> experiments/Step_00/nas_runs/g18_a5a01c20/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.6019 loss=1.2439 -> experiments/Step_00/nas_runs/g18_a5a01c20/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.7704 loss=0.7040 -> experiments/Step_00/nas_runs/g18_a5a01c20/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9741 loss=0.0999 -> experiments/Step_00/nas_runs/g18_a5a01c20/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.9833 loss=0.0652 -> experiments/Step_00/nas_runs/g18_a5a01c20/best_model.keras\n",
      "\n",
      "[Run-DONE ] g18_a5a01c20 | time=117.7s | acc=0.9833 | loss=0.0652 | params=2,624,879\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Gen 18] Leaderboard (Top 12)\n",
      " rank    hash8  fitness      acc     loss  params        sec\n",
      "    1 2026944f 0.978592 0.990741 0.033059 1128927 110.193583\n",
      "    2 58d5702f 0.978396 0.990741 0.036645 1024991 113.195752\n",
      "    3 32e20554 0.975911 0.990741 0.054681 1566663 132.626005\n",
      "    4 076341a5 0.975181 0.990741 0.036963 1910695 136.492071\n",
      "    5 9ee6a5b2 0.969504 0.983333 0.061449  861111 129.682789\n",
      "    6 a5a01c20 0.968941 0.983333 0.065233 2624879 117.676423\n",
      "    7 108caa13 0.968137 0.985185 0.067625 1542279 155.056625\n",
      "    8 0493ce24 0.923766 0.935185 0.188271  482423 109.372704\n",
      "    9 bccb60b9 0.860130 0.879630 0.350073 3479559 160.203276\n",
      "   10 89c9f8d8 0.777557 0.809259 0.592893 1682991 300.194430\n",
      "   11 ad914044 0.719373 0.744444 0.829615 2201503 228.695419\n",
      "   12 26928f6c 0.669479 0.690741 1.069412 1162375 200.993230\n",
      "[GC] Gen 18: removed 8 run dirs (non-top4)\n",
      "     g18_9ee6a5b2, g18_a5a01c20, g18_108caa13, g18_0493ce24, g18_bccb60b9, g18_89c9f8d8, g18_ad914044, g18_26928f6c\n",
      "\n",
      "========= Generation 19 START (pop=12) =========\n",
      "\n",
      "[Run-START] g19_7530c556\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 10:18:37.493272: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 10:18:37.513277: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 10:18:37.994756: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 10:18:38.693722: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:18:38.704418: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:18:38.704582: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:18:38.704982: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:18:43.958859: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:18:43.959023: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:18:43.959148: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:18:44.035434: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:18:44.035595: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:18:44.035614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 10:18:44.035715: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:18:44.035745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 10:18:55.316211: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 10:18:55.769715: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 10:18:56.055797: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6fd0005800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 10:18:56.055824: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 10:18:56.058864: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 10:18:56.123858: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.9463 -> experiments/Step_00/nas_runs/g19_7530c556/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.6167 loss=1.1375 -> experiments/Step_00/nas_runs/g19_7530c556/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.9537 loss=0.1583 -> experiments/Step_00/nas_runs/g19_7530c556/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9537 loss=0.1425 -> experiments/Step_00/nas_runs/g19_7530c556/best_model.keras\n",
      "\n",
      "[Run-DONE ] g19_7530c556 | time=105.2s | acc=0.9537 | loss=0.1425 | params=1,080,239\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g19_398ab89f\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 6, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 104, \"repeats\": 4, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 10:20:39.702050: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 10:20:39.724561: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 10:20:40.234926: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 10:20:40.933392: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:20:40.945367: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:20:40.945610: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:20:40.946016: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:20:46.694775: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:20:46.694948: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:20:46.695078: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:20:46.782617: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:20:46.782763: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:20:46.782778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 10:20:46.782865: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:20:46.782897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 10:21:02.426103: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 10:21:02.938846: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 10:21:03.278993: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7c7c0073c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 10:21:03.279045: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 10:21:03.282483: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 10:21:03.404393: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.1852 -> experiments/Step_00/nas_runs/g19_398ab89f/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.5537 loss=1.3460 -> experiments/Step_00/nas_runs/g19_398ab89f/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.7315 loss=1.4745 -> experiments/Step_00/nas_runs/g19_398ab89f/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9593 loss=0.1193 -> experiments/Step_00/nas_runs/g19_398ab89f/best_model.keras\n",
      "\n",
      "[Run-DONE ] g19_398ab89f | time=137.6s | acc=0.9593 | loss=0.1193 | params=1,685,655\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g19_fab6f1fa\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 10:23:22.330646: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 10:23:22.352243: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 10:23:22.786368: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 10:23:23.491942: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:23:23.502903: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:23:23.503497: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:23:23.515188: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:23:29.452419: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:23:29.452604: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:23:29.452728: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:23:29.533312: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:23:29.533523: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:23:29.533541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 10:23:29.533663: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:23:29.533701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 10:23:44.649264: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 10:23:45.284505: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 10:23:45.810472: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff85400f3a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 10:23:45.810504: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 10:23:45.814144: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 10:23:45.878435: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.6481 -> experiments/Step_00/nas_runs/g19_fab6f1fa/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.5667 loss=1.2111 -> experiments/Step_00/nas_runs/g19_fab6f1fa/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8204 loss=0.6220 -> experiments/Step_00/nas_runs/g19_fab6f1fa/best_model.keras\n",
      "\n",
      "[Run-DONE ] g19_fab6f1fa | time=203.5s | acc=0.8204 | loss=0.6220 | params=999,855\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g19_2236d851\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 80, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 24, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 6, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 80, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 10:27:06.920590: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 10:27:06.943256: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 10:27:07.353229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 10:27:08.070938: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:27:08.082027: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:27:08.082543: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:27:08.082984: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:27:13.705507: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:27:13.705681: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:27:13.705807: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:27:13.790350: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:27:13.790518: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:27:13.790537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 10:27:13.790655: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:27:13.790690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 10:27:34.221870: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 10:27:35.290802: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 10:27:36.228985: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd48ce222e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 10:27:36.229015: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 10:27:36.232041: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 10:27:36.335412: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.7395 -> experiments/Step_00/nas_runs/g19_2236d851/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.3833 loss=2.8933 -> experiments/Step_00/nas_runs/g19_2236d851/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.4130 loss=4.9939 -> experiments/Step_00/nas_runs/g19_2236d851/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.5093 loss=2.9174 -> experiments/Step_00/nas_runs/g19_2236d851/best_model.keras\n",
      "[BestSaver] epoch 5 acc=0.5407 loss=4.0672 -> experiments/Step_00/nas_runs/g19_2236d851/best_model.keras\n",
      "\n",
      "[Run-DONE ] g19_2236d851 | time=624.8s | acc=0.5407 | loss=4.0672 | params=1,852,543\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g19_7badbafd\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 4, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 56, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 4, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 10:38:05.155202: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 10:38:05.176930: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 10:38:05.640956: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 10:38:06.437451: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:38:06.447789: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:38:06.453458: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:38:06.454322: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:38:11.875541: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:38:11.875773: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:38:11.875898: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:38:12.088287: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:38:12.088519: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:38:12.088554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 10:38:12.088779: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:38:12.088847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 10:38:29.015018: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 10:38:29.517757: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 10:38:29.839052: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3c68002d20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 10:38:29.839081: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 10:38:29.842528: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 10:38:29.907328: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.8272 -> experiments/Step_00/nas_runs/g19_7badbafd/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.5222 loss=1.5907 -> experiments/Step_00/nas_runs/g19_7badbafd/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8148 loss=0.5426 -> experiments/Step_00/nas_runs/g19_7badbafd/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9500 loss=0.1714 -> experiments/Step_00/nas_runs/g19_7badbafd/best_model.keras\n",
      "\n",
      "[Run-DONE ] g19_7badbafd | time=148.1s | acc=0.9500 | loss=0.1714 | params=3,584,607\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g19_161f4366\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 48, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 10:41:13.982476: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 10:41:14.004258: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 10:41:14.432525: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 10:41:15.106629: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:41:15.118271: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:41:15.118636: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:41:15.119093: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:41:20.826742: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:41:20.826873: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:41:20.826969: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:41:20.905335: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:41:20.905510: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:41:20.905529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 10:41:20.905622: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:41:20.905657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 10:41:35.740668: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 10:41:36.174804: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 10:41:36.501281: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6b00f1a840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 10:41:36.501313: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 10:41:36.504475: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 10:41:36.563939: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=4.0715 -> experiments/Step_00/nas_runs/g19_161f4366/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.2204 loss=2.4417 -> experiments/Step_00/nas_runs/g19_161f4366/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.9648 loss=0.1349 -> experiments/Step_00/nas_runs/g19_161f4366/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.9704 loss=0.0889 -> experiments/Step_00/nas_runs/g19_161f4366/best_model.keras\n",
      "\n",
      "[Run-DONE ] g19_161f4366 | time=132.9s | acc=0.9704 | loss=0.0889 | params=1,236,447\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g19_5daac771\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 40, \"repeats\": 2, \"stride\": 1, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 64, \"repeats\": 4, \"stride\": 1, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 10:43:46.304837: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 10:43:46.326249: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 10:43:46.741765: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 10:43:47.548440: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:43:47.559602: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:43:47.559865: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:43:47.560307: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:43:52.995413: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:43:52.995701: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:43:52.995908: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:43:53.190379: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:43:53.190552: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:43:53.190566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 10:43:53.190699: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:43:53.190735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 10:44:04.792008: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 10:44:05.310619: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 10:44:05.664837: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4a4000ae90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 10:44:05.664866: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 10:44:05.668395: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 10:44:05.734729: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.6916 -> experiments/Step_00/nas_runs/g19_5daac771/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.7444 loss=0.7547 -> experiments/Step_00/nas_runs/g19_5daac771/best_model.keras\n",
      "[BestSaver] epoch 4 acc=0.8926 loss=0.2921 -> experiments/Step_00/nas_runs/g19_5daac771/best_model.keras\n",
      "\n",
      "[Run-DONE ] g19_5daac771 | time=119.2s | acc=0.8926 | loss=0.2921 | params=1,486,839\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Run-START] g19_678a5d55\n",
      "{\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 72, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 2, \"stride\": 2, \"use_se\": true}}}\n",
      "[Subprocess STDERR]\n",
      "2025-09-23 10:46:05.986568: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-23 10:46:06.012954: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-23 10:46:06.460692: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-23 10:46:07.179793: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:46:07.193271: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:46:07.193531: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:46:07.193959: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:46:13.108141: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:46:13.108393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:46:13.108547: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:46:13.193693: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:46:13.193867: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:46:13.193883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-23 10:46:13.193975: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-23 10:46:13.194008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-23 10:46:28.353304: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-09-23 10:46:28.923414: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-09-23 10:46:29.281545: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa094005b70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 10:46:29.281574: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-09-23 10:46:29.285248: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 10:46:29.354159: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "[BestSaver] epoch 1 acc=0.0667 loss=3.8228 -> experiments/Step_00/nas_runs/g19_678a5d55/best_model.keras\n",
      "[BestSaver] epoch 2 acc=0.5296 loss=2.0714 -> experiments/Step_00/nas_runs/g19_678a5d55/best_model.keras\n",
      "[BestSaver] epoch 3 acc=0.8241 loss=0.5118 -> experiments/Step_00/nas_runs/g19_678a5d55/best_model.keras\n",
      "\n",
      "[Run-DONE ] g19_678a5d55 | time=131.5s | acc=0.8241 | loss=0.5118 | params=2,137,655\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Gen 19] Leaderboard (Top 12)\n",
      " rank    hash8  fitness      acc     loss  params        sec\n",
      "    1 2026944f 0.978592 0.990741 0.033059 1128927 110.193583\n",
      "    2 58d5702f 0.978396 0.990741 0.036645 1024991 113.195752\n",
      "    3 32e20554 0.975911 0.990741 0.054681 1566663 132.626005\n",
      "    4 076341a5 0.975181 0.990741 0.036963 1910695 136.492071\n",
      "    5 161f4366 0.955849 0.970370 0.088927 1236447 132.850049\n",
      "    6 398ab89f 0.943810 0.959259 0.119342 1685655 137.640013\n",
      "    7 7530c556 0.942108 0.953704 0.142535 1080239 105.151158\n",
      "    8 7badbafd 0.931606 0.950000 0.171360 3584607 148.095701\n",
      "    9 5daac771 0.879186 0.892593 0.292131 1486839 119.192894\n",
      "   10 678a5d55 0.808789 0.824074 0.511804 2137655 131.479147\n",
      "   11 fab6f1fa 0.799019 0.820370 0.622042  999855 203.517035\n",
      "   12 2236d851 0.476408 0.540741 4.067167 1852543 624.805033\n",
      "[GC] Gen 19: removed 8 run dirs (non-top4)\n",
      "     g19_161f4366, g19_398ab89f, g19_7530c556, g19_7badbafd, g19_5daac771, g19_678a5d55, g19_fab6f1fa, g19_2236d851\n",
      "\n",
      "[Final Best]\n",
      "hash=2026944feaa2e0fb1517eb1425e56c455604e2c3, gen=13\n",
      "fitness=0.978592, acc=0.9907, loss=0.0331, params=1,128,927, sec=110.2\n",
      "run_dir=experiments/Step_00/nas_runs/g13_2026944f\n",
      "\n",
      "Best Config JSON\n",
      "{\n",
      "  \"dtm\": {\n",
      "    \"conv1x1_out\": 112,\n",
      "    \"stage1\": {\n",
      "      \"block_type\": \"fused\",\n",
      "      \"expand_ratio\": 4,\n",
      "      \"out_channels\": 24,\n",
      "      \"repeats\": 2,\n",
      "      \"stride\": 2,\n",
      "      \"use_se\": true\n",
      "    },\n",
      "    \"stage2\": {\n",
      "      \"block_type\": \"fused\",\n",
      "      \"expand_ratio\": 2,\n",
      "      \"out_channels\": 56,\n",
      "      \"repeats\": 6,\n",
      "      \"stride\": 2,\n",
      "      \"use_se\": false\n",
      "    },\n",
      "    \"stage3\": {\n",
      "      \"block_type\": \"mbconv\",\n",
      "      \"expand_ratio\": 2,\n",
      "      \"out_channels\": 80,\n",
      "      \"repeats\": 2,\n",
      "      \"stride\": 2,\n",
      "      \"use_se\": false\n",
      "    },\n",
      "    \"stage4\": {\n",
      "      \"block_type\": \"mbconv\",\n",
      "      \"expand_ratio\": 4,\n",
      "      \"out_channels\": 88,\n",
      "      \"repeats\": 2,\n",
      "      \"stride\": 1,\n",
      "      \"use_se\": false\n",
      "    }\n",
      "  },\n",
      "  \"rtm\": {\n",
      "    \"conv1x1_out\": 112,\n",
      "    \"stage1\": {\n",
      "      \"block_type\": \"fused\",\n",
      "      \"expand_ratio\": 4,\n",
      "      \"out_channels\": 24,\n",
      "      \"repeats\": 2,\n",
      "      \"stride\": 2,\n",
      "      \"use_se\": true\n",
      "    },\n",
      "    \"stage2\": {\n",
      "      \"block_type\": \"fused\",\n",
      "      \"expand_ratio\": 2,\n",
      "      \"out_channels\": 56,\n",
      "      \"repeats\": 6,\n",
      "      \"stride\": 2,\n",
      "      \"use_se\": false\n",
      "    },\n",
      "    \"stage3\": {\n",
      "      \"block_type\": \"mbconv\",\n",
      "      \"expand_ratio\": 2,\n",
      "      \"out_channels\": 80,\n",
      "      \"repeats\": 2,\n",
      "      \"stride\": 2,\n",
      "      \"use_se\": false\n",
      "    },\n",
      "    \"stage4\": {\n",
      "      \"block_type\": \"mbconv\",\n",
      "      \"expand_ratio\": 4,\n",
      "      \"out_channels\": 88,\n",
      "      \"repeats\": 2,\n",
      "      \"stride\": 1,\n",
      "      \"use_se\": false\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 4. 진화형 NAS 루프\n",
    "# =========================\n",
    "POP_SIZE = 12\n",
    "N_GEN = 20\n",
    "ELITE_K = 4\n",
    "CHILDREN_K = 6\n",
    "IMMIGRANTS_K = 2\n",
    "MUT_PROB = 0.5\n",
    "\n",
    "evaluated = {}     # hash -> record\n",
    "history_best = []  # per-gen best\n",
    "\n",
    "def ensure_unique_from(fn_make_cfg, blacklist, max_tries=200):\n",
    "    tried = 0\n",
    "    while tried < max_tries:\n",
    "        cfg = fn_make_cfg()\n",
    "        h = cfg_hash(cfg)\n",
    "        if h not in blacklist:\n",
    "            return cfg, h\n",
    "        tried += 1\n",
    "    # 계속 충돌하면 완전 랜덤으로\n",
    "    cfg = sample_config_with_constraint()\n",
    "    h = cfg_hash(cfg)\n",
    "    return cfg, h\n",
    "\n",
    "def evaluate_cfg(cfg, h, gen_idx):\n",
    "    run_dir = os.path.join(NAS_LOG_DIR, f\"g{gen_idx:02d}_{h[:8]}\")\n",
    "    if h in evaluated:\n",
    "        return evaluated[h]\n",
    "    out = run_cfg_in_subprocess(cfg, run_dir, train_base, val_base, label_map)\n",
    "    if out is None:\n",
    "        return None\n",
    "    fit = compute_fitness(out[\"val_acc\"], out[\"params\"], out[\"train_sec\"])\n",
    "    rec = {\n",
    "        \"hash\": h,\n",
    "        \"gen\": gen_idx,\n",
    "        \"val_acc\": out[\"val_acc\"],\n",
    "        \"val_loss\": out[\"val_loss\"],\n",
    "        \"params\": out[\"params\"],\n",
    "        \"train_sec\": out[\"train_sec\"],\n",
    "        \"fitness\": fit,\n",
    "        \"run_dir\": run_dir,\n",
    "        \"cfg_json\": json.dumps(cfg, sort_keys=True)\n",
    "    }\n",
    "    evaluated[h] = rec\n",
    "    append_log(rec)\n",
    "    return rec\n",
    "\n",
    "\n",
    "# ===== Generation 0 =====\n",
    "population = []\n",
    "seen = set()\n",
    "print(\"\\n========= Generation 0 START (pop=12, init random) =========\")\n",
    "while len(population) < POP_SIZE:\n",
    "    cfg = sample_config_with_constraint()\n",
    "    h = cfg_hash(cfg)\n",
    "    if h not in seen and h not in evaluated:\n",
    "        population.append((cfg, h))\n",
    "        seen.add(h)\n",
    "\n",
    "records = []\n",
    "for cfg, h in population:\n",
    "    rec = evaluate_cfg(cfg, h, 0)\n",
    "    if rec: records.append(rec)\n",
    "\n",
    "records.sort(key=lambda x: (x[\"fitness\"], x[\"val_acc\"], -x[\"val_loss\"]), reverse=True)\n",
    "print_leaderboard(records, gen_idx=0)\n",
    "\n",
    "prune_non_elites(0, records, ELITE_K)\n",
    "\n",
    "best = records[0]\n",
    "history_best.append(best)\n",
    "\n",
    "# ===== Generations 1..N_GEN-1 =====\n",
    "for gen in range(1, N_GEN):\n",
    "    print(f\"\\n========= Generation {gen} START (pop={POP_SIZE}) =========\")\n",
    "    elites = records[:ELITE_K]\n",
    "\n",
    "    # children 6\n",
    "    children = []\n",
    "    blacklist = set(evaluated.keys())\n",
    "    attempts = 0\n",
    "    while len(children) < CHILDREN_K and attempts < 1000:\n",
    "        attempts += 1\n",
    "        pa, pb = random.sample(elites, 2)\n",
    "        ca = json.loads(pa[\"cfg_json\"])\n",
    "        cb = json.loads(pb[\"cfg_json\"])\n",
    "        child = mutate(crossover(ca, cb), prob=MUT_PROB)\n",
    "        ch = cfg_hash(child)\n",
    "        if ch not in blacklist and ch not in {h for _, h in children} and ch not in {e[\"hash\"] for e in elites}:\n",
    "            children.append((child, ch))\n",
    "        else:\n",
    "            # 충돌이 계속되면 랜덤 이주자 대체\n",
    "            rcfg, rh = ensure_unique_from(sample_config_with_constraint,\n",
    "                                          blacklist | {h for _, h in children} | {e[\"hash\"] for e in elites})\n",
    "            children.append((rcfg, rh))\n",
    "\n",
    "    # immigrants 2\n",
    "    immigrants = []\n",
    "    while len(immigrants) < IMMIGRANTS_K:\n",
    "        cfg, h = ensure_unique_from(sample_config_with_constraint,\n",
    "                                    set(evaluated.keys()) | {x[1] for x in children} | {e[\"hash\"] for e in elites})\n",
    "        immigrants.append((cfg, h))\n",
    "\n",
    "    # next population (elites carry-over + children + immigrants)\n",
    "    next_population = []\n",
    "    for e in elites:\n",
    "        cfg_e = json.loads(e[\"cfg_json\"])\n",
    "        next_population.append((cfg_e, e[\"hash\"]))\n",
    "    next_population.extend(children)\n",
    "    next_population.extend(immigrants)\n",
    "\n",
    "    # evaluate (skip elites)\n",
    "    records = []\n",
    "    elite_hashes = {e[\"hash\"] for e in elites}\n",
    "    for cfg, h in next_population:\n",
    "        if h in elite_hashes:\n",
    "            records.append(evaluated[h])  # carry-over\n",
    "        else:\n",
    "            rec = evaluate_cfg(cfg, h, gen)\n",
    "            if rec: records.append(rec)\n",
    "\n",
    "    records.sort(key=lambda x: (x[\"fitness\"], x[\"val_acc\"], -x[\"val_loss\"]), reverse=True)\n",
    "    print_leaderboard(records, gen_idx=gen)\n",
    "\n",
    "    prune_non_elites(gen, records, ELITE_K)\n",
    "\n",
    "\n",
    "    best = records[0]\n",
    "    history_best.append(best)\n",
    "\n",
    "# ===== Final best =====\n",
    "global_best = max(evaluated.values(), key=lambda x: (x[\"fitness\"], x[\"val_acc\"], -x[\"val_loss\"]))\n",
    "print(\"\\n[Final Best]\")\n",
    "print(f\"hash={global_best['hash']}, gen={global_best['gen']}\")\n",
    "print(f\"fitness={global_best['fitness']:.6f}, acc={global_best['val_acc']:.4f}, loss={global_best['val_loss']:.4f}, params={global_best['params']:,}, sec={global_best['train_sec']:.1f}\")\n",
    "print(f\"run_dir={global_best['run_dir']}\")\n",
    "print(\"\\nBest Config JSON\")\n",
    "print(json.dumps(json.loads(global_best[\"cfg_json\"]), indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25bf6e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Final Top-4 Models from results.csv]\n",
      "                                    hash  gen  val_acc  val_loss  params  train_sec  fitness                                   run_dir                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     cfg_json\n",
      "2026944feaa2e0fb1517eb1425e56c455604e2c3   13 0.990741  0.033059 1128927 110.193583 0.978592 experiments/Step_00/nas_runs/g13_2026944f {\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 24, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "58d5702f00ca59a62e667e42913c741618cca310   15 0.990741  0.036645 1024991 113.195752 0.978396 experiments/Step_00/nas_runs/g15_58d5702f   {\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 48, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "32e20554c0f1c5417741490a107412b5cf0054f1    8 0.990741  0.054681 1566663 132.626005 0.975911 experiments/Step_00/nas_runs/g08_32e20554 {\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}}\n",
      "076341a58a6e19a9540f107f05b63be0a270e5e3   13 0.990741  0.036963 1910695 136.492071 0.975181 experiments/Step_00/nas_runs/g13_076341a5 {\"dtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 128, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 64, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 104, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "b1be27becd277cee39c9cc7ab3e94a57df03d656    8 0.988889  0.041636  654223 160.818027 0.972153 experiments/Step_00/nas_runs/g08_b1be27be     {\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}}\n",
      "e27017f954696124fb063eb7ce8d3d772a3677ab    8 0.983333  0.080747 1751631 106.679139 0.970914 experiments/Step_00/nas_runs/g08_e27017f9   {\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 2, \"use_se\": false}}}\n",
      "e120559e1b5c397a5dd3f892c6c2dc212387c503   14 0.985185  0.084023 1582519 138.488153 0.969754 experiments/Step_00/nas_runs/g14_e120559e   {\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 40, \"repeats\": 4, \"stride\": 2, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 72, \"repeats\": 6, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 88, \"repeats\": 2, \"stride\": 1, \"use_se\": false}}}\n",
      "9ee6a5b23220a545611b94680e8a0e17fa01bee3   18 0.983333  0.061449  861111 129.682789 0.969504 experiments/Step_00/nas_runs/g18_9ee6a5b2   {\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 16, \"repeats\": 2, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 64, \"repeats\": 4, \"stride\": 1, \"use_se\": true}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 4, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}}\n",
      "a4edcdb8f6586077184b5469a1881080b7772238    3 0.987037  0.045545 2253639 153.330601 0.969450 experiments/Step_00/nas_runs/g03_a4edcdb8   {\"dtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 120, \"stage1\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 32, \"repeats\": 6, \"stride\": 2, \"use_se\": true}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 2, \"out_channels\": 56, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage3\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 72, \"repeats\": 4, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 96, \"repeats\": 2, \"stride\": 1, \"use_se\": true}}}\n",
      "a5a01c206dcf41440d0e8b85a858ff10c66f4229   18 0.983333  0.065233 2624879 117.676423 0.968941 experiments/Step_00/nas_runs/g18_a5a01c20   {\"dtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": true}}, \"rtm\": {\"conv1x1_out\": 112, \"stage1\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 32, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage2\": {\"block_type\": \"fused\", \"expand_ratio\": 4, \"out_channels\": 40, \"repeats\": 2, \"stride\": 1, \"use_se\": true}, \"stage3\": {\"block_type\": \"mbconv\", \"expand_ratio\": 2, \"out_channels\": 80, \"repeats\": 2, \"stride\": 2, \"use_se\": false}, \"stage4\": {\"block_type\": \"mbconv\", \"expand_ratio\": 6, \"out_channels\": 96, \"repeats\": 4, \"stride\": 2, \"use_se\": true}}}\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 5. 최종 Top-4 결과\n",
    "# =========================\n",
    "df = pd.read_csv(NAS_LOG_CSV)\n",
    "\n",
    "# fitness 기준 내림차순 정렬\n",
    "df_sorted = df.sort_values(by=[\"fitness\", \"val_acc\", \"val_loss\"], ascending=[False, False, True])\n",
    "\n",
    "# 상위 4개만 출력\n",
    "top4 = df_sorted.head(10)\n",
    "\n",
    "print(\"\\n[Final Top-4 Models from results.csv]\")\n",
    "print(top4.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3c058c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF213_Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
